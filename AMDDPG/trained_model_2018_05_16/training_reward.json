{"Training time": 0.0008910836113823785, "Episode Reward": -0.3316130421296252, "Mean Reward": -0.3316130421296252, "Episode": 0, "Episode Step": 1}
{"Training time": 0.002104083299636841, "Episode Reward": 115.67754237228564, "Mean Reward": 3.2132650658968234, "Episode": 1, "Episode Step": 36}
{"Training time": 0.0030056738853454588, "Episode Reward": -155.7064058477381, "Mean Reward": -9.159200343984594, "Episode": 2, "Episode Step": 17}
{"Training time": 0.004160691897074381, "Episode Reward": 1885.9421438012264, "Mean Reward": 31.96512108137672, "Episode": 3, "Episode Step": 59}
{"Training time": 0.00484879301653968, "Episode Reward": 1324.2586060144, "Mean Reward": 22.445061118888134, "Episode": 4, "Episode Step": 59}
{"Training time": 0.005598471098475986, "Episode Reward": 1456.2772105359861, "Mean Reward": 23.115511278348986, "Episode": 5, "Episode Step": 63}
{"Training time": 0.0068582980500327215, "Episode Reward": 1771.6333743730902, "Mean Reward": 26.053431976074855, "Episode": 6, "Episode Step": 68}
{"Training time": 0.007417566908730401, "Episode Reward": 244.83863907890066, "Mean Reward": 5.322579110410884, "Episode": 7, "Episode Step": 46}
{"Training time": 0.008256424996587965, "Episode Reward": 2332.497175963466, "Mean Reward": 34.30142905828626, "Episode": 8, "Episode Step": 68}
{"Training time": 0.009524368577533297, "Episode Reward": 2027.4820015342498, "Mean Reward": 28.964028593346427, "Episode": 9, "Episode Step": 70}
{"Training time": 0.010371310777134365, "Episode Reward": 1703.5851948008021, "Mean Reward": 24.336931354297175, "Episode": 10, "Episode Step": 70}
{"Training time": 0.011217367185486687, "Episode Reward": 1872.2149844511018, "Mean Reward": 26.745928349301455, "Episode": 11, "Episode Step": 70}
{"Training time": 0.012220058838526409, "Episode Reward": 820.8802314836901, "Mean Reward": 17.84522242355848, "Episode": 12, "Episode Step": 46}
{"Training time": 0.013061155809296503, "Episode Reward": 1668.5864052100928, "Mean Reward": 23.50121697479004, "Episode": 13, "Episode Step": 71}
{"Training time": 0.013519904149903192, "Episode Reward": 294.16487934714377, "Mean Reward": 7.741181035451151, "Episode": 14, "Episode Step": 38}
{"Training time": 0.014779542220963372, "Episode Reward": 1612.4510632958138, "Mean Reward": 23.712515636703145, "Episode": 15, "Episode Step": 68}
{"Training time": 0.015601962738566929, "Episode Reward": 1777.0143722844498, "Mean Reward": 25.75383148238333, "Episode": 16, "Episode Step": 69}
{"Training time": 0.01640532049867842, "Episode Reward": 1837.993037754618, "Mean Reward": 27.432731906785342, "Episode": 17, "Episode Step": 67}
{"Training time": 0.017619279689259, "Episode Reward": 1389.1393494544704, "Mean Reward": 21.7053023352261, "Episode": 18, "Episode Step": 64}
{"Training time": 0.018307579159736635, "Episode Reward": 1272.1630154071504, "Mean Reward": 21.93384509322673, "Episode": 19, "Episode Step": 58}
{"Training time": 0.019140404131677415, "Episode Reward": 1528.6245103821684, "Mean Reward": 21.83749300545955, "Episode": 20, "Episode Step": 70}
{"Training time": 0.02026216083102756, "Episode Reward": 1099.3608967883415, "Mean Reward": 19.28703327698845, "Episode": 21, "Episode Step": 57}
{"Training time": 0.021110615531603497, "Episode Reward": 2341.438407520818, "Mean Reward": 32.97800573972983, "Episode": 22, "Episode Step": 71}
{"Training time": 0.0219707766506407, "Episode Reward": 2051.779287451585, "Mean Reward": 28.49693454793868, "Episode": 23, "Episode Step": 72}
{"Training time": 0.02325067440668742, "Episode Reward": 1961.0125087549286, "Mean Reward": 28.420471141375778, "Episode": 24, "Episode Step": 69}
{"Training time": 0.024043830235799153, "Episode Reward": 1812.9970733298821, "Mean Reward": 27.059657810893764, "Episode": 25, "Episode Step": 67}
{"Training time": 0.024853301379415722, "Episode Reward": 1856.8290341451539, "Mean Reward": 28.133773244623544, "Episode": 26, "Episode Step": 66}
{"Training time": 0.026181454128689236, "Episode Reward": 2025.7506528807817, "Mean Reward": 27.375008822713266, "Episode": 27, "Episode Step": 74}
{"Training time": 0.027035246623886955, "Episode Reward": 1721.9389479573383, "Mean Reward": 24.25266123883575, "Episode": 28, "Episode Step": 71}
{"Training time": 0.027834928035736083, "Episode Reward": 1806.854939337091, "Mean Reward": 26.57139616672193, "Episode": 29, "Episode Step": 68}
{"Training time": 0.029091048306889005, "Episode Reward": 1832.0156384193085, "Mean Reward": 26.94140644734277, "Episode": 30, "Episode Step": 68}
{"Training time": 0.029954338868459066, "Episode Reward": 1663.9498896904117, "Mean Reward": 23.11041513458905, "Episode": 31, "Episode Step": 72}
{"Training time": 0.03078482276863522, "Episode Reward": 1522.2400599955233, "Mean Reward": 22.061450144862658, "Episode": 32, "Episode Step": 69}
{"Training time": 0.03202583776579963, "Episode Reward": 1667.9923983553674, "Mean Reward": 24.895408930677124, "Episode": 33, "Episode Step": 67}
{"Training time": 0.03286071995894114, "Episode Reward": 1508.1454288163688, "Mean Reward": 21.544934697376696, "Episode": 34, "Episode Step": 70}
{"Training time": 0.03372411277559068, "Episode Reward": 2407.336571227834, "Mean Reward": 33.43523015594214, "Episode": 35, "Episode Step": 72}
{"Training time": 0.035072075525919594, "Episode Reward": 2018.5771032177008, "Mean Reward": 27.278068962401363, "Episode": 36, "Episode Step": 74}
{"Training time": 0.03593431777424282, "Episode Reward": 1748.4095487022496, "Mean Reward": 23.950815735647254, "Episode": 37, "Episode Step": 73}
{"Training time": 0.037137920525338916, "Episode Reward": 3535.9011042982374, "Mean Reward": 34.665697100963115, "Episode": 38, "Episode Step": 102}
{"Training time": 0.03845799439483219, "Episode Reward": 1690.7837818884811, "Mean Reward": 23.16142166970522, "Episode": 39, "Episode Step": 73}
{"Training time": 0.03933548079596626, "Episode Reward": 1599.362130680713, "Mean Reward": 21.90907028329744, "Episode": 40, "Episode Step": 73}
{"Training time": 0.040147170821825666, "Episode Reward": 1672.4467941970654, "Mean Reward": 24.594805797015667, "Episode": 41, "Episode Step": 68}
{"Training time": 0.04145148747497135, "Episode Reward": 1954.6126542322572, "Mean Reward": 27.147397975448015, "Episode": 42, "Episode Step": 72}
{"Training time": 0.04234623856014676, "Episode Reward": 1363.5155074023974, "Mean Reward": 18.42588523516753, "Episode": 43, "Episode Step": 74}
{"Training time": 0.043196451928880476, "Episode Reward": 1788.5793308911998, "Mean Reward": 24.841379595711107, "Episode": 44, "Episode Step": 72}
{"Training time": 0.044502921369340684, "Episode Reward": 1701.1930963194945, "Mean Reward": 23.62768189332631, "Episode": 45, "Episode Step": 72}
{"Training time": 0.04537462996111976, "Episode Reward": 1951.0373902226356, "Mean Reward": 26.726539592090898, "Episode": 46, "Episode Step": 73}
{"Training time": 0.04615565750333998, "Episode Reward": 1859.1785125591878, "Mean Reward": 28.169371402411937, "Episode": 47, "Episode Step": 66}
{"Training time": 0.04744012885623508, "Episode Reward": 1673.5527165078443, "Mean Reward": 23.571165021237242, "Episode": 48, "Episode Step": 71}
{"Training time": 0.04888821442921956, "Episode Reward": 1726.7670877778721, "Mean Reward": 23.65434366819003, "Episode": 49, "Episode Step": 73}
{"Training time": 0.05003344191445245, "Episode Reward": 1410.5335814663586, "Mean Reward": 19.590744187032758, "Episode": 50, "Episode Step": 72}
{"Training time": 0.05134309166007572, "Episode Reward": 1611.4052982982432, "Mean Reward": 21.775747274300585, "Episode": 51, "Episode Step": 74}
{"Training time": 0.05220240831375122, "Episode Reward": 1623.8094158033966, "Mean Reward": 22.552908552824952, "Episode": 52, "Episode Step": 72}
{"Training time": 0.05308271692858802, "Episode Reward": 2121.7853903324217, "Mean Reward": 29.065553292224955, "Episode": 53, "Episode Step": 73}
{"Training time": 0.05433992359373305, "Episode Reward": 1650.0236165134768, "Mean Reward": 23.91338574657213, "Episode": 54, "Episode Step": 69}
{"Training time": 0.05517257942093743, "Episode Reward": 1178.7273315344914, "Mean Reward": 16.601793401894245, "Episode": 55, "Episode Step": 71}
{"Training time": 0.056019639174143473, "Episode Reward": 1684.6653246546805, "Mean Reward": 23.72768062893916, "Episode": 56, "Episode Step": 71}
{"Training time": 0.05719512442747752, "Episode Reward": 1357.8482664364392, "Mean Reward": 21.90077849091031, "Episode": 57, "Episode Step": 62}
{"Training time": 0.058044614129596286, "Episode Reward": 1062.4297750435906, "Mean Reward": 14.755969097827647, "Episode": 58, "Episode Step": 72}
{"Training time": 0.05887222773498959, "Episode Reward": 1647.343340730282, "Mean Reward": 23.87454117000409, "Episode": 59, "Episode Step": 69}
{"Training time": 0.060151930252710976, "Episode Reward": 1442.3959484941633, "Mean Reward": 20.904289108611064, "Episode": 60, "Episode Step": 69}
{"Training time": 0.06100093166033427, "Episode Reward": 804.1275858674576, "Mean Reward": 11.487536940963679, "Episode": 61, "Episode Step": 70}
{"Training time": 0.061846291091707015, "Episode Reward": 1733.4108162499406, "Mean Reward": 24.41423684859071, "Episode": 62, "Episode Step": 71}
{"Training time": 0.06314948499202729, "Episode Reward": 1602.568924878325, "Mean Reward": 22.257901734421182, "Episode": 63, "Episode Step": 72}
{"Training time": 0.06396938025951386, "Episode Reward": 894.7758983193123, "Mean Reward": 12.782512833133033, "Episode": 64, "Episode Step": 70}
{"Training time": 0.06482284552521175, "Episode Reward": 1793.5883216073214, "Mean Reward": 25.261807346581993, "Episode": 65, "Episode Step": 71}
{"Training time": 0.06590284718407526, "Episode Reward": 910.3302720383856, "Mean Reward": 17.506351385353568, "Episode": 66, "Episode Step": 52}
{"Training time": 0.06674332499504089, "Episode Reward": 1144.3930601284978, "Mean Reward": 16.118212114485885, "Episode": 67, "Episode Step": 71}
{"Training time": 0.06753808551364475, "Episode Reward": 1216.8369702528455, "Mean Reward": 18.161745824669335, "Episode": 68, "Episode Step": 67}
{"Training time": 0.06885422858926984, "Episode Reward": 1436.4222653821328, "Mean Reward": 19.95030924141851, "Episode": 69, "Episode Step": 72}
{"Training time": 0.06970158523983426, "Episode Reward": 1240.9529326051681, "Mean Reward": 17.47821031838265, "Episode": 70, "Episode Step": 71}
{"Training time": 0.07055385635958777, "Episode Reward": 1408.057885804738, "Mean Reward": 19.831801208517437, "Episode": 71, "Episode Step": 71}
{"Training time": 0.07185776438977984, "Episode Reward": 1057.0424595556835, "Mean Reward": 15.100606565081193, "Episode": 72, "Episode Step": 70}
{"Training time": 0.07271172410911984, "Episode Reward": 1028.1597910969447, "Mean Reward": 14.687997015670637, "Episode": 73, "Episode Step": 70}
{"Training time": 0.07355527692370945, "Episode Reward": 1648.648284229381, "Mean Reward": 23.552118346134016, "Episode": 74, "Episode Step": 70}
{"Training time": 0.07486336496141222, "Episode Reward": 1421.2790240422516, "Mean Reward": 20.018014423130303, "Episode": 75, "Episode Step": 71}
{"Training time": 0.07556955383883582, "Episode Reward": 715.2545155838843, "Mean Reward": 12.122957891252277, "Episode": 76, "Episode Step": 59}
{"Training time": 0.07640344189272986, "Episode Reward": 1240.8401956052128, "Mean Reward": 17.726288508645897, "Episode": 77, "Episode Step": 70}
{"Training time": 0.07771874162885878, "Episode Reward": 1526.53308125667, "Mean Reward": 21.500465933192533, "Episode": 78, "Episode Step": 71}
{"Training time": 0.07842440578672621, "Episode Reward": 740.4168939322369, "Mean Reward": 12.549438880207406, "Episode": 79, "Episode Step": 59}
{"Training time": 0.079223486383756, "Episode Reward": 1214.8911229860632, "Mean Reward": 17.866045926265635, "Episode": 80, "Episode Step": 68}
{"Training time": 0.08036325494448344, "Episode Reward": 996.5796014927771, "Mean Reward": 17.18240692228926, "Episode": 81, "Episode Step": 58}
{"Training time": 0.08117444694042206, "Episode Reward": 835.608312160477, "Mean Reward": 12.288357531771721, "Episode": 82, "Episode Step": 68}
{"Training time": 0.08203862832652198, "Episode Reward": 1334.8482872327224, "Mean Reward": 18.285592975790717, "Episode": 83, "Episode Step": 73}
{"Training time": 0.08333842582172818, "Episode Reward": 1541.9748150211315, "Mean Reward": 21.416316875293493, "Episode": 84, "Episode Step": 72}
{"Training time": 0.08420761916372511, "Episode Reward": 1505.4784240644433, "Mean Reward": 20.622992110471827, "Episode": 85, "Episode Step": 73}
{"Training time": 0.08501979026529524, "Episode Reward": 1382.140140968991, "Mean Reward": 20.03101653578248, "Episode": 86, "Episode Step": 69}
{"Training time": 0.08632035500473446, "Episode Reward": 1119.5755705011552, "Mean Reward": 15.768670007058525, "Episode": 87, "Episode Step": 71}
{"Training time": 0.08687962942653232, "Episode Reward": 383.72686113973145, "Mean Reward": 8.16440130084535, "Episode": 88, "Episode Step": 47}
{"Training time": 0.0877574888865153, "Episode Reward": 962.4532618123487, "Mean Reward": 12.832710157497983, "Episode": 89, "Episode Step": 75}
{"Training time": 0.08904661105738745, "Episode Reward": 2092.6706945814426, "Mean Reward": 29.064870758075593, "Episode": 90, "Episode Step": 72}
{"Training time": 0.08978848689132267, "Episode Reward": 599.9879938109558, "Mean Reward": 9.677225706628318, "Episode": 91, "Episode Step": 62}
{"Training time": 0.0906448319223192, "Episode Reward": 1225.4261385991224, "Mean Reward": 17.019807480543367, "Episode": 92, "Episode Step": 72}
{"Training time": 0.09193648583359189, "Episode Reward": 1730.091945250056, "Mean Reward": 24.367492186620506, "Episode": 93, "Episode Step": 71}
{"Training time": 0.09273861805597941, "Episode Reward": 904.6556252969808, "Mean Reward": 13.303759195543835, "Episode": 94, "Episode Step": 68}
{"Training time": 0.09319093220763737, "Episode Reward": 247.64030114296207, "Mean Reward": 6.692981111971948, "Episode": 95, "Episode Step": 37}
{"Training time": 0.0945419399605857, "Episode Reward": 1161.0717028908987, "Mean Reward": 15.690158147174307, "Episode": 96, "Episode Step": 74}
{"Training time": 0.09533993886576758, "Episode Reward": 1465.3497835764858, "Mean Reward": 21.236953385166462, "Episode": 97, "Episode Step": 69}
{"Training time": 0.0962019955449634, "Episode Reward": 1467.3232274834331, "Mean Reward": 20.379489270603237, "Episode": 98, "Episode Step": 72}
{"Training time": 0.09812087800767687, "Episode Reward": 1639.9829704244655, "Mean Reward": 22.777541255895354, "Episode": 99, "Episode Step": 72}
{"Training time": 0.09923574414518144, "Episode Reward": 1553.262843147764, "Mean Reward": 22.1894691878252, "Episode": 100, "Episode Step": 70}
{"Training time": 0.09983180496427747, "Episode Reward": 712.9297386814873, "Mean Reward": 14.549586503703821, "Episode": 101, "Episode Step": 49}
{"Training time": 0.10086898883183797, "Episode Reward": 734.6872952911673, "Mean Reward": 15.305985318565986, "Episode": 102, "Episode Step": 48}
{"Training time": 0.10173814276854197, "Episode Reward": 1325.2260548163792, "Mean Reward": 17.90846020022134, "Episode": 103, "Episode Step": 74}
{"Training time": 0.10260873052808973, "Episode Reward": 1302.8189276973762, "Mean Reward": 17.846834625991455, "Episode": 104, "Episode Step": 73}
{"Training time": 0.10429043412208557, "Episode Reward": 2707.777381201073, "Mean Reward": 26.28910078835993, "Episode": 105, "Episode Step": 103}
{"Training time": 0.10514131943384807, "Episode Reward": 1667.631100288139, "Mean Reward": 23.48776197588928, "Episode": 106, "Episode Step": 71}
{"Training time": 0.10582904915014903, "Episode Reward": 893.5043766162837, "Mean Reward": 15.955435296719353, "Episode": 107, "Episode Step": 56}
{"Training time": 0.10713862856229146, "Episode Reward": 1563.1975170620137, "Mean Reward": 21.711076625861303, "Episode": 108, "Episode Step": 72}
{"Training time": 0.10801405939790938, "Episode Reward": 1548.086288693633, "Mean Reward": 21.206661488953877, "Episode": 109, "Episode Step": 73}
{"Training time": 0.10888099193572998, "Episode Reward": 1692.9597324404176, "Mean Reward": 23.513329617228024, "Episode": 110, "Episode Step": 72}
{"Training time": 0.11020068804423014, "Episode Reward": 2122.5326680555913, "Mean Reward": 29.47962038966099, "Episode": 111, "Episode Step": 72}
{"Training time": 0.1110684788889355, "Episode Reward": 1693.9011847789704, "Mean Reward": 23.85776316590099, "Episode": 112, "Episode Step": 71}
{"Training time": 0.11192486498090956, "Episode Reward": 1709.0783341946908, "Mean Reward": 24.07152583372804, "Episode": 113, "Episode Step": 71}
{"Training time": 0.11312051024701861, "Episode Reward": 1503.0827093348282, "Mean Reward": 25.051378488913805, "Episode": 114, "Episode Step": 60}
{"Training time": 0.1143658713499705, "Episode Reward": 3008.4742265388436, "Mean Reward": 28.927636793642726, "Episode": 115, "Episode Step": 104}
{"Training time": 0.11520946164925894, "Episode Reward": 1892.759992192925, "Mean Reward": 26.65859143933697, "Episode": 116, "Episode Step": 71}
{"Training time": 0.11650998552640279, "Episode Reward": 1883.4060721135802, "Mean Reward": 26.52684608610676, "Episode": 117, "Episode Step": 71}
{"Training time": 0.11734837525420719, "Episode Reward": 2007.9181927143422, "Mean Reward": 28.280537925554118, "Episode": 118, "Episode Step": 71}
{"Training time": 0.11824083189169565, "Episode Reward": 1409.2551446883451, "Mean Reward": 19.043988441734392, "Episode": 119, "Episode Step": 74}
{"Training time": 0.11941723750697242, "Episode Reward": 1582.8334833181113, "Mean Reward": 25.948089890460842, "Episode": 120, "Episode Step": 61}
{"Training time": 0.12031198355886671, "Episode Reward": 2086.7480105265845, "Mean Reward": 28.585589185295678, "Episode": 121, "Episode Step": 73}
{"Training time": 0.12119715611139933, "Episode Reward": 2086.572984688529, "Mean Reward": 28.19693222552066, "Episode": 122, "Episode Step": 74}
{"Training time": 0.12254497024748061, "Episode Reward": 2041.3295072209403, "Mean Reward": 27.21772676294587, "Episode": 123, "Episode Step": 75}
{"Training time": 0.12340935554769304, "Episode Reward": 1959.6888914940632, "Mean Reward": 26.845053308137853, "Episode": 124, "Episode Step": 73}
{"Training time": 0.12428553720315297, "Episode Reward": 2053.0578380182387, "Mean Reward": 28.124079972852584, "Episode": 125, "Episode Step": 73}
{"Training time": 0.12560376637511783, "Episode Reward": 2116.3231321226367, "Mean Reward": 29.39337683503662, "Episode": 126, "Episode Step": 72}
{"Training time": 0.1264533738957511, "Episode Reward": 2153.6461015683635, "Mean Reward": 29.911751410671716, "Episode": 127, "Episode Step": 72}
{"Training time": 0.12733531971772513, "Episode Reward": 2045.450632816871, "Mean Reward": 27.272675104224945, "Episode": 128, "Episode Step": 75}
{"Training time": 0.128679239153862, "Episode Reward": 2605.710790289795, "Mean Reward": 34.742810537197265, "Episode": 129, "Episode Step": 75}
{"Training time": 0.1294569166501363, "Episode Reward": 1616.2372452759168, "Mean Reward": 24.865188388860258, "Episode": 130, "Episode Step": 65}
{"Training time": 0.13038430690765382, "Episode Reward": 2025.1212781370414, "Mean Reward": 25.96309330944925, "Episode": 131, "Episode Step": 78}
{"Training time": 0.13173784414927164, "Episode Reward": 2447.19428466903, "Mean Reward": 31.781743956740648, "Episode": 132, "Episode Step": 77}
{"Training time": 0.13299842304653592, "Episode Reward": 3046.9959041564375, "Mean Reward": 28.476597235106894, "Episode": 133, "Episode Step": 107}
{"Training time": 0.13389636860953438, "Episode Reward": 2417.6270108415542, "Mean Reward": 32.23502681122072, "Episode": 134, "Episode Step": 75}
{"Training time": 0.1352730205323961, "Episode Reward": 2182.401060115482, "Mean Reward": 28.342870910590673, "Episode": 135, "Episode Step": 77}
{"Training time": 0.13616726054085626, "Episode Reward": 2441.6160303952383, "Mean Reward": 32.55488040526984, "Episode": 136, "Episode Step": 75}
{"Training time": 0.13708533300293815, "Episode Reward": 2162.1347236910683, "Mean Reward": 28.07967173624764, "Episode": 137, "Episode Step": 77}
{"Training time": 0.13844453970591228, "Episode Reward": 2231.8407326891024, "Mean Reward": 29.36632543011977, "Episode": 138, "Episode Step": 76}
{"Training time": 0.13968358609411452, "Episode Reward": 3098.6511027077067, "Mean Reward": 29.79472214142026, "Episode": 139, "Episode Step": 104}
{"Training time": 0.14058751775158776, "Episode Reward": 2659.132612428193, "Mean Reward": 34.98858700563412, "Episode": 140, "Episode Step": 76}
{"Training time": 0.14194039636188083, "Episode Reward": 2171.1316573725467, "Mean Reward": 28.56752180753351, "Episode": 141, "Episode Step": 76}
{"Training time": 0.1428620591428545, "Episode Reward": 2463.1909865424036, "Mean Reward": 31.989493331719526, "Episode": 142, "Episode Step": 77}
{"Training time": 0.14373405330710942, "Episode Reward": 2052.3386097644343, "Mean Reward": 28.114227531019647, "Episode": 143, "Episode Step": 73}
{"Training time": 0.1450955499543084, "Episode Reward": 2045.6618301684925, "Mean Reward": 26.56703675543497, "Episode": 144, "Episode Step": 77}
{"Training time": 0.14595720913675098, "Episode Reward": 2677.8141476344185, "Mean Reward": 37.19186316158915, "Episode": 145, "Episode Step": 72}
{"Training time": 0.1468175055583318, "Episode Reward": 2168.2170319226902, "Mean Reward": 29.701603177023156, "Episode": 146, "Episode Step": 73}
{"Training time": 0.14821685387028588, "Episode Reward": 2230.4950528323957, "Mean Reward": 28.234114592815136, "Episode": 147, "Episode Step": 79}
{"Training time": 0.14914412246810066, "Episode Reward": 2540.2317144383023, "Mean Reward": 32.56707326202952, "Episode": 148, "Episode Step": 78}
{"Training time": 0.15209185163180033, "Episode Reward": 2291.7438757604878, "Mean Reward": 32.27808275718997, "Episode": 149, "Episode Step": 71}
{"Training time": 0.1534466371933619, "Episode Reward": 2355.8404393014953, "Mean Reward": 30.203082555147375, "Episode": 150, "Episode Step": 78}
{"Training time": 0.1543419657813178, "Episode Reward": 2428.949640126581, "Mean Reward": 32.38599520168775, "Episode": 151, "Episode Step": 75}
{"Training time": 0.15523587498399946, "Episode Reward": 2524.638276666224, "Mean Reward": 33.218924692976636, "Episode": 152, "Episode Step": 76}
{"Training time": 0.15658973495165507, "Episode Reward": 2385.2562249357647, "Mean Reward": 30.977353570594346, "Episode": 153, "Episode Step": 77}
{"Training time": 0.1574802758296331, "Episode Reward": 2439.122835604428, "Mean Reward": 32.09372152111089, "Episode": 154, "Episode Step": 76}
{"Training time": 0.15838232861624824, "Episode Reward": 2487.4430193173016, "Mean Reward": 33.16590692423069, "Episode": 155, "Episode Step": 75}
{"Training time": 0.16013638695081076, "Episode Reward": 4100.873717800464, "Mean Reward": 37.97105294259689, "Episode": 156, "Episode Step": 108}
{"Training time": 0.16102927883466084, "Episode Reward": 2128.885200447009, "Mean Reward": 28.768718924959582, "Episode": 157, "Episode Step": 74}
{"Training time": 0.16190121995078194, "Episode Reward": 2560.636792984773, "Mean Reward": 34.60319990519963, "Episode": 158, "Episode Step": 74}
{"Training time": 0.16326888276471033, "Episode Reward": 2394.8282918440473, "Mean Reward": 31.510898576895357, "Episode": 159, "Episode Step": 76}
{"Training time": 0.1641958569155799, "Episode Reward": 2508.228999827039, "Mean Reward": 32.1567820490646, "Episode": 160, "Episode Step": 78}
{"Training time": 0.16505048162407346, "Episode Reward": 2645.7299526443135, "Mean Reward": 37.79614218063305, "Episode": 161, "Episode Step": 70}
{"Training time": 0.16642314189010196, "Episode Reward": 2330.1227969866354, "Mean Reward": 30.26133502580046, "Episode": 162, "Episode Step": 77}
{"Training time": 0.1673236713806788, "Episode Reward": 2332.97222607612, "Mean Reward": 31.958523644878355, "Episode": 163, "Episode Step": 73}
{"Training time": 0.16819218940205044, "Episode Reward": 2441.896723904243, "Mean Reward": 33.915232276447824, "Episode": 164, "Episode Step": 72}
{"Training time": 0.1698969774776035, "Episode Reward": 4383.905878198129, "Mean Reward": 41.357602624510655, "Episode": 165, "Episode Step": 106}
{"Training time": 0.17080005221896702, "Episode Reward": 2497.1867755829635, "Mean Reward": 33.745767237607616, "Episode": 166, "Episode Step": 74}
{"Training time": 0.17167783439159393, "Episode Reward": 2455.462543503094, "Mean Reward": 33.63647319867252, "Episode": 167, "Episode Step": 73}
{"Training time": 0.173039001888699, "Episode Reward": 2450.6171062951466, "Mean Reward": 32.24496192493614, "Episode": 168, "Episode Step": 76}
{"Training time": 0.17394823577668933, "Episode Reward": 2233.8025364194013, "Mean Reward": 29.78403381892535, "Episode": 169, "Episode Step": 75}
{"Training time": 0.17485261831018659, "Episode Reward": 1964.4610267264752, "Mean Reward": 26.192813689686336, "Episode": 170, "Episode Step": 75}
{"Training time": 0.1762542208035787, "Episode Reward": 2495.5828385389204, "Mean Reward": 31.994651776140007, "Episode": 171, "Episode Step": 78}
{"Training time": 0.17721076720290713, "Episode Reward": 2229.476628050262, "Mean Reward": 27.86845785062828, "Episode": 172, "Episode Step": 80}
{"Training time": 0.17800573858949872, "Episode Reward": 2249.7606077929086, "Mean Reward": 35.152509496764196, "Episode": 173, "Episode Step": 64}
{"Training time": 0.17939007136556837, "Episode Reward": 2592.97183367136, "Mean Reward": 33.674958878848834, "Episode": 174, "Episode Step": 77}
{"Training time": 0.18032442026668125, "Episode Reward": 1669.9051184399736, "Mean Reward": 21.409039979999662, "Episode": 175, "Episode Step": 78}
{"Training time": 0.18127515302764044, "Episode Reward": 2528.405236117305, "Mean Reward": 32.836431637887074, "Episode": 176, "Episode Step": 77}
{"Training time": 0.1826586569017834, "Episode Reward": 2770.045424895768, "Mean Reward": 35.51340288327908, "Episode": 177, "Episode Step": 78}
{"Training time": 0.1836163236035241, "Episode Reward": 2207.537077276757, "Mean Reward": 27.94350730730072, "Episode": 178, "Episode Step": 79}
{"Training time": 0.18452276441786025, "Episode Reward": 2574.4170624517405, "Mean Reward": 33.87390871647027, "Episode": 179, "Episode Step": 76}
{"Training time": 0.18589829915099673, "Episode Reward": 2747.2275797262414, "Mean Reward": 36.14773131218739, "Episode": 180, "Episode Step": 76}
{"Training time": 0.1868592616584566, "Episode Reward": 2085.6378977335753, "Mean Reward": 26.400479718146524, "Episode": 181, "Episode Step": 79}
{"Training time": 0.1877641827530331, "Episode Reward": 2531.5878167980068, "Mean Reward": 34.210646172946035, "Episode": 182, "Episode Step": 74}
{"Training time": 0.1891035611099667, "Episode Reward": 2568.718777337352, "Mean Reward": 34.24958369783136, "Episode": 183, "Episode Step": 75}
{"Training time": 0.19010965718163383, "Episode Reward": 2209.6479713824865, "Mean Reward": 26.622264715451646, "Episode": 184, "Episode Step": 83}
{"Training time": 0.19095491859647962, "Episode Reward": 2450.759438197404, "Mean Reward": 35.01084911710577, "Episode": 185, "Episode Step": 70}
{"Training time": 0.19235096746020847, "Episode Reward": 2471.3513754974015, "Mean Reward": 32.09547240905716, "Episode": 186, "Episode Step": 77}
{"Training time": 0.19331935942173004, "Episode Reward": 2498.4286117039514, "Mean Reward": 31.625678629163943, "Episode": 187, "Episode Step": 79}
{"Training time": 0.19421465052498713, "Episode Reward": 2670.1901163353086, "Mean Reward": 36.083650220747415, "Episode": 188, "Episode Step": 74}
{"Training time": 0.19554599304993947, "Episode Reward": 2389.795880654889, "Mean Reward": 32.736929871984785, "Episode": 189, "Episode Step": 73}
{"Training time": 0.19650531828403472, "Episode Reward": 2233.801367540888, "Mean Reward": 27.9225170942611, "Episode": 190, "Episode Step": 80}
{"Training time": 0.19739982022179497, "Episode Reward": 2598.7137317232523, "Mean Reward": 35.598818242784276, "Episode": 191, "Episode Step": 73}
{"Training time": 0.1987388457854589, "Episode Reward": 2440.086382745493, "Mean Reward": 33.425840859527305, "Episode": 192, "Episode Step": 73}
{"Training time": 0.19971281912591723, "Episode Reward": 2198.220570006254, "Mean Reward": 27.477757125078178, "Episode": 193, "Episode Step": 80}
{"Training time": 0.20061724106470744, "Episode Reward": 2222.6123507151337, "Mean Reward": 30.035302036690997, "Episode": 194, "Episode Step": 74}
{"Training time": 0.20196150912178887, "Episode Reward": 2393.3575129908018, "Mean Reward": 31.911433506544025, "Episode": 195, "Episode Step": 75}
{"Training time": 0.2033025019036399, "Episode Reward": 4067.5627731004643, "Mean Reward": 35.68037520263565, "Episode": 196, "Episode Step": 114}
{"Training time": 0.20424382216400572, "Episode Reward": 2699.7679228665684, "Mean Reward": 34.61240926752011, "Episode": 197, "Episode Step": 78}
{"Training time": 0.20557411889235178, "Episode Reward": 2587.758279570559, "Mean Reward": 35.448743555761084, "Episode": 198, "Episode Step": 73}
{"Training time": 0.20886079245143466, "Episode Reward": 2022.7324463439895, "Mean Reward": 24.972005510419624, "Episode": 199, "Episode Step": 81}
{"Training time": 0.21006192611323463, "Episode Reward": 1951.1552514614705, "Mean Reward": 25.0148109161727, "Episode": 200, "Episode Step": 78}
{"Training time": 0.21135890940825144, "Episode Reward": 2659.9619517139968, "Mean Reward": 36.943915996027734, "Episode": 201, "Episode Step": 72}
{"Training time": 0.21228858497407702, "Episode Reward": 2080.833122343216, "Mean Reward": 26.339659776496404, "Episode": 202, "Episode Step": 79}
{"Training time": 0.21359884440898896, "Episode Reward": 4295.973325750301, "Mean Reward": 38.702462394146856, "Episode": 203, "Episode Step": 111}
{"Training time": 0.21494104133711922, "Episode Reward": 2677.2678087577387, "Mean Reward": 35.22720800997025, "Episode": 204, "Episode Step": 76}
{"Training time": 0.21583908994992573, "Episode Reward": 2026.5327638675622, "Mean Reward": 26.664904787731082, "Episode": 205, "Episode Step": 76}
{"Training time": 0.2167406921916538, "Episode Reward": 2016.3394242457543, "Mean Reward": 26.530781897970453, "Episode": 206, "Episode Step": 76}
{"Training time": 0.21806521389219496, "Episode Reward": 2585.8178513466273, "Mean Reward": 34.94348447765712, "Episode": 207, "Episode Step": 74}
{"Training time": 0.2190395419465171, "Episode Reward": 2476.700280907517, "Mean Reward": 30.57654667787058, "Episode": 208, "Episode Step": 81}
{"Training time": 0.2199328535795212, "Episode Reward": 2367.161384707332, "Mean Reward": 31.562151796097762, "Episode": 209, "Episode Step": 75}
{"Training time": 0.22127832803461286, "Episode Reward": 2315.895543244304, "Mean Reward": 30.878607243257388, "Episode": 210, "Episode Step": 75}
{"Training time": 0.22221999579005772, "Episode Reward": 2484.94022574908, "Mean Reward": 31.858208022424105, "Episode": 211, "Episode Step": 78}
{"Training time": 0.22311980777316623, "Episode Reward": 2155.0507427432926, "Mean Reward": 28.7340099032439, "Episode": 212, "Episode Step": 75}
{"Training time": 0.224426985250579, "Episode Reward": 2180.9385941163705, "Mean Reward": 30.717444987554515, "Episode": 213, "Episode Step": 71}
{"Training time": 0.22538567105929055, "Episode Reward": 1947.2855205254737, "Mean Reward": 24.34106900656842, "Episode": 214, "Episode Step": 80}
{"Training time": 0.22634389327632057, "Episode Reward": 2532.1487234727724, "Mean Reward": 31.651859043409655, "Episode": 215, "Episode Step": 80}
{"Training time": 0.22804661360051898, "Episode Reward": 3593.060493986134, "Mean Reward": 33.89679711307674, "Episode": 216, "Episode Step": 106}
{"Training time": 0.22906321969297197, "Episode Reward": 2046.120962857939, "Mean Reward": 23.518631756987805, "Episode": 217, "Episode Step": 87}
{"Training time": 0.22997561971346536, "Episode Reward": 2294.069597992492, "Mean Reward": 30.587594639899894, "Episode": 218, "Episode Step": 75}
{"Training time": 0.23131446136368647, "Episode Reward": 2072.8837758892428, "Mean Reward": 28.39566816286634, "Episode": 219, "Episode Step": 73}
{"Training time": 0.2323651588625378, "Episode Reward": 2321.611378306539, "Mean Reward": 26.685188256396998, "Episode": 220, "Episode Step": 87}
{"Training time": 0.23326902634567684, "Episode Reward": 2122.0543617387134, "Mean Reward": 27.92176791761465, "Episode": 221, "Episode Step": 76}
{"Training time": 0.23459368109703063, "Episode Reward": 2063.095341330055, "Mean Reward": 28.26158001821993, "Episode": 222, "Episode Step": 73}
{"Training time": 0.23563602109750112, "Episode Reward": 1730.2607863698886, "Mean Reward": 19.888055015745845, "Episode": 223, "Episode Step": 87}
{"Training time": 0.23657958222760095, "Episode Reward": 2261.9361120337862, "Mean Reward": 28.63210268397198, "Episode": 224, "Episode Step": 79}
{"Training time": 0.23793087661266327, "Episode Reward": 1747.8199649324345, "Mean Reward": 23.304266199099125, "Episode": 225, "Episode Step": 75}
{"Training time": 0.23891631411181555, "Episode Reward": 1998.5419980578686, "Mean Reward": 24.07881925370926, "Episode": 226, "Episode Step": 83}
{"Training time": 0.24022750192218356, "Episode Reward": 3751.5757262718403, "Mean Reward": 34.10523387519855, "Episode": 227, "Episode Step": 110}
{"Training time": 0.24192914525667827, "Episode Reward": 3092.2929108381363, "Mean Reward": 29.450408674648916, "Episode": 228, "Episode Step": 105}
{"Training time": 0.2428787366549174, "Episode Reward": 2187.697782368989, "Mean Reward": 27.00861459714801, "Episode": 229, "Episode Step": 81}
{"Training time": 0.24421726637416416, "Episode Reward": 3753.65431812203, "Mean Reward": 33.21817980638964, "Episode": 230, "Episode Step": 113}
{"Training time": 0.24551330387592316, "Episode Reward": 1718.9109858666568, "Mean Reward": 23.546725833789818, "Episode": 231, "Episode Step": 73}
{"Training time": 0.24689876549773745, "Episode Reward": 3936.854424750428, "Mean Reward": 33.648328416670324, "Episode": 232, "Episode Step": 117}
{"Training time": 0.24822893692387474, "Episode Reward": 3711.3387752527624, "Mean Reward": 33.136953350471096, "Episode": 233, "Episode Step": 112}
{"Training time": 0.24956408388084836, "Episode Reward": 1728.1882698381442, "Mean Reward": 23.673811915591017, "Episode": 234, "Episode Step": 73}
{"Training time": 0.2505279652277629, "Episode Reward": 2239.5229489722033, "Mean Reward": 27.311255475270773, "Episode": 235, "Episode Step": 82}
{"Training time": 0.2514420888821284, "Episode Reward": 2267.620842036767, "Mean Reward": 30.234944560490227, "Episode": 236, "Episode Step": 75}
{"Training time": 0.2531446933084064, "Episode Reward": 2716.171179936887, "Mean Reward": 25.624256414498934, "Episode": 237, "Episode Step": 106}
{"Training time": 0.2540780233012305, "Episode Reward": 2328.1361150786915, "Mean Reward": 29.470077406059385, "Episode": 238, "Episode Step": 79}
{"Training time": 0.25497029330995347, "Episode Reward": 2167.4859733213457, "Mean Reward": 29.290350990828994, "Episode": 239, "Episode Step": 74}
{"Training time": 0.256129881673389, "Episode Reward": 1176.4925323646755, "Mean Reward": 20.284354006287508, "Episode": 240, "Episode Step": 58}
{"Training time": 0.25710842079586455, "Episode Reward": 2251.558055852911, "Mean Reward": 27.797013035221124, "Episode": 241, "Episode Step": 81}
{"Training time": 0.2580504071712494, "Episode Reward": 2239.6464446695327, "Mean Reward": 28.34995499581687, "Episode": 242, "Episode Step": 79}
{"Training time": 0.2597315369049708, "Episode Reward": 2574.2181508956405, "Mean Reward": 24.99240923199651, "Episode": 243, "Episode Step": 103}
{"Training time": 0.26077232056193883, "Episode Reward": 2086.7129775312433, "Mean Reward": 24.54956444154404, "Episode": 244, "Episode Step": 85}
{"Training time": 0.2617587099472682, "Episode Reward": 1997.3970797330644, "Mean Reward": 24.065025057024872, "Episode": 245, "Episode Step": 83}
{"Training time": 0.2630540374914805, "Episode Reward": 1667.9315021799155, "Mean Reward": 23.491992988449514, "Episode": 246, "Episode Step": 71}
{"Training time": 0.26401089939806194, "Episode Reward": 2405.695808556648, "Mean Reward": 29.699948253785777, "Episode": 247, "Episode Step": 81}
{"Training time": 0.2649608119328817, "Episode Reward": 1883.0923024821013, "Mean Reward": 23.538653781026266, "Episode": 248, "Episode Step": 80}
{"Training time": 0.2668420082992978, "Episode Reward": 1708.112904074882, "Mean Reward": 23.08260681182273, "Episode": 249, "Episode Step": 74}
{"Training time": 0.2685753858089447, "Episode Reward": 4421.989442643829, "Mean Reward": 35.66120518261152, "Episode": 250, "Episode Step": 124}
{"Training time": 0.26943140049775444, "Episode Reward": 1995.2018943993403, "Mean Reward": 27.71113742221306, "Episode": 251, "Episode Step": 72}
{"Training time": 0.27076808777120376, "Episode Reward": 1670.6759259158175, "Mean Reward": 22.2756790122109, "Episode": 252, "Episode Step": 75}
{"Training time": 0.271731657187144, "Episode Reward": 2305.720688149926, "Mean Reward": 28.465687508023777, "Episode": 253, "Episode Step": 81}
{"Training time": 0.2726522041691674, "Episode Reward": 2179.7865201759446, "Mean Reward": 27.945981027896725, "Episode": 254, "Episode Step": 78}
{"Training time": 0.27402886582745445, "Episode Reward": 1668.2101365247026, "Mean Reward": 21.950133375325034, "Episode": 255, "Episode Step": 76}
{"Training time": 0.2750508993864059, "Episode Reward": 2475.293161603459, "Mean Reward": 29.121096018864222, "Episode": 256, "Episode Step": 85}
{"Training time": 0.276016041636467, "Episode Reward": 2124.067646258137, "Mean Reward": 26.223057361211566, "Episode": 257, "Episode Step": 81}
{"Training time": 0.27737098972002666, "Episode Reward": 1627.8669341617801, "Mean Reward": 21.998201812997028, "Episode": 258, "Episode Step": 74}
{"Training time": 0.27832209693060983, "Episode Reward": 2328.3595685265877, "Mean Reward": 29.4729059307163, "Episode": 259, "Episode Step": 79}
{"Training time": 0.2792423913876216, "Episode Reward": 2311.229615204043, "Mean Reward": 31.232832637892475, "Episode": 260, "Episode Step": 74}
{"Training time": 0.28055664857228596, "Episode Reward": 1627.3720428816605, "Mean Reward": 22.29276771070768, "Episode": 261, "Episode Step": 73}
{"Training time": 0.28203607744640774, "Episode Reward": 4227.108371552764, "Mean Reward": 34.08958364155455, "Episode": 262, "Episode Step": 124}
{"Training time": 0.28297599024242825, "Episode Reward": 2088.0299678269216, "Mean Reward": 26.430759086416728, "Episode": 263, "Episode Step": 79}
{"Training time": 0.28429886745082006, "Episode Reward": 1465.7264360979484, "Mean Reward": 20.357311612471506, "Episode": 264, "Episode Step": 72}
{"Training time": 0.28522031135029263, "Episode Reward": 1955.6087362984408, "Mean Reward": 25.071906875621035, "Episode": 265, "Episode Step": 78}
{"Training time": 0.2861614866389169, "Episode Reward": 1929.8907962767703, "Mean Reward": 24.74218969585603, "Episode": 266, "Episode Step": 78}
{"Training time": 0.28749164217048223, "Episode Reward": 1539.4366143164289, "Mean Reward": 21.08817279885519, "Episode": 267, "Episode Step": 73}
{"Training time": 0.28847798744837444, "Episode Reward": 2275.3041167407505, "Mean Reward": 27.413302611334345, "Episode": 268, "Episode Step": 83}
{"Training time": 0.28947794470522137, "Episode Reward": 1874.4476486357203, "Mean Reward": 22.31485295994905, "Episode": 269, "Episode Step": 84}
{"Training time": 0.29112416552172765, "Episode Reward": 2364.224429594641, "Mean Reward": 22.953635238782923, "Episode": 270, "Episode Step": 103}
{"Training time": 0.2920650766293208, "Episode Reward": 1924.4609630367304, "Mean Reward": 23.758777321441116, "Episode": 271, "Episode Step": 81}
{"Training time": 0.2930043105284373, "Episode Reward": 2071.1510951495193, "Mean Reward": 25.56976660678419, "Episode": 272, "Episode Step": 81}
{"Training time": 0.2943018447028266, "Episode Reward": 1374.0071677813876, "Mean Reward": 19.352213630723767, "Episode": 273, "Episode Step": 71}
{"Training time": 0.295291601618131, "Episode Reward": 2300.817324263078, "Mean Reward": 27.068439108977387, "Episode": 274, "Episode Step": 85}
{"Training time": 0.29626668804221684, "Episode Reward": 1966.931435933695, "Mean Reward": 23.69796910763488, "Episode": 275, "Episode Step": 83}
{"Training time": 0.29795992778407204, "Episode Reward": 2468.853335107912, "Mean Reward": 23.738974376037614, "Episode": 276, "Episode Step": 104}
{"Training time": 0.29896029472351077, "Episode Reward": 2266.134887022488, "Mean Reward": 26.66041043555868, "Episode": 277, "Episode Step": 85}
{"Training time": 0.2999040657944149, "Episode Reward": 2035.7616366030002, "Mean Reward": 25.4470204575375, "Episode": 278, "Episode Step": 80}
{"Training time": 0.30121091663837435, "Episode Reward": 1547.5962179364196, "Mean Reward": 21.494391915783606, "Episode": 279, "Episode Step": 72}
{"Training time": 0.30284238470925223, "Episode Reward": 4463.101917951828, "Mean Reward": 31.879299413941627, "Episode": 280, "Episode Step": 140}
{"Training time": 0.3038257833321889, "Episode Reward": 2073.112404056583, "Mean Reward": 24.977257880199794, "Episode": 281, "Episode Step": 83}
{"Training time": 0.3051807619465722, "Episode Reward": 1499.0872451823593, "Mean Reward": 19.724832173452096, "Episode": 282, "Episode Step": 76}
{"Training time": 0.30614713887373607, "Episode Reward": 2347.0208253398055, "Mean Reward": 28.27735934144344, "Episode": 283, "Episode Step": 83}
{"Training time": 0.3071067602766885, "Episode Reward": 2280.5911153447287, "Mean Reward": 28.86824196638897, "Episode": 284, "Episode Step": 79}
{"Training time": 0.3084772413306766, "Episode Reward": 1506.9719129095895, "Mean Reward": 19.571063804020643, "Episode": 285, "Episode Step": 77}
{"Training time": 0.30950214472081927, "Episode Reward": 2332.498972231296, "Mean Reward": 26.810333014152828, "Episode": 286, "Episode Step": 87}
{"Training time": 0.31048010746637983, "Episode Reward": 2277.062443103642, "Mean Reward": 27.769054184190757, "Episode": 287, "Episode Step": 82}
{"Training time": 0.3118838663895925, "Episode Reward": 1703.7861778294773, "Mean Reward": 21.297327222868468, "Episode": 288, "Episode Step": 80}
{"Training time": 0.3138019666406843, "Episode Reward": 5672.882390975119, "Mean Reward": 34.59074628643365, "Episode": 289, "Episode Step": 164}
{"Training time": 0.31471913748317293, "Episode Reward": 2185.4004045195293, "Mean Reward": 27.66329625974088, "Episode": 290, "Episode Step": 79}
{"Training time": 0.31606771137979295, "Episode Reward": 1649.0851599601976, "Mean Reward": 21.987802132802635, "Episode": 291, "Episode Step": 75}
{"Training time": 0.3175258230500751, "Episode Reward": 4305.594088512966, "Mean Reward": 35.00482998791029, "Episode": 292, "Episode Step": 123}
{"Training time": 0.3184712227847841, "Episode Reward": 2400.744008268358, "Mean Reward": 30.009300103354473, "Episode": 293, "Episode Step": 80}
{"Training time": 0.31982217523786755, "Episode Reward": 1403.3671196418725, "Mean Reward": 18.225547008336004, "Episode": 294, "Episode Step": 77}
{"Training time": 0.32124134136570826, "Episode Reward": 4784.281398964176, "Mean Reward": 39.8690116580348, "Episode": 295, "Episode Step": 120}
{"Training time": 0.3225538808107376, "Episode Reward": 4224.236698804505, "Mean Reward": 37.7163990964688, "Episode": 296, "Episode Step": 112}
{"Training time": 0.32433252943886653, "Episode Reward": 2461.4269595919145, "Mean Reward": 21.782539465415173, "Episode": 297, "Episode Step": 113}
{"Training time": 0.32577796664502884, "Episode Reward": 4495.1625704525395, "Mean Reward": 36.84559483977491, "Episode": 298, "Episode Step": 122}
{"Training time": 0.32748709943559434, "Episode Reward": 2483.065954564366, "Mean Reward": 29.916457283908027, "Episode": 299, "Episode Step": 83}
{"Training time": 0.3289028313424852, "Episode Reward": 1552.2101310420146, "Mean Reward": 19.163088037555735, "Episode": 300, "Episode Step": 81}
{"Training time": 0.3303148491515054, "Episode Reward": 4255.3163758347055, "Mean Reward": 35.46096979862254, "Episode": 301, "Episode Step": 120}
{"Training time": 0.331223327782419, "Episode Reward": 2203.2361513384967, "Mean Reward": 28.989949359717063, "Episode": 302, "Episode Step": 76}
{"Training time": 0.3326457663377126, "Episode Reward": 1633.9913731261095, "Mean Reward": 19.92672406251353, "Episode": 303, "Episode Step": 82}
{"Training time": 0.3340731385681364, "Episode Reward": 4183.732070791838, "Mean Reward": 34.57629810571767, "Episode": 304, "Episode Step": 121}
{"Training time": 0.3350569969415665, "Episode Reward": 2472.5567037418377, "Mean Reward": 30.52539140422022, "Episode": 305, "Episode Step": 81}
{"Training time": 0.3364559510681364, "Episode Reward": 1857.3109969898228, "Mean Reward": 23.216387462372786, "Episode": 306, "Episode Step": 80}
{"Training time": 0.33793054276042517, "Episode Reward": 4747.583950298507, "Mean Reward": 37.679237700781805, "Episode": 307, "Episode Step": 126}
{"Training time": 0.3389190146658156, "Episode Reward": 2607.331202737835, "Mean Reward": 30.67448473809218, "Episode": 308, "Episode Step": 85}
{"Training time": 0.34030379162894353, "Episode Reward": 1644.007046428273, "Mean Reward": 20.55008808035341, "Episode": 309, "Episode Step": 80}
{"Training time": 0.34126433471838635, "Episode Reward": 2283.6566786262842, "Mean Reward": 28.193292328719558, "Episode": 310, "Episode Step": 81}
{"Training time": 0.34259787023067473, "Episode Reward": 4595.549776502654, "Mean Reward": 40.668582092943836, "Episode": 311, "Episode Step": 113}
{"Training time": 0.3439557996723387, "Episode Reward": 1928.138538092437, "Mean Reward": 24.719724847338938, "Episode": 312, "Episode Step": 78}
{"Training time": 0.34541789611180623, "Episode Reward": 4561.968881015696, "Mean Reward": 36.2061022302833, "Episode": 313, "Episode Step": 126}
{"Training time": 0.3464443063735962, "Episode Reward": 2562.5347325787548, "Mean Reward": 29.454422213548906, "Episode": 314, "Episode Step": 87}
{"Training time": 0.34781552301512825, "Episode Reward": 1811.2194880364, "Mean Reward": 23.220762667133332, "Episode": 315, "Episode Step": 78}
{"Training time": 0.3493427888552348, "Episode Reward": 4424.532717626567, "Mean Reward": 33.775058913179905, "Episode": 316, "Episode Step": 131}
{"Training time": 0.3507387997044457, "Episode Reward": 4350.454479135573, "Mean Reward": 36.558441001139265, "Episode": 317, "Episode Step": 119}
{"Training time": 0.3524679969416724, "Episode Reward": 2964.3123955078254, "Mean Reward": 27.703854163624538, "Episode": 318, "Episode Step": 107}
{"Training time": 0.35393756495581735, "Episode Reward": 4826.766346460331, "Mean Reward": 38.00603422409709, "Episode": 319, "Episode Step": 127}
{"Training time": 0.35489714523156485, "Episode Reward": 2385.0545954839836, "Mean Reward": 29.813182443549795, "Episode": 320, "Episode Step": 80}
{"Training time": 0.35626815219720204, "Episode Reward": 2256.466916933799, "Mean Reward": 28.929063037612806, "Episode": 321, "Episode Step": 78}
{"Training time": 0.35809992750485736, "Episode Reward": 5393.329593882908, "Mean Reward": 34.795674799244566, "Episode": 322, "Episode Step": 155}
{"Training time": 0.35908372276359135, "Episode Reward": 2569.0366190404347, "Mean Reward": 31.329714866346766, "Episode": 323, "Episode Step": 82}
{"Training time": 0.3607900677786933, "Episode Reward": 3989.0336409878114, "Mean Reward": 37.63239283950765, "Episode": 324, "Episode Step": 106}
{"Training time": 0.3621964666578505, "Episode Reward": 4418.487636661925, "Mean Reward": 36.51642674927211, "Episode": 325, "Episode Step": 121}
{"Training time": 0.36355637550354003, "Episode Reward": 4309.395918994382, "Mean Reward": 37.80171858767002, "Episode": 326, "Episode Step": 114}
{"Training time": 0.36488992386394076, "Episode Reward": 1732.8304340878196, "Mean Reward": 23.104405787837596, "Episode": 327, "Episode Step": 75}
{"Training time": 0.36632022301356, "Episode Reward": 4314.515943264436, "Mean Reward": 35.07736539239379, "Episode": 328, "Episode Step": 123}
{"Training time": 0.3676358171966341, "Episode Reward": 4285.43873904273, "Mean Reward": 38.26284588431009, "Episode": 329, "Episode Step": 112}
{"Training time": 0.3694177538818783, "Episode Reward": 3528.414591375341, "Mean Reward": 31.78751884121929, "Episode": 330, "Episode Step": 111}
{"Training time": 0.37087665134006076, "Episode Reward": 4277.200180042849, "Mean Reward": 34.7739852036004, "Episode": 331, "Episode Step": 123}
{"Training time": 0.371788540813658, "Episode Reward": 2634.735206943236, "Mean Reward": 33.77865649927225, "Episode": 332, "Episode Step": 78}
{"Training time": 0.3730847132868237, "Episode Reward": 2135.8108657193584, "Mean Reward": 30.511583795990834, "Episode": 333, "Episode Step": 70}
{"Training time": 0.3745549077457852, "Episode Reward": 3934.5325600039087, "Mean Reward": 31.98806959352771, "Episode": 334, "Episode Step": 123}
{"Training time": 0.3755212516254849, "Episode Reward": 2370.763064764815, "Mean Reward": 29.63453830956019, "Episode": 335, "Episode Step": 80}
{"Training time": 0.37681755748060014, "Episode Reward": 1968.86689959234, "Mean Reward": 26.97077944647041, "Episode": 336, "Episode Step": 73}
{"Training time": 0.3783003444141812, "Episode Reward": 4404.118601196296, "Mean Reward": 34.67809922201808, "Episode": 337, "Episode Step": 127}
{"Training time": 0.3792643216583464, "Episode Reward": 2445.0760841631486, "Mean Reward": 29.458748001965645, "Episode": 338, "Episode Step": 83}
{"Training time": 0.3809847097264396, "Episode Reward": 4264.5396992854, "Mean Reward": 39.48647869708704, "Episode": 339, "Episode Step": 108}
{"Training time": 0.382453254726198, "Episode Reward": 3995.6935313456497, "Mean Reward": 31.9655482507652, "Episode": 340, "Episode Step": 125}
{"Training time": 0.3834083919392692, "Episode Reward": 2283.690811086305, "Mean Reward": 28.546135138578812, "Episode": 341, "Episode Step": 80}
{"Training time": 0.3851049902704027, "Episode Reward": 3583.744700942804, "Mean Reward": 33.808912273045316, "Episode": 342, "Episode Step": 106}
{"Training time": 0.38656188580724926, "Episode Reward": 4110.7048924399805, "Mean Reward": 33.15084590677404, "Episode": 343, "Episode Step": 124}
{"Training time": 0.3875400177637736, "Episode Reward": 2383.254606915284, "Mean Reward": 29.422896381670174, "Episode": 344, "Episode Step": 81}
{"Training time": 0.3892584280172984, "Episode Reward": 4677.88901753636, "Mean Reward": 43.71858894893795, "Episode": 345, "Episode Step": 107}
{"Training time": 0.39066309081183537, "Episode Reward": 3968.8064049288655, "Mean Reward": 33.35131432713332, "Episode": 346, "Episode Step": 119}
{"Training time": 0.39198955496152244, "Episode Reward": 4278.907070443552, "Mean Reward": 37.534272547750454, "Episode": 347, "Episode Step": 114}
{"Training time": 0.393707671629058, "Episode Reward": 3723.078846053911, "Mean Reward": 34.15668666104506, "Episode": 348, "Episode Step": 109}
{"Training time": 0.3954517760541704, "Episode Reward": 4403.158811855426, "Mean Reward": 37.633835998764326, "Episode": 349, "Episode Step": 117}
{"Training time": 0.3966629166735543, "Episode Reward": 2424.2532133221007, "Mean Reward": 31.080169401565392, "Episode": 350, "Episode Step": 78}
{"Training time": 0.3980385561121835, "Episode Reward": 2232.764707833893, "Mean Reward": 28.996944257583028, "Episode": 351, "Episode Step": 77}
{"Training time": 0.3993563613626692, "Episode Reward": 3793.6781926841295, "Mean Reward": 33.57237338658522, "Episode": 352, "Episode Step": 113}
{"Training time": 0.4002750727203157, "Episode Reward": 2580.734595784902, "Mean Reward": 32.667526528922814, "Episode": 353, "Episode Step": 79}
{"Training time": 0.402010079158677, "Episode Reward": 4787.721734553954, "Mean Reward": 43.13262823922481, "Episode": 354, "Episode Step": 111}
{"Training time": 0.4033363146914376, "Episode Reward": 3943.2590129423784, "Mean Reward": 34.289208808194594, "Episode": 355, "Episode Step": 115}
{"Training time": 0.4045812922053867, "Episode Reward": 4207.707898996846, "Mean Reward": 39.32437288782099, "Episode": 356, "Episode Step": 107}
{"Training time": 0.4058808433347278, "Episode Reward": 2301.2936845159284, "Mean Reward": 31.524571020766142, "Episode": 357, "Episode Step": 73}
{"Training time": 0.40717517495155336, "Episode Reward": 3891.8205138376984, "Mean Reward": 34.138776437172794, "Episode": 358, "Episode Step": 114}
{"Training time": 0.4084109663963318, "Episode Reward": 4449.806933391533, "Mean Reward": 41.97931069237295, "Episode": 359, "Episode Step": 106}
{"Training time": 0.4100837241278754, "Episode Reward": 4480.149319173848, "Mean Reward": 42.66808875403665, "Episode": 360, "Episode Step": 105}
{"Training time": 0.41142947773138683, "Episode Reward": 3548.4401327020605, "Mean Reward": 30.59000114398328, "Episode": 361, "Episode Step": 116}
{"Training time": 0.41233332163757747, "Episode Reward": 2346.706483259473, "Mean Reward": 30.47670757479835, "Episode": 362, "Episode Step": 77}
{"Training time": 0.41365732080406614, "Episode Reward": 2506.1718580420315, "Mean Reward": 33.415624773893754, "Episode": 363, "Episode Step": 75}
{"Training time": 0.4149984030591117, "Episode Reward": 3828.4663396419037, "Mean Reward": 33.583038067034245, "Episode": 364, "Episode Step": 114}
{"Training time": 0.41588055166933274, "Episode Reward": 2570.4596828126128, "Mean Reward": 34.27279577083484, "Episode": 365, "Episode Step": 75}
{"Training time": 0.4171466291613049, "Episode Reward": 2103.3226588967395, "Mean Reward": 30.047466555667707, "Episode": 366, "Episode Step": 70}
{"Training time": 0.41850552055570817, "Episode Reward": 3063.379965892008, "Mean Reward": 26.182734751213744, "Episode": 367, "Episode Step": 117}
{"Training time": 0.41977094915178087, "Episode Reward": 4683.664054647606, "Mean Reward": 43.367259765255604, "Episode": 368, "Episode Step": 108}
{"Training time": 0.4210531783103943, "Episode Reward": 2209.0168649249035, "Mean Reward": 31.112913590491598, "Episode": 369, "Episode Step": 71}
{"Training time": 0.421950971616639, "Episode Reward": 1643.840056192494, "Mean Reward": 21.34857215834408, "Episode": 370, "Episode Step": 77}
{"Training time": 0.42327029274569616, "Episode Reward": 4364.347990934002, "Mean Reward": 38.96739277619645, "Episode": 371, "Episode Step": 112}
{"Training time": 0.42494684524006315, "Episode Reward": 4278.895401867983, "Mean Reward": 41.14322501796138, "Episode": 372, "Episode Step": 104}
{"Training time": 0.42626410888301003, "Episode Reward": 3292.155079250166, "Mean Reward": 29.134115745576693, "Episode": 373, "Episode Step": 113}
{"Training time": 0.42752534250418345, "Episode Reward": 4656.865882121496, "Mean Reward": 43.52211104786445, "Episode": 374, "Episode Step": 107}
{"Training time": 0.42919172889656493, "Episode Reward": 4066.59433554688, "Mean Reward": 39.10186861102769, "Episode": 375, "Episode Step": 104}
{"Training time": 0.430538110004531, "Episode Reward": 3647.258846144293, "Mean Reward": 31.173152531147803, "Episode": 376, "Episode Step": 117}
{"Training time": 0.4317567966381709, "Episode Reward": 4333.077490048626, "Mean Reward": 41.66420663508294, "Episode": 377, "Episode Step": 104}
{"Training time": 0.43344794942273035, "Episode Reward": 4342.186453926264, "Mean Reward": 40.581181812394995, "Episode": 378, "Episode Step": 107}
{"Training time": 0.43432143496142495, "Episode Reward": 1902.2891170382081, "Mean Reward": 25.363854893842774, "Episode": 379, "Episode Step": 75}
{"Training time": 0.435174689690272, "Episode Reward": 2512.0224936909517, "Mean Reward": 34.88920130126322, "Episode": 380, "Episode Step": 72}
{"Training time": 0.4364583005507787, "Episode Reward": 2203.624372335003, "Mean Reward": 30.605894060208374, "Episode": 381, "Episode Step": 72}
{"Training time": 0.43735655135578577, "Episode Reward": 1374.9099630406126, "Mean Reward": 18.3321328405415, "Episode": 382, "Episode Step": 75}
{"Training time": 0.43820100247859956, "Episode Reward": 2484.1823245906476, "Mean Reward": 34.50253228598122, "Episode": 383, "Episode Step": 72}
{"Training time": 0.43984112719694773, "Episode Reward": 3836.6679095768477, "Mean Reward": 37.61439127036125, "Episode": 384, "Episode Step": 102}
{"Training time": 0.441127657228046, "Episode Reward": 2740.63509607718, "Mean Reward": 24.46995621497482, "Episode": 385, "Episode Step": 112}
{"Training time": 0.4420650949743059, "Episode Reward": 1865.5730034181242, "Mean Reward": 23.61484814453322, "Episode": 386, "Episode Step": 79}
{"Training time": 0.443699944946501, "Episode Reward": 4192.105245980684, "Mean Reward": 41.09907103902631, "Episode": 387, "Episode Step": 102}
{"Training time": 0.44497361580530803, "Episode Reward": 3313.5227689317367, "Mean Reward": 30.399291458089326, "Episode": 388, "Episode Step": 109}
{"Training time": 0.44587336467372046, "Episode Reward": 2361.2111330467906, "Mean Reward": 30.66507964995832, "Episode": 389, "Episode Step": 77}
{"Training time": 0.44751593801710343, "Episode Reward": 4646.851591931949, "Mean Reward": 45.55736854835244, "Episode": 390, "Episode Step": 102}
{"Training time": 0.4487479010555479, "Episode Reward": 3536.6413946072826, "Mean Reward": 33.68229899625983, "Episode": 391, "Episode Step": 105}
{"Training time": 0.44961178249782985, "Episode Reward": 2544.877085756967, "Mean Reward": 34.861329941876264, "Episode": 392, "Episode Step": 73}
{"Training time": 0.45092890633477106, "Episode Reward": 2109.6663308364514, "Mean Reward": 28.509004470762857, "Episode": 393, "Episode Step": 74}
{"Training time": 0.4521992972162035, "Episode Reward": 3115.0824604651198, "Mean Reward": 28.843356115417777, "Episode": 394, "Episode Step": 108}
{"Training time": 0.45312252355946436, "Episode Reward": 2052.1850976823157, "Mean Reward": 26.310065354901482, "Episode": 395, "Episode Step": 78}
{"Training time": 0.4548239286078347, "Episode Reward": 4636.509219990622, "Mean Reward": 45.4559727450061, "Episode": 396, "Episode Step": 102}
{"Training time": 0.4556326441632377, "Episode Reward": 1586.0700602963227, "Mean Reward": 23.672687467109295, "Episode": 397, "Episode Step": 67}
{"Training time": 0.45657005747159324, "Episode Reward": 2312.3942573813915, "Mean Reward": 30.031094251706385, "Episode": 398, "Episode Step": 77}
{"Training time": 0.45855817245112523, "Episode Reward": 3948.825501519903, "Mean Reward": 37.969475976152914, "Episode": 399, "Episode Step": 104}
{"Training time": 0.46021161079406736, "Episode Reward": 3092.7373253996648, "Mean Reward": 27.129274784207585, "Episode": 400, "Episode Step": 114}
{"Training time": 0.4610921638541751, "Episode Reward": 2199.6139945386526, "Mean Reward": 29.724513439711522, "Episode": 401, "Episode Step": 74}
{"Training time": 0.46242708053853776, "Episode Reward": 2152.3883279440306, "Mean Reward": 29.086328756000412, "Episode": 402, "Episode Step": 74}
{"Training time": 0.46376886718802984, "Episode Reward": 3354.330818644915, "Mean Reward": 29.949382309329597, "Episode": 403, "Episode Step": 112}
{"Training time": 0.4646724941333135, "Episode Reward": 2327.210006992036, "Mean Reward": 31.029466759893815, "Episode": 404, "Episode Step": 75}
{"Training time": 0.466007044977612, "Episode Reward": 2258.379357492738, "Mean Reward": 30.936703527297784, "Episode": 405, "Episode Step": 73}
{"Training time": 0.46719685667090943, "Episode Reward": 3604.7356700769665, "Mean Reward": 35.3405457850683, "Episode": 406, "Episode Step": 102}
{"Training time": 0.4684056807888879, "Episode Reward": 4508.754373378567, "Mean Reward": 43.77431430464628, "Episode": 407, "Episode Step": 103}
{"Training time": 0.4696330941385693, "Episode Reward": 2184.66151394932, "Mean Reward": 33.610177137681845, "Episode": 408, "Episode Step": 65}
{"Training time": 0.4708726844522688, "Episode Reward": 3716.906320954254, "Mean Reward": 35.399107818611945, "Episode": 409, "Episode Step": 105}
{"Training time": 0.47172442191176944, "Episode Reward": 2117.671411684051, "Mean Reward": 30.25244873834358, "Episode": 410, "Episode Step": 70}
{"Training time": 0.472960849404335, "Episode Reward": 2179.528104144534, "Mean Reward": 33.531201602223604, "Episode": 411, "Episode Step": 65}
{"Training time": 0.47418158219920264, "Episode Reward": 3981.6969022383655, "Mean Reward": 37.92092287846062, "Episode": 412, "Episode Step": 105}
{"Training time": 0.4753966718912125, "Episode Reward": 4083.197293933457, "Mean Reward": 39.64269217411123, "Episode": 413, "Episode Step": 103}
{"Training time": 0.4770130049520069, "Episode Reward": 4201.3070414010745, "Mean Reward": 41.18928471961838, "Episode": 414, "Episode Step": 102}
{"Training time": 0.4778712766700321, "Episode Reward": 1614.5044345042706, "Mean Reward": 22.11649910279823, "Episode": 415, "Episode Step": 73}
{"Training time": 0.47872038828002084, "Episode Reward": 2283.3096276310366, "Mean Reward": 31.71263371709773, "Episode": 416, "Episode Step": 72}
{"Training time": 0.4803588385714425, "Episode Reward": 4138.918657104969, "Mean Reward": 40.57763389318597, "Episode": 417, "Episode Step": 102}
{"Training time": 0.48115978082021077, "Episode Reward": 2100.329718374317, "Mean Reward": 30.88720174079878, "Episode": 418, "Episode Step": 68}
{"Training time": 0.48202228996488783, "Episode Reward": 2126.232962223494, "Mean Reward": 28.349772829646586, "Episode": 419, "Episode Step": 75}
{"Training time": 0.4833501466115316, "Episode Reward": 2124.953677197972, "Mean Reward": 28.332715695972958, "Episode": 420, "Episode Step": 75}
{"Training time": 0.48462323274877334, "Episode Reward": 3314.04196975615, "Mean Reward": 30.685573794038426, "Episode": 421, "Episode Step": 108}
{"Training time": 0.4858314777745141, "Episode Reward": 3977.9062497595814, "Mean Reward": 38.999080879995894, "Episode": 422, "Episode Step": 102}
{"Training time": 0.4870322760608461, "Episode Reward": 2596.5546457704454, "Mean Reward": 39.94699455031454, "Episode": 423, "Episode Step": 65}
{"Training time": 0.4883016166422102, "Episode Reward": 3620.1596641072524, "Mean Reward": 33.519996889881966, "Episode": 424, "Episode Step": 108}
{"Training time": 0.4895444663365682, "Episode Reward": 4344.607551647283, "Mean Reward": 40.60380889389984, "Episode": 425, "Episode Step": 107}
{"Training time": 0.4907545988427268, "Episode Reward": 2449.5981168349904, "Mean Reward": 38.274970575546725, "Episode": 426, "Episode Step": 64}
{"Training time": 0.491575121945805, "Episode Reward": 2048.7123042711632, "Mean Reward": 29.26731863244519, "Episode": 427, "Episode Step": 70}
{"Training time": 0.4927872605456246, "Episode Reward": 4113.765015033396, "Mean Reward": 39.178714428889485, "Episode": 428, "Episode Step": 105}
{"Training time": 0.4940191105339262, "Episode Reward": 2449.430173118072, "Mean Reward": 36.55865930026973, "Episode": 429, "Episode Step": 67}
{"Training time": 0.49481399999724496, "Episode Reward": 1796.9735925282582, "Mean Reward": 26.82050138101878, "Episode": 430, "Episode Step": 67}
{"Training time": 0.4961920138862398, "Episode Reward": 4748.3490182741425, "Mean Reward": 40.24024591757748, "Episode": 431, "Episode Step": 118}
{"Training time": 0.49781959222422706, "Episode Reward": 4283.173691115271, "Mean Reward": 41.99189893250266, "Episode": 432, "Episode Step": 102}
{"Training time": 0.4986424544122484, "Episode Reward": 1840.7321871964537, "Mean Reward": 26.296174102806482, "Episode": 433, "Episode Step": 70}
{"Training time": 0.4996299097273085, "Episode Reward": 2641.470579319406, "Mean Reward": 31.446078325231024, "Episode": 434, "Episode Step": 84}
{"Training time": 0.5012215738826328, "Episode Reward": 3615.206343642296, "Mean Reward": 36.88986064941118, "Episode": 435, "Episode Step": 98}
{"Training time": 0.5020119438568751, "Episode Reward": 1561.7407504117589, "Mean Reward": 23.309563438981474, "Episode": 436, "Episode Step": 67}
{"Training time": 0.5034350330299802, "Episode Reward": 4673.637206857149, "Mean Reward": 38.625100883116936, "Episode": 437, "Episode Step": 121}
{"Training time": 0.5046828669309616, "Episode Reward": 2634.4445410816893, "Mean Reward": 39.32006777733864, "Episode": 438, "Episode Step": 67}
{"Training time": 0.505523306661182, "Episode Reward": 1474.4929328936703, "Mean Reward": 20.767506097093946, "Episode": 439, "Episode Step": 71}
{"Training time": 0.5068509435653686, "Episode Reward": 4525.429655417819, "Mean Reward": 39.6967513633142, "Episode": 440, "Episode Step": 114}
{"Training time": 0.5085521596670151, "Episode Reward": 4685.651628358145, "Mean Reward": 43.38566322553838, "Episode": 441, "Episode Step": 108}
{"Training time": 0.5093717622094684, "Episode Reward": 1372.9381492724474, "Mean Reward": 19.613402132463534, "Episode": 442, "Episode Step": 70}
{"Training time": 0.5103613838884565, "Episode Reward": 2462.2317696333726, "Mean Reward": 30.397923081893488, "Episode": 443, "Episode Step": 81}
{"Training time": 0.5119982196887334, "Episode Reward": 3857.9540412977485, "Mean Reward": 37.823078836252435, "Episode": 444, "Episode Step": 102}
{"Training time": 0.5132523127396902, "Episode Reward": 3073.1903947416545, "Mean Reward": 28.99236221454391, "Episode": 445, "Episode Step": 106}
{"Training time": 0.5145822307798598, "Episode Reward": 4927.517421672511, "Mean Reward": 43.6063488643585, "Episode": 446, "Episode Step": 113}
{"Training time": 0.5162617624468273, "Episode Reward": 3997.313642844348, "Mean Reward": 37.71050606456932, "Episode": 447, "Episode Step": 106}
{"Training time": 0.5170876730150646, "Episode Reward": 1477.0089652819165, "Mean Reward": 21.10012807545595, "Episode": 448, "Episode Step": 70}
{"Training time": 0.5187675235668818, "Episode Reward": 4018.141522877764, "Mean Reward": 33.76589515023331, "Episode": 449, "Episode Step": 119}
{"Training time": 0.5204069644212723, "Episode Reward": 3993.779415025484, "Mean Reward": 39.15470014730867, "Episode": 450, "Episode Step": 102}
{"Training time": 0.5216554777489768, "Episode Reward": 3302.1635563979708, "Mean Reward": 30.861341648579167, "Episode": 451, "Episode Step": 107}
{"Training time": 0.5229189563459821, "Episode Reward": 4500.638548559213, "Mean Reward": 41.67257915332604, "Episode": 452, "Episode Step": 108}
{"Training time": 0.5245568907923168, "Episode Reward": 3997.235087753304, "Mean Reward": 39.18857929169906, "Episode": 453, "Episode Step": 102}
{"Training time": 0.5258374536037445, "Episode Reward": 3377.6293105856303, "Mean Reward": 30.987424867758076, "Episode": 454, "Episode Step": 109}
{"Training time": 0.527160971628295, "Episode Reward": 4159.238751020051, "Mean Reward": 37.136060276964734, "Episode": 455, "Episode Step": 112}
{"Training time": 0.5288061588340336, "Episode Reward": 4014.4932183022, "Mean Reward": 39.35777665002157, "Episode": 456, "Episode Step": 102}
{"Training time": 0.5295873408185111, "Episode Reward": 1638.7847791294896, "Mean Reward": 24.099776163668963, "Episode": 457, "Episode Step": 68}
{"Training time": 0.5309573044379552, "Episode Reward": 4465.739094343984, "Mean Reward": 38.16871020806824, "Episode": 458, "Episode Step": 117}
{"Training time": 0.5326078244050344, "Episode Reward": 3955.2050177055007, "Mean Reward": 38.40004871558739, "Episode": 459, "Episode Step": 103}
{"Training time": 0.5338708333174388, "Episode Reward": 3678.6390784856094, "Mean Reward": 34.70414224986424, "Episode": 460, "Episode Step": 106}
{"Training time": 0.5348643663856718, "Episode Reward": 2590.7846149780103, "Mean Reward": 31.21427246961458, "Episode": 461, "Episode Step": 83}
{"Training time": 0.5365363346868092, "Episode Reward": 4002.600223057093, "Mean Reward": 38.860196340360126, "Episode": 462, "Episode Step": 103}
{"Training time": 0.5377964938349195, "Episode Reward": 3791.712958704527, "Mean Reward": 35.770876968910635, "Episode": 463, "Episode Step": 106}
{"Training time": 0.5391038799948162, "Episode Reward": 4315.428137414622, "Mean Reward": 39.231164885587475, "Episode": 464, "Episode Step": 110}
{"Training time": 0.5407606608337826, "Episode Reward": 3383.717427350255, "Mean Reward": 33.173700268139754, "Episode": 465, "Episode Step": 102}
{"Training time": 0.5419716305202908, "Episode Reward": 3499.4191879423106, "Mean Reward": 33.64826142252222, "Episode": 466, "Episode Step": 104}
{"Training time": 0.543247137731976, "Episode Reward": 4240.609326220367, "Mean Reward": 39.2649011687071, "Episode": 467, "Episode Step": 108}
{"Training time": 0.5449095722039541, "Episode Reward": 4012.3016479938865, "Mean Reward": 39.33629066660673, "Episode": 468, "Episode Step": 102}
{"Training time": 0.5460968055327733, "Episode Reward": 3986.586355869342, "Mean Reward": 39.08417995950335, "Episode": 469, "Episode Step": 102}
{"Training time": 0.5473969424433178, "Episode Reward": 4382.923805332552, "Mean Reward": 39.84476186665956, "Episode": 470, "Episode Step": 110}
{"Training time": 0.5490990671846602, "Episode Reward": 3419.068359661807, "Mean Reward": 32.562555806302925, "Episode": 471, "Episode Step": 105}
{"Training time": 0.5502767944335938, "Episode Reward": 3680.6166273364647, "Mean Reward": 36.44174878550955, "Episode": 472, "Episode Step": 101}
{"Training time": 0.5512289777729247, "Episode Reward": 2436.0552314152687, "Mean Reward": 30.45069039269086, "Episode": 473, "Episode Step": 80}
{"Training time": 0.5528884938690397, "Episode Reward": 3138.6473970293982, "Mean Reward": 30.771052912052923, "Episode": 474, "Episode Step": 102}
{"Training time": 0.554086138010025, "Episode Reward": 4055.904019996204, "Mean Reward": 39.37770893200198, "Episode": 475, "Episode Step": 103}
{"Training time": 0.5553810583220588, "Episode Reward": 4204.271917051349, "Mean Reward": 37.87632357703918, "Episode": 476, "Episode Step": 111}
{"Training time": 0.5570259675052431, "Episode Reward": 3759.760843934412, "Mean Reward": 36.860400430729534, "Episode": 477, "Episode Step": 102}
{"Training time": 0.557862289680375, "Episode Reward": 1939.7706419929223, "Mean Reward": 27.71100917132746, "Episode": 478, "Episode Step": 70}
{"Training time": 0.5592595980564753, "Episode Reward": 4342.118665533141, "Mean Reward": 36.79761580960289, "Episode": 479, "Episode Step": 118}
{"Training time": 0.5609856247239643, "Episode Reward": 3531.741148589634, "Mean Reward": 32.7013069313855, "Episode": 480, "Episode Step": 108}
{"Training time": 0.5621987638870874, "Episode Reward": 3707.0806257645245, "Mean Reward": 35.99107403654878, "Episode": 481, "Episode Step": 103}
{"Training time": 0.5635403491391076, "Episode Reward": 4628.974212709555, "Mean Reward": 39.90495010956513, "Episode": 482, "Episode Step": 116}
{"Training time": 0.56520186636183, "Episode Reward": 3781.140632323964, "Mean Reward": 37.07000619925455, "Episode": 483, "Episode Step": 102}
{"Training time": 0.5660110330581665, "Episode Reward": 2199.347667137638, "Mean Reward": 32.82608458414385, "Episode": 484, "Episode Step": 67}
{"Training time": 0.567343821922938, "Episode Reward": 3749.891936066257, "Mean Reward": 33.184884389966875, "Episode": 485, "Episode Step": 113}
{"Training time": 0.56899928967158, "Episode Reward": 3452.498951613221, "Mean Reward": 33.519407297215736, "Episode": 486, "Episode Step": 103}
{"Training time": 0.5702089758051766, "Episode Reward": 3941.9311901106385, "Mean Reward": 37.9031845202946, "Episode": 487, "Episode Step": 104}
{"Training time": 0.5715891583098306, "Episode Reward": 4174.270889635942, "Mean Reward": 35.07790663559615, "Episode": 488, "Episode Step": 119}
{"Training time": 0.5732795302735435, "Episode Reward": 3757.3254553579945, "Mean Reward": 35.11519117157004, "Episode": 489, "Episode Step": 107}
{"Training time": 0.5741397602690591, "Episode Reward": 2193.4956339057935, "Mean Reward": 30.8943047028985, "Episode": 490, "Episode Step": 71}
{"Training time": 0.5755498672193952, "Episode Reward": 4027.539500369545, "Mean Reward": 34.720168106634006, "Episode": 491, "Episode Step": 116}
{"Training time": 0.5772113310628467, "Episode Reward": 3954.3533109959835, "Mean Reward": 38.7681697156469, "Episode": 492, "Episode Step": 102}
{"Training time": 0.5784515538480547, "Episode Reward": 3964.8727568039126, "Mean Reward": 37.40445996984823, "Episode": 493, "Episode Step": 106}
{"Training time": 0.5797957585917579, "Episode Reward": 3795.9017556472077, "Mean Reward": 33.59205093493104, "Episode": 494, "Episode Step": 113}
{"Training time": 0.5814695488744311, "Episode Reward": 4092.5156786290713, "Mean Reward": 39.3511122945103, "Episode": 495, "Episode Step": 104}
{"Training time": 0.5823101716571384, "Episode Reward": 2559.9748671365555, "Mean Reward": 37.101085030964576, "Episode": 496, "Episode Step": 69}
{"Training time": 0.583632841375139, "Episode Reward": 3843.822835474173, "Mean Reward": 34.31984674530512, "Episode": 497, "Episode Step": 112}
{"Training time": 0.5853207258383433, "Episode Reward": 4069.20597414983, "Mean Reward": 39.126980520671445, "Episode": 498, "Episode Step": 104}
{"Training time": 0.5870812261104583, "Episode Reward": 4417.193237681649, "Mean Reward": 41.67163431775141, "Episode": 499, "Episode Step": 106}
{"Training time": 0.5886964124441146, "Episode Reward": 3783.8486803581814, "Mean Reward": 33.48538655184231, "Episode": 500, "Episode Step": 113}
{"Training time": 0.5900415472189585, "Episode Reward": 2123.8343323560175, "Mean Reward": 28.317791098080235, "Episode": 501, "Episode Step": 75}
{"Training time": 0.5912791158093347, "Episode Reward": 4852.296872156506, "Mean Reward": 45.776385586382126, "Episode": 502, "Episode Step": 106}
{"Training time": 0.5926063741577996, "Episode Reward": 4006.397408963394, "Mean Reward": 35.14383692073152, "Episode": 503, "Episode Step": 114}
{"Training time": 0.5943038827843137, "Episode Reward": 4191.006868133083, "Mean Reward": 39.537800642764935, "Episode": 504, "Episode Step": 106}
{"Training time": 0.5955015432834625, "Episode Reward": 4507.735832328222, "Mean Reward": 43.76442555658468, "Episode": 505, "Episode Step": 103}
{"Training time": 0.5968602363930808, "Episode Reward": 3805.722842121225, "Mean Reward": 32.8079555355278, "Episode": 506, "Episode Step": 116}
{"Training time": 0.5985530938704808, "Episode Reward": 3669.2167332241665, "Mean Reward": 34.944921268801586, "Episode": 507, "Episode Step": 105}
{"Training time": 0.5993433168861602, "Episode Reward": 2171.7438155599116, "Mean Reward": 32.414086799401666, "Episode": 508, "Episode Step": 67}
{"Training time": 0.6003581952386432, "Episode Reward": 2213.081597464324, "Mean Reward": 25.437719511084186, "Episode": 509, "Episode Step": 87}
{"Training time": 0.6021282210614947, "Episode Reward": 4115.765813186438, "Mean Reward": 36.42270631138441, "Episode": 510, "Episode Step": 113}
{"Training time": 0.6033257952663633, "Episode Reward": 4398.143787963038, "Mean Reward": 43.11905674473567, "Episode": 511, "Episode Step": 102}
{"Training time": 0.6046521610683865, "Episode Reward": 4104.975689692551, "Mean Reward": 36.008558681513605, "Episode": 512, "Episode Step": 114}
{"Training time": 0.6063360910945469, "Episode Reward": 3983.5231436233457, "Mean Reward": 37.93831565355568, "Episode": 513, "Episode Step": 105}
{"Training time": 0.6075223780340618, "Episode Reward": 4016.9512087540147, "Mean Reward": 39.38187459562759, "Episode": 514, "Episode Step": 102}
{"Training time": 0.6087449952628877, "Episode Reward": 4077.175041753193, "Mean Reward": 39.20360617070378, "Episode": 515, "Episode Step": 104}
{"Training time": 0.6100782918930053, "Episode Reward": 2126.823339881178, "Mean Reward": 27.9845176300155, "Episode": 516, "Episode Step": 76}
{"Training time": 0.6112755086024603, "Episode Reward": 4262.377650457963, "Mean Reward": 41.78801618096042, "Episode": 517, "Episode Step": 102}
{"Training time": 0.6124880088700189, "Episode Reward": 3939.3677307734465, "Mean Reward": 37.16384651673063, "Episode": 518, "Episode Step": 106}
{"Training time": 0.6141842318905725, "Episode Reward": 3916.786182755352, "Mean Reward": 36.60547834350796, "Episode": 519, "Episode Step": 107}
{"Training time": 0.6154058891534805, "Episode Reward": 4070.7113352700235, "Mean Reward": 38.76867938352403, "Episode": 520, "Episode Step": 105}
{"Training time": 0.6166455035739474, "Episode Reward": 3492.305890331713, "Mean Reward": 33.260056098397264, "Episode": 521, "Episode Step": 105}
{"Training time": 0.6183255269130071, "Episode Reward": 4355.395896241114, "Mean Reward": 42.69995976706975, "Episode": 522, "Episode Step": 102}
{"Training time": 0.619528315530883, "Episode Reward": 4086.8551312153068, "Mean Reward": 40.067207168777514, "Episode": 523, "Episode Step": 102}
{"Training time": 0.6207929180065791, "Episode Reward": 4235.580875882139, "Mean Reward": 39.58486799889849, "Episode": 524, "Episode Step": 107}
{"Training time": 0.6225689888662762, "Episode Reward": 3974.9524912363518, "Mean Reward": 35.176570718905765, "Episode": 525, "Episode Step": 113}
{"Training time": 0.6239613883362876, "Episode Reward": 5161.487067136065, "Mean Reward": 43.373840900303065, "Episode": 526, "Episode Step": 119}
{"Training time": 0.6252318363719517, "Episode Reward": 4336.282184034512, "Mean Reward": 40.15076096328252, "Episode": 527, "Episode Step": 108}
{"Training time": 0.6269031116697523, "Episode Reward": 3862.1089693101, "Mean Reward": 37.135663166443265, "Episode": 528, "Episode Step": 104}
{"Training time": 0.6281043574545119, "Episode Reward": 4499.659517901154, "Mean Reward": 43.686014736904404, "Episode": 529, "Episode Step": 103}
{"Training time": 0.629391995800866, "Episode Reward": 4357.836721109048, "Mean Reward": 39.61669746462771, "Episode": 530, "Episode Step": 110}
{"Training time": 0.6311315249734455, "Episode Reward": 4167.876479871679, "Mean Reward": 38.237398897905315, "Episode": 531, "Episode Step": 109}
{"Training time": 0.6326089313957426, "Episode Reward": 4944.235635134316, "Mean Reward": 38.626840899486844, "Episode": 532, "Episode Step": 128}
{"Training time": 0.6338565174738566, "Episode Reward": 3821.640473118725, "Mean Reward": 36.053212010554006, "Episode": 533, "Episode Step": 106}
{"Training time": 0.6355094630188413, "Episode Reward": 3402.389321687375, "Mean Reward": 33.032906035799755, "Episode": 534, "Episode Step": 103}
{"Training time": 0.6367099763949712, "Episode Reward": 3924.387966009335, "Mean Reward": 38.47439182362093, "Episode": 535, "Episode Step": 102}
{"Training time": 0.6379086663325627, "Episode Reward": 3958.2726511482415, "Mean Reward": 38.060313953348476, "Episode": 536, "Episode Step": 104}
{"Training time": 0.6396318649583392, "Episode Reward": 3469.5849942996474, "Mean Reward": 31.831054993574746, "Episode": 537, "Episode Step": 109}
{"Training time": 0.6410540449619293, "Episode Reward": 5093.221942112078, "Mean Reward": 42.09274332324031, "Episode": 538, "Episode Step": 121}
{"Training time": 0.6422708491484325, "Episode Reward": 4166.305102355144, "Mean Reward": 39.67909621290614, "Episode": 539, "Episode Step": 105}
{"Training time": 0.6439552738931444, "Episode Reward": 4212.073839043981, "Mean Reward": 40.50070999080751, "Episode": 540, "Episode Step": 104}
{"Training time": 0.6451701938443714, "Episode Reward": 4257.969814536677, "Mean Reward": 41.744802103300756, "Episode": 541, "Episode Step": 102}
{"Training time": 0.6464014394415749, "Episode Reward": 3825.3742014031036, "Mean Reward": 36.08843586229343, "Episode": 542, "Episode Step": 106}
{"Training time": 0.6480931493971083, "Episode Reward": 3709.7579020422563, "Mean Reward": 36.01706701011899, "Episode": 543, "Episode Step": 103}
{"Training time": 0.6488695830106735, "Episode Reward": 2461.4274822805996, "Mean Reward": 37.86811511200923, "Episode": 544, "Episode Step": 65}
{"Training time": 0.6501238730218676, "Episode Reward": 4201.688315350848, "Mean Reward": 40.016079193817596, "Episode": 545, "Episode Step": 105}
{"Training time": 0.6514289952649011, "Episode Reward": 2136.8806896025617, "Mean Reward": 29.678898466702247, "Episode": 546, "Episode Step": 72}
{"Training time": 0.6522453274991777, "Episode Reward": 2255.7278807340863, "Mean Reward": 33.172468834324796, "Episode": 547, "Episode Step": 68}
{"Training time": 0.6534835580322478, "Episode Reward": 3878.598509809732, "Mean Reward": 37.294216440478195, "Episode": 548, "Episode Step": 104}
{"Training time": 0.655464779999521, "Episode Reward": 3568.7949538758753, "Mean Reward": 34.9881858223125, "Episode": 549, "Episode Step": 102}
{"Training time": 0.6572089533011118, "Episode Reward": 5359.703938432107, "Mean Reward": 42.877631507456854, "Episode": 550, "Episode Step": 125}
{"Training time": 0.6581015133195454, "Episode Reward": 2399.128894153524, "Mean Reward": 32.420660731804375, "Episode": 551, "Episode Step": 74}
{"Training time": 0.6597377427419027, "Episode Reward": 4047.6474269249784, "Mean Reward": 39.6828179110292, "Episode": 552, "Episode Step": 102}
{"Training time": 0.6609413502613704, "Episode Reward": 4573.65939673941, "Mean Reward": 44.83979800724912, "Episode": 553, "Episode Step": 102}
{"Training time": 0.6618159291479323, "Episode Reward": 1987.3620209127657, "Mean Reward": 27.22413727277761, "Episode": 554, "Episode Step": 73}
{"Training time": 0.6634474530484942, "Episode Reward": 3949.467984344212, "Mean Reward": 38.720274356315805, "Episode": 555, "Episode Step": 102}
{"Training time": 0.6646785060564677, "Episode Reward": 4376.372492391548, "Mean Reward": 42.08050473453412, "Episode": 556, "Episode Step": 104}
{"Training time": 0.6659153438938988, "Episode Reward": 3774.24987798765, "Mean Reward": 35.606130924411794, "Episode": 557, "Episode Step": 106}
{"Training time": 0.6671774016486274, "Episode Reward": 2333.6672167105517, "Mean Reward": 33.82126401029785, "Episode": 558, "Episode Step": 69}
{"Training time": 0.6679775174458822, "Episode Reward": 2434.6572213586683, "Mean Reward": 36.88874577816164, "Episode": 559, "Episode Step": 66}
{"Training time": 0.6692247263590495, "Episode Reward": 3884.840712265071, "Mean Reward": 36.99848297395306, "Episode": 560, "Episode Step": 105}
{"Training time": 0.6708942466311985, "Episode Reward": 4314.6804487653235, "Mean Reward": 42.30078871338552, "Episode": 561, "Episode Step": 102}
{"Training time": 0.6721022927761078, "Episode Reward": 4246.923390727833, "Mean Reward": 41.63650383066503, "Episode": 562, "Episode Step": 102}
{"Training time": 0.6733651636044184, "Episode Reward": 3597.2287875760644, "Mean Reward": 33.61896063155201, "Episode": 563, "Episode Step": 107}
{"Training time": 0.6750221721993552, "Episode Reward": 4171.577811900413, "Mean Reward": 40.89782168529816, "Episode": 564, "Episode Step": 102}
{"Training time": 0.6762301388714048, "Episode Reward": 4208.835565381764, "Mean Reward": 41.26309377825259, "Episode": 565, "Episode Step": 102}
{"Training time": 0.6775368155373467, "Episode Reward": 4642.925064393262, "Mean Reward": 42.20840967630238, "Episode": 566, "Episode Step": 110}
{"Training time": 0.6788224241468641, "Episode Reward": 2194.5723346552013, "Mean Reward": 31.805396154423207, "Episode": 567, "Episode Step": 69}
{"Training time": 0.6800287657976151, "Episode Reward": 4225.40283928467, "Mean Reward": 41.42551803220265, "Episode": 568, "Episode Step": 102}
{"Training time": 0.6809177658292982, "Episode Reward": 2067.0011786638015, "Mean Reward": 27.560015715517352, "Episode": 569, "Episode Step": 75}
{"Training time": 0.6825353363487455, "Episode Reward": 4207.096597222409, "Mean Reward": 42.070965972224094, "Episode": 570, "Episode Step": 100}
{"Training time": 0.6837548408243391, "Episode Reward": 4286.5472337489255, "Mean Reward": 42.02497287989143, "Episode": 571, "Episode Step": 102}
{"Training time": 0.6849861294031143, "Episode Reward": 4551.707621663284, "Mean Reward": 42.53932356694658, "Episode": 572, "Episode Step": 107}
{"Training time": 0.686239905556043, "Episode Reward": 2276.777960160188, "Mean Reward": 33.482028825885116, "Episode": 573, "Episode Step": 68}
{"Training time": 0.6874253913429048, "Episode Reward": 4321.676620686177, "Mean Reward": 42.369378634178204, "Episode": 574, "Episode Step": 102}
{"Training time": 0.6886092846923404, "Episode Reward": 4361.984535845455, "Mean Reward": 42.76455427299466, "Episode": 575, "Episode Step": 102}
{"Training time": 0.6902675682968563, "Episode Reward": 3994.005989032512, "Mean Reward": 39.15692146110306, "Episode": 576, "Episode Step": 102}
{"Training time": 0.6914583138624827, "Episode Reward": 3816.7115446948956, "Mean Reward": 36.69914946822015, "Episode": 577, "Episode Step": 104}
{"Training time": 0.692687572505739, "Episode Reward": 3903.556897089617, "Mean Reward": 37.17673235323445, "Episode": 578, "Episode Step": 105}
{"Training time": 0.6935229671663709, "Episode Reward": -51.28756275241818, "Mean Reward": -1.9725985674006994, "Episode": 579, "Episode Step": 26}
{"Training time": 0.6947262485822042, "Episode Reward": 4193.066666648716, "Mean Reward": 41.10849673185015, "Episode": 580, "Episode Step": 102}
{"Training time": 0.696090513004197, "Episode Reward": 4150.057799826815, "Mean Reward": 35.470579485699275, "Episode": 581, "Episode Step": 117}
{"Training time": 0.6977167718940311, "Episode Reward": 4010.4491798859235, "Mean Reward": 39.318129214567875, "Episode": 582, "Episode Step": 102}
{"Training time": 0.6991632069481744, "Episode Reward": 4916.50547300757, "Mean Reward": 39.33204378406056, "Episode": 583, "Episode Step": 125}
{"Training time": 0.700406884153684, "Episode Reward": 4480.6892425282085, "Mean Reward": 41.87560039745989, "Episode": 584, "Episode Step": 107}
{"Training time": 0.7021629552708731, "Episode Reward": 3974.589689974165, "Mean Reward": 36.80175638864968, "Episode": 585, "Episode Step": 108}
{"Training time": 0.7033653757969538, "Episode Reward": 4345.632899226187, "Mean Reward": 42.604244110060655, "Episode": 586, "Episode Step": 102}
{"Training time": 0.7042909380462434, "Episode Reward": 2408.2336442605447, "Mean Reward": 31.27576161377331, "Episode": 587, "Episode Step": 77}
{"Training time": 0.7059457827276654, "Episode Reward": 4406.2824493338885, "Mean Reward": 43.198847542489105, "Episode": 588, "Episode Step": 102}
{"Training time": 0.7074363027678595, "Episode Reward": 5299.732523757527, "Mean Reward": 42.397860190060214, "Episode": 589, "Episode Step": 125}
{"Training time": 0.7087802099519306, "Episode Reward": 4287.128554998631, "Mean Reward": 37.60639083332133, "Episode": 590, "Episode Step": 114}
{"Training time": 0.7100302469068104, "Episode Reward": 2084.334926907257, "Mean Reward": 30.651984219224367, "Episode": 591, "Episode Step": 68}
{"Training time": 0.7115272716681162, "Episode Reward": 5034.878136469599, "Mean Reward": 40.60385593927096, "Episode": 592, "Episode Step": 124}
{"Training time": 0.7128082713815901, "Episode Reward": 4519.5609564431315, "Mean Reward": 43.043437680410776, "Episode": 593, "Episode Step": 105}
{"Training time": 0.7144101779990726, "Episode Reward": 3463.6701606148845, "Mean Reward": 35.70793980015345, "Episode": 594, "Episode Step": 97}
{"Training time": 0.7159050616290834, "Episode Reward": 4935.66812074819, "Mean Reward": 39.17196921228722, "Episode": 595, "Episode Step": 126}
{"Training time": 0.7172824568880929, "Episode Reward": 4039.2013214936896, "Mean Reward": 35.43159053941833, "Episode": 596, "Episode Step": 114}
{"Training time": 0.7189874394072426, "Episode Reward": 3795.2967952160084, "Mean Reward": 35.80468674732084, "Episode": 597, "Episode Step": 106}
{"Training time": 0.7204733557833566, "Episode Reward": 4463.198252610954, "Mean Reward": 35.70558602088763, "Episode": 598, "Episode Step": 125}
{"Training time": 0.7221535677380032, "Episode Reward": 3907.300692435823, "Mean Reward": 33.683626658929505, "Episode": 599, "Episode Step": 116}
{"Training time": 0.7238198733329773, "Episode Reward": 3982.698840272608, "Mean Reward": 39.04606706149615, "Episode": 600, "Episode Step": 102}
{"Training time": 0.7250301002793842, "Episode Reward": 3952.65019210031, "Mean Reward": 38.75147247157167, "Episode": 601, "Episode Step": 102}
{"Training time": 0.7259860466586219, "Episode Reward": 2319.875230916037, "Mean Reward": 29.74199013994919, "Episode": 602, "Episode Step": 78}
{"Training time": 0.7276101797156864, "Episode Reward": 3811.2415144713077, "Mean Reward": 38.49738903506371, "Episode": 603, "Episode Step": 99}
{"Training time": 0.7289970927768283, "Episode Reward": 4628.3760280850165, "Mean Reward": 39.55876947081211, "Episode": 604, "Episode Step": 117}
{"Training time": 0.7302764963441425, "Episode Reward": 3743.9492995390683, "Mean Reward": 34.348158711367596, "Episode": 605, "Episode Step": 109}
{"Training time": 0.7319418299860424, "Episode Reward": 4208.135422927169, "Mean Reward": 41.25622963654087, "Episode": 606, "Episode Step": 102}
{"Training time": 0.7332984030246734, "Episode Reward": 4869.959638709789, "Mean Reward": 41.982410678532666, "Episode": 607, "Episode Step": 116}
{"Training time": 0.7346465410788854, "Episode Reward": 4253.696258537475, "Mean Reward": 37.643329721570574, "Episode": 608, "Episode Step": 113}
{"Training time": 0.736322230829133, "Episode Reward": 4216.899640548572, "Mean Reward": 42.16899640548572, "Episode": 609, "Episode Step": 100}
{"Training time": 0.7375510097212261, "Episode Reward": 4019.9599962004054, "Mean Reward": 39.41137251176868, "Episode": 610, "Episode Step": 102}
{"Training time": 0.7389550385872523, "Episode Reward": 4250.873781665974, "Mean Reward": 36.96411984057369, "Episode": 611, "Episode Step": 115}
{"Training time": 0.7406316369109683, "Episode Reward": 4086.3027052255743, "Mean Reward": 40.06179122770171, "Episode": 612, "Episode Step": 102}
{"Training time": 0.7420153307914734, "Episode Reward": 4435.188429941137, "Mean Reward": 37.907593418300316, "Episode": 613, "Episode Step": 117}
{"Training time": 0.7434153493907717, "Episode Reward": 3908.5765726537816, "Mean Reward": 32.84518128280489, "Episode": 614, "Episode Step": 119}
{"Training time": 0.7451020508342319, "Episode Reward": 4730.231958979288, "Mean Reward": 46.37482312724792, "Episode": 615, "Episode Step": 102}
{"Training time": 0.746266590224372, "Episode Reward": 3901.122862542882, "Mean Reward": 39.01122862542882, "Episode": 616, "Episode Step": 100}
{"Training time": 0.7474946169058482, "Episode Reward": 4030.0268790734426, "Mean Reward": 38.750258452629254, "Episode": 617, "Episode Step": 104}
{"Training time": 0.7491411377323999, "Episode Reward": 3870.128337603263, "Mean Reward": 37.94243468238493, "Episode": 618, "Episode Step": 102}
{"Training time": 0.7505409019523197, "Episode Reward": 5242.740539100735, "Mean Reward": 44.4300045686503, "Episode": 619, "Episode Step": 118}
{"Training time": 0.7518590263525645, "Episode Reward": 3875.915699488178, "Mean Reward": 34.91815945484845, "Episode": 620, "Episode Step": 111}
{"Training time": 0.7534903346829944, "Episode Reward": 3733.047021755597, "Mean Reward": 37.33047021755597, "Episode": 621, "Episode Step": 100}
{"Training time": 0.7548856116665734, "Episode Reward": 4602.225698005945, "Mean Reward": 39.33526237611918, "Episode": 622, "Episode Step": 117}
{"Training time": 0.7561203624804814, "Episode Reward": 3862.7881156399267, "Mean Reward": 37.50279723922259, "Episode": 623, "Episode Step": 103}
{"Training time": 0.7577192625072268, "Episode Reward": 4185.424734485635, "Mean Reward": 42.70841565801668, "Episode": 624, "Episode Step": 98}
{"Training time": 0.759114906390508, "Episode Reward": 4821.515381670145, "Mean Reward": 40.51693598042139, "Episode": 625, "Episode Step": 119}
{"Training time": 0.7603385652436151, "Episode Reward": 3836.481271788611, "Mean Reward": 37.61256148812364, "Episode": 626, "Episode Step": 102}
{"Training time": 0.7620074266195297, "Episode Reward": 4312.166203711499, "Mean Reward": 42.27613925207352, "Episode": 627, "Episode Step": 102}
{"Training time": 0.7633884838554594, "Episode Reward": 4241.190120059439, "Mean Reward": 36.24948820563623, "Episode": 628, "Episode Step": 117}
{"Training time": 0.7646409052610398, "Episode Reward": 4006.8078800397593, "Mean Reward": 37.80007433999773, "Episode": 629, "Episode Step": 106}
{"Training time": 0.7663033819198608, "Episode Reward": 4414.730035284733, "Mean Reward": 42.86145665324984, "Episode": 630, "Episode Step": 103}
{"Training time": 0.7676979391442404, "Episode Reward": 4830.914148342177, "Mean Reward": 40.93995040967947, "Episode": 631, "Episode Step": 118}
{"Training time": 0.7689794235759311, "Episode Reward": 4139.747457368819, "Mean Reward": 38.33099497563721, "Episode": 632, "Episode Step": 108}
{"Training time": 0.7706584486034181, "Episode Reward": 3912.0635775107685, "Mean Reward": 37.98119978165795, "Episode": 633, "Episode Step": 103}
{"Training time": 0.7720698269208273, "Episode Reward": 5343.413427482138, "Mean Reward": 45.283164639679136, "Episode": 634, "Episode Step": 118}
{"Training time": 0.7733495627509223, "Episode Reward": 4277.0187741435575, "Mean Reward": 38.88198885585052, "Episode": 635, "Episode Step": 110}
{"Training time": 0.7750165355205536, "Episode Reward": 4540.21649666522, "Mean Reward": 44.07977181228369, "Episode": 636, "Episode Step": 103}
{"Training time": 0.7764105330573188, "Episode Reward": 5133.957851186041, "Mean Reward": 42.42940372881026, "Episode": 637, "Episode Step": 121}
{"Training time": 0.7777270132965511, "Episode Reward": 4086.6479272292595, "Mean Reward": 36.48792792168982, "Episode": 638, "Episode Step": 112}
{"Training time": 0.7793917952643501, "Episode Reward": 4417.053402339606, "Mean Reward": 42.47166733018852, "Episode": 639, "Episode Step": 104}
{"Training time": 0.780708987183041, "Episode Reward": 5289.049077300009, "Mean Reward": 46.80574404690274, "Episode": 640, "Episode Step": 113}
{"Training time": 0.7819390183024936, "Episode Reward": 4331.453696282891, "Mean Reward": 41.25193996459896, "Episode": 641, "Episode Step": 105}
{"Training time": 0.7836170472039117, "Episode Reward": 4023.653302165439, "Mean Reward": 39.06459516665475, "Episode": 642, "Episode Step": 103}
{"Training time": 0.7849571666452619, "Episode Reward": 5119.311797176692, "Mean Reward": 44.90624383488327, "Episode": 643, "Episode Step": 114}
{"Training time": 0.7862979802820418, "Episode Reward": 4204.044746236919, "Mean Reward": 36.87758549330631, "Episode": 644, "Episode Step": 114}
{"Training time": 0.7880312255356047, "Episode Reward": 4029.3999684092164, "Mean Reward": 37.309258966752004, "Episode": 645, "Episode Step": 108}
{"Training time": 0.7893876102235582, "Episode Reward": 5025.811039358118, "Mean Reward": 43.32595723584585, "Episode": 646, "Episode Step": 116}
{"Training time": 0.7907003980212741, "Episode Reward": 4581.839273778984, "Mean Reward": 40.54725021043348, "Episode": 647, "Episode Step": 113}
{"Training time": 0.7923577735821407, "Episode Reward": 4074.131166566631, "Mean Reward": 40.74131166566631, "Episode": 648, "Episode Step": 100}
{"Training time": 0.7942485141091876, "Episode Reward": 4991.775810441487, "Mean Reward": 42.30318483424989, "Episode": 649, "Episode Step": 118}
{"Training time": 0.7959451919131809, "Episode Reward": 4630.2928519365105, "Mean Reward": 38.26688307385546, "Episode": 650, "Episode Step": 121}
{"Training time": 0.7975822363959418, "Episode Reward": 4162.294045792304, "Mean Reward": 41.210832136557464, "Episode": 651, "Episode Step": 101}
{"Training time": 0.7990335543950399, "Episode Reward": 5190.356802761315, "Mean Reward": 41.85771615130093, "Episode": 652, "Episode Step": 124}
{"Training time": 0.8003133383062151, "Episode Reward": 4788.6490769455195, "Mean Reward": 43.93256033894972, "Episode": 653, "Episode Step": 109}
{"Training time": 0.8020076224539014, "Episode Reward": 4135.335383041131, "Mean Reward": 39.01259795321821, "Episode": 654, "Episode Step": 106}
{"Training time": 0.8033959696690242, "Episode Reward": 5410.703220984149, "Mean Reward": 45.85341712698431, "Episode": 655, "Episode Step": 118}
{"Training time": 0.804750907752249, "Episode Reward": 4704.731677709751, "Mean Reward": 40.91071024095436, "Episode": 656, "Episode Step": 115}
{"Training time": 0.8064070041312111, "Episode Reward": 4144.37628201309, "Mean Reward": 40.23666293216592, "Episode": 657, "Episode Step": 103}
{"Training time": 0.807924051615927, "Episode Reward": 5365.592262808295, "Mean Reward": 41.59373847138213, "Episode": 658, "Episode Step": 129}
{"Training time": 0.809260022772683, "Episode Reward": 4698.2312722065735, "Mean Reward": 41.57726789563339, "Episode": 659, "Episode Step": 113}
{"Training time": 0.8109026410844591, "Episode Reward": 4564.28642149467, "Mean Reward": 44.747906093085, "Episode": 660, "Episode Step": 102}
{"Training time": 0.8122847177584966, "Episode Reward": 5435.197986077647, "Mean Reward": 45.67393265611469, "Episode": 661, "Episode Step": 119}
{"Training time": 0.8136480263868968, "Episode Reward": 4261.0584690000005, "Mean Reward": 36.733262663793106, "Episode": 662, "Episode Step": 116}
{"Training time": 0.8153150357802709, "Episode Reward": 4273.008857349353, "Mean Reward": 41.89224369950346, "Episode": 663, "Episode Step": 102}
{"Training time": 0.816711791091495, "Episode Reward": 5579.041858890648, "Mean Reward": 46.88270469656006, "Episode": 664, "Episode Step": 119}
{"Training time": 0.8181959460841285, "Episode Reward": 4461.961202714107, "Mean Reward": 35.98355808640409, "Episode": 665, "Episode Step": 124}
{"Training time": 0.8199378797080782, "Episode Reward": 4331.613978033394, "Mean Reward": 41.253466457460895, "Episode": 666, "Episode Step": 105}
{"Training time": 0.8214473013745414, "Episode Reward": 5679.1855405164, "Mean Reward": 44.717996382018896, "Episode": 667, "Episode Step": 127}
{"Training time": 0.8228072780370712, "Episode Reward": 4519.562747734467, "Mean Reward": 39.99613051092449, "Episode": 668, "Episode Step": 113}
{"Training time": 0.8245358919435077, "Episode Reward": 3529.439564075609, "Mean Reward": 33.93691888534239, "Episode": 669, "Episode Step": 104}
{"Training time": 0.8260939577553007, "Episode Reward": 5172.427132478528, "Mean Reward": 40.09633436029866, "Episode": 670, "Episode Step": 129}
{"Training time": 0.8275566983222962, "Episode Reward": 4452.947808093876, "Mean Reward": 36.499572197490785, "Episode": 671, "Episode Step": 122}
{"Training time": 0.829293395280838, "Episode Reward": 4242.825469549829, "Mean Reward": 40.026655373111595, "Episode": 672, "Episode Step": 106}
{"Training time": 0.8309410613775253, "Episode Reward": 5561.219074857396, "Mean Reward": 40.59283996246274, "Episode": 673, "Episode Step": 137}
{"Training time": 0.8322505505217446, "Episode Reward": 4435.727433090026, "Mean Reward": 40.69474709256905, "Episode": 674, "Episode Step": 109}
{"Training time": 0.8339350157976151, "Episode Reward": 4692.949943021894, "Mean Reward": 46.00931316688131, "Episode": 675, "Episode Step": 102}
{"Training time": 0.8354708655012979, "Episode Reward": 5612.143786009864, "Mean Reward": 43.50499058922375, "Episode": 676, "Episode Step": 129}
{"Training time": 0.8367813297112783, "Episode Reward": 4499.195695062642, "Mean Reward": 40.90177904602402, "Episode": 677, "Episode Step": 110}
{"Training time": 0.8385007177458869, "Episode Reward": 4622.378787444681, "Mean Reward": 43.19980175181944, "Episode": 678, "Episode Step": 107}
{"Training time": 0.8397452371650272, "Episode Reward": 4634.490127199883, "Mean Reward": 43.72160497358381, "Episode": 679, "Episode Step": 106}
{"Training time": 0.840952887998687, "Episode Reward": 4029.260480159176, "Mean Reward": 39.502553727050746, "Episode": 680, "Episode Step": 102}
{"Training time": 0.842666038605902, "Episode Reward": 3907.9110927056004, "Mean Reward": 36.86708578024151, "Episode": 681, "Episode Step": 106}
{"Training time": 0.8442362141609192, "Episode Reward": 5181.169176092425, "Mean Reward": 39.251281637063826, "Episode": 682, "Episode Step": 132}
{"Training time": 0.8454610500070784, "Episode Reward": 4208.169237507912, "Mean Reward": 40.07780226198011, "Episode": 683, "Episode Step": 105}
{"Training time": 0.8474975674682194, "Episode Reward": 4883.874422784769, "Mean Reward": 36.17684757618348, "Episode": 684, "Episode Step": 135}
{"Training time": 0.8490535363886091, "Episode Reward": 5811.622205640589, "Mean Reward": 44.363528287332734, "Episode": 685, "Episode Step": 131}
{"Training time": 0.8502509744299782, "Episode Reward": 4227.333393677231, "Mean Reward": 42.70033730987102, "Episode": 686, "Episode Step": 99}
{"Training time": 0.8519936968882879, "Episode Reward": 4121.587061033063, "Mean Reward": 38.162843157713546, "Episode": 687, "Episode Step": 108}
{"Training time": 0.8535647991630766, "Episode Reward": 5412.065365100373, "Mean Reward": 41.00049519015434, "Episode": 688, "Episode Step": 132}
{"Training time": 0.8550844835572773, "Episode Reward": 5249.314541065568, "Mean Reward": 41.01026985207475, "Episode": 689, "Episode Step": 128}
{"Training time": 0.8568386171923743, "Episode Reward": 4216.120969664514, "Mean Reward": 38.32837245149558, "Episode": 690, "Episode Step": 110}
{"Training time": 0.8584267385800679, "Episode Reward": 5508.559263954302, "Mean Reward": 40.5041122349581, "Episode": 691, "Episode Step": 136}
{"Training time": 0.8592752771907383, "Episode Reward": 2250.693559598356, "Mean Reward": 32.15276513711937, "Episode": 692, "Episode Step": 70}
{"Training time": 0.8610543488793903, "Episode Reward": 4430.014563939512, "Mean Reward": 40.27285967217738, "Episode": 693, "Episode Step": 110}
{"Training time": 0.8625759813520644, "Episode Reward": 5701.02404666689, "Mean Reward": 44.19398485788287, "Episode": 694, "Episode Step": 129}
{"Training time": 0.8634472141663233, "Episode Reward": 2613.7925460873203, "Mean Reward": 35.805377343661924, "Episode": 695, "Episode Step": 73}
{"Training time": 0.8652309979995092, "Episode Reward": 4217.191768719379, "Mean Reward": 37.32028113910955, "Episode": 696, "Episode Step": 113}
{"Training time": 0.8668042408095465, "Episode Reward": 5605.356463583424, "Mean Reward": 42.14553732017612, "Episode": 697, "Episode Step": 133}
{"Training time": 0.8681708577606413, "Episode Reward": 4758.497494898735, "Mean Reward": 41.741206095602934, "Episode": 698, "Episode Step": 114}
{"Training time": 0.8701582141717275, "Episode Reward": 4262.409274434941, "Mean Reward": 40.21140824938624, "Episode": 699, "Episode Step": 106}
{"Training time": 0.8719768557945887, "Episode Reward": 5405.432210913523, "Mean Reward": 41.26284130468338, "Episode": 700, "Episode Step": 131}
{"Training time": 0.8735499125056797, "Episode Reward": 5732.254127338958, "Mean Reward": 42.46114168399228, "Episode": 701, "Episode Step": 135}
{"Training time": 0.8752619477775362, "Episode Reward": 3944.2723094556277, "Mean Reward": 36.86235803229559, "Episode": 702, "Episode Step": 107}
{"Training time": 0.8767611819505692, "Episode Reward": 5412.907337391866, "Mean Reward": 42.95958204279259, "Episode": 703, "Episode Step": 126}
{"Training time": 0.8783221808407041, "Episode Reward": 5338.013751261683, "Mean Reward": 41.061644240474486, "Episode": 704, "Episode Step": 130}
{"Training time": 0.8800042910708321, "Episode Reward": 4662.227565416934, "Mean Reward": 45.70811338644053, "Episode": 705, "Episode Step": 102}
{"Training time": 0.8812095352676179, "Episode Reward": 4676.823501201924, "Mean Reward": 45.85121079609729, "Episode": 706, "Episode Step": 102}
{"Training time": 0.882441053059366, "Episode Reward": 4119.665498776756, "Mean Reward": 39.996752415308315, "Episode": 707, "Episode Step": 103}
{"Training time": 0.884202963312467, "Episode Reward": 4125.016344078822, "Mean Reward": 38.19459577850761, "Episode": 708, "Episode Step": 108}
{"Training time": 0.8857283030615912, "Episode Reward": 5341.1267292701, "Mean Reward": 42.05611597850473, "Episode": 709, "Episode Step": 127}
{"Training time": 0.8869701238473257, "Episode Reward": 4545.524717468376, "Mean Reward": 44.131307936586175, "Episode": 710, "Episode Step": 103}
{"Training time": 0.8887283235788346, "Episode Reward": 4255.49479958624, "Mean Reward": 38.337790987263425, "Episode": 711, "Episode Step": 111}
{"Training time": 0.8902503936158286, "Episode Reward": 4709.343976538044, "Mean Reward": 36.50654245378329, "Episode": 712, "Episode Step": 129}
{"Training time": 0.8917849280436834, "Episode Reward": 5011.210974009682, "Mean Reward": 39.15008573445064, "Episode": 713, "Episode Step": 128}
{"Training time": 0.893502583305041, "Episode Reward": 4527.124019624049, "Mean Reward": 42.70871716626461, "Episode": 714, "Episode Step": 106}
{"Training time": 0.8951399858130349, "Episode Reward": 5073.554103564518, "Mean Reward": 37.0332416318578, "Episode": 715, "Episode Step": 137}
{"Training time": 0.8963513875007629, "Episode Reward": 3873.6796455346785, "Mean Reward": 37.977251426810575, "Episode": 716, "Episode Step": 102}
{"Training time": 0.8981177922089895, "Episode Reward": 4283.217038706243, "Mean Reward": 38.24300927416289, "Episode": 717, "Episode Step": 112}
{"Training time": 0.8997828416691886, "Episode Reward": 4788.885265565016, "Mean Reward": 34.2063233254644, "Episode": 718, "Episode Step": 140}
{"Training time": 0.9010076957941056, "Episode Reward": 4260.949560722186, "Mean Reward": 41.774015301197906, "Episode": 719, "Episode Step": 102}
{"Training time": 0.902744874159495, "Episode Reward": 4285.086003829518, "Mean Reward": 40.810342893614454, "Episode": 720, "Episode Step": 105}
{"Training time": 0.9040363497204251, "Episode Reward": 3580.570585751181, "Mean Reward": 33.15343134954797, "Episode": 721, "Episode Step": 108}
{"Training time": 0.9055458049641715, "Episode Reward": 4792.895236743868, "Mean Reward": 38.038851085268796, "Episode": 722, "Episode Step": 126}
{"Training time": 0.9072010924418767, "Episode Reward": 4261.306835655764, "Mean Reward": 42.61306835655764, "Episode": 723, "Episode Step": 100}
{"Training time": 0.9086707407898373, "Episode Reward": 4342.236268882646, "Mean Reward": 35.01803442647295, "Episode": 724, "Episode Step": 124}
{"Training time": 0.9095859130223592, "Episode Reward": 2206.689770115823, "Mean Reward": 28.2908944886644, "Episode": 725, "Episode Step": 78}
{"Training time": 0.9114330246713427, "Episode Reward": 5004.555341786742, "Mean Reward": 43.14271846367881, "Episode": 726, "Episode Step": 116}
{"Training time": 0.9129303777217865, "Episode Reward": 4641.325259589486, "Mean Reward": 37.73435170397956, "Episode": 727, "Episode Step": 123}
{"Training time": 0.9142051263650258, "Episode Reward": 3766.349424451452, "Mean Reward": 35.53159834388162, "Episode": 728, "Episode Step": 106}
{"Training time": 0.916125182443195, "Episode Reward": 4605.668182033082, "Mean Reward": 38.703093966664554, "Episode": 729, "Episode Step": 119}
{"Training time": 0.9175972213347753, "Episode Reward": 4360.284185464085, "Mean Reward": 35.74003430708266, "Episode": 730, "Episode Step": 122}
{"Training time": 0.9188765894042121, "Episode Reward": 3860.4407678629195, "Mean Reward": 36.76610255107543, "Episode": 731, "Episode Step": 105}
{"Training time": 0.9205624491638608, "Episode Reward": 3654.262403302425, "Mean Reward": 36.180815874281436, "Episode": 732, "Episode Step": 101}
{"Training time": 0.9221456869443257, "Episode Reward": 4598.1058269310115, "Mean Reward": 35.64423121651947, "Episode": 733, "Episode Step": 129}
{"Training time": 0.923091378013293, "Episode Reward": 2091.672402605655, "Mean Reward": 26.816312853918653, "Episode": 734, "Episode Step": 78}
{"Training time": 0.9247005863322152, "Episode Reward": 3849.095546221695, "Mean Reward": 40.09474527314266, "Episode": 735, "Episode Step": 96}
{"Training time": 0.926277231640286, "Episode Reward": 5095.5977626844415, "Mean Reward": 38.60301335367001, "Episode": 736, "Episode Step": 132}
{"Training time": 0.9278075641393662, "Episode Reward": 4670.90394260706, "Mean Reward": 36.208557694628375, "Episode": 737, "Episode Step": 129}
{"Training time": 0.9294874563482073, "Episode Reward": 4409.384055218711, "Mean Reward": 42.39792360787222, "Episode": 738, "Episode Step": 104}
{"Training time": 0.9310868755314086, "Episode Reward": 4940.04551338047, "Mean Reward": 36.86601129388411, "Episode": 739, "Episode Step": 134}
{"Training time": 0.9323743591705959, "Episode Reward": 4217.372365611037, "Mean Reward": 38.691489592761805, "Episode": 740, "Episode Step": 109}
{"Training time": 0.9340564155578613, "Episode Reward": 4395.451544645938, "Mean Reward": 43.092662202411155, "Episode": 741, "Episode Step": 102}
{"Training time": 0.9355594280030992, "Episode Reward": 4838.728191058732, "Mean Reward": 38.10022197684041, "Episode": 742, "Episode Step": 127}
{"Training time": 0.937043998837471, "Episode Reward": 4726.183498116924, "Mean Reward": 37.50939284219781, "Episode": 743, "Episode Step": 126}
{"Training time": 0.9387302324506972, "Episode Reward": 4466.181801852012, "Mean Reward": 43.78609609658835, "Episode": 744, "Episode Step": 102}
{"Training time": 0.9402174677451451, "Episode Reward": 4417.832720867515, "Mean Reward": 34.78608441627964, "Episode": 745, "Episode Step": 127}
{"Training time": 0.9414779447184669, "Episode Reward": 4165.818565904352, "Mean Reward": 39.300175150041056, "Episode": 746, "Episode Step": 106}
{"Training time": 0.9431665221850077, "Episode Reward": 4442.717824187972, "Mean Reward": 43.133182759106525, "Episode": 747, "Episode Step": 103}
{"Training time": 0.9447804907957713, "Episode Reward": 4438.60688365669, "Mean Reward": 32.39859039165467, "Episode": 748, "Episode Step": 137}
{"Training time": 0.9467455918921365, "Episode Reward": 4830.720257475371, "Mean Reward": 36.59636558693463, "Episode": 749, "Episode Step": 132}
{"Training time": 0.9484092605113983, "Episode Reward": 3708.8760377713666, "Mean Reward": 36.721544928429374, "Episode": 750, "Episode Step": 101}
{"Training time": 0.9500164382987553, "Episode Reward": 4759.864647285547, "Mean Reward": 34.99900475945255, "Episode": 751, "Episode Step": 136}
{"Training time": 0.9513079835971197, "Episode Reward": 4204.975922326851, "Mean Reward": 39.29884039557805, "Episode": 752, "Episode Step": 107}
{"Training time": 0.9530067938566208, "Episode Reward": 4449.5844019697, "Mean Reward": 42.37699430447333, "Episode": 753, "Episode Step": 105}
{"Training time": 0.9546160413821538, "Episode Reward": 4809.185162356735, "Mean Reward": 35.36165560556423, "Episode": 754, "Episode Step": 136}
{"Training time": 0.9558802907996707, "Episode Reward": 4251.720887227792, "Mean Reward": 40.492579878359926, "Episode": 755, "Episode Step": 105}
{"Training time": 0.9576246782806185, "Episode Reward": 4485.054648368893, "Mean Reward": 41.91639858288685, "Episode": 756, "Episode Step": 107}
{"Training time": 0.9592591613531113, "Episode Reward": 4085.0969105847985, "Mean Reward": 30.715014365299236, "Episode": 757, "Episode Step": 133}
{"Training time": 0.9605338710546494, "Episode Reward": 3759.175178783466, "Mean Reward": 35.46391678097609, "Episode": 758, "Episode Step": 106}
{"Training time": 0.9622596527470483, "Episode Reward": 4762.748459217547, "Mean Reward": 44.931589237901385, "Episode": 759, "Episode Step": 106}
{"Training time": 0.963845811618699, "Episode Reward": 4441.724053116407, "Mean Reward": 33.649424644821266, "Episode": 760, "Episode Step": 132}
{"Training time": 0.9650620349910524, "Episode Reward": 4211.847544145366, "Mean Reward": 41.29262298181731, "Episode": 761, "Episode Step": 102}
{"Training time": 0.9668213544289271, "Episode Reward": 4092.349957548976, "Mean Reward": 37.5444950233851, "Episode": 762, "Episode Step": 109}
{"Training time": 0.9683991669283973, "Episode Reward": 4013.316637209694, "Mean Reward": 29.728271386738474, "Episode": 763, "Episode Step": 135}
{"Training time": 0.9691846574677362, "Episode Reward": 1998.580341381747, "Mean Reward": 30.281520323965864, "Episode": 764, "Episode Step": 66}
{"Training time": 0.9708579460779826, "Episode Reward": 4727.086906444351, "Mean Reward": 46.34398927886619, "Episode": 765, "Episode Step": 102}
{"Training time": 0.9724739125039843, "Episode Reward": 4072.2671639435907, "Mean Reward": 30.16494195513771, "Episode": 766, "Episode Step": 135}
{"Training time": 0.9737752744224336, "Episode Reward": 3800.6071847976286, "Mean Reward": 35.51969331586569, "Episode": 767, "Episode Step": 107}
{"Training time": 0.9754779535531998, "Episode Reward": 4566.159759938119, "Mean Reward": 44.76627215625607, "Episode": 768, "Episode Step": 102}
{"Training time": 0.9771859677632649, "Episode Reward": 3789.5464905726317, "Mean Reward": 26.50032510889952, "Episode": 769, "Episode Step": 143}
{"Training time": 0.9787071566449271, "Episode Reward": 4267.400883137718, "Mean Reward": 33.33906939951342, "Episode": 770, "Episode Step": 128}
{"Training time": 0.9805949760807885, "Episode Reward": 5546.110566750048, "Mean Reward": 46.2175880562504, "Episode": 771, "Episode Step": 120}
{"Training time": 0.9821921722094218, "Episode Reward": 3649.5494557441107, "Mean Reward": 27.033699672178596, "Episode": 772, "Episode Step": 135}
{"Training time": 0.9837374602423774, "Episode Reward": 4039.810914349486, "Mean Reward": 30.604628139011258, "Episode": 773, "Episode Step": 132}
{"Training time": 0.9854176202747557, "Episode Reward": 4408.382792817156, "Mean Reward": 43.219439145266236, "Episode": 774, "Episode Step": 102}
{"Training time": 0.98701652083132, "Episode Reward": 3049.719763523833, "Mean Reward": 22.424410025910536, "Episode": 775, "Episode Step": 136}
{"Training time": 0.9883299205038283, "Episode Reward": 4064.2664100807983, "Mean Reward": 36.288092947149984, "Episode": 776, "Episode Step": 112}
{"Training time": 0.9900008174445895, "Episode Reward": 4681.8007152891205, "Mean Reward": 45.90000701263843, "Episode": 777, "Episode Step": 102}
{"Training time": 0.9915709366401037, "Episode Reward": 2802.466223184459, "Mean Reward": 21.071174610409468, "Episode": 778, "Episode Step": 133}
{"Training time": 0.9928409657875696, "Episode Reward": 4087.770685218757, "Mean Reward": 38.20346434783885, "Episode": 779, "Episode Step": 107}
{"Training time": 0.9944784941275915, "Episode Reward": 4707.471927120829, "Mean Reward": 46.151685560008126, "Episode": 780, "Episode Step": 102}
{"Training time": 0.996058611339993, "Episode Reward": 2917.0614531041283, "Mean Reward": 21.607862615586136, "Episode": 781, "Episode Step": 135}
{"Training time": 0.9973828893899918, "Episode Reward": 4327.0984406205425, "Mean Reward": 38.9828688344193, "Episode": 782, "Episode Step": 111}
{"Training time": 0.9992947052584754, "Episode Reward": 5427.2708014845975, "Mean Reward": 44.124152857598354, "Episode": 783, "Episode Step": 123}
{"Training time": 1.0008374494314194, "Episode Reward": 2948.281387707255, "Mean Reward": 22.679087597748115, "Episode": 784, "Episode Step": 130}
{"Training time": 1.0020891085598205, "Episode Reward": 4163.071565285892, "Mean Reward": 39.648300621770396, "Episode": 785, "Episode Step": 105}
{"Training time": 1.0041571472088495, "Episode Reward": 5404.625635743352, "Mean Reward": 39.4498221587106, "Episode": 786, "Episode Step": 137}
{"Training time": 1.005785311659177, "Episode Reward": 2975.002877120961, "Mean Reward": 21.55799186319537, "Episode": 787, "Episode Step": 138}
{"Training time": 1.0070687886079153, "Episode Reward": 3847.22985756589, "Mean Reward": 35.95541922958776, "Episode": 788, "Episode Step": 107}
{"Training time": 1.008995736108886, "Episode Reward": 5380.162704785431, "Mean Reward": 42.69970400623358, "Episode": 789, "Episode Step": 126}
{"Training time": 1.010587102505896, "Episode Reward": 2717.988737345333, "Mean Reward": 19.839333849236006, "Episode": 790, "Episode Step": 137}
{"Training time": 1.0119619646999571, "Episode Reward": 3490.2015847566313, "Mean Reward": 30.087944696177857, "Episode": 791, "Episode Step": 116}
{"Training time": 1.013667194975747, "Episode Reward": 4376.890791516232, "Mean Reward": 42.49408535452652, "Episode": 792, "Episode Step": 103}
{"Training time": 1.0152464205026626, "Episode Reward": 2936.8292114243827, "Mean Reward": 22.248706147154415, "Episode": 793, "Episode Step": 132}
{"Training time": 1.0167255196968714, "Episode Reward": 4035.496984269169, "Mean Reward": 32.54433051829975, "Episode": 794, "Episode Step": 124}
{"Training time": 1.0183785785569086, "Episode Reward": 4268.7807653158625, "Mean Reward": 42.26515609223626, "Episode": 795, "Episode Step": 101}
{"Training time": 1.020000935792923, "Episode Reward": 3130.2524147328586, "Mean Reward": 22.84855777177269, "Episode": 796, "Episode Step": 137}
{"Training time": 1.021372051636378, "Episode Reward": 3672.626314403151, "Mean Reward": 31.660571675889233, "Episode": 797, "Episode Step": 116}
{"Training time": 1.023534473048316, "Episode Reward": 5843.393407425671, "Mean Reward": 40.5791208849005, "Episode": 798, "Episode Step": 144}
{"Training time": 1.026194142765469, "Episode Reward": 3724.5145362903413, "Mean Reward": 19.100074545078673, "Episode": 799, "Episode Step": 195}
{"Training time": 1.0280874049663544, "Episode Reward": 4451.000729009112, "Mean Reward": 32.7279465368317, "Episode": 800, "Episode Step": 136}
{"Training time": 1.029783861372206, "Episode Reward": 4498.256530020979, "Mean Reward": 43.252466634817104, "Episode": 801, "Episode Step": 104}
{"Training time": 1.03131425831053, "Episode Reward": 3508.4770324323126, "Mean Reward": 27.197496375444285, "Episode": 802, "Episode Step": 129}
{"Training time": 1.0329958018991683, "Episode Reward": 4398.045417200211, "Mean Reward": 31.41461012285865, "Episode": 803, "Episode Step": 140}
{"Training time": 1.0349323497215908, "Episode Reward": 4685.036298085826, "Mean Reward": 37.78255079101473, "Episode": 804, "Episode Step": 124}
{"Training time": 1.036464376118448, "Episode Reward": 3163.442043325223, "Mean Reward": 24.714390963478305, "Episode": 805, "Episode Step": 128}
{"Training time": 1.0376620863543617, "Episode Reward": 4015.698361084629, "Mean Reward": 40.15698361084629, "Episode": 806, "Episode Step": 100}
{"Training time": 1.0395928294128842, "Episode Reward": 4464.986887776999, "Mean Reward": 37.20822406480832, "Episode": 807, "Episode Step": 120}
{"Training time": 1.0410777277416654, "Episode Reward": 3590.722870320248, "Mean Reward": 28.497800558097207, "Episode": 808, "Episode Step": 126}
{"Training time": 1.0423947635624145, "Episode Reward": 4974.365658614643, "Mean Reward": 44.81410503256435, "Episode": 809, "Episode Step": 111}
{"Training time": 1.0443016024430594, "Episode Reward": 4189.908703323046, "Mean Reward": 34.343513961664314, "Episode": 810, "Episode Step": 122}
{"Training time": 1.0460859727197223, "Episode Reward": 2966.392600989226, "Mean Reward": 19.64498411251143, "Episode": 811, "Episode Step": 151}
{"Training time": 1.047428546084298, "Episode Reward": 4713.852082851018, "Mean Reward": 41.71550515797361, "Episode": 812, "Episode Step": 113}
{"Training time": 1.0491299347082774, "Episode Reward": 4167.692198609593, "Mean Reward": 40.07396344816917, "Episode": 813, "Episode Step": 104}
{"Training time": 1.0508604154984156, "Episode Reward": 3240.8445607812105, "Mean Reward": 22.505865005425072, "Episode": 814, "Episode Step": 144}
{"Training time": 1.0521581238508224, "Episode Reward": 5575.051354315566, "Mean Reward": 50.68228503923242, "Episode": 815, "Episode Step": 110}
{"Training time": 1.0542912516329024, "Episode Reward": 5176.842941059644, "Mean Reward": 36.97744957899746, "Episode": 816, "Episode Step": 140}
{"Training time": 1.055763849152459, "Episode Reward": 2858.4948249104596, "Mean Reward": 23.23979532447528, "Episode": 817, "Episode Step": 123}
{"Training time": 1.057099861105283, "Episode Reward": 5286.441656918761, "Mean Reward": 48.058560517443276, "Episode": 818, "Episode Step": 110}
{"Training time": 1.0588687872224385, "Episode Reward": 4323.374416663532, "Mean Reward": 40.40536838003301, "Episode": 819, "Episode Step": 107}
{"Training time": 1.0604190486007266, "Episode Reward": 2660.817912826135, "Mean Reward": 20.467830098662578, "Episode": 820, "Episode Step": 130}
{"Training time": 1.061567552222146, "Episode Reward": 3801.9733486716837, "Mean Reward": 39.60388904866337, "Episode": 821, "Episode Step": 96}
{"Training time": 1.0635597216420702, "Episode Reward": 5023.075620658873, "Mean Reward": 39.55177654062105, "Episode": 822, "Episode Step": 127}
{"Training time": 1.0662092077732086, "Episode Reward": 4601.948220439953, "Mean Reward": 20.91794645654524, "Episode": 823, "Episode Step": 220}
{"Training time": 1.0669810746775734, "Episode Reward": 1750.98399994193, "Mean Reward": 28.241677418418227, "Episode": 824, "Episode Step": 62}
{"Training time": 1.0686670316590203, "Episode Reward": 4035.1748287328383, "Mean Reward": 39.560537536596456, "Episode": 825, "Episode Step": 102}
{"Training time": 1.0703702819347383, "Episode Reward": 2767.574751002843, "Mean Reward": 19.768391078591737, "Episode": 826, "Episode Step": 140}
{"Training time": 1.0717838077412711, "Episode Reward": 5049.824976255719, "Mean Reward": 43.911521532658426, "Episode": 827, "Episode Step": 115}
{"Training time": 1.0734980897108715, "Episode Reward": 3880.8763378290223, "Mean Reward": 38.04780723361787, "Episode": 828, "Episode Step": 102}
{"Training time": 1.0750902897119523, "Episode Reward": 2831.182426207912, "Mean Reward": 21.612079589373376, "Episode": 829, "Episode Step": 131}
{"Training time": 1.0765197108189264, "Episode Reward": 5005.358161028826, "Mean Reward": 43.14963931921402, "Episode": 830, "Episode Step": 116}
{"Training time": 1.0785046269496281, "Episode Reward": 4104.4123849283, "Mean Reward": 32.8352990794264, "Episode": 831, "Episode Step": 125}
{"Training time": 1.0811069944169787, "Episode Reward": 4607.801847762141, "Mean Reward": 21.43163650121926, "Episode": 832, "Episode Step": 215}
{"Training time": 1.0825719613499112, "Episode Reward": 4963.924767925845, "Mean Reward": 42.067159050219026, "Episode": 833, "Episode Step": 118}
{"Training time": 1.0845369952254824, "Episode Reward": 4754.834865094009, "Mean Reward": 38.34544246043556, "Episode": 834, "Episode Step": 124}
{"Training time": 1.0862876482804615, "Episode Reward": 3061.598318305255, "Mean Reward": 21.26109943267538, "Episode": 835, "Episode Step": 144}
{"Training time": 1.0877271202537748, "Episode Reward": 4439.569294202396, "Mean Reward": 37.94503670258458, "Episode": 836, "Episode Step": 117}
{"Training time": 1.0897036094135708, "Episode Reward": 5311.394695988579, "Mean Reward": 42.49115756790863, "Episode": 837, "Episode Step": 125}
{"Training time": 1.0912391130129497, "Episode Reward": 3090.0787073958986, "Mean Reward": 24.331328404692115, "Episode": 838, "Episode Step": 127}
{"Training time": 1.092684293852912, "Episode Reward": 4475.56797567762, "Mean Reward": 38.582482548945, "Episode": 839, "Episode Step": 116}
{"Training time": 1.0943822285864089, "Episode Reward": 4118.842808859899, "Mean Reward": 40.38081185156764, "Episode": 840, "Episode Step": 102}
{"Training time": 1.0959365213579602, "Episode Reward": 2985.02519967983, "Mean Reward": 23.139730230076204, "Episode": 841, "Episode Step": 129}
{"Training time": 1.0966311683257421, "Episode Reward": 2144.106279240398, "Mean Reward": 37.61589963579646, "Episode": 842, "Episode Step": 57}
{"Training time": 1.0983165605200662, "Episode Reward": 4013.7944612269985, "Mean Reward": 39.35092609046077, "Episode": 843, "Episode Step": 102}
{"Training time": 1.099906869398223, "Episode Reward": 3003.9336354581, "Mean Reward": 22.7570729958947, "Episode": 844, "Episode Step": 132}
{"Training time": 1.1006196624702878, "Episode Reward": 1840.2976504740795, "Mean Reward": 30.671627507901327, "Episode": 845, "Episode Step": 60}
{"Training time": 1.1026118104987674, "Episode Reward": 5090.759025022616, "Mean Reward": 40.084716732461544, "Episode": 846, "Episode Step": 127}
{"Training time": 1.1041996038622326, "Episode Reward": 2616.569942661127, "Mean Reward": 19.526641363142737, "Episode": 847, "Episode Step": 134}
{"Training time": 1.1056011280086306, "Episode Reward": 4787.146524510296, "Mean Reward": 40.91578226077176, "Episode": 848, "Episode Step": 117}
{"Training time": 1.108065312769678, "Episode Reward": 5198.363993773256, "Mean Reward": 37.944262728271944, "Episode": 849, "Episode Step": 137}
{"Training time": 1.1109100421932008, "Episode Reward": 5222.805860776826, "Mean Reward": 24.179656762855675, "Episode": 850, "Episode Step": 216}
{"Training time": 1.112052780257331, "Episode Reward": 3761.202750736493, "Mean Reward": 39.5916079024894, "Episode": 851, "Episode Step": 95}
{"Training time": 1.1140833822223875, "Episode Reward": 5195.697725412657, "Mean Reward": 38.773863622482516, "Episode": 852, "Episode Step": 134}
{"Training time": 1.1156353419356877, "Episode Reward": 2881.7652943646094, "Mean Reward": 21.83155526033795, "Episode": 853, "Episode Step": 132}
{"Training time": 1.1169616321722666, "Episode Reward": 5141.338498156371, "Mean Reward": 46.3183648482556, "Episode": 854, "Episode Step": 111}
{"Training time": 1.1188536616166433, "Episode Reward": 4794.360091734979, "Mean Reward": 39.2980335388113, "Episode": 855, "Episode Step": 122}
{"Training time": 1.1214299841721853, "Episode Reward": 5201.807694229717, "Mean Reward": 23.644580428316893, "Episode": 856, "Episode Step": 220}
{"Training time": 1.1228027230501174, "Episode Reward": 5089.2171048547425, "Mean Reward": 44.254061781345584, "Episode": 857, "Episode Step": 115}
{"Training time": 1.1244911858108309, "Episode Reward": 3861.317750389656, "Mean Reward": 37.12805529220823, "Episode": 858, "Episode Step": 104}
{"Training time": 1.127143945230378, "Episode Reward": 5185.019432265395, "Mean Reward": 23.355943388582862, "Episode": 859, "Episode Step": 222}
{"Training time": 1.1278186408016417, "Episode Reward": 2224.583047803901, "Mean Reward": 39.72469728221252, "Episode": 860, "Episode Step": 56}
{"Training time": 1.1295420841375987, "Episode Reward": 4138.365463688039, "Mean Reward": 39.41300441607656, "Episode": 861, "Episode Step": 105}
{"Training time": 1.1310937207937242, "Episode Reward": 3161.3126511126434, "Mean Reward": 24.132157642081246, "Episode": 862, "Episode Step": 131}
{"Training time": 1.131755282746421, "Episode Reward": 2552.5955434943494, "Mean Reward": 47.27028784248795, "Episode": 863, "Episode Step": 54}
{"Training time": 1.1335769457949532, "Episode Reward": 4422.890440283694, "Mean Reward": 38.459916872032125, "Episode": 864, "Episode Step": 115}
{"Training time": 1.1351532530122332, "Episode Reward": 3016.113415964611, "Mean Reward": 23.023766534081, "Episode": 865, "Episode Step": 131}
{"Training time": 1.1365323163403405, "Episode Reward": 4806.340539648158, "Mean Reward": 41.79426556215789, "Episode": 866, "Episode Step": 115}
{"Training time": 1.1386497669087516, "Episode Reward": 4165.65208818258, "Mean Reward": 29.968720058867483, "Episode": 867, "Episode Step": 139}
{"Training time": 1.1413299836052788, "Episode Reward": 5233.024194791175, "Mean Reward": 22.752279107787718, "Episode": 868, "Episode Step": 230}
{"Training time": 1.1427002755138609, "Episode Reward": 4837.595668851134, "Mean Reward": 42.06604929435769, "Episode": 869, "Episode Step": 115}
{"Training time": 1.1452023422055775, "Episode Reward": 4172.5695740507335, "Mean Reward": 24.259125430527522, "Episode": 870, "Episode Step": 172}
{"Training time": 1.1465581721729703, "Episode Reward": 3316.220826003164, "Mean Reward": 28.836702834810122, "Episode": 871, "Episode Step": 115}
{"Training time": 1.1479372882843017, "Episode Reward": 4826.805924470988, "Mean Reward": 41.25475149120503, "Episode": 872, "Episode Step": 117}
{"Training time": 1.14962049027284, "Episode Reward": -12.6693607336246, "Mean Reward": -0.12420941895710393, "Episode": 873, "Episode Step": 102}
{"Training time": 1.1519775593943067, "Episode Reward": 5719.946063720063, "Mean Reward": 28.88861648343466, "Episode": 874, "Episode Step": 198}
{"Training time": 1.153335490822792, "Episode Reward": 5304.435520081924, "Mean Reward": 46.125526261581946, "Episode": 875, "Episode Step": 115}
{"Training time": 1.1561735385656358, "Episode Reward": 5604.695966447826, "Mean Reward": 28.023479832239133, "Episode": 876, "Episode Step": 200}
{"Training time": 1.1575020724534988, "Episode Reward": 3374.761992495262, "Mean Reward": 30.13180350442198, "Episode": 877, "Episode Step": 112}
{"Training time": 1.1588574610816107, "Episode Reward": 5536.035365231719, "Mean Reward": 49.42888718956892, "Episode": 878, "Episode Step": 112}
{"Training time": 1.1615008633004293, "Episode Reward": 5377.591436487501, "Mean Reward": 29.547205694986268, "Episode": 879, "Episode Step": 182}
{"Training time": 1.1629991710848278, "Episode Reward": 3388.122438278189, "Mean Reward": 26.889860621255465, "Episode": 880, "Episode Step": 126}
{"Training time": 1.1640675022204716, "Episode Reward": 4324.813767127253, "Mean Reward": 48.59341311378937, "Episode": 881, "Episode Step": 89}
{"Training time": 1.1671831732988358, "Episode Reward": 7801.044695943796, "Mean Reward": 34.9822632105103, "Episode": 882, "Episode Step": 223}
{"Training time": 1.1694889794455634, "Episode Reward": 6412.556802080236, "Mean Reward": 32.717126541225696, "Episode": 883, "Episode Step": 196}
{"Training time": 1.1708144274685117, "Episode Reward": 5121.299148500836, "Mean Reward": 45.72588525447175, "Episode": 884, "Episode Step": 112}
{"Training time": 1.1730031483040915, "Episode Reward": 5136.664887925373, "Mean Reward": 34.94329855731546, "Episode": 885, "Episode Step": 147}
{"Training time": 1.174715902739101, "Episode Reward": 4785.168844283445, "Mean Reward": 32.77512907043455, "Episode": 886, "Episode Step": 146}
{"Training time": 1.1760610608259836, "Episode Reward": 5326.640916330892, "Mean Reward": 47.98775600298101, "Episode": 887, "Episode Step": 111}
{"Training time": 1.17825835413403, "Episode Reward": 4808.527782019059, "Mean Reward": 32.27199853704066, "Episode": 888, "Episode Step": 149}
{"Training time": 1.179979984164238, "Episode Reward": 5565.817309485374, "Mean Reward": 38.12203636633818, "Episode": 889, "Episode Step": 146}
{"Training time": 1.1812998741202885, "Episode Reward": 5296.474657188341, "Mean Reward": 47.28995229632447, "Episode": 890, "Episode Step": 112}
{"Training time": 1.1831898330317603, "Episode Reward": 4333.347855106515, "Mean Reward": 35.230470366719636, "Episode": 891, "Episode Step": 123}
{"Training time": 1.1858381779988607, "Episode Reward": 8050.750594209614, "Mean Reward": 36.102020601836834, "Episode": 892, "Episode Step": 223}
{"Training time": 1.1871775960922242, "Episode Reward": 5604.046201226572, "Mean Reward": 50.03612679666582, "Episode": 893, "Episode Step": 112}
{"Training time": 1.1893185694350137, "Episode Reward": 4816.079535749979, "Mean Reward": 33.67887787237748, "Episode": 894, "Episode Step": 143}
{"Training time": 1.1906714416212505, "Episode Reward": 5340.301924948686, "Mean Reward": 46.84475372762005, "Episode": 895, "Episode Step": 114}
{"Training time": 1.1917957377433777, "Episode Reward": 4588.19549078636, "Mean Reward": 49.335435384799574, "Episode": 896, "Episode Step": 93}
{"Training time": 1.193710704975658, "Episode Reward": 4898.026283573267, "Mean Reward": 39.50021196430054, "Episode": 897, "Episode Step": 124}
{"Training time": 1.195342956052886, "Episode Reward": 6194.437170371091, "Mean Reward": 44.56429618972008, "Episode": 898, "Episode Step": 139}
{"Training time": 1.1969582686159346, "Episode Reward": 5236.9529625328505, "Mean Reward": 47.17975641921487, "Episode": 899, "Episode Step": 111}
{"Training time": 1.198800083597501, "Episode Reward": 4512.856640904064, "Mean Reward": 38.24454780427173, "Episode": 900, "Episode Step": 118}
{"Training time": 1.201015383336279, "Episode Reward": 7656.389736883052, "Mean Reward": 40.29678808885817, "Episode": 901, "Episode Step": 190}
{"Training time": 1.202361254956987, "Episode Reward": 4897.719075249631, "Mean Reward": 44.123595272519196, "Episode": 902, "Episode Step": 111}
{"Training time": 1.2046070410807928, "Episode Reward": 5483.9026665823, "Mean Reward": 36.80471588310269, "Episode": 903, "Episode Step": 149}
{"Training time": 1.2062203802665075, "Episode Reward": 5735.815767797338, "Mean Reward": 42.487524205906205, "Episode": 904, "Episode Step": 135}
{"Training time": 1.2075556972291734, "Episode Reward": 5193.542993875004, "Mean Reward": 46.37091958816968, "Episode": 905, "Episode Step": 112}
{"Training time": 1.2098039269447327, "Episode Reward": 6207.651092350701, "Mean Reward": 41.110272134772856, "Episode": 906, "Episode Step": 151}
{"Training time": 1.2112189675039715, "Episode Reward": 5031.647978320015, "Mean Reward": 42.641084562034024, "Episode": 907, "Episode Step": 118}
{"Training time": 1.2119233488374286, "Episode Reward": 2634.190854385062, "Mean Reward": 45.41708369629417, "Episode": 908, "Episode Step": 58}
{"Training time": 1.2138897113667595, "Episode Reward": 5238.56238761687, "Mean Reward": 41.57589196521325, "Episode": 909, "Episode Step": 126}
{"Training time": 1.2155650466680528, "Episode Reward": 5749.693197218688, "Mean Reward": 40.490797163511886, "Episode": 910, "Episode Step": 142}
{"Training time": 1.2168704408407212, "Episode Reward": 5163.195159887702, "Mean Reward": 46.93813781716093, "Episode": 911, "Episode Step": 110}
{"Training time": 1.218796312742763, "Episode Reward": 5894.7792812910975, "Mean Reward": 47.53854259105724, "Episode": 912, "Episode Step": 124}
{"Training time": 1.220344513323572, "Episode Reward": 5655.716907234689, "Mean Reward": 42.8463402063234, "Episode": 913, "Episode Step": 132}
{"Training time": 1.221658171084192, "Episode Reward": 5111.447883204087, "Mean Reward": 45.63792752860792, "Episode": 914, "Episode Step": 112}
{"Training time": 1.2233651957909266, "Episode Reward": 4897.654536643004, "Mean Reward": 48.01622094748043, "Episode": 915, "Episode Step": 102}
{"Training time": 1.225833897723092, "Episode Reward": 7883.413962718035, "Mean Reward": 37.185914918481295, "Episode": 916, "Episode Step": 212}
{"Training time": 1.226901614665985, "Episode Reward": 3884.8938533872843, "Mean Reward": 43.165487259858715, "Episode": 917, "Episode Step": 90}
{"Training time": 1.2286316216654247, "Episode Reward": 4918.561426253434, "Mean Reward": 45.967863796761065, "Episode": 918, "Episode Step": 107}
{"Training time": 1.230371984442075, "Episode Reward": 5793.3195881784, "Mean Reward": 39.9539281943338, "Episode": 919, "Episode Step": 145}
{"Training time": 1.2317657258113226, "Episode Reward": 5151.870292579302, "Mean Reward": 44.798872109385236, "Episode": 920, "Episode Step": 115}
{"Training time": 1.2335344105296664, "Episode Reward": 4739.751686403045, "Mean Reward": 43.483960425716006, "Episode": 921, "Episode Step": 109}
{"Training time": 1.235132392777337, "Episode Reward": 6037.650048913886, "Mean Reward": 45.39586502942772, "Episode": 922, "Episode Step": 133}
{"Training time": 1.2357847941584057, "Episode Reward": 2501.263395450439, "Mean Reward": 47.193648970763, "Episode": 923, "Episode Step": 53}
{"Training time": 1.237466379404068, "Episode Reward": 4987.730214379067, "Mean Reward": 48.89931582724575, "Episode": 924, "Episode Step": 102}
{"Training time": 1.238814473880662, "Episode Reward": 6071.126502816251, "Mean Reward": 54.206486632287955, "Episode": 925, "Episode Step": 112}
{"Training time": 1.2401461177402073, "Episode Reward": 5236.879179231681, "Mean Reward": 46.75784981456858, "Episode": 926, "Episode Step": 112}
{"Training time": 1.241857581337293, "Episode Reward": 5016.533477825441, "Mean Reward": 49.18170076299452, "Episode": 927, "Episode Step": 102}
{"Training time": 1.243560778564877, "Episode Reward": 6578.819994288845, "Mean Reward": 46.99157138777746, "Episode": 928, "Episode Step": 140}
{"Training time": 1.2448995719353357, "Episode Reward": 4589.77682572917, "Mean Reward": 41.34934077233486, "Episode": 929, "Episode Step": 111}
{"Training time": 1.2468152719073826, "Episode Reward": 5108.053647379026, "Mean Reward": 42.21531939982666, "Episode": 930, "Episode Step": 121}
{"Training time": 1.2483871969249514, "Episode Reward": 6425.62407061762, "Mean Reward": 49.42787746628939, "Episode": 931, "Episode Step": 130}
{"Training time": 1.2497739955451754, "Episode Reward": 4968.547811649836, "Mean Reward": 43.583752733770496, "Episode": 932, "Episode Step": 114}
{"Training time": 1.251488730510076, "Episode Reward": 4492.805081745128, "Mean Reward": 43.20004886293392, "Episode": 933, "Episode Step": 104}
{"Training time": 1.2531956252786849, "Episode Reward": 6579.600597626477, "Mean Reward": 46.011192990394946, "Episode": 934, "Episode Step": 143}
{"Training time": 1.2545946902698941, "Episode Reward": 5128.735330405998, "Mean Reward": 44.21323560694826, "Episode": 935, "Episode Step": 116}
{"Training time": 1.2567974927690293, "Episode Reward": 6044.539051798953, "Mean Reward": 40.84148007972265, "Episode": 936, "Episode Step": 148}
{"Training time": 1.2581554857889812, "Episode Reward": 5665.083156207605, "Mean Reward": 49.26159266267482, "Episode": 937, "Episode Step": 115}
{"Training time": 1.2594384644428889, "Episode Reward": 5066.787709485626, "Mean Reward": 46.914701013755796, "Episode": 938, "Episode Step": 108}
{"Training time": 1.2615890763865576, "Episode Reward": 5982.195441781267, "Mean Reward": 41.5430239012588, "Episode": 939, "Episode Step": 144}
{"Training time": 1.263274462752872, "Episode Reward": 6161.026190443431, "Mean Reward": 43.69522120881866, "Episode": 940, "Episode Step": 141}
{"Training time": 1.2643258885542552, "Episode Reward": 3708.9913409531664, "Mean Reward": 41.67406001070974, "Episode": 941, "Episode Step": 89}
{"Training time": 1.2664984649419784, "Episode Reward": 5697.04952929162, "Mean Reward": 39.0208871869289, "Episode": 942, "Episode Step": 146}
{"Training time": 1.2677964144282872, "Episode Reward": 5471.51092453474, "Mean Reward": 50.66213819013648, "Episode": 943, "Episode Step": 108}
{"Training time": 1.2689428966575198, "Episode Reward": 4268.492023496333, "Mean Reward": 44.00507240717869, "Episode": 944, "Episode Step": 97}
{"Training time": 1.270609925786654, "Episode Reward": 4146.468311529485, "Mean Reward": 39.86988761086043, "Episode": 945, "Episode Step": 104}
{"Training time": 1.272277741101053, "Episode Reward": 5707.572126935535, "Mean Reward": 40.47923494280521, "Episode": 946, "Episode Step": 141}
{"Training time": 1.2733852818939422, "Episode Reward": 4294.386800567434, "Mean Reward": 46.17620215663907, "Episode": 947, "Episode Step": 93}
{"Training time": 1.2750636182890998, "Episode Reward": 4424.966475158587, "Mean Reward": 43.38202426626066, "Episode": 948, "Episode Step": 102}
{"Training time": 1.2770017091433208, "Episode Reward": 6167.152000363329, "Mean Reward": 42.532082761126404, "Episode": 949, "Episode Step": 145}
{"Training time": 1.2783728085623847, "Episode Reward": 4131.512621552073, "Mean Reward": 44.90774588643558, "Episode": 950, "Episode Step": 92}
{"Training time": 1.28010632859336, "Episode Reward": 4821.950844272625, "Mean Reward": 44.238081140115824, "Episode": 951, "Episode Step": 109}
{"Training time": 1.2816552769475513, "Episode Reward": 5746.664922950698, "Mean Reward": 44.20511479192845, "Episode": 952, "Episode Step": 130}
{"Training time": 1.2827589399947061, "Episode Reward": 4207.551133165359, "Mean Reward": 45.24248530285332, "Episode": 953, "Episode Step": 93}
{"Training time": 1.2844298430283865, "Episode Reward": 4943.530602360568, "Mean Reward": 47.99544274136474, "Episode": 954, "Episode Step": 103}
{"Training time": 1.28498947388596, "Episode Reward": 2005.149259883316, "Mean Reward": 43.59020130181122, "Episode": 955, "Episode Step": 46}
{"Training time": 1.285706343319681, "Episode Reward": 2488.983930759473, "Mean Reward": 42.18616831795717, "Episode": 956, "Episode Step": 59}
{"Training time": 1.2873587460650338, "Episode Reward": 4535.870885149218, "Mean Reward": 44.46932240342371, "Episode": 957, "Episode Step": 102}
{"Training time": 1.2886865407890744, "Episode Reward": 4830.409604202375, "Mean Reward": 43.517203641462835, "Episode": 958, "Episode Step": 111}
{"Training time": 1.2901023324992922, "Episode Reward": 5177.0629849943325, "Mean Reward": 43.873415127070615, "Episode": 959, "Episode Step": 118}
{"Training time": 1.2923902869224548, "Episode Reward": 6154.414480031003, "Mean Reward": 39.96373038981171, "Episode": 960, "Episode Step": 154}
{"Training time": 1.2939122796720928, "Episode Reward": 5772.630994087366, "Mean Reward": 44.065885451048594, "Episode": 961, "Episode Step": 131}
{"Training time": 1.2949877499871785, "Episode Reward": 4288.722895964636, "Mean Reward": 47.128823032578424, "Episode": 962, "Episode Step": 91}
{"Training time": 1.2966693530480067, "Episode Reward": 4523.983700850723, "Mean Reward": 43.92217185291964, "Episode": 963, "Episode Step": 103}
{"Training time": 1.2993706360790465, "Episode Reward": 10022.600656034592, "Mean Reward": 43.95877480716926, "Episode": 964, "Episode Step": 228}
{"Training time": 1.3005823496977489, "Episode Reward": 4527.606655103341, "Mean Reward": 44.827788664389516, "Episode": 965, "Episode Step": 101}
{"Training time": 1.302234370244874, "Episode Reward": 4442.115010715188, "Mean Reward": 43.55014716387439, "Episode": 966, "Episode Step": 102}
{"Training time": 1.3039522899521723, "Episode Reward": 6703.946408586474, "Mean Reward": 46.23411316266534, "Episode": 967, "Episode Step": 145}
{"Training time": 1.30576474222872, "Episode Reward": 5811.497997815726, "Mean Reward": 38.23353945931399, "Episode": 968, "Episode Step": 152}
{"Training time": 1.3076351302199893, "Episode Reward": 5345.694152776001, "Mean Reward": 44.54745127313334, "Episode": 969, "Episode Step": 120}
{"Training time": 1.3090317085716459, "Episode Reward": 5020.551255883917, "Mean Reward": 43.65696744246885, "Episode": 970, "Episode Step": 115}
{"Training time": 1.31086387972037, "Episode Reward": 6336.37090344677, "Mean Reward": 41.4141889114168, "Episode": 971, "Episode Step": 153}
{"Training time": 1.3130096358060837, "Episode Reward": 5932.386877549182, "Mean Reward": 41.19713109409154, "Episode": 972, "Episode Step": 144}
{"Training time": 1.314316585527526, "Episode Reward": 4220.595787679877, "Mean Reward": 38.72106227229244, "Episode": 973, "Episode Step": 109}
{"Training time": 1.3159560327397453, "Episode Reward": 6188.886322912853, "Mean Reward": 44.52436203534427, "Episode": 974, "Episode Step": 139}
{"Training time": 1.3181148686011632, "Episode Reward": 6117.821040698312, "Mean Reward": 42.78196531956861, "Episode": 975, "Episode Step": 143}
{"Training time": 1.3204906900061502, "Episode Reward": 8745.525791836788, "Mean Reward": 43.29468213780588, "Episode": 976, "Episode Step": 202}
{"Training time": 1.3221476924419404, "Episode Reward": 6237.05490583604, "Mean Reward": 44.55039218454314, "Episode": 977, "Episode Step": 140}
{"Training time": 1.3243454844421811, "Episode Reward": 5890.30888454832, "Mean Reward": 40.070128466315104, "Episode": 978, "Episode Step": 147}
{"Training time": 1.3256991005606122, "Episode Reward": 5236.309006998091, "Mean Reward": 45.5331217999834, "Episode": 979, "Episode Step": 115}
{"Training time": 1.3271741030613582, "Episode Reward": 6166.1149284957055, "Mean Reward": 49.726733294320205, "Episode": 980, "Episode Step": 124}
{"Training time": 1.3288101019461949, "Episode Reward": 4247.752619958175, "Mean Reward": 41.644633529001716, "Episode": 981, "Episode Step": 102}
{"Training time": 1.330334752202034, "Episode Reward": 4870.213679550138, "Mean Reward": 37.46318215038568, "Episode": 982, "Episode Step": 130}
{"Training time": 1.3317874111069574, "Episode Reward": 5619.992827165714, "Mean Reward": 46.06551497676814, "Episode": 983, "Episode Step": 122}
{"Training time": 1.3334520422087774, "Episode Reward": 4407.762876379847, "Mean Reward": 43.21336153313575, "Episode": 984, "Episode Step": 102}
{"Training time": 1.3352158266305922, "Episode Reward": 4847.692424311672, "Mean Reward": 32.31794949541115, "Episode": 985, "Episode Step": 150}
{"Training time": 1.3366623344024022, "Episode Reward": 5726.257264509239, "Mean Reward": 47.32444020255569, "Episode": 986, "Episode Step": 121}
{"Training time": 1.338348904715644, "Episode Reward": 3934.0991756076864, "Mean Reward": 38.19513762725909, "Episode": 987, "Episode Step": 103}
{"Training time": 1.3403020877308316, "Episode Reward": 4642.779599880433, "Mean Reward": 27.968551806508632, "Episode": 988, "Episode Step": 166}
{"Training time": 1.3415131994088492, "Episode Reward": 4989.672120474417, "Mean Reward": 48.918354122298204, "Episode": 989, "Episode Step": 102}
{"Training time": 1.3433863033188713, "Episode Reward": 5123.737999712326, "Mean Reward": 41.32046773961553, "Episode": 990, "Episode Step": 124}
{"Training time": 1.3455699124601153, "Episode Reward": 4937.141331363103, "Mean Reward": 26.832289844364688, "Episode": 991, "Episode Step": 184}
{"Training time": 1.3470399522119099, "Episode Reward": 5546.084238448098, "Mean Reward": 45.83540692932313, "Episode": 992, "Episode Step": 121}
{"Training time": 1.3488710521989398, "Episode Reward": 5840.89629394955, "Mean Reward": 51.23593240306623, "Episode": 993, "Episode Step": 114}
{"Training time": 1.351145143310229, "Episode Reward": 5859.583195687508, "Mean Reward": 30.678446050719938, "Episode": 994, "Episode Step": 191}
{"Training time": 1.3525669544272954, "Episode Reward": 5254.831596382728, "Mean Reward": 43.7902633031894, "Episode": 995, "Episode Step": 120}
{"Training time": 1.3543921599785487, "Episode Reward": 5141.030879871021, "Mean Reward": 45.09676210413176, "Episode": 996, "Episode Step": 114}
{"Training time": 1.357475624680519, "Episode Reward": 7734.939754200012, "Mean Reward": 29.980386644186094, "Episode": 997, "Episode Step": 258}
{"Training time": 1.3588905016581216, "Episode Reward": 5427.775776027426, "Mean Reward": 46.39124594895236, "Episode": 998, "Episode Step": 117}
{"Training time": 1.3613321360614565, "Episode Reward": 5747.958534513473, "Mean Reward": 39.36957900351694, "Episode": 999, "Episode Step": 146}
{"Training time": 1.3628245766295326, "Episode Reward": 273.42621805569314, "Mean Reward": 2.6806491966244423, "Episode": 1000, "Episode Step": 102}
{"Training time": 1.3640277280410131, "Episode Reward": 4719.49084835096, "Mean Reward": 47.1949084835096, "Episode": 1001, "Episode Step": 100}
{"Training time": 1.3659723346763186, "Episode Reward": 5193.930296341312, "Mean Reward": 41.5514423707305, "Episode": 1002, "Episode Step": 125}
{"Training time": 1.3671904660595788, "Episode Reward": 343.6562306674004, "Mean Reward": 3.3691787320333373, "Episode": 1003, "Episode Step": 102}
{"Training time": 1.3683977052238252, "Episode Reward": 4725.408546098061, "Mean Reward": 47.25408546098061, "Episode": 1004, "Episode Step": 100}
{"Training time": 1.3711288725005255, "Episode Reward": 6978.82140595391, "Mean Reward": 36.53833196834508, "Episode": 1005, "Episode Step": 191}
{"Training time": 1.3736038702726363, "Episode Reward": 4015.556029032675, "Mean Reward": 19.031071227643007, "Episode": 1006, "Episode Step": 211}
{"Training time": 1.3743395041094886, "Episode Reward": 2564.5459018669553, "Mean Reward": 42.0417360961796, "Episode": 1007, "Episode Step": 61}
{"Training time": 1.3766142816676035, "Episode Reward": 6265.126815797281, "Mean Reward": 40.94854127972079, "Episode": 1008, "Episode Step": 153}
{"Training time": 1.37784074332979, "Episode Reward": 118.84047681213889, "Mean Reward": 1.165102713844499, "Episode": 1009, "Episode Step": 102}
{"Training time": 1.3792648655176163, "Episode Reward": 5241.773410509156, "Mean Reward": 44.04851605469879, "Episode": 1010, "Episode Step": 119}
{"Training time": 1.3814732021755642, "Episode Reward": 6022.663240799537, "Mean Reward": 41.25111808766806, "Episode": 1011, "Episode Step": 146}
{"Training time": 1.3828004441658657, "Episode Reward": 466.81756679912974, "Mean Reward": 4.282729970634218, "Episode": 1012, "Episode Step": 109}
{"Training time": 1.3841718247201709, "Episode Reward": 4909.088913796943, "Mean Reward": 42.68772968519081, "Episode": 1013, "Episode Step": 115}
{"Training time": 1.3860500472121768, "Episode Reward": 5669.986440338439, "Mean Reward": 47.24988700282032, "Episode": 1014, "Episode Step": 120}
{"Training time": 1.3894320863485337, "Episode Reward": 5437.424128376084, "Mean Reward": 18.945728670299943, "Episode": 1015, "Episode Step": 287}
{"Training time": 1.3905611399809519, "Episode Reward": 4550.068854881821, "Mean Reward": 47.89546163033496, "Episode": 1016, "Episode Step": 95}
{"Training time": 1.3924640049537023, "Episode Reward": 5829.299071697423, "Mean Reward": 49.400839590656126, "Episode": 1017, "Episode Step": 118}
{"Training time": 1.3937031785647074, "Episode Reward": 108.64778063170832, "Mean Reward": 1.065174319918709, "Episode": 1018, "Episode Step": 102}
{"Training time": 1.3948754816585116, "Episode Reward": 4656.132446616749, "Mean Reward": 49.01192049070262, "Episode": 1019, "Episode Step": 95}
{"Training time": 1.3971042819155588, "Episode Reward": 5826.146350057749, "Mean Reward": 39.63364863984864, "Episode": 1020, "Episode Step": 147}
{"Training time": 1.3983440316385694, "Episode Reward": 209.00617937781473, "Mean Reward": 2.029186207551599, "Episode": 1021, "Episode Step": 103}
{"Training time": 1.4000684552722507, "Episode Reward": 5952.219617169127, "Mean Reward": 41.623913406777106, "Episode": 1022, "Episode Step": 143}
{"Training time": 1.4019518549574745, "Episode Reward": 5628.566008035836, "Mean Reward": 48.52212075892962, "Episode": 1023, "Episode Step": 116}
{"Training time": 1.4033658946885004, "Episode Reward": 434.67546162745026, "Mean Reward": 3.715174885704703, "Episode": 1024, "Episode Step": 117}
{"Training time": 1.4047641066710155, "Episode Reward": 5268.284491644682, "Mean Reward": 45.81116949256245, "Episode": 1025, "Episode Step": 115}
{"Training time": 1.406930839419365, "Episode Reward": 6206.383368357859, "Mean Reward": 43.7069251292807, "Episode": 1026, "Episode Step": 142}
{"Training time": 1.4081464280022515, "Episode Reward": 191.09223267564192, "Mean Reward": 1.8734532615259012, "Episode": 1027, "Episode Step": 102}
{"Training time": 1.409300309419632, "Episode Reward": 4208.362825707283, "Mean Reward": 44.29855606007666, "Episode": 1028, "Episode Step": 95}
{"Training time": 1.4116203863753214, "Episode Reward": 6067.7597983798805, "Mean Reward": 38.895896143460774, "Episode": 1029, "Episode Step": 156}
{"Training time": 1.4131045224931504, "Episode Reward": 410.2831564200631, "Mean Reward": 3.308735132419864, "Episode": 1030, "Episode Step": 124}
{"Training time": 1.414830924404992, "Episode Reward": 6185.789107338134, "Mean Reward": 42.66061453336644, "Episode": 1031, "Episode Step": 145}
{"Training time": 1.4168073949548934, "Episode Reward": 5754.09194488641, "Mean Reward": 44.953843319425076, "Episode": 1032, "Episode Step": 128}
{"Training time": 1.4193801071908738, "Episode Reward": 4091.4865463999026, "Mean Reward": 18.68258696986257, "Episode": 1033, "Episode Step": 219}
{"Training time": 1.4206873810953564, "Episode Reward": 5165.648765701239, "Mean Reward": 46.96044332455672, "Episode": 1034, "Episode Step": 110}
{"Training time": 1.422533312175009, "Episode Reward": 5576.0509966159625, "Mean Reward": 48.069405143241056, "Episode": 1035, "Episode Step": 116}
{"Training time": 1.4245758310953776, "Episode Reward": 5905.406575003658, "Mean Reward": 34.135298121408425, "Episode": 1036, "Episode Step": 173}
{"Training time": 1.4262963760561413, "Episode Reward": 5941.945551771275, "Mean Reward": 40.978934839801894, "Episode": 1037, "Episode Step": 145}
{"Training time": 1.428175758851899, "Episode Reward": 5517.665521443579, "Mean Reward": 45.98054601202982, "Episode": 1038, "Episode Step": 120}
{"Training time": 1.4306886713372335, "Episode Reward": 5184.458607095092, "Mean Reward": 24.340181253967568, "Episode": 1039, "Episode Step": 213}
{"Training time": 1.432076939675543, "Episode Reward": 4931.852194597448, "Mean Reward": 42.88567125736911, "Episode": 1040, "Episode Step": 115}
{"Training time": 1.433913207186593, "Episode Reward": 5760.46881848305, "Mean Reward": 50.091033204200436, "Episode": 1041, "Episode Step": 115}
{"Training time": 1.435348415242301, "Episode Reward": 4127.62365269396, "Mean Reward": 34.6859130478484, "Episode": 1042, "Episode Step": 119}
{"Training time": 1.4369065346982743, "Episode Reward": 5225.279478021376, "Mean Reward": 40.194457523241354, "Episode": 1043, "Episode Step": 130}
{"Training time": 1.4386126091745164, "Episode Reward": 4678.408756923626, "Mean Reward": 44.9846995858041, "Episode": 1044, "Episode Step": 104}
{"Training time": 1.4398526163895924, "Episode Reward": 242.24673166693236, "Mean Reward": 2.374967957518945, "Episode": 1045, "Episode Step": 102}
{"Training time": 1.4412087727255292, "Episode Reward": 4725.091125474789, "Mean Reward": 41.44816776732271, "Episode": 1046, "Episode Step": 114}
{"Training time": 1.4429186605082618, "Episode Reward": 4813.985570674675, "Mean Reward": 46.2883227949488, "Episode": 1047, "Episode Step": 104}
{"Training time": 1.4452606802516514, "Episode Reward": 6206.472944667309, "Mean Reward": 31.828066382909277, "Episode": 1048, "Episode Step": 195}
{"Training time": 1.4472792969147363, "Episode Reward": 4658.921600549013, "Mean Reward": 32.353622226034815, "Episode": 1049, "Episode Step": 144}
{"Training time": 1.4491826372014152, "Episode Reward": 5001.382124355655, "Mean Reward": 41.333736564922766, "Episode": 1050, "Episode Step": 121}
{"Training time": 1.450887884961234, "Episode Reward": 3975.2770432673624, "Mean Reward": 27.799140162708827, "Episode": 1051, "Episode Step": 143}
{"Training time": 1.4521827369266087, "Episode Reward": 4309.4871890555405, "Mean Reward": 39.177156264141274, "Episode": 1052, "Episode Step": 110}
{"Training time": 1.4540504919158088, "Episode Reward": 5288.6505207186, "Mean Reward": 44.819072209479664, "Episode": 1053, "Episode Step": 118}
{"Training time": 1.4546637530459299, "Episode Reward": 2223.8832254438994, "Mean Reward": 41.96006085743206, "Episode": 1054, "Episode Step": 53}
{"Training time": 1.4560291843944126, "Episode Reward": 4417.962230191146, "Mean Reward": 38.41706287122736, "Episode": 1055, "Episode Step": 115}
{"Training time": 1.457906994952096, "Episode Reward": 5787.979807370493, "Mean Reward": 48.23316506142078, "Episode": 1056, "Episode Step": 120}
{"Training time": 1.4595548930433062, "Episode Reward": 5524.957580868951, "Mean Reward": 40.32815752459088, "Episode": 1057, "Episode Step": 137}
{"Training time": 1.4601859188742108, "Episode Reward": 1261.611677174472, "Mean Reward": 24.73748386616612, "Episode": 1058, "Episode Step": 51}
{"Training time": 1.461937036646737, "Episode Reward": 5459.975604614985, "Mean Reward": 49.63614186013623, "Episode": 1059, "Episode Step": 110}
{"Training time": 1.4636835257874594, "Episode Reward": 5466.529908103831, "Mean Reward": 36.443532720692204, "Episode": 1060, "Episode Step": 150}
{"Training time": 1.4653865324788624, "Episode Reward": 3554.181153733668, "Mean Reward": 24.854413662473203, "Episode": 1061, "Episode Step": 143}
{"Training time": 1.467217016087638, "Episode Reward": 5218.436663717466, "Mean Reward": 46.593184497477374, "Episode": 1062, "Episode Step": 112}
{"Training time": 1.4687617355585099, "Episode Reward": 5060.496680174845, "Mean Reward": 40.16267206487972, "Episode": 1063, "Episode Step": 126}
{"Training time": 1.4700812186135186, "Episode Reward": 3998.4314180965926, "Mean Reward": 36.34937652815084, "Episode": 1064, "Episode Step": 110}
{"Training time": 1.4718945897287792, "Episode Reward": 5171.446284541567, "Mean Reward": 46.17362754054971, "Episode": 1065, "Episode Step": 112}
{"Training time": 1.473548878563775, "Episode Reward": 5643.633228522543, "Mean Reward": 40.60167790303988, "Episode": 1066, "Episode Step": 139}
{"Training time": 1.4748984194464154, "Episode Reward": 4330.31532928623, "Mean Reward": 38.321374595453364, "Episode": 1067, "Episode Step": 113}
{"Training time": 1.4767040280501047, "Episode Reward": 5796.458446972115, "Mean Reward": 50.84612672782557, "Episode": 1068, "Episode Step": 114}
{"Training time": 1.4784147216214074, "Episode Reward": 5270.141502151775, "Mean Reward": 37.11367255036461, "Episode": 1069, "Episode Step": 142}
{"Training time": 1.4790365716483858, "Episode Reward": 1016.6785821038104, "Mean Reward": 19.934874158898243, "Episode": 1070, "Episode Step": 51}
{"Training time": 1.480828775498602, "Episode Reward": 5669.789176222551, "Mean Reward": 50.62311764484421, "Episode": 1071, "Episode Step": 112}
{"Training time": 1.4821484308110342, "Episode Reward": 4604.684895178701, "Mean Reward": 42.24481555209817, "Episode": 1072, "Episode Step": 109}
{"Training time": 1.4827805138958825, "Episode Reward": 1138.7492497002684, "Mean Reward": 21.485834900005063, "Episode": 1073, "Episode Step": 53}
{"Training time": 1.484641000562244, "Episode Reward": 5266.725007603031, "Mean Reward": 45.79760876176549, "Episode": 1074, "Episode Step": 115}
{"Training time": 1.4863297296894922, "Episode Reward": 5218.58962020058, "Mean Reward": 37.27564014428985, "Episode": 1075, "Episode Step": 140}
{"Training time": 1.4882308499680625, "Episode Reward": 3992.6553106039073, "Mean Reward": 24.799101308098802, "Episode": 1076, "Episode Step": 161}
{"Training time": 1.4900497880246903, "Episode Reward": 5335.3800532774185, "Mean Reward": 46.394609158934074, "Episode": 1077, "Episode Step": 115}
{"Training time": 1.4917305299970838, "Episode Reward": 5060.021991247075, "Mean Reward": 36.14301422319339, "Episode": 1078, "Episode Step": 140}
{"Training time": 1.493031148314476, "Episode Reward": 3698.1290438892943, "Mean Reward": 33.92778939347976, "Episode": 1079, "Episode Step": 109}
{"Training time": 1.494833030237092, "Episode Reward": 4995.687306243549, "Mean Reward": 43.821818475820606, "Episode": 1080, "Episode Step": 114}
{"Training time": 1.4964462361070845, "Episode Reward": 4304.410943730146, "Mean Reward": 31.88452550911219, "Episode": 1081, "Episode Step": 135}
{"Training time": 1.497092478275299, "Episode Reward": 930.3538394474726, "Mean Reward": 17.553846027310804, "Episode": 1082, "Episode Step": 53}
{"Training time": 1.4988675936063132, "Episode Reward": 5525.336734551638, "Mean Reward": 49.77780841938413, "Episode": 1083, "Episode Step": 111}
{"Training time": 1.5005225121974946, "Episode Reward": 4576.788944216654, "Mean Reward": 32.69134960154753, "Episode": 1084, "Episode Step": 140}
{"Training time": 1.5021700530582005, "Episode Reward": 4080.96863244195, "Mean Reward": 29.788092207605473, "Episode": 1085, "Episode Step": 137}
{"Training time": 1.5040378808312946, "Episode Reward": 5388.621628662133, "Mean Reward": 45.66628498866214, "Episode": 1086, "Episode Step": 118}
{"Training time": 1.5057219327820672, "Episode Reward": 4145.34330571768, "Mean Reward": 29.192558490969578, "Episode": 1087, "Episode Step": 142}
{"Training time": 1.5071388274431228, "Episode Reward": 3580.7787794160736, "Mean Reward": 30.090577978286333, "Episode": 1088, "Episode Step": 119}
{"Training time": 1.5089556619193818, "Episode Reward": 5326.600559747849, "Mean Reward": 47.13805805086592, "Episode": 1089, "Episode Step": 113}
{"Training time": 1.5106781863503986, "Episode Reward": 4397.612097679618, "Mean Reward": 29.91572855564366, "Episode": 1090, "Episode Step": 147}
{"Training time": 1.5120769641134475, "Episode Reward": 3897.1546172512244, "Mean Reward": 33.596160493545035, "Episode": 1091, "Episode Step": 116}
{"Training time": 1.5138963930474387, "Episode Reward": 5671.353350503898, "Mean Reward": 49.31611609133824, "Episode": 1092, "Episode Step": 115}
{"Training time": 1.515571943057908, "Episode Reward": 5142.84590620326, "Mean Reward": 36.217224691572255, "Episode": 1093, "Episode Step": 142}
{"Training time": 1.5168720885780123, "Episode Reward": 2596.691350279585, "Mean Reward": 23.82285642458335, "Episode": 1094, "Episode Step": 109}
{"Training time": 1.5186639988422395, "Episode Reward": 5251.15725005986, "Mean Reward": 46.88533258982018, "Episode": 1095, "Episode Step": 112}
{"Training time": 1.52039238108529, "Episode Reward": 4769.027667395814, "Mean Reward": 32.66457306435489, "Episode": 1096, "Episode Step": 146}
{"Training time": 1.5217503927813636, "Episode Reward": 3308.2208630125656, "Mean Reward": 28.51914537079798, "Episode": 1097, "Episode Step": 116}
{"Training time": 1.5235475663344065, "Episode Reward": 5430.517459763715, "Mean Reward": 48.05767663507712, "Episode": 1098, "Episode Step": 113}
{"Training time": 1.5254377024703556, "Episode Reward": 4943.490475685039, "Mean Reward": 35.822394751340866, "Episode": 1099, "Episode Step": 138}
{"Training time": 1.526461006336742, "Episode Reward": 873.8284666246457, "Mean Reward": 13.87029312102612, "Episode": 1100, "Episode Step": 63}
{"Training time": 1.5282538077566359, "Episode Reward": 5413.4824861772095, "Mean Reward": 47.48668847523868, "Episode": 1101, "Episode Step": 114}
{"Training time": 1.5299928388330672, "Episode Reward": 4760.379729131453, "Mean Reward": 32.16472789953684, "Episode": 1102, "Episode Step": 148}
{"Training time": 1.5313591502772437, "Episode Reward": 3276.672440548193, "Mean Reward": 28.99710124378932, "Episode": 1103, "Episode Step": 113}
{"Training time": 1.5331881535715528, "Episode Reward": 5758.175476121724, "Mean Reward": 50.51031119405022, "Episode": 1104, "Episode Step": 114}
{"Training time": 1.535000184443262, "Episode Reward": 5074.972642520299, "Mean Reward": 32.954367808573366, "Episode": 1105, "Episode Step": 154}
{"Training time": 1.5362708222203785, "Episode Reward": 3254.9307769136753, "Mean Reward": 30.706894121827126, "Episode": 1106, "Episode Step": 106}
{"Training time": 1.5381524991326863, "Episode Reward": 6050.027518349255, "Mean Reward": 51.271419647027585, "Episode": 1107, "Episode Step": 118}
{"Training time": 1.539855331381162, "Episode Reward": 4901.29848354368, "Mean Reward": 34.27481457023553, "Episode": 1108, "Episode Step": 143}
{"Training time": 1.5412040652831396, "Episode Reward": 3775.696461630851, "Mean Reward": 33.711575550275455, "Episode": 1109, "Episode Step": 112}
{"Training time": 1.5434782350063323, "Episode Reward": 6420.540713320715, "Mean Reward": 43.38203184676159, "Episode": 1110, "Episode Step": 148}
{"Training time": 1.5453613413704765, "Episode Reward": 4664.719763853693, "Mean Reward": 29.9020497682929, "Episode": 1111, "Episode Step": 156}
{"Training time": 1.5467822263638178, "Episode Reward": 3678.853289395793, "Mean Reward": 31.44319050765635, "Episode": 1112, "Episode Step": 117}
{"Training time": 1.5486483377218248, "Episode Reward": 5212.3628312252695, "Mean Reward": 44.55010966859205, "Episode": 1113, "Episode Step": 117}
{"Training time": 1.5498928930362066, "Episode Reward": 3171.8692071143532, "Mean Reward": 31.09675693249366, "Episode": 1114, "Episode Step": 102}
{"Training time": 1.5512806416220135, "Episode Reward": 3615.2206451697634, "Mean Reward": 31.71246179973477, "Episode": 1115, "Episode Step": 114}
{"Training time": 1.5531882391373317, "Episode Reward": 5593.815969233434, "Mean Reward": 46.615133076945284, "Episode": 1116, "Episode Step": 120}
{"Training time": 1.5540728988912371, "Episode Reward": 1754.471283955269, "Mean Reward": 24.0338532048667, "Episode": 1117, "Episode Step": 73}
{"Training time": 1.5554730919334623, "Episode Reward": 3498.553975206343, "Mean Reward": 30.689069957950377, "Episode": 1118, "Episode Step": 114}
{"Training time": 1.5573853577507866, "Episode Reward": 5742.499859222576, "Mean Reward": 48.66525304425912, "Episode": 1119, "Episode Step": 118}
{"Training time": 1.558656972779168, "Episode Reward": 3985.3817526312378, "Mean Reward": 38.69302672457513, "Episode": 1120, "Episode Step": 103}
{"Training time": 1.560095178021325, "Episode Reward": 2937.802565593808, "Mean Reward": 24.896631911811934, "Episode": 1121, "Episode Step": 118}
{"Training time": 1.5623553352223503, "Episode Reward": 5918.634802048605, "Mean Reward": 39.1962569672093, "Episode": 1122, "Episode Step": 151}
{"Training time": 1.5642779163519542, "Episode Reward": 5083.970227782077, "Mean Reward": 31.774813923637982, "Episode": 1123, "Episode Step": 160}
{"Training time": 1.5646718988815944, "Episode Reward": 159.58001000137432, "Mean Reward": 5.3193336667124775, "Episode": 1124, "Episode Step": 30}
{"Training time": 1.566558816101816, "Episode Reward": 5414.656657926432, "Mean Reward": 45.50131645316329, "Episode": 1125, "Episode Step": 119}
{"Training time": 1.5683347224526936, "Episode Reward": 4336.463781516829, "Mean Reward": 29.30043095619479, "Episode": 1126, "Episode Step": 148}
{"Training time": 1.5696651208400727, "Episode Reward": 3312.2012315204856, "Mean Reward": 29.05439676772356, "Episode": 1127, "Episode Step": 114}
{"Training time": 1.5719600088728798, "Episode Reward": 6478.186250261164, "Mean Reward": 42.34108660301414, "Episode": 1128, "Episode Step": 153}
{"Training time": 1.5737838266293207, "Episode Reward": 5404.0789009782675, "Mean Reward": 35.55315066433071, "Episode": 1129, "Episode Step": 152}
{"Training time": 1.574408630794949, "Episode Reward": 1151.4250172903498, "Mean Reward": 22.576961123340194, "Episode": 1130, "Episode Step": 51}
{"Training time": 1.5766576260990566, "Episode Reward": 6413.804202764536, "Mean Reward": 43.045665790366016, "Episode": 1131, "Episode Step": 149}
{"Training time": 1.5784868838389714, "Episode Reward": 5270.963718119321, "Mean Reward": 34.677392882363954, "Episode": 1132, "Episode Step": 152}
{"Training time": 1.579838983880149, "Episode Reward": 3680.0641074344144, "Mean Reward": 32.28126410030188, "Episode": 1133, "Episode Step": 114}
{"Training time": 1.5821681335899564, "Episode Reward": 6559.110238824191, "Mean Reward": 41.77777222181013, "Episode": 1134, "Episode Step": 157}
{"Training time": 1.5834841136137645, "Episode Reward": 4477.821923203842, "Mean Reward": 40.340738046881455, "Episode": 1135, "Episode Step": 111}
{"Training time": 1.5852039963669247, "Episode Reward": 4260.441283759389, "Mean Reward": 29.586397803884648, "Episode": 1136, "Episode Step": 144}
{"Training time": 1.5871820016702016, "Episode Reward": 6021.929189053416, "Mean Reward": 48.56394507301142, "Episode": 1137, "Episode Step": 124}
{"Training time": 1.5888815332783592, "Episode Reward": 5442.608295620063, "Mean Reward": 38.3282274339441, "Episode": 1138, "Episode Step": 142}
{"Training time": 1.5895451202657487, "Episode Reward": 1468.527644238001, "Mean Reward": 27.708068759207563, "Episode": 1139, "Episode Step": 53}
{"Training time": 1.5917977546983295, "Episode Reward": 5354.583613507567, "Mean Reward": 35.93680277521857, "Episode": 1140, "Episode Step": 149}
{"Training time": 1.5935041632917193, "Episode Reward": 5236.83192053335, "Mean Reward": 36.62120224149196, "Episode": 1141, "Episode Step": 143}
{"Training time": 1.5941361263725493, "Episode Reward": 1311.9304835333967, "Mean Reward": 25.229432375642244, "Episode": 1142, "Episode Step": 52}
{"Training time": 1.5964282594124477, "Episode Reward": 6389.580177350777, "Mean Reward": 41.76196194346913, "Episode": 1143, "Episode Step": 153}
{"Training time": 1.5977714838584265, "Episode Reward": 4742.954237204001, "Mean Reward": 41.604861729859664, "Episode": 1144, "Episode Step": 114}
{"Training time": 1.5990912297036912, "Episode Reward": 3229.3447101622514, "Mean Reward": 29.093195587047312, "Episode": 1145, "Episode Step": 111}
{"Training time": 1.601354664961497, "Episode Reward": 6484.3024549802285, "Mean Reward": 43.22868303320152, "Episode": 1146, "Episode Step": 150}
{"Training time": 1.6027397382921642, "Episode Reward": 4191.22673856254, "Mean Reward": 37.42166730859411, "Episode": 1147, "Episode Step": 112}
{"Training time": 1.6040858391258452, "Episode Reward": 3498.10712796319, "Mean Reward": 31.800973890574454, "Episode": 1148, "Episode Step": 110}
{"Training time": 1.6069183921813965, "Episode Reward": 6709.31826868158, "Mean Reward": 43.285924314074705, "Episode": 1149, "Episode Step": 155}
{"Training time": 1.6089546036058002, "Episode Reward": 5464.945001007555, "Mean Reward": 37.176496605493575, "Episode": 1150, "Episode Step": 147}
{"Training time": 1.6102825791305966, "Episode Reward": 3733.50063721575, "Mean Reward": 33.63514087581757, "Episode": 1151, "Episode Step": 111}
{"Training time": 1.6124654671880934, "Episode Reward": 6450.6513078113885, "Mean Reward": 44.182543204187596, "Episode": 1152, "Episode Step": 146}
{"Training time": 1.6151990805069605, "Episode Reward": 9010.272291082512, "Mean Reward": 39.00550775360395, "Episode": 1153, "Episode Step": 231}
{"Training time": 1.6158228930499818, "Episode Reward": 1435.1902328048986, "Mean Reward": 28.140984956958796, "Episode": 1154, "Episode Step": 51}
{"Training time": 1.6190720307826996, "Episode Reward": 11308.166723193312, "Mean Reward": 47.51330555963576, "Episode": 1155, "Episode Step": 238}
{"Training time": 1.620826142165396, "Episode Reward": 5503.947668582723, "Mean Reward": 37.4418208747124, "Episode": 1156, "Episode Step": 147}
{"Training time": 1.622498813006613, "Episode Reward": 4539.558983640879, "Mean Reward": 32.42542131172056, "Episode": 1157, "Episode Step": 140}
{"Training time": 1.6247261557976405, "Episode Reward": 6326.057802739876, "Mean Reward": 42.45676377677769, "Episode": 1158, "Episode Step": 149}
{"Training time": 1.6263889835940466, "Episode Reward": 5098.572690076779, "Mean Reward": 36.946178913599844, "Episode": 1159, "Episode Step": 138}
{"Training time": 1.6269870660702388, "Episode Reward": 1487.1889353092697, "Mean Reward": 30.35079459814836, "Episode": 1160, "Episode Step": 49}
{"Training time": 1.6301333496967951, "Episode Reward": 10214.028585430107, "Mean Reward": 45.19481674969074, "Episode": 1161, "Episode Step": 226}
{"Training time": 1.6317768808205921, "Episode Reward": 5302.287525566013, "Mean Reward": 38.42237337366676, "Episode": 1162, "Episode Step": 138}
{"Training time": 1.6324010186062918, "Episode Reward": 1896.5760699857742, "Mean Reward": 37.187766078152436, "Episode": 1163, "Episode Step": 51}
{"Training time": 1.6343545541498397, "Episode Reward": 6099.918775674657, "Mean Reward": 50.83265646395547, "Episode": 1164, "Episode Step": 120}
{"Training time": 1.63569609105587, "Episode Reward": 4662.992956684827, "Mean Reward": 41.265424395440945, "Episode": 1165, "Episode Step": 113}
{"Training time": 1.6363133149676852, "Episode Reward": 1802.0545980409986, "Mean Reward": 36.776624449816296, "Episode": 1166, "Episode Step": 49}
{"Training time": 1.6385462882783677, "Episode Reward": 6394.823720122537, "Mean Reward": 43.50220217770433, "Episode": 1167, "Episode Step": 147}
{"Training time": 1.6398829872078367, "Episode Reward": 4284.542452878873, "Mean Reward": 38.59948155746732, "Episode": 1168, "Episode Step": 111}
{"Training time": 1.6415666727224987, "Episode Reward": 5618.342297796654, "Mean Reward": 40.13101641283324, "Episode": 1169, "Episode Step": 140}
{"Training time": 1.6448172341452705, "Episode Reward": 9287.19423173858, "Mean Reward": 39.51997545420672, "Episode": 1170, "Episode Step": 235}
{"Training time": 1.6463461580541399, "Episode Reward": 5020.159005482741, "Mean Reward": 39.84253178954557, "Episode": 1171, "Episode Step": 126}
{"Training time": 1.6469356718990538, "Episode Reward": 1897.9326141919255, "Mean Reward": 38.73331865697807, "Episode": 1172, "Episode Step": 49}
{"Training time": 1.6491849130392076, "Episode Reward": 6266.940241299928, "Mean Reward": 42.34419081959411, "Episode": 1173, "Episode Step": 148}
{"Training time": 1.6514160191350513, "Episode Reward": 6772.4341981592615, "Mean Reward": 36.60775242248249, "Episode": 1174, "Episode Step": 185}
{"Training time": 1.6520366897185643, "Episode Reward": 1613.9802251096753, "Mean Reward": 32.938371941013784, "Episode": 1175, "Episode Step": 49}
{"Training time": 1.6542618893914753, "Episode Reward": 6787.044503621709, "Mean Reward": 45.85840880825479, "Episode": 1176, "Episode Step": 148}
{"Training time": 1.6559980436166128, "Episode Reward": 5014.39814489581, "Mean Reward": 34.58205617169524, "Episode": 1177, "Episode Step": 145}
{"Training time": 1.6566130285792882, "Episode Reward": 1643.5666780500967, "Mean Reward": 32.87133356100193, "Episode": 1178, "Episode Step": 50}
{"Training time": 1.6598342602782779, "Episode Reward": 10625.424323727824, "Mean Reward": 45.40779625524711, "Episode": 1179, "Episode Step": 234}
{"Training time": 1.661309336092737, "Episode Reward": 5443.6053835744315, "Mean Reward": 43.90004341592284, "Episode": 1180, "Episode Step": 124}
{"Training time": 1.661921696331766, "Episode Reward": 1745.0065481582435, "Mean Reward": 34.21581466976948, "Episode": 1181, "Episode Step": 51}
{"Training time": 1.6651566210720274, "Episode Reward": 9521.807080190778, "Mean Reward": 40.86612480768574, "Episode": 1182, "Episode Step": 233}
{"Training time": 1.6670057872268889, "Episode Reward": 5556.484741394642, "Mean Reward": 36.7979121946665, "Episode": 1183, "Episode Step": 151}
{"Training time": 1.6676022777292463, "Episode Reward": 1580.5278030483187, "Mean Reward": 32.25566944996569, "Episode": 1184, "Episode Step": 49}
{"Training time": 1.6708231272300085, "Episode Reward": 10804.74509117964, "Mean Reward": 46.57217711715362, "Episode": 1185, "Episode Step": 232}
{"Training time": 1.6725769738356273, "Episode Reward": 4930.517368179566, "Mean Reward": 34.0035680564108, "Episode": 1186, "Episode Step": 145}
{"Training time": 1.673189723028077, "Episode Reward": 1938.9431615802368, "Mean Reward": 38.01849336431837, "Episode": 1187, "Episode Step": 51}
{"Training time": 1.6761331730418736, "Episode Reward": 8796.851506425981, "Mean Reward": 42.09019859533962, "Episode": 1188, "Episode Step": 209}
{"Training time": 1.6778333116239972, "Episode Reward": 4775.757020729585, "Mean Reward": 33.39690224286423, "Episode": 1189, "Episode Step": 143}
{"Training time": 1.6784405288431379, "Episode Reward": 1741.899275856205, "Mean Reward": 35.54896481339193, "Episode": 1190, "Episode Step": 49}
{"Training time": 1.6815343449513118, "Episode Reward": 10245.406037770652, "Mean Reward": 45.94352483305225, "Episode": 1191, "Episode Step": 223}
{"Training time": 1.6825580105516647, "Episode Reward": 2904.294709958526, "Mean Reward": 33.77086872044797, "Episode": 1192, "Episode Step": 86}
{"Training time": 1.6832007757822673, "Episode Reward": 1679.024814021031, "Mean Reward": 31.679713472094924, "Episode": 1193, "Episode Step": 53}
{"Training time": 1.685302663842837, "Episode Reward": 6521.210831491353, "Mean Reward": 46.91518583806729, "Episode": 1194, "Episode Step": 139}
{"Training time": 1.6870199677679274, "Episode Reward": 4463.641566337836, "Mean Reward": 30.99751087734608, "Episode": 1195, "Episode Step": 144}
{"Training time": 1.687632217473454, "Episode Reward": 1826.11239283471, "Mean Reward": 36.5222478566942, "Episode": 1196, "Episode Step": 50}
{"Training time": 1.6908463858233558, "Episode Reward": 9887.975875754402, "Mean Reward": 42.0764930883166, "Episode": 1197, "Episode Step": 235}
{"Training time": 1.692596937749121, "Episode Reward": 5005.55762973205, "Mean Reward": 34.05141244715681, "Episode": 1198, "Episode Step": 147}
{"Training time": 1.6937338797251384, "Episode Reward": 1691.9069108131484, "Mean Reward": 33.83813821626297, "Episode": 1199, "Episode Step": 50}
{"Training time": 1.6968930016623602, "Episode Reward": 9923.485545506963, "Mean Reward": 44.10438020225317, "Episode": 1200, "Episode Step": 225}
{"Training time": 1.6987744902239905, "Episode Reward": 5658.627467237415, "Mean Reward": 35.814097893907686, "Episode": 1201, "Episode Step": 158}
{"Training time": 1.6994110102785958, "Episode Reward": 2094.6764349639207, "Mean Reward": 41.072086960076874, "Episode": 1202, "Episode Step": 51}
{"Training time": 1.701656107770072, "Episode Reward": 5989.611984574022, "Mean Reward": 40.198738151503505, "Episode": 1203, "Episode Step": 149}
{"Training time": 1.7033857341607412, "Episode Reward": 4772.979992788341, "Mean Reward": 33.37748246705134, "Episode": 1204, "Episode Step": 143}
{"Training time": 1.7039905341466268, "Episode Reward": 1590.4720673084441, "Mean Reward": 31.18572680996949, "Episode": 1205, "Episode Step": 51}
{"Training time": 1.7067718249559403, "Episode Reward": 8366.922885038257, "Mean Reward": 42.4716897717678, "Episode": 1206, "Episode Step": 197}
{"Training time": 1.708473153313001, "Episode Reward": 4574.3293903174535, "Mean Reward": 31.988317414807366, "Episode": 1207, "Episode Step": 143}
{"Training time": 1.7090957927703858, "Episode Reward": 1743.3450298165847, "Mean Reward": 34.18323587875656, "Episode": 1208, "Episode Step": 51}
{"Training time": 1.7123405213488472, "Episode Reward": 10455.422667658511, "Mean Reward": 43.93034734310299, "Episode": 1209, "Episode Step": 238}
{"Training time": 1.714126616385248, "Episode Reward": 4502.409920491424, "Mean Reward": 29.621117897969892, "Episode": 1210, "Episode Step": 152}
{"Training time": 1.7147240846686893, "Episode Reward": 2359.4284753198062, "Mean Reward": 48.1516015371389, "Episode": 1211, "Episode Step": 49}
{"Training time": 1.7174570443895127, "Episode Reward": 7795.345658640635, "Mean Reward": 40.600758638753305, "Episode": 1212, "Episode Step": 192}
{"Training time": 1.719297964109315, "Episode Reward": 4807.052645758105, "Mean Reward": 30.81444003691093, "Episode": 1213, "Episode Step": 156}
{"Training time": 1.7198699027299882, "Episode Reward": 1636.689592776057, "Mean Reward": 34.82318282502249, "Episode": 1214, "Episode Step": 47}
{"Training time": 1.7231012621853086, "Episode Reward": 10331.993704045739, "Mean Reward": 43.77963433917686, "Episode": 1215, "Episode Step": 236}
{"Training time": 1.724292408294148, "Episode Reward": 2832.7384973860994, "Mean Reward": 27.771946052804896, "Episode": 1216, "Episode Step": 102}
{"Training time": 1.724908254676395, "Episode Reward": 1915.424815031372, "Mean Reward": 37.55734931434063, "Episode": 1217, "Episode Step": 51}
{"Training time": 1.7280253922277027, "Episode Reward": 9755.426827771644, "Mean Reward": 43.165605432617895, "Episode": 1218, "Episode Step": 226}
{"Training time": 1.7297540377246008, "Episode Reward": 4078.5596031354676, "Mean Reward": 27.935339747503203, "Episode": 1219, "Episode Step": 146}
{"Training time": 1.7303607008192274, "Episode Reward": 1940.7843224347848, "Mean Reward": 38.0545945575448, "Episode": 1220, "Episode Step": 51}
{"Training time": 1.733735744158427, "Episode Reward": 10152.062499403777, "Mean Reward": 41.778034976970275, "Episode": 1221, "Episode Step": 243}
{"Training time": 1.7349601480033663, "Episode Reward": 2349.6617245748635, "Mean Reward": 23.035899260537878, "Episode": 1222, "Episode Step": 102}
{"Training time": 1.7355882955259747, "Episode Reward": 1793.4988494959393, "Mean Reward": 35.16664410776352, "Episode": 1223, "Episode Step": 51}
{"Training time": 1.7388137635919783, "Episode Reward": 9691.670956718235, "Mean Reward": 41.77444377895791, "Episode": 1224, "Episode Step": 232}
{"Training time": 1.7405762874417834, "Episode Reward": 3897.670183584523, "Mean Reward": 26.158860292513577, "Episode": 1225, "Episode Step": 149}
{"Training time": 1.741195444729593, "Episode Reward": 2144.3319537038, "Mean Reward": 43.761876606200005, "Episode": 1226, "Episode Step": 49}
{"Training time": 1.7445129032929738, "Episode Reward": 10908.18134821334, "Mean Reward": 45.450755617555586, "Episode": 1227, "Episode Step": 240}
{"Training time": 1.7455054110950894, "Episode Reward": 1542.4155513436285, "Mean Reward": 18.583319895706367, "Episode": 1228, "Episode Step": 83}
{"Training time": 1.7461100927326414, "Episode Reward": 2413.50332344871, "Mean Reward": 49.25516986630021, "Episode": 1229, "Episode Step": 49}
{"Training time": 1.7483253229988946, "Episode Reward": 5880.743324179052, "Mean Reward": 40.279063864240086, "Episode": 1230, "Episode Step": 146}
{"Training time": 1.7495592033200793, "Episode Reward": 2515.1424326057027, "Mean Reward": 24.18406185197791, "Episode": 1231, "Episode Step": 104}
{"Training time": 1.7516991094085905, "Episode Reward": 7783.552499827525, "Mean Reward": 43.003052485234946, "Episode": 1232, "Episode Step": 181}
{"Training time": 1.7544380893972185, "Episode Reward": 8132.381814252122, "Mean Reward": 41.91949388789754, "Episode": 1233, "Episode Step": 194}
{"Training time": 1.7555475683344735, "Episode Reward": 2370.7326916547527, "Mean Reward": 25.768833604942962, "Episode": 1234, "Episode Step": 92}
{"Training time": 1.7561037866274516, "Episode Reward": 2149.0444481870504, "Mean Reward": 46.718357569283704, "Episode": 1235, "Episode Step": 46}
{"Training time": 1.7590405513842902, "Episode Reward": 8869.902739928746, "Mean Reward": 42.23763209489879, "Episode": 1236, "Episode Step": 210}
{"Training time": 1.7613735036055247, "Episode Reward": 5194.825699062564, "Mean Reward": 26.104651754083235, "Episode": 1237, "Episode Step": 199}
{"Training time": 1.7619365121920902, "Episode Reward": 1525.8392578052494, "Mean Reward": 33.1704186479402, "Episode": 1238, "Episode Step": 46}
{"Training time": 1.7646442749765183, "Episode Reward": 8218.17131186529, "Mean Reward": 43.25353322034363, "Episode": 1239, "Episode Step": 190}
{"Training time": 1.765954180823432, "Episode Reward": 2728.6231059901925, "Mean Reward": 25.03323950449718, "Episode": 1240, "Episode Step": 109}
{"Training time": 1.7665401088529162, "Episode Reward": 1973.5047834603788, "Mean Reward": 40.27560782572202, "Episode": 1241, "Episode Step": 49}
{"Training time": 1.769548649125629, "Episode Reward": 9203.047849462837, "Mean Reward": 42.60670300677239, "Episode": 1242, "Episode Step": 216}
{"Training time": 1.7712530610958734, "Episode Reward": 3342.937167240495, "Mean Reward": 23.214841439170105, "Episode": 1243, "Episode Step": 144}
{"Training time": 1.7722738132874172, "Episode Reward": 3818.3314204989624, "Mean Reward": 46.00399301805979, "Episode": 1244, "Episode Step": 83}
{"Training time": 1.774500519434611, "Episode Reward": 6511.459516683052, "Mean Reward": 44.90661735643484, "Episode": 1245, "Episode Step": 145}
{"Training time": 1.7750446271896363, "Episode Reward": 1177.2570575236887, "Mean Reward": 27.37807110520206, "Episode": 1246, "Episode Step": 43}
{"Training time": 1.7756450596782896, "Episode Reward": 2331.150801898885, "Mean Reward": 48.56564170622678, "Episode": 1247, "Episode Step": 48}
{"Training time": 1.778736179669698, "Episode Reward": 10440.734655599623, "Mean Reward": 48.11398458801669, "Episode": 1248, "Episode Step": 217}
{"Training time": 1.7813302702373928, "Episode Reward": 4780.537374103983, "Mean Reward": 26.706912704491526, "Episode": 1249, "Episode Step": 179}
{"Training time": 1.7837328783008788, "Episode Reward": 7648.029278961642, "Mean Reward": 42.96645662338001, "Episode": 1250, "Episode Step": 178}
{"Training time": 1.786711063053873, "Episode Reward": 8760.661454422361, "Mean Reward": 41.91704045178163, "Episode": 1251, "Episode Step": 209}
{"Training time": 1.7873056627644432, "Episode Reward": 1117.3271297290296, "Mean Reward": 23.27764853602145, "Episode": 1252, "Episode Step": 48}
{"Training time": 1.787895895242691, "Episode Reward": 1818.2510675423418, "Mean Reward": 37.88023057379879, "Episode": 1253, "Episode Step": 48}
{"Training time": 1.7910036130083933, "Episode Reward": 9546.703334280748, "Mean Reward": 43.7922171297282, "Episode": 1254, "Episode Step": 218}
{"Training time": 1.7933032649755478, "Episode Reward": 5412.013854656865, "Mean Reward": 28.33515107150191, "Episode": 1255, "Episode Step": 191}
{"Training time": 1.7938576308223937, "Episode Reward": 1589.9737740132566, "Mean Reward": 35.33275053362792, "Episode": 1256, "Episode Step": 45}
{"Training time": 1.7967117991712358, "Episode Reward": 8320.750563241701, "Mean Reward": 41.812816900712065, "Episode": 1257, "Episode Step": 199}
{"Training time": 1.7994183133045831, "Episode Reward": 7783.522283123783, "Mean Reward": 35.379646741471745, "Episode": 1258, "Episode Step": 220}
{"Training time": 1.8000616696808074, "Episode Reward": 1726.1056677701772, "Mean Reward": 32.568031467361834, "Episode": 1259, "Episode Step": 53}
{"Training time": 1.8023076483276155, "Episode Reward": 6660.953575892636, "Mean Reward": 46.256622054809974, "Episode": 1260, "Episode Step": 144}
{"Training time": 1.8047176869048012, "Episode Reward": 6882.946008542578, "Mean Reward": 34.58766838463607, "Episode": 1261, "Episode Step": 199}
{"Training time": 1.8052962063418494, "Episode Reward": 1853.5406201541148, "Mean Reward": 40.294361307698146, "Episode": 1262, "Episode Step": 46}
{"Training time": 1.8075605905056, "Episode Reward": 6492.635506049713, "Mean Reward": 44.16758847652866, "Episode": 1263, "Episode Step": 147}
{"Training time": 1.8088280708260007, "Episode Reward": 3988.654402086167, "Mean Reward": 39.1044549224134, "Episode": 1264, "Episode Step": 102}
{"Training time": 1.8111627780066597, "Episode Reward": 7144.2354278621215, "Mean Reward": 37.60123909401116, "Episode": 1265, "Episode Step": 190}
{"Training time": 1.8143672282828225, "Episode Reward": 10318.840418036485, "Mean Reward": 46.2728269867107, "Episode": 1266, "Episode Step": 223}
{"Training time": 1.8162176711029476, "Episode Reward": 5279.1896758294415, "Mean Reward": 34.7315110251937, "Episode": 1267, "Episode Step": 152}
{"Training time": 1.81684037413862, "Episode Reward": 1944.6345011002759, "Mean Reward": 38.89269002200552, "Episode": 1268, "Episode Step": 50}
{"Training time": 1.8195947794119518, "Episode Reward": 8862.244586316565, "Mean Reward": 45.68167312534312, "Episode": 1269, "Episode Step": 194}
{"Training time": 1.8221408636040157, "Episode Reward": 8163.402713042795, "Mean Reward": 38.325834333534246, "Episode": 1270, "Episode Step": 213}
{"Training time": 1.822773188882404, "Episode Reward": 2267.2895844666537, "Mean Reward": 43.60172277820488, "Episode": 1271, "Episode Step": 52}
{"Training time": 1.8249169510602952, "Episode Reward": 6340.948103624337, "Mean Reward": 44.971263146271895, "Episode": 1272, "Episode Step": 141}
{"Training time": 1.827684955265787, "Episode Reward": 9014.14664505257, "Mean Reward": 38.521994209626364, "Episode": 1273, "Episode Step": 234}
{"Training time": 1.8283022788498138, "Episode Reward": 2250.334562950798, "Mean Reward": 45.00669125901596, "Episode": 1274, "Episode Step": 50}
{"Training time": 1.8313184097078112, "Episode Reward": 9884.736381496165, "Mean Reward": 45.13578256390943, "Episode": 1275, "Episode Step": 219}
{"Training time": 1.8341607477267583, "Episode Reward": 9409.803682656655, "Mean Reward": 39.20751534440273, "Episode": 1276, "Episode Step": 240}
{"Training time": 1.8353642896811166, "Episode Reward": 5091.129150395766, "Mean Reward": 49.913030886233, "Episode": 1277, "Episode Step": 102}
{"Training time": 1.838277411063512, "Episode Reward": 9210.491389413595, "Mean Reward": 44.069336791452606, "Episode": 1278, "Episode Step": 209}
{"Training time": 1.8405998843908309, "Episode Reward": 7745.085996470609, "Mean Reward": 39.718389725490304, "Episode": 1279, "Episode Step": 195}
{"Training time": 1.8426735835605197, "Episode Reward": 7646.191772959865, "Mean Reward": 43.943630879079684, "Episode": 1280, "Episode Step": 174}
{"Training time": 1.8448645310931735, "Episode Reward": 6847.4589131492585, "Mean Reward": 46.58135315067523, "Episode": 1281, "Episode Step": 147}
{"Training time": 1.845497340824869, "Episode Reward": 1948.8013369633213, "Mean Reward": 38.21179092084944, "Episode": 1282, "Episode Step": 51}
{"Training time": 1.8461105469200345, "Episode Reward": 1693.1463165007283, "Mean Reward": 33.86292633001457, "Episode": 1283, "Episode Step": 50}
{"Training time": 1.853149116370413, "Episode Reward": 26818.164689427376, "Mean Reward": 47.975249891641106, "Episode": 1284, "Episode Step": 559}
{"Training time": 1.856214346355862, "Episode Reward": 9819.18483182836, "Mean Reward": 38.206944870927465, "Episode": 1285, "Episode Step": 257}
{"Training time": 1.8572415302197138, "Episode Reward": 3795.418205143388, "Mean Reward": 44.1327698272487, "Episode": 1286, "Episode Step": 86}
{"Training time": 1.8625680971807903, "Episode Reward": 19705.44202075336, "Mean Reward": 48.17956484291775, "Episode": 1287, "Episode Step": 409}
{"Training time": 1.8651749196979734, "Episode Reward": 8400.588127791616, "Mean Reward": 37.6707987793346, "Episode": 1288, "Episode Step": 223}
{"Training time": 1.8657628288533952, "Episode Reward": 2245.383080245306, "Mean Reward": 47.774108090325655, "Episode": 1289, "Episode Step": 47}
{"Training time": 1.87502493944433, "Episode Reward": 36989.734183185, "Mean Reward": 49.98612727457432, "Episode": 1290, "Episode Step": 740}
{"Training time": 1.8773868479993607, "Episode Reward": 7758.887188402465, "Mean Reward": 38.989382856293794, "Episode": 1291, "Episode Step": 199}
{"Training time": 1.8791904944181441, "Episode Reward": 5462.2712994928515, "Mean Reward": 38.46669929220318, "Episode": 1292, "Episode Step": 142}
{"Training time": 1.8821511722273296, "Episode Reward": 8669.208444011103, "Mean Reward": 41.67888675005338, "Episode": 1293, "Episode Step": 208}
{"Training time": 1.8837984308269289, "Episode Reward": 5939.9871121473425, "Mean Reward": 43.04338487063292, "Episode": 1294, "Episode Step": 138}
{"Training time": 1.885051738884714, "Episode Reward": 5119.876547758777, "Mean Reward": 48.3007221486677, "Episode": 1295, "Episode Step": 106}
{"Training time": 1.88775869415866, "Episode Reward": 7498.365279014394, "Mean Reward": 39.05398582819997, "Episode": 1296, "Episode Step": 192}
{"Training time": 1.8901129321919548, "Episode Reward": 8248.636783708189, "Mean Reward": 41.24318391854094, "Episode": 1297, "Episode Step": 200}
{"Training time": 1.8906635360585318, "Episode Reward": 2031.333192636575, "Mean Reward": 44.15941723122989, "Episode": 1298, "Episode Step": 46}
{"Training time": 1.8995516333315108, "Episode Reward": 32399.09319392064, "Mean Reward": 47.09170522372186, "Episode": 1299, "Episode Step": 688}
{"Training time": 1.9022139033344057, "Episode Reward": 7999.095227114762, "Mean Reward": 40.81171034242225, "Episode": 1300, "Episode Step": 196}
{"Training time": 1.9034758788347244, "Episode Reward": 4460.182839121243, "Mean Reward": 43.302746010885855, "Episode": 1301, "Episode Step": 103}
{"Training time": 1.9064853682782914, "Episode Reward": 9065.027849858898, "Mean Reward": 42.759565329523106, "Episode": 1302, "Episode Step": 212}
{"Training time": 1.9087973146968418, "Episode Reward": 7995.423051240192, "Mean Reward": 42.08117395389575, "Episode": 1303, "Episode Step": 190}
{"Training time": 1.909416715833876, "Episode Reward": 1527.4738963873472, "Mean Reward": 30.549477927746942, "Episode": 1304, "Episode Step": 50}
{"Training time": 1.9144442416561975, "Episode Reward": 18563.303933618743, "Mean Reward": 48.216373853555176, "Episode": 1305, "Episode Step": 385}
{"Training time": 1.9166269946760601, "Episode Reward": 7754.8402739914645, "Mean Reward": 42.6090124944586, "Episode": 1306, "Episode Step": 182}
{"Training time": 1.9172242550055185, "Episode Reward": 2281.787215687191, "Mean Reward": 46.567086034432464, "Episode": 1307, "Episode Step": 49}
{"Training time": 1.9201890838808484, "Episode Reward": 8912.329874821851, "Mean Reward": 42.439666070580245, "Episode": 1308, "Episode Step": 210}
{"Training time": 1.9227441530095206, "Episode Reward": 8795.431220371334, "Mean Reward": 40.531941107702, "Episode": 1309, "Episode Step": 217}
{"Training time": 1.9248815305365456, "Episode Reward": 7498.4943676970515, "Mean Reward": 41.89102998713437, "Episode": 1310, "Episode Step": 179}
{"Training time": 1.9277999302413729, "Episode Reward": 7914.985308097607, "Mean Reward": 38.236644000471536, "Episode": 1311, "Episode Step": 207}
{"Training time": 1.9310711099704108, "Episode Reward": 12397.37116531159, "Mean Reward": 44.75585258235231, "Episode": 1312, "Episode Step": 277}
{"Training time": 1.9316984755463071, "Episode Reward": 1990.6652289288309, "Mean Reward": 38.282023633246745, "Episode": 1313, "Episode Step": 52}
{"Training time": 1.934610643055704, "Episode Reward": 8496.141149762718, "Mean Reward": 41.243403639624844, "Episode": 1314, "Episode Step": 206}
{"Training time": 1.937235070798132, "Episode Reward": 8763.176436706519, "Mean Reward": 40.19805704911247, "Episode": 1315, "Episode Step": 218}
{"Training time": 1.9378704657819537, "Episode Reward": 2488.2520593713666, "Mean Reward": 47.85100114175705, "Episode": 1316, "Episode Step": 52}
{"Training time": 1.9407234338919321, "Episode Reward": 7969.2259607559035, "Mean Reward": 40.04636161183871, "Episode": 1317, "Episode Step": 199}
{"Training time": 1.943239256342252, "Episode Reward": 8464.996303538885, "Mean Reward": 40.30950620732802, "Episode": 1318, "Episode Step": 210}
{"Training time": 1.9438516822126177, "Episode Reward": 1809.91505583313, "Mean Reward": 35.48853050653196, "Episode": 1319, "Episode Step": 51}
{"Training time": 1.9508245833052529, "Episode Reward": 27972.250418048374, "Mean Reward": 50.491426747379734, "Episode": 1320, "Episode Step": 554}
{"Training time": 1.954092244439655, "Episode Reward": 11789.56838137138, "Mean Reward": 42.871157750441384, "Episode": 1321, "Episode Step": 275}
{"Training time": 1.9547367755572, "Episode Reward": 2312.802990217772, "Mean Reward": 45.34907823956415, "Episode": 1322, "Episode Step": 51}
{"Training time": 1.9576735019021565, "Episode Reward": 9047.905256233185, "Mean Reward": 43.29141270924969, "Episode": 1323, "Episode Step": 209}
{"Training time": 1.9613789124621286, "Episode Reward": 13889.955937237884, "Mean Reward": 44.0950982134536, "Episode": 1324, "Episode Step": 315}
{"Training time": 1.9646890513764488, "Episode Reward": 13605.572415132216, "Mean Reward": 49.11758994632569, "Episode": 1325, "Episode Step": 277}
{"Training time": 1.9855181855625577, "Episode Reward": 80394.42247504667, "Mean Reward": 46.177152484231286, "Episode": 1326, "Episode Step": 1741}
{"Training time": 1.9880600172281264, "Episode Reward": 8408.82792836962, "Mean Reward": 38.75035911691069, "Episode": 1327, "Episode Step": 217}
{"Training time": 1.9887007155021033, "Episode Reward": 2414.894819737641, "Mean Reward": 47.35087881838511, "Episode": 1328, "Episode Step": 51}
{"Training time": 2.0046757060951657, "Episode Reward": 61823.12688344146, "Mean Reward": 47.01378470223685, "Episode": 1329, "Episode Step": 1315}
{"Training time": 2.0075490330325234, "Episode Reward": 9385.293580322985, "Mean Reward": 38.782204877367704, "Episode": 1330, "Episode Step": 242}
{"Training time": 2.010903566347228, "Episode Reward": 14175.625526832997, "Mean Reward": 51.54772918848362, "Episode": 1331, "Episode Step": 275}
{"Training time": 2.0132881860600578, "Episode Reward": 7049.023554210349, "Mean Reward": 44.6140731279136, "Episode": 1332, "Episode Step": 158}
{"Training time": 2.015951451924112, "Episode Reward": 8279.926946643349, "Mean Reward": 36.799675318414884, "Episode": 1333, "Episode Step": 225}
{"Training time": 2.0190144008398057, "Episode Reward": 11642.674879923432, "Mean Reward": 45.479198749700906, "Episode": 1334, "Episode Step": 256}
{"Training time": 2.0332795288827685, "Episode Reward": 56615.59301911298, "Mean Reward": 48.02001104250465, "Episode": 1335, "Episode Step": 1179}
{"Training time": 2.0439843116203944, "Episode Reward": 37324.56327698254, "Mean Reward": 40.70290433694933, "Episode": 1336, "Episode Step": 917}
{"Training time": 2.0465561566087933, "Episode Reward": 10127.89179909192, "Mean Reward": 45.62113423014378, "Episode": 1337, "Episode Step": 222}
{"Training time": 2.0945372196700838, "Episode Reward": 217178.71215914475, "Mean Reward": 53.452796494990096, "Episode": 1338, "Episode Step": 4063}
{"Training time": 2.0988465469413335, "Episode Reward": 15373.447923470465, "Mean Reward": 41.32647291255501, "Episode": 1339, "Episode Step": 372}
{"Training time": 2.1004184038771525, "Episode Reward": 5356.382053709468, "Mean Reward": 39.38516215962844, "Episode": 1340, "Episode Step": 136}
{"Training time": 2.1104420374499426, "Episode Reward": 47315.29542709413, "Mean Reward": 56.869345465257375, "Episode": 1341, "Episode Step": 832}
{"Training time": 2.1177711227205065, "Episode Reward": 26897.66739491355, "Mean Reward": 42.49236555278602, "Episode": 1342, "Episode Step": 633}
{"Training time": 2.1203852041562397, "Episode Reward": 8172.402002460062, "Mean Reward": 36.32178667760028, "Episode": 1343, "Episode Step": 225}
{"Training time": 2.124098909695943, "Episode Reward": 13557.373117761314, "Mean Reward": 48.24687942263812, "Episode": 1344, "Episode Step": 281}
{"Training time": 2.134542013870345, "Episode Reward": 37602.7935371123, "Mean Reward": 42.20291081606319, "Episode": 1345, "Episode Step": 891}
{"Training time": 2.1373008235957887, "Episode Reward": 9549.339770810357, "Mean Reward": 41.160947287975674, "Episode": 1346, "Episode Step": 232}
{"Training time": 2.145033200515641, "Episode Reward": 34031.12953482714, "Mean Reward": 55.15580151511692, "Episode": 1347, "Episode Step": 617}
{"Training time": 2.152262101901902, "Episode Reward": 24900.998679867345, "Mean Reward": 40.09822653762858, "Episode": 1348, "Episode Step": 621}
{"Training time": 2.155021367735333, "Episode Reward": 4607.467637173233, "Mean Reward": 35.71680338893979, "Episode": 1349, "Episode Step": 129}
{"Training time": 2.165429089665413, "Episode Reward": 46769.091312568475, "Mean Reward": 54.89329966263905, "Episode": 1350, "Episode Step": 852}
{"Training time": 2.1757389666636784, "Episode Reward": 35286.47560591839, "Mean Reward": 39.73702207873693, "Episode": 1351, "Episode Step": 888}
{"Training time": 2.1769479505221048, "Episode Reward": 3101.1841925893173, "Mean Reward": 30.403766594012914, "Episode": 1352, "Episode Step": 102}
{"Training time": 2.1803906066550147, "Episode Reward": 11453.959961860903, "Mean Reward": 44.74203110101915, "Episode": 1353, "Episode Step": 256}
{"Training time": 2.1829861593908735, "Episode Reward": 9023.0105685432, "Mean Reward": 40.6441917501946, "Episode": 1354, "Episode Step": 222}
{"Training time": 2.1855408274465136, "Episode Reward": 8297.162143124222, "Mean Reward": 37.714373377837376, "Episode": 1355, "Episode Step": 220}
{"Training time": 2.194509399400817, "Episode Reward": 38402.540957752695, "Mean Reward": 52.75074307383612, "Episode": 1356, "Episode Step": 728}
{"Training time": 2.2333798121743733, "Episode Reward": 149425.359320796, "Mean Reward": 44.366199323276724, "Episode": 1357, "Episode Step": 3368}
{"Training time": 2.236036471658283, "Episode Reward": 8676.04192675253, "Mean Reward": 38.052815468212856, "Episode": 1358, "Episode Step": 228}
{"Training time": 2.242974015540547, "Episode Reward": 29030.32369453695, "Mean Reward": 52.30688953970622, "Episode": 1359, "Episode Step": 555}
{"Training time": 2.263190827171008, "Episode Reward": 81862.6813979532, "Mean Reward": 46.67199623600525, "Episode": 1360, "Episode Step": 1754}
{"Training time": 2.263873869975408, "Episode Reward": 1973.175546002581, "Mean Reward": 35.87591901822875, "Episode": 1361, "Episode Step": 55}
{"Training time": 2.266761140558455, "Episode Reward": 9544.76999622831, "Mean Reward": 46.33383493314713, "Episode": 1362, "Episode Step": 206}
{"Training time": 2.2971358838346267, "Episode Reward": 128094.0171611185, "Mean Reward": 48.87219273602385, "Episode": 1363, "Episode Step": 2621}
{"Training time": 2.2983696513705785, "Episode Reward": 4055.698708467596, "Mean Reward": 39.375715616190256, "Episode": 1364, "Episode Step": 103}
{"Training time": 2.30002938164605, "Episode Reward": 99.94902391083778, "Mean Reward": 0.9798923912827233, "Episode": 1365, "Episode Step": 102}
{"Training time": 2.335963217218717, "Episode Reward": 156687.63710239186, "Mean Reward": 50.12400419142414, "Episode": 1366, "Episode Step": 3126}
{"Training time": 2.34044942551189, "Episode Reward": 18988.040493958008, "Mean Reward": 49.57712922704441, "Episode": 1367, "Episode Step": 383}
{"Training time": 2.3674928783045877, "Episode Reward": 128152.12832535215, "Mean Reward": 56.33060585729765, "Episode": 1368, "Episode Step": 2275}
{"Training time": 2.3693445074558257, "Episode Reward": 6913.364252637032, "Mean Reward": 42.9401506374971, "Episode": 1369, "Episode Step": 161}
{"Training time": 2.3719981316725414, "Episode Reward": 8734.50770267752, "Mean Reward": 38.14195503352629, "Episode": 1370, "Episode Step": 229}
{"Training time": 2.378490697476599, "Episode Reward": 25761.180393771792, "Mean Reward": 49.82820192218915, "Episode": 1371, "Episode Step": 517}
{"Training time": 2.409601423011886, "Episode Reward": 135899.52784430084, "Mean Reward": 50.87964352089137, "Episode": 1372, "Episode Step": 2671}
{"Training time": 2.4111682366662555, "Episode Reward": 4737.081392491766, "Mean Reward": 35.88698024614974, "Episode": 1373, "Episode Step": 132}
{"Training time": 2.4139441902769936, "Episode Reward": 7378.6425275821375, "Mean Reward": 37.64613534480682, "Episode": 1374, "Episode Step": 196}
{"Training time": 2.4250785327619977, "Episode Reward": 48335.09419445677, "Mean Reward": 51.256727671746305, "Episode": 1375, "Episode Step": 943}
{"Training time": 2.4263350255621803, "Episode Reward": 5028.212685906794, "Mean Reward": 48.34819890294994, "Episode": 1376, "Episode Step": 104}
{"Training time": 2.4473307147290972, "Episode Reward": 97783.88197666858, "Mean Reward": 56.5224751310223, "Episode": 1377, "Episode Step": 1730}
{"Training time": 2.454908319446776, "Episode Reward": 32368.688017620178, "Mean Reward": 50.57607502753153, "Episode": 1378, "Episode Step": 640}
{"Training time": 2.4561964707904393, "Episode Reward": 4235.296405032054, "Mean Reward": 39.58220939282294, "Episode": 1379, "Episode Step": 107}
{"Training time": 2.460546664992968, "Episode Reward": 18088.7567621544, "Mean Reward": 54.484207114922896, "Episode": 1380, "Episode Step": 332}
{"Training time": 2.461777478588952, "Episode Reward": 5005.049404889194, "Mean Reward": 49.06911181263916, "Episode": 1381, "Episode Step": 102}
{"Training time": 2.464627775284979, "Episode Reward": 10176.20332112959, "Mean Reward": 42.050426946816486, "Episode": 1382, "Episode Step": 242}
{"Training time": 2.467335493895743, "Episode Reward": 8725.1199299154, "Mean Reward": 45.68125617756753, "Episode": 1383, "Episode Step": 191}
{"Training time": 2.4780878352456623, "Episode Reward": 46887.174720986855, "Mean Reward": 51.075353726565204, "Episode": 1384, "Episode Step": 918}
{"Training time": 2.4814841977755226, "Episode Reward": 12840.845832595394, "Mean Reward": 44.27877873308756, "Episode": 1385, "Episode Step": 290}
{"Training time": 2.4841953735881384, "Episode Reward": 8117.059065836366, "Mean Reward": 42.497691444169455, "Episode": 1386, "Episode Step": 191}
{"Training time": 2.4865378113587697, "Episode Reward": 8652.03588822971, "Mean Reward": 43.0449546678095, "Episode": 1387, "Episode Step": 201}
{"Training time": 2.488927417728636, "Episode Reward": 7264.844459275963, "Mean Reward": 35.61198264350963, "Episode": 1388, "Episode Step": 204}
{"Training time": 2.49239452805784, "Episode Reward": 12590.410837778045, "Mean Reward": 48.989925438825075, "Episode": 1389, "Episode Step": 257}
{"Training time": 2.4978209113412433, "Episode Reward": 22144.339624841446, "Mean Reward": 47.520042113393664, "Episode": 1390, "Episode Step": 466}
{"Training time": 2.5033862686157224, "Episode Reward": 21553.71250654725, "Mean Reward": 44.99731212222808, "Episode": 1391, "Episode Step": 479}
{"Training time": 2.506434567504459, "Episode Reward": 10068.882333447598, "Mean Reward": 45.56055354501176, "Episode": 1392, "Episode Step": 221}
{"Training time": 2.508356109129058, "Episode Reward": 6891.003800767831, "Mean Reward": 41.763659398592914, "Episode": 1393, "Episode Step": 165}
{"Training time": 2.5107458280192483, "Episode Reward": 7484.809463956186, "Mean Reward": 36.511265677835055, "Episode": 1394, "Episode Step": 205}
{"Training time": 2.5200730566183727, "Episode Reward": 40876.30082037006, "Mean Reward": 53.433072967804, "Episode": 1395, "Episode Step": 765}
{"Training time": 2.5224137357870737, "Episode Reward": 8608.938332288948, "Mean Reward": 43.26099664466808, "Episode": 1396, "Episode Step": 199}
{"Training time": 2.524845741391182, "Episode Reward": 7078.834026151299, "Mean Reward": 34.03285589495817, "Episode": 1397, "Episode Step": 208}
{"Training time": 2.529204719728894, "Episode Reward": 17914.990431950333, "Mean Reward": 54.123838162991945, "Episode": 1398, "Episode Step": 331}
{"Training time": 2.5412009902795156, "Episode Reward": 48887.61509496141, "Mean Reward": 52.73744886187854, "Episode": 1399, "Episode Step": 927}
{"Training time": 2.5448572405179344, "Episode Reward": 12593.919322721358, "Mean Reward": 43.42730800938399, "Episode": 1400, "Episode Step": 290}
{"Training time": 2.547607812749015, "Episode Reward": 9085.691090982615, "Mean Reward": 46.35556679072763, "Episode": 1401, "Episode Step": 196}
{"Training time": 2.5547075868977442, "Episode Reward": 33067.6977406376, "Mean Reward": 54.29835425392053, "Episode": 1402, "Episode Step": 609}
{"Training time": 2.556032290259997, "Episode Reward": 5270.085403935184, "Mean Reward": 46.63792392862995, "Episode": 1403, "Episode Step": 113}
{"Training time": 2.5587987105051675, "Episode Reward": 8815.752135179931, "Mean Reward": 46.644191191428206, "Episode": 1404, "Episode Step": 189}
{"Training time": 2.5621265049775444, "Episode Reward": 15446.489160212703, "Mean Reward": 55.16603271504537, "Episode": 1405, "Episode Step": 280}
{"Training time": 2.565047411388821, "Episode Reward": 9635.791817307816, "Mean Reward": 39.011302904080225, "Episode": 1406, "Episode Step": 247}
{"Training time": 2.568876698613167, "Episode Reward": 16827.000248002405, "Mean Reward": 59.6702136453986, "Episode": 1407, "Episode Step": 282}
{"Training time": 2.571064708299107, "Episode Reward": 8927.876398892216, "Mean Reward": 47.99933547791514, "Episode": 1408, "Episode Step": 186}
{"Training time": 2.5759986669487422, "Episode Reward": 20321.574605523496, "Mean Reward": 48.6162071902476, "Episode": 1409, "Episode Step": 418}
{"Training time": 2.5802350093921027, "Episode Reward": 17667.250655615695, "Mean Reward": 55.383230895347005, "Episode": 1410, "Episode Step": 319}
{"Training time": 2.5824647635883755, "Episode Reward": 8195.108558813141, "Mean Reward": 43.360362745043076, "Episode": 1411, "Episode Step": 189}
{"Training time": 2.5861207599772347, "Episode Reward": 14962.751271200617, "Mean Reward": 48.42314327249391, "Episode": 1412, "Episode Step": 309}
{"Training time": 2.592964078320397, "Episode Reward": 29625.448812712144, "Mean Reward": 54.35862167470118, "Episode": 1413, "Episode Step": 545}
{"Training time": 2.594035277499093, "Episode Reward": 4832.162171864562, "Mean Reward": 54.29395698724227, "Episode": 1414, "Episode Step": 89}
{"Training time": 2.5964506591690912, "Episode Reward": 8588.936162506336, "Mean Reward": 41.897249573201634, "Episode": 1415, "Episode Step": 205}
{"Training time": 2.6008247438404295, "Episode Reward": 16735.98072931952, "Mean Reward": 50.25820038834691, "Episode": 1416, "Episode Step": 333}
{"Training time": 2.6024125532971487, "Episode Reward": 6392.298333578473, "Mean Reward": 47.70371890730204, "Episode": 1417, "Episode Step": 134}
{"Training time": 2.6034830674860214, "Episode Reward": 4000.0610884938424, "Mean Reward": 43.95671525817409, "Episode": 1418, "Episode Step": 91}
{"Training time": 2.6135669777790707, "Episode Reward": 48913.71704272433, "Mean Reward": 59.50573849479846, "Episode": 1419, "Episode Step": 822}
{"Training time": 2.6151107455624474, "Episode Reward": 6096.044335578067, "Mean Reward": 47.62534637170365, "Episode": 1420, "Episode Step": 128}
{"Training time": 2.620655877457725, "Episode Reward": 23415.623842141744, "Mean Reward": 49.82047625987605, "Episode": 1421, "Episode Step": 470}
{"Training time": 2.623473123047087, "Episode Reward": 8799.180679546113, "Mean Reward": 44.4403064623541, "Episode": 1422, "Episode Step": 198}
{"Training time": 2.6245463452736537, "Episode Reward": 4959.9394080319935, "Mean Reward": 55.11043786702215, "Episode": 1423, "Episode Step": 90}
{"Training time": 2.6294213327434326, "Episode Reward": 19433.904254721627, "Mean Reward": 46.82868495113645, "Episode": 1424, "Episode Step": 415}
{"Training time": 2.6417760083410475, "Episode Reward": 58705.42715424543, "Mean Reward": 57.72411716248322, "Episode": 1425, "Episode Step": 1017}
{"Training time": 2.643297647502687, "Episode Reward": 6623.210418934394, "Mean Reward": 51.34271642584801, "Episode": 1426, "Episode Step": 129}
{"Training time": 2.6439839824703006, "Episode Reward": 2373.1006270580565, "Mean Reward": 41.63334433435187, "Episode": 1427, "Episode Step": 57}
{"Training time": 2.6455784830119873, "Episode Reward": 4248.34090939417, "Mean Reward": 44.71937799362284, "Episode": 1428, "Episode Step": 95}
{"Training time": 2.6478716649611793, "Episode Reward": 9000.796341918276, "Mean Reward": 46.157929958555265, "Episode": 1429, "Episode Step": 195}
{"Training time": 2.650156484444936, "Episode Reward": 7379.006762433372, "Mean Reward": 38.036117332130786, "Episode": 1430, "Episode Step": 194}
{"Training time": 2.659145341118177, "Episode Reward": 39334.38142927287, "Mean Reward": 53.809003323218704, "Episode": 1431, "Episode Step": 731}
{"Training time": 2.6613075596756404, "Episode Reward": 9055.479039887241, "Mean Reward": 48.94853535074184, "Episode": 1432, "Episode Step": 185}
{"Training time": 2.6619715702533724, "Episode Reward": 2528.937710803031, "Mean Reward": 45.15960197862556, "Episode": 1433, "Episode Step": 56}
{"Training time": 2.66476731300354, "Episode Reward": 9017.905386899363, "Mean Reward": 45.776169476646515, "Episode": 1434, "Episode Step": 197}
{"Training time": 2.665445684724384, "Episode Reward": 2430.549902816774, "Mean Reward": 44.19181641485044, "Episode": 1435, "Episode Step": 55}
{"Training time": 2.6712650085820093, "Episode Reward": 22566.65714287715, "Mean Reward": 45.681492192059004, "Episode": 1436, "Episode Step": 494}
{"Training time": 2.673882314430343, "Episode Reward": 9156.606169009674, "Mean Reward": 49.7641639620091, "Episode": 1437, "Episode Step": 184}
{"Training time": 2.677269293003612, "Episode Reward": 15295.185107895772, "Mean Reward": 53.479668209425775, "Episode": 1438, "Episode Step": 286}
{"Training time": 2.6860583305358885, "Episode Reward": 36434.3235884059, "Mean Reward": 48.19354972011363, "Episode": 1439, "Episode Step": 756}
{"Training time": 2.6886353260940976, "Episode Reward": 9157.465320874679, "Mean Reward": 51.15902413896468, "Episode": 1440, "Episode Step": 179}
{"Training time": 2.6897667686144513, "Episode Reward": 4952.08661416879, "Mean Reward": 52.12722751756621, "Episode": 1441, "Episode Step": 95}
{"Training time": 2.6921283935838276, "Episode Reward": 7703.272034258478, "Mean Reward": 38.51636017129239, "Episode": 1442, "Episode Step": 200}
{"Training time": 2.6947273424598905, "Episode Reward": 8838.34323532863, "Mean Reward": 48.56232546883862, "Episode": 1443, "Episode Step": 182}
{"Training time": 2.6969379702541563, "Episode Reward": 8821.64725348717, "Mean Reward": 46.67538229358291, "Episode": 1444, "Episode Step": 189}
{"Training time": 2.700270633035236, "Episode Reward": 11761.0407072779, "Mean Reward": 41.41211516647148, "Episode": 1445, "Episode Step": 284}
{"Training time": 2.70375114719073, "Episode Reward": 13300.773922300436, "Mean Reward": 50.960819625672166, "Episode": 1446, "Episode Step": 261}
{"Training time": 2.704452773332596, "Episode Reward": 2284.3754014528886, "Mean Reward": 38.718227143269296, "Episode": 1447, "Episode Step": 59}
{"Training time": 2.709275716079606, "Episode Reward": 19390.86510179338, "Mean Reward": 47.17972044231966, "Episode": 1448, "Episode Step": 411}
{"Training time": 2.713166830274794, "Episode Reward": 14608.293565185253, "Mean Reward": 56.84160920305546, "Episode": 1449, "Episode Step": 257}
{"Training time": 2.7141023449765314, "Episode Reward": 2787.5948572228, "Mean Reward": 51.6221269856074, "Episode": 1450, "Episode Step": 54}
{"Training time": 2.733026340537601, "Episode Reward": 75172.75323955968, "Mean Reward": 46.43159557724501, "Episode": 1451, "Episode Step": 1619}
{"Training time": 2.7356993485821617, "Episode Reward": 8956.087198942207, "Mean Reward": 48.151006445925844, "Episode": 1452, "Episode Step": 186}
{"Training time": 2.7430082255601884, "Episode Reward": 34326.68359507522, "Mean Reward": 55.099010585995536, "Episode": 1453, "Episode Step": 623}
{"Training time": 2.7464574852254655, "Episode Reward": 12695.137949647664, "Mean Reward": 43.476499827560495, "Episode": 1454, "Episode Step": 292}
{"Training time": 2.7547892019483777, "Episode Reward": 36162.721798321065, "Mean Reward": 53.89377317186448, "Episode": 1455, "Episode Step": 671}
{"Training time": 2.7562183952331543, "Episode Reward": 4802.670842243565, "Mean Reward": 39.69149456399641, "Episode": 1456, "Episode Step": 121}
{"Training time": 2.759564750790596, "Episode Reward": 12202.760921972138, "Mean Reward": 43.11929654407116, "Episode": 1457, "Episode Step": 283}
{"Training time": 2.7629211796654594, "Episode Reward": 13786.979631756873, "Mean Reward": 56.04463264941818, "Episode": 1458, "Episode Step": 246}
{"Training time": 2.7647248319122526, "Episode Reward": 5306.9755437167105, "Mean Reward": 35.61728552830007, "Episode": 1459, "Episode Step": 149}
{"Training time": 2.774231402476629, "Episode Reward": 36771.76630777341, "Mean Reward": 45.73602774598683, "Episode": 1460, "Episode Step": 804}
{"Training time": 2.7768668774763743, "Episode Reward": 8725.135319116258, "Mean Reward": 48.205167508929605, "Episode": 1461, "Episode Step": 181}
{"Training time": 2.7781199291679592, "Episode Reward": 4482.546724156555, "Mean Reward": 43.51987110831607, "Episode": 1462, "Episode Step": 103}
{"Training time": 2.7923124638530945, "Episode Reward": 56102.96153677893, "Mean Reward": 46.791460831341894, "Episode": 1463, "Episode Step": 1199}
{"Training time": 2.7949803068902757, "Episode Reward": 8204.67181042393, "Mean Reward": 44.11113876572005, "Episode": 1464, "Episode Step": 186}
{"Training time": 2.796502856347296, "Episode Reward": 5900.8906226959725, "Mean Reward": 45.74333816043389, "Episode": 1465, "Episode Step": 129}
{"Training time": 2.8058544486098818, "Episode Reward": 38370.046393527584, "Mean Reward": 47.84295061537105, "Episode": 1466, "Episode Step": 802}
{"Training time": 2.8084396024545035, "Episode Reward": 8471.757154483348, "Mean Reward": 46.54811623342499, "Episode": 1467, "Episode Step": 182}
{"Training time": 2.809709585507711, "Episode Reward": 4906.249618717731, "Mean Reward": 45.01146439190579, "Episode": 1468, "Episode Step": 109}
{"Training time": 2.8128485733270647, "Episode Reward": 11672.70057209797, "Mean Reward": 43.71797967077892, "Episode": 1469, "Episode Step": 267}
{"Training time": 2.815299867192904, "Episode Reward": 7050.818548448545, "Mean Reward": 41.969158026479434, "Episode": 1470, "Episode Step": 168}
{"Training time": 2.816558007200559, "Episode Reward": 5176.97033919247, "Mean Reward": 49.778560953773756, "Episode": 1471, "Episode Step": 104}
{"Training time": 2.817287214729521, "Episode Reward": 1913.7999241237603, "Mean Reward": 31.373769247930497, "Episode": 1472, "Episode Step": 61}
{"Training time": 2.8206689013375175, "Episode Reward": 11285.28974173635, "Mean Reward": 44.96131371209701, "Episode": 1473, "Episode Step": 251}
{"Training time": 2.8226282911168203, "Episode Reward": 6394.73279400404, "Mean Reward": 38.29181313774875, "Episode": 1474, "Episode Step": 167}
{"Training time": 2.8314409094386632, "Episode Reward": 36646.22115070884, "Mean Reward": 49.656126220472686, "Episode": 1475, "Episode Step": 738}
{"Training time": 2.8342483858267467, "Episode Reward": 8917.698866190161, "Mean Reward": 45.038883162576575, "Episode": 1476, "Episode Step": 198}
{"Training time": 2.836104788051711, "Episode Reward": 6603.4733436549595, "Mean Reward": 42.329957331121534, "Episode": 1477, "Episode Step": 156}
{"Training time": 2.846073623895645, "Episode Reward": 42622.60404889026, "Mean Reward": 50.32184657484092, "Episode": 1478, "Episode Step": 847}
{"Training time": 2.849342075785001, "Episode Reward": 12820.871363030368, "Mean Reward": 53.869207407690624, "Episode": 1479, "Episode Step": 238}
{"Training time": 2.852252311640316, "Episode Reward": 10416.072867418821, "Mean Reward": 42.34175962365374, "Episode": 1480, "Episode Step": 246}
{"Training time": 2.8545891791582108, "Episode Reward": 9085.486046026614, "Mean Reward": 45.88629316175057, "Episode": 1481, "Episode Step": 198}
{"Training time": 2.857972159716818, "Episode Reward": 12614.612306868688, "Mean Reward": 50.45844922747475, "Episode": 1482, "Episode Step": 250}
{"Training time": 2.8607921163903343, "Episode Reward": 9022.829415152166, "Mean Reward": 37.59512256313403, "Episode": 1483, "Episode Step": 240}
{"Training time": 2.8798617335822847, "Episode Reward": 84606.84472243214, "Mean Reward": 51.43273235406209, "Episode": 1484, "Episode Step": 1645}
{"Training time": 2.882513869404793, "Episode Reward": 9127.012960761722, "Mean Reward": 49.87438776372526, "Episode": 1485, "Episode Step": 183}
{"Training time": 2.885977648033036, "Episode Reward": 16547.56941468559, "Mean Reward": 55.528756425119425, "Episode": 1486, "Episode Step": 298}
{"Training time": 2.8894247963693407, "Episode Reward": 13654.154177243525, "Mean Reward": 46.28526839743568, "Episode": 1487, "Episode Step": 295}
{"Training time": 2.890491014122963, "Episode Reward": 2423.643631882696, "Mean Reward": 45.72912512986219, "Episode": 1488, "Episode Step": 53}
{"Training time": 2.891286826928457, "Episode Reward": 2481.171208955554, "Mean Reward": 37.03240610381424, "Episode": 1489, "Episode Step": 67}
{"Training time": 2.896819831662708, "Episode Reward": 23124.85724167811, "Mean Reward": 49.0973614472996, "Episode": 1490, "Episode Step": 471}
{"Training time": 2.899539530277252, "Episode Reward": 7924.234575941682, "Mean Reward": 41.27205508302959, "Episode": 1491, "Episode Step": 192}
{"Training time": 2.901113014684783, "Episode Reward": 4977.341753735778, "Mean Reward": 37.70713449799832, "Episode": 1492, "Episode Step": 132}
{"Training time": 2.9017657230297726, "Episode Reward": 2491.907726649458, "Mean Reward": 46.14643938239737, "Episode": 1493, "Episode Step": 54}
{"Training time": 2.9032958649926717, "Episode Reward": 4679.850623426402, "Mean Reward": 51.426929927762664, "Episode": 1494, "Episode Step": 91}
{"Training time": 2.905744493868616, "Episode Reward": 8343.997210639522, "Mean Reward": 40.30916526878996, "Episode": 1495, "Episode Step": 207}
{"Training time": 2.9087899663713244, "Episode Reward": 10199.527196596377, "Mean Reward": 39.68687625134777, "Episode": 1496, "Episode Step": 257}
{"Training time": 2.910344081653489, "Episode Reward": 4990.39019738439, "Mean Reward": 54.2433717106999, "Episode": 1497, "Episode Step": 92}
{"Training time": 2.9128123205237917, "Episode Reward": 8870.706027753444, "Mean Reward": 41.84295296110115, "Episode": 1498, "Episode Step": 212}
{"Training time": 2.916260828839408, "Episode Reward": 8230.275790569616, "Mean Reward": 35.02245017263667, "Episode": 1499, "Episode Step": 235}
{"Training time": 2.918890262775951, "Episode Reward": 7959.034316530128, "Mean Reward": 43.02180711637907, "Episode": 1500, "Episode Step": 185}
{"Training time": 2.92053090525998, "Episode Reward": 5823.599786792754, "Mean Reward": 41.59714133423395, "Episode": 1501, "Episode Step": 140}
{"Training time": 2.921258928047286, "Episode Reward": 2362.6453450339386, "Mean Reward": 39.37742241723231, "Episode": 1502, "Episode Step": 60}
{"Training time": 2.923952133589321, "Episode Reward": 8694.28505735677, "Mean Reward": 46.49350298051749, "Episode": 1503, "Episode Step": 187}
{"Training time": 2.9255432902442084, "Episode Reward": 5558.847887907853, "Mean Reward": 42.43395334280804, "Episode": 1504, "Episode Step": 131}
{"Training time": 2.928077265554004, "Episode Reward": 7078.336078219571, "Mean Reward": 33.54661648445295, "Episode": 1505, "Episode Step": 211}
{"Training time": 2.930886211925083, "Episode Reward": 8379.948663121657, "Mean Reward": 42.97409570831619, "Episode": 1506, "Episode Step": 195}
{"Training time": 2.932763072450956, "Episode Reward": 5704.730414574551, "Mean Reward": 37.043703990743836, "Episode": 1507, "Episode Step": 154}
{"Training time": 2.9335286244418888, "Episode Reward": 1981.602622786524, "Mean Reward": 31.961332625589097, "Episode": 1508, "Episode Step": 62}
{"Training time": 2.940735692448086, "Episode Reward": 32293.784274720914, "Mean Reward": 56.55653988567585, "Episode": 1509, "Episode Step": 571}
{"Training time": 2.9420933394299613, "Episode Reward": 4773.453919020455, "Mean Reward": 42.62012427696835, "Episode": 1510, "Episode Step": 112}
{"Training time": 2.945075021651056, "Episode Reward": 11725.25088291054, "Mean Reward": 46.5287733448831, "Episode": 1511, "Episode Step": 252}
{"Training time": 2.94792267329163, "Episode Reward": 9502.537891344968, "Mean Reward": 47.512689456724836, "Episode": 1512, "Episode Step": 200}
{"Training time": 2.949477756354544, "Episode Reward": 4934.513998463802, "Mean Reward": 37.66804578980001, "Episode": 1513, "Episode Step": 131}
{"Training time": 2.958300924433602, "Episode Reward": 35642.61986453309, "Mean Reward": 46.959973471058085, "Episode": 1514, "Episode Step": 759}
{"Training time": 2.9611982966131634, "Episode Reward": 7297.642386620993, "Mean Reward": 35.08481916644708, "Episode": 1515, "Episode Step": 208}
{"Training time": 2.9632373460796146, "Episode Reward": 5789.216122860035, "Mean Reward": 33.27135702793124, "Episode": 1516, "Episode Step": 174}
{"Training time": 2.9657311658064525, "Episode Reward": 7806.166794195072, "Mean Reward": 37.52964804901477, "Episode": 1517, "Episode Step": 208}
{"Training time": 2.9684573435783386, "Episode Reward": 9243.90621808049, "Mean Reward": 48.39741475434812, "Episode": 1518, "Episode Step": 191}
{"Training time": 2.9704279699590472, "Episode Reward": 5684.134743856582, "Mean Reward": 34.24177556540109, "Episode": 1519, "Episode Step": 166}
{"Training time": 2.9723509408368005, "Episode Reward": 6087.611045895638, "Mean Reward": 37.34730703003459, "Episode": 1520, "Episode Step": 163}
{"Training time": 2.974960346950425, "Episode Reward": 8560.18490733111, "Mean Reward": 47.293839267022705, "Episode": 1521, "Episode Step": 181}
{"Training time": 2.975882884396447, "Episode Reward": 2557.405846937627, "Mean Reward": 33.21306294724191, "Episode": 1522, "Episode Step": 77}
{"Training time": 2.9776929944091375, "Episode Reward": 6055.628420436787, "Mean Reward": 40.103499473091304, "Episode": 1523, "Episode Step": 151}
{"Training time": 2.980394626657168, "Episode Reward": 7839.483056979191, "Mean Reward": 42.14775837085587, "Episode": 1524, "Episode Step": 186}
{"Training time": 2.981921821633975, "Episode Reward": 4779.603854885801, "Mean Reward": 36.48552560981528, "Episode": 1525, "Episode Step": 131}
{"Training time": 2.9847325816419388, "Episode Reward": 8655.989567592094, "Mean Reward": 36.06662319830039, "Episode": 1526, "Episode Step": 240}
{"Training time": 2.987371980282995, "Episode Reward": 7700.554294132097, "Mean Reward": 42.31073787984669, "Episode": 1527, "Episode Step": 182}
{"Training time": 2.9889808419015673, "Episode Reward": 4731.090742634698, "Mean Reward": 35.30664733309476, "Episode": 1528, "Episode Step": 134}
{"Training time": 2.9896814302603403, "Episode Reward": 1795.8043100311338, "Mean Reward": 30.96214327639886, "Episode": 1529, "Episode Step": 58}
{"Training time": 2.9908815197149914, "Episode Reward": 1860.506522749236, "Mean Reward": 30.500106930315344, "Episode": 1530, "Episode Step": 61}
{"Training time": 2.9925263927380246, "Episode Reward": 4917.8969660402245, "Mean Reward": 35.89705814627901, "Episode": 1531, "Episode Step": 137}
{"Training time": 2.995216346912914, "Episode Reward": 8554.382446194839, "Mean Reward": 38.01947753864373, "Episode": 1532, "Episode Step": 225}
{"Training time": 2.996891671948963, "Episode Reward": 4203.613967643882, "Mean Reward": 41.211901643567465, "Episode": 1533, "Episode Step": 102}
{"Training time": 2.9990302160713407, "Episode Reward": 6068.761905947694, "Mean Reward": 33.715343921931634, "Episode": 1534, "Episode Step": 180}
{"Training time": 3.0008549722035727, "Episode Reward": 6008.914234820261, "Mean Reward": 39.27394924719125, "Episode": 1535, "Episode Step": 153}
{"Training time": 3.0023551535606385, "Episode Reward": 3854.808037149817, "Mean Reward": 43.312449855615924, "Episode": 1536, "Episode Step": 89}
{"Training time": 3.0038207863436805, "Episode Reward": 5156.750702882807, "Mean Reward": 41.58669921679683, "Episode": 1537, "Episode Step": 124}
{"Training time": 3.0055825991100735, "Episode Reward": 5925.968510666336, "Mean Reward": 39.50645673777558, "Episode": 1538, "Episode Step": 150}
{"Training time": 3.008158332175679, "Episode Reward": 7692.2055468078825, "Mean Reward": 42.734475260043794, "Episode": 1539, "Episode Step": 180}
{"Training time": 3.009992310007413, "Episode Reward": 6119.79368779642, "Mean Reward": 39.738920050626106, "Episode": 1540, "Episode Step": 154}
{"Training time": 3.01284973833296, "Episode Reward": 9786.454814999302, "Mean Reward": 39.9447135306094, "Episode": 1541, "Episode Step": 245}
{"Training time": 3.0154602105087704, "Episode Reward": 7868.853680713879, "Mean Reward": 43.23545978414219, "Episode": 1542, "Episode Step": 182}
{"Training time": 3.0196551174587674, "Episode Reward": 14843.592814234891, "Mean Reward": 40.89144025960025, "Episode": 1543, "Episode Step": 363}
{"Training time": 3.022789300547706, "Episode Reward": 12218.336222021655, "Mean Reward": 45.42132424543366, "Episode": 1544, "Episode Step": 269}
{"Training time": 3.0283920554982293, "Episode Reward": 25070.036122207155, "Mean Reward": 56.46404532028639, "Episode": 1545, "Episode Step": 444}
{"Training time": 3.029493798613548, "Episode Reward": 302.5234266713486, "Mean Reward": 3.437766212174416, "Episode": 1546, "Episode Step": 88}
{"Training time": 3.03172287662824, "Episode Reward": 8428.901806824839, "Mean Reward": 44.83458407885553, "Episode": 1547, "Episode Step": 188}
{"Training time": 3.0328487808174556, "Episode Reward": 2177.948014608105, "Mean Reward": 40.33237064089084, "Episode": 1548, "Episode Step": 54}
{"Training time": 3.037050860259268, "Episode Reward": 11788.880600542325, "Mean Reward": 35.19068835982784, "Episode": 1549, "Episode Step": 335}
{"Training time": 3.0380693807866836, "Episode Reward": 2381.712044046084, "Mean Reward": 38.41471038784007, "Episode": 1550, "Episode Step": 62}
{"Training time": 3.03957233329614, "Episode Reward": 4773.778970171717, "Mean Reward": 53.63796595698559, "Episode": 1551, "Episode Step": 89}
{"Training time": 3.0418773724635444, "Episode Reward": 4621.244752872119, "Mean Reward": 23.458095192244258, "Episode": 1552, "Episode Step": 197}
{"Training time": 3.0425633086098567, "Episode Reward": 2089.1736183158464, "Mean Reward": 36.65216874238327, "Episode": 1553, "Episode Step": 57}
{"Training time": 3.044067356056637, "Episode Reward": 4541.875148248939, "Mean Reward": 52.81250172382487, "Episode": 1554, "Episode Step": 86}
{"Training time": 3.04532030834092, "Episode Reward": -161.37842838595935, "Mean Reward": -1.5821414547643073, "Episode": 1555, "Episode Step": 102}
{"Training time": 3.0476421446932687, "Episode Reward": 9147.790700368108, "Mean Reward": 47.397879276518694, "Episode": 1556, "Episode Step": 193}
{"Training time": 3.050275365511576, "Episode Reward": 7655.657666173825, "Mean Reward": 42.064053110845194, "Episode": 1557, "Episode Step": 182}
{"Training time": 3.053907141354349, "Episode Reward": 7428.072900378698, "Mean Reward": 24.354337378290815, "Episode": 1558, "Episode Step": 305}
{"Training time": 3.0561788800027636, "Episode Reward": 7835.884701189216, "Mean Reward": 41.025574351776, "Episode": 1559, "Episode Step": 191}
{"Training time": 3.058859923614396, "Episode Reward": 7821.08411659015, "Mean Reward": 41.381397442275926, "Episode": 1560, "Episode Step": 189}
{"Training time": 3.0623561396863725, "Episode Reward": 8279.378123596587, "Mean Reward": 28.1611500802605, "Episode": 1561, "Episode Step": 294}
{"Training time": 3.0645824072096084, "Episode Reward": 7717.908654169052, "Mean Reward": 40.83549552470398, "Episode": 1562, "Episode Step": 189}
{"Training time": 3.067242935829692, "Episode Reward": 8104.1804599933685, "Mean Reward": 44.04445902170309, "Episode": 1563, "Episode Step": 184}
{"Training time": 3.0684515921937097, "Episode Reward": -11.740702032419355, "Mean Reward": -0.11510492188646426, "Episode": 1564, "Episode Step": 102}
{"Training time": 3.0701920866303976, "Episode Reward": 5862.627459076118, "Mean Reward": 40.15498259641176, "Episode": 1565, "Episode Step": 146}
{"Training time": 3.07290950357914, "Episode Reward": 7569.486719166616, "Mean Reward": 39.630820519196945, "Episode": 1566, "Episode Step": 191}
{"Training time": 3.0738873619503444, "Episode Reward": -245.83952443702697, "Mean Reward": -3.0350558572472464, "Episode": 1567, "Episode Step": 81}
{"Training time": 3.0763763666152952, "Episode Reward": 7950.531140867448, "Mean Reward": 38.78307873593877, "Episode": 1568, "Episode Step": 205}
{"Training time": 3.078459831343757, "Episode Reward": 6438.646388814077, "Mean Reward": 48.41087510386524, "Episode": 1569, "Episode Step": 133}
{"Training time": 3.079715004960696, "Episode Reward": 6.601763316447473, "Mean Reward": 0.06472316976909287, "Episode": 1570, "Episode Step": 102}
{"Training time": 3.0820873591634963, "Episode Reward": 8023.056043740533, "Mean Reward": 40.933959406839456, "Episode": 1571, "Episode Step": 196}
{"Training time": 3.0835831130213207, "Episode Reward": 4616.169144067243, "Mean Reward": 53.67638539613073, "Episode": 1572, "Episode Step": 86}
{"Training time": 3.0873293044169743, "Episode Reward": 5810.831935447998, "Mean Reward": 18.447085509358725, "Episode": 1573, "Episode Step": 315}
{"Training time": 3.09086558467812, "Episode Reward": 15743.05032668565, "Mean Reward": 52.652342229717895, "Episode": 1574, "Episode Step": 299}
{"Training time": 3.093477705253495, "Episode Reward": 7617.728723586184, "Mean Reward": 42.086899025338035, "Episode": 1575, "Episode Step": 181}
{"Training time": 3.0957794260978697, "Episode Reward": 4334.555946332089, "Mean Reward": 21.672779731660444, "Episode": 1576, "Episode Step": 200}
{"Training time": 3.0992004635598924, "Episode Reward": 15804.610461972028, "Mean Reward": 54.68723343242916, "Episode": 1577, "Episode Step": 289}
{"Training time": 3.1012331816222933, "Episode Reward": 4988.7648632695655, "Mean Reward": 38.37511433284281, "Episode": 1578, "Episode Step": 130}
{"Training time": 3.101986514396138, "Episode Reward": -240.69743831615654, "Mean Reward": -4.011623971935943, "Episode": 1579, "Episode Step": 60}
{"Training time": 3.1034420361121495, "Episode Reward": 5289.547504756288, "Mean Reward": 44.44997903156544, "Episode": 1580, "Episode Step": 119}
{"Training time": 3.106529101067119, "Episode Reward": 10738.760628705673, "Mean Reward": 48.81254831229852, "Episode": 1581, "Episode Step": 220}
{"Training time": 3.1072100230058033, "Episode Reward": -229.749965288659, "Mean Reward": -4.030701145415071, "Episode": 1582, "Episode Step": 57}
{"Training time": 3.1100453758239746, "Episode Reward": 9808.012742100656, "Mean Reward": 41.2101375718515, "Episode": 1583, "Episode Step": 238}
{"Training time": 3.113264118035634, "Episode Reward": 12475.776230191006, "Mean Reward": 53.3152830350043, "Episode": 1584, "Episode Step": 234}
{"Training time": 3.1139329380459255, "Episode Reward": -229.35676710523944, "Mean Reward": -4.095656555450704, "Episode": 1585, "Episode Step": 56}
{"Training time": 3.114598723848661, "Episode Reward": 2397.2044984156564, "Mean Reward": 44.39267589658623, "Episode": 1586, "Episode Step": 54}
{"Training time": 3.117193086081081, "Episode Reward": 7971.373134334868, "Mean Reward": 44.040735548811426, "Episode": 1587, "Episode Step": 181}
{"Training time": 3.1182714896731905, "Episode Reward": -284.47048891950897, "Mean Reward": -3.160783210216766, "Episode": 1588, "Episode Step": 90}
{"Training time": 3.1200367599725722, "Episode Reward": 6073.584654297551, "Mean Reward": 40.76231311609095, "Episode": 1589, "Episode Step": 149}
{"Training time": 3.122552029689153, "Episode Reward": 8664.619825484766, "Mean Reward": 49.23079446298163, "Episode": 1590, "Episode Step": 176}
{"Training time": 3.1233231219318176, "Episode Reward": -286.77401732085445, "Mean Reward": -4.480844020638351, "Episode": 1591, "Episode Step": 64}
{"Training time": 3.124042246937752, "Episode Reward": 2366.3851140023876, "Mean Reward": 40.10822227122691, "Episode": 1592, "Episode Step": 59}
{"Training time": 3.126008113887575, "Episode Reward": 6555.53597233612, "Mean Reward": 51.215124783875936, "Episode": 1593, "Episode Step": 128}
{"Training time": 3.1272269066174827, "Episode Reward": -94.56242322044956, "Mean Reward": -0.936261616044055, "Episode": 1594, "Episode Step": 101}
{"Training time": 3.1279082874457043, "Episode Reward": 2442.251362816237, "Mean Reward": 43.611631478861376, "Episode": 1595, "Episode Step": 56}
{"Training time": 3.1291702818870544, "Episode Reward": -218.8682113918254, "Mean Reward": -3.266689722266051, "Episode": 1596, "Episode Step": 67}
{"Training time": 3.130354261332088, "Episode Reward": -86.14854623963625, "Mean Reward": -0.8445935905846691, "Episode": 1597, "Episode Step": 102}
{"Training time": 3.1325563469198014, "Episode Reward": 8338.554004815755, "Mean Reward": 44.591197886715264, "Episode": 1598, "Episode Step": 187}
{"Training time": 3.1360417124960156, "Episode Reward": 8683.130268867817, "Mean Reward": 38.083904688016744, "Episode": 1599, "Episode Step": 228}
{"Training time": 3.137532852490743, "Episode Reward": -69.93845685818502, "Mean Reward": -0.6856711456684806, "Episode": 1600, "Episode Step": 102}
{"Training time": 3.1390870143969853, "Episode Reward": 5373.700315048843, "Mean Reward": 41.020613091975896, "Episode": 1601, "Episode Step": 131}
{"Training time": 3.1417593327495785, "Episode Reward": 8443.640304787215, "Mean Reward": 45.15315671009206, "Episode": 1602, "Episode Step": 187}
{"Training time": 3.1429690063662, "Episode Reward": -26.275839798196863, "Mean Reward": -0.2576062725313418, "Episode": 1603, "Episode Step": 102}
{"Training time": 3.143689493338267, "Episode Reward": 2138.419767870102, "Mean Reward": 35.640329464501704, "Episode": 1604, "Episode Step": 60}
{"Training time": 3.146207597454389, "Episode Reward": 8347.221845644783, "Mean Reward": 48.24983725806233, "Episode": 1605, "Episode Step": 173}
{"Training time": 3.1470671474933622, "Episode Reward": -343.6824672853967, "Mean Reward": -4.707979003909544, "Episode": 1606, "Episode Step": 73}
{"Training time": 3.148763316935963, "Episode Reward": 5778.838301233191, "Mean Reward": 40.1308215363416, "Episode": 1607, "Episode Step": 144}
{"Training time": 3.151332996355163, "Episode Reward": 8217.817722737791, "Mean Reward": 45.65454290409884, "Episode": 1608, "Episode Step": 180}
{"Training time": 3.152241601347923, "Episode Reward": -347.2768199163637, "Mean Reward": -4.569431841004786, "Episode": 1609, "Episode Step": 76}
{"Training time": 3.1537552383210925, "Episode Reward": 6095.248438262904, "Mean Reward": 46.886526448176184, "Episode": 1610, "Episode Step": 130}
{"Training time": 3.1562249875068664, "Episode Reward": 8806.233610633662, "Mean Reward": 50.90308445452984, "Episode": 1611, "Episode Step": 173}
{"Training time": 3.1588408452272416, "Episode Reward": 5690.228790433903, "Mean Reward": 25.28990573526179, "Episode": 1612, "Episode Step": 225}
{"Training time": 3.160371789402432, "Episode Reward": 5793.259115361046, "Mean Reward": 44.9089853903957, "Episode": 1613, "Episode Step": 129}
{"Training time": 3.162842631936073, "Episode Reward": 8501.749452306476, "Mean Reward": 49.14306041795651, "Episode": 1614, "Episode Step": 173}
{"Training time": 3.16407087776396, "Episode Reward": -19.600680857192852, "Mean Reward": -0.1921635378156162, "Episode": 1615, "Episode Step": 102}
{"Training time": 3.1647327499919466, "Episode Reward": 2489.5016536928742, "Mean Reward": 46.101882475793964, "Episode": 1616, "Episode Step": 54}
{"Training time": 3.1666620680358677, "Episode Reward": 5394.68409268801, "Mean Reward": 43.859220265756186, "Episode": 1617, "Episode Step": 123}
{"Training time": 3.1677648238341014, "Episode Reward": -410.2691681121928, "Mean Reward": -4.411496431313901, "Episode": 1618, "Episode Step": 93}
{"Training time": 3.1692679007848104, "Episode Reward": 5842.151481581569, "Mean Reward": 44.93962678139668, "Episode": 1619, "Episode Step": 130}
{"Training time": 3.1709455360968906, "Episode Reward": 5068.463785159013, "Mean Reward": 48.73522870345205, "Episode": 1620, "Episode Step": 104}
{"Training time": 3.1721475683318245, "Episode Reward": -403.1141604377466, "Mean Reward": -4.031141604377466, "Episode": 1621, "Episode Step": 100}
{"Training time": 3.173557431631618, "Episode Reward": 4317.938475637119, "Mean Reward": 35.98282063030933, "Episode": 1622, "Episode Step": 120}
{"Training time": 3.1754858713679845, "Episode Reward": 6223.77328592735, "Mean Reward": 49.39502607878849, "Episode": 1623, "Episode Step": 126}
{"Training time": 3.176704111893972, "Episode Reward": -57.57290658453292, "Mean Reward": -0.5644402606326757, "Episode": 1624, "Episode Step": 102}
{"Training time": 3.178152285284466, "Episode Reward": 5897.039364691483, "Mean Reward": 47.5567690700926, "Episode": 1625, "Episode Step": 124}
{"Training time": 3.1798622569110657, "Episode Reward": 6117.753278378441, "Mean Reward": 57.175264283910664, "Episode": 1626, "Episode Step": 107}
{"Training time": 3.181036943329705, "Episode Reward": -372.70218656942546, "Mean Reward": -3.6539430055826028, "Episode": 1627, "Episode Step": 102}
{"Training time": 3.182620554169019, "Episode Reward": 5998.341421900914, "Mean Reward": 44.432158680747506, "Episode": 1628, "Episode Step": 135}
{"Training time": 3.1851612297031613, "Episode Reward": 8819.830330955649, "Mean Reward": 48.99905739419805, "Episode": 1629, "Episode Step": 180}
{"Training time": 3.1861080838574303, "Episode Reward": -499.1197195758046, "Mean Reward": -6.238996494697558, "Episode": 1630, "Episode Step": 80}
{"Training time": 3.187407682471805, "Episode Reward": 5532.08934880674, "Mean Reward": 49.838642782042704, "Episode": 1631, "Episode Step": 111}
{"Training time": 3.189997347460853, "Episode Reward": 9083.480550971744, "Mean Reward": 49.909233796548044, "Episode": 1632, "Episode Step": 182}
{"Training time": 3.191174825562371, "Episode Reward": -866.9886514134758, "Mean Reward": -8.669886514134758, "Episode": 1633, "Episode Step": 100}
{"Training time": 3.1925339749786588, "Episode Reward": 5631.246663227996, "Mean Reward": 48.54522985541376, "Episode": 1634, "Episode Step": 116}
{"Training time": 3.19600927942329, "Episode Reward": 15486.475222610801, "Mean Reward": 59.56336624081077, "Episode": 1635, "Episode Step": 260}
{"Training time": 3.197243189944161, "Episode Reward": 11.98649179120301, "Mean Reward": 0.11751462540395108, "Episode": 1636, "Episode Step": 102}
{"Training time": 3.1979408983389535, "Episode Reward": 2015.8183817163317, "Mean Reward": 35.365234766953186, "Episode": 1637, "Episode Step": 57}
{"Training time": 3.2004769116640093, "Episode Reward": 8956.94622450342, "Mean Reward": 50.03880572348279, "Episode": 1638, "Episode Step": 179}
{"Training time": 3.2016920644044875, "Episode Reward": -620.5302071888341, "Mean Reward": -6.083629482243471, "Episode": 1639, "Episode Step": 102}
{"Training time": 3.2030912899971007, "Episode Reward": 5812.32488980935, "Mean Reward": 48.43604074841125, "Episode": 1640, "Episode Step": 120}
{"Training time": 3.2077711355023912, "Episode Reward": 21615.2445806353, "Mean Reward": 59.38254005669038, "Episode": 1641, "Episode Step": 364}
{"Training time": 3.2088382366630768, "Episode Reward": -324.15123204202274, "Mean Reward": -3.601680356022475, "Episode": 1642, "Episode Step": 90}
{"Training time": 3.211106015841166, "Episode Reward": 9135.123715056092, "Mean Reward": 47.57876934925048, "Episode": 1643, "Episode Step": 192}
{"Training time": 3.213687614136272, "Episode Reward": 8334.30008497698, "Mean Reward": 46.04585682307724, "Episode": 1644, "Episode Step": 181}
{"Training time": 3.214906003276507, "Episode Reward": -209.89475222421282, "Mean Reward": -2.057791688472675, "Episode": 1645, "Episode Step": 102}
{"Training time": 3.216573992504014, "Episode Reward": 6017.4415466764285, "Mean Reward": 42.98172533340306, "Episode": 1646, "Episode Step": 140}
{"Training time": 3.2229849461052154, "Episode Reward": 25936.971572390714, "Mean Reward": 51.462245183314906, "Episode": 1647, "Episode Step": 504}
{"Training time": 3.224097238050567, "Episode Reward": -641.3114840276296, "Mean Reward": -6.895822408899243, "Episode": 1648, "Episode Step": 93}
{"Training time": 3.2268779241376455, "Episode Reward": 5526.748212162153, "Mean Reward": 42.513447785862716, "Episode": 1649, "Episode Step": 130}
{"Training time": 3.229511237475607, "Episode Reward": 7980.419625256164, "Mean Reward": 44.58334986176628, "Episode": 1650, "Episode Step": 179}
{"Training time": 3.23046927107705, "Episode Reward": -438.00939060598694, "Mean Reward": -5.615505007769063, "Episode": 1651, "Episode Step": 78}
{"Training time": 3.232107365263833, "Episode Reward": 5829.523976724733, "Mean Reward": 42.55126990310024, "Episode": 1652, "Episode Step": 137}
{"Training time": 3.2340220108297135, "Episode Reward": 5517.513575508025, "Mean Reward": 44.49607722183891, "Episode": 1653, "Episode Step": 124}
{"Training time": 3.2350731788741216, "Episode Reward": -236.8211575211117, "Mean Reward": -2.69114951728536, "Episode": 1654, "Episode Step": 88}
{"Training time": 3.2365512013435365, "Episode Reward": 4674.912431163899, "Mean Reward": 37.70090670293467, "Episode": 1655, "Episode Step": 124}
{"Training time": 3.2384881146748863, "Episode Reward": 5263.005274545397, "Mean Reward": 42.788660768661764, "Episode": 1656, "Episode Step": 123}
{"Training time": 3.239419479701254, "Episode Reward": -251.4378242370669, "Mean Reward": -3.2654262887930767, "Episode": 1657, "Episode Step": 77}
{"Training time": 3.2411960838900673, "Episode Reward": 6049.603251980135, "Mean Reward": 40.33068834653423, "Episode": 1658, "Episode Step": 150}
{"Training time": 3.2446324896812437, "Episode Reward": 14336.990082968652, "Mean Reward": 57.11948240226555, "Episode": 1659, "Episode Step": 251}
{"Training time": 3.245331696338124, "Episode Reward": -260.9501464770382, "Mean Reward": -4.499140456500658, "Episode": 1660, "Episode Step": 58}
{"Training time": 3.2509802869293423, "Episode Reward": 23749.21115456289, "Mean Reward": 49.170209429736836, "Episode": 1661, "Episode Step": 483}
{"Training time": 3.254159659412172, "Episode Reward": 12278.103301646386, "Mean Reward": 52.92285905882063, "Episode": 1662, "Episode Step": 232}
{"Training time": 3.2553635952207776, "Episode Reward": -41.07694408142865, "Mean Reward": -0.40271513805322207, "Episode": 1663, "Episode Step": 102}
{"Training time": 3.2576986555258434, "Episode Reward": 8374.732435913957, "Mean Reward": 42.08408259253245, "Episode": 1664, "Episode Step": 199}
{"Training time": 3.260341167781088, "Episode Reward": 9059.356088499382, "Mean Reward": 48.96949237026693, "Episode": 1665, "Episode Step": 185}
{"Training time": 3.2611092688639958, "Episode Reward": -271.43110213805335, "Mean Reward": -4.2411109709070836, "Episode": 1666, "Episode Step": 64}
{"Training time": 3.2617584052350788, "Episode Reward": 2076.7980939545764, "Mean Reward": 37.75996534462866, "Episode": 1667, "Episode Step": 55}
{"Training time": 3.271061599122153, "Episode Reward": 43636.101958573956, "Mean Reward": 57.26522566741989, "Episode": 1668, "Episode Step": 762}
{"Training time": 3.271781726611985, "Episode Reward": -242.38209801988154, "Mean Reward": -4.039701633664692, "Episode": 1669, "Episode Step": 60}
{"Training time": 3.2733866502841313, "Episode Reward": 6153.326678550847, "Mean Reward": 44.58932375761483, "Episode": 1670, "Episode Step": 138}
{"Training time": 3.278365963300069, "Episode Reward": 21236.63678724709, "Mean Reward": 55.44813782571042, "Episode": 1671, "Episode Step": 383}
{"Training time": 3.2796010910802416, "Episode Reward": -33.51661887227456, "Mean Reward": -0.32859430266935846, "Episode": 1672, "Episode Step": 102}
{"Training time": 3.281300114724371, "Episode Reward": 6002.197052532524, "Mean Reward": 42.56877342221648, "Episode": 1673, "Episode Step": 141}
{"Training time": 3.2845822363429598, "Episode Reward": 13485.548023115183, "Mean Reward": 57.14215264031857, "Episode": 1674, "Episode Step": 236}
{"Training time": 3.2858233219385147, "Episode Reward": -6.770432986957932, "Mean Reward": -0.06637679398978365, "Episode": 1675, "Episode Step": 102}
{"Training time": 3.2875725322299534, "Episode Reward": 5723.998008549454, "Mean Reward": 38.41609401711043, "Episode": 1676, "Episode Step": 149}
{"Training time": 3.2902591421869065, "Episode Reward": 7814.776287359026, "Mean Reward": 41.56795897531397, "Episode": 1677, "Episode Step": 188}
{"Training time": 3.291065128048261, "Episode Reward": -274.7695417875946, "Mean Reward": -4.163174875569616, "Episode": 1678, "Episode Step": 66}
{"Training time": 3.2929480627510284, "Episode Reward": 5635.063095888661, "Mean Reward": 35.664956303092794, "Episode": 1679, "Episode Step": 158}
{"Training time": 3.301907846662733, "Episode Reward": 36591.494654576774, "Mean Reward": 50.610642675763174, "Episode": 1680, "Episode Step": 723}
{"Training time": 3.3028405544492934, "Episode Reward": -215.95734727201832, "Mean Reward": -2.8046408736625756, "Episode": 1681, "Episode Step": 77}
{"Training time": 3.304155250257916, "Episode Reward": 5589.986280427224, "Mean Reward": 49.46890513652411, "Episode": 1682, "Episode Step": 113}
{"Training time": 3.3070551444424523, "Episode Reward": 8268.833744316742, "Mean Reward": 39.18878551808883, "Episode": 1683, "Episode Step": 211}
{"Training time": 3.3082691830396653, "Episode Reward": 18.555499360165253, "Mean Reward": 0.181916660393777, "Episode": 1684, "Episode Step": 102}
{"Training time": 3.3103734221723347, "Episode Reward": 8834.756346722808, "Mean Reward": 48.81080854542988, "Episode": 1685, "Episode Step": 181}
{"Training time": 3.3132930838399464, "Episode Reward": 9423.909891488955, "Mean Reward": 44.66308005445002, "Episode": 1686, "Episode Step": 211}
{"Training time": 3.314128734668096, "Episode Reward": -311.8100651974097, "Mean Reward": -4.518986452136373, "Episode": 1687, "Episode Step": 69}
{"Training time": 3.315667426387469, "Episode Reward": 5575.148833420095, "Mean Reward": 42.23597601075829, "Episode": 1688, "Episode Step": 132}
{"Training time": 3.3182682299613955, "Episode Reward": 8886.892205664699, "Mean Reward": 48.03725516575513, "Episode": 1689, "Episode Step": 185}
{"Training time": 3.3221725696987576, "Episode Reward": 13659.929597830893, "Mean Reward": 40.77590924725639, "Episode": 1690, "Episode Step": 335}
{"Training time": 3.3247181066539553, "Episode Reward": 9320.61624147701, "Mean Reward": 41.984757844491035, "Episode": 1691, "Episode Step": 222}
{"Training time": 3.327393186887105, "Episode Reward": 8395.998202859351, "Mean Reward": 44.65956490882634, "Episode": 1692, "Episode Step": 188}
{"Training time": 3.329730186396175, "Episode Reward": 9089.056701566287, "Mean Reward": 45.445283507831434, "Episode": 1693, "Episode Step": 200}
{"Training time": 3.332172047164705, "Episode Reward": 9100.169197680305, "Mean Reward": 43.33413903657288, "Episode": 1694, "Episode Step": 210}
{"Training time": 3.3347831633355884, "Episode Reward": 8688.554748449977, "Mean Reward": 47.22040624157596, "Episode": 1695, "Episode Step": 184}
{"Training time": 3.3364237611161336, "Episode Reward": 5910.932180225098, "Mean Reward": 41.626282959331675, "Episode": 1696, "Episode Step": 142}
{"Training time": 3.3525708335638047, "Episode Reward": 66559.20247071637, "Mean Reward": 47.6103021965067, "Episode": 1697, "Episode Step": 1398}
{"Training time": 3.3551226282782025, "Episode Reward": 9314.312582351693, "Mean Reward": 51.46029051023035, "Episode": 1698, "Episode Step": 181}
{"Training time": 3.365580819712745, "Episode Reward": 44272.61320299207, "Mean Reward": 54.92880049999016, "Episode": 1699, "Episode Step": 806}
{"Training time": 3.3693342696958117, "Episode Reward": 10765.567269360283, "Mean Reward": 35.885224231200944, "Episode": 1700, "Episode Step": 300}
{"Training time": 3.3899271524614756, "Episode Reward": 97786.93133593365, "Mean Reward": 55.84633428665543, "Episode": 1701, "Episode Step": 1751}
{"Training time": 3.3931410249736573, "Episode Reward": 16250.44367790049, "Mean Reward": 58.66586165307036, "Episode": 1702, "Episode Step": 277}
{"Training time": 3.4023729413747787, "Episode Reward": 38737.570036100595, "Mean Reward": 48.66528899007612, "Episode": 1703, "Episode Step": 796}
{"Training time": 3.4050019668870504, "Episode Reward": 7871.4750669432515, "Mean Reward": 41.64801622721297, "Episode": 1704, "Episode Step": 189}
{"Training time": 3.4074193671676847, "Episode Reward": 9295.478684367006, "Mean Reward": 44.90569412737684, "Episode": 1705, "Episode Step": 207}
{"Training time": 3.4106980299949647, "Episode Reward": 12277.15490792558, "Mean Reward": 43.690942732831246, "Episode": 1706, "Episode Step": 281}
{"Training time": 3.414154295259052, "Episode Reward": 14750.665023127058, "Mean Reward": 57.3955837475761, "Episode": 1707, "Episode Step": 257}
{"Training time": 3.4166020558277768, "Episode Reward": 8879.493496968458, "Mean Reward": 42.4856148180309, "Episode": 1708, "Episode Step": 209}
{"Training time": 3.419646006623904, "Episode Reward": 12763.413106811087, "Mean Reward": 48.34626176822382, "Episode": 1709, "Episode Step": 264}
{"Training time": 3.422521213557985, "Episode Reward": 8644.750602750135, "Mean Reward": 41.3624430753595, "Episode": 1710, "Episode Step": 209}
{"Training time": 3.425332490536902, "Episode Reward": 11640.80261992231, "Mean Reward": 48.50334424967629, "Episode": 1711, "Episode Step": 240}
{"Training time": 3.4282342724667654, "Episode Reward": 11086.384706514576, "Mean Reward": 44.523633359496294, "Episode": 1712, "Episode Step": 249}
{"Training time": 3.433687367770407, "Episode Reward": 22061.12348228123, "Mean Reward": 51.30493833088658, "Episode": 1713, "Episode Step": 430}
{"Training time": 3.43477823442883, "Episode Reward": 4105.954278944263, "Mean Reward": 44.15004601015337, "Episode": 1714, "Episode Step": 93}
{"Training time": 3.4393905377388, "Episode Reward": 17665.808215809055, "Mean Reward": 44.164520539522634, "Episode": 1715, "Episode Step": 400}
{"Training time": 3.454225561618805, "Episode Reward": 63063.785114156715, "Mean Reward": 50.735144902780945, "Episode": 1716, "Episode Step": 1243}
{"Training time": 3.460301168560982, "Episode Reward": 24009.83432298962, "Mean Reward": 45.995851193466706, "Episode": 1717, "Episode Step": 522}
{"Training time": 3.4622477244006262, "Episode Reward": 6324.337232413959, "Mean Reward": 37.42211380126603, "Episode": 1718, "Episode Step": 169}
{"Training time": 3.4663485238949456, "Episode Reward": 19138.545704363798, "Mean Reward": 61.34149264219166, "Episode": 1719, "Episode Step": 312}
{"Training time": 3.4684002033207153, "Episode Reward": 7565.088804403036, "Mean Reward": 42.74061471414145, "Episode": 1720, "Episode Step": 177}
{"Training time": 3.471745259695583, "Episode Reward": 9518.143526308091, "Mean Reward": 33.28022211995836, "Episode": 1721, "Episode Step": 286}
{"Training time": 3.4759741685787837, "Episode Reward": 19169.36357854913, "Mean Reward": 59.347874856189264, "Episode": 1722, "Episode Step": 323}
{"Training time": 3.4774294427368377, "Episode Reward": 5975.278351055311, "Mean Reward": 48.18772863754283, "Episode": 1723, "Episode Step": 124}
{"Training time": 3.4804189249542024, "Episode Reward": 11208.231499272704, "Mean Reward": 43.953849016755704, "Episode": 1724, "Episode Step": 255}
{"Training time": 3.483014939957195, "Episode Reward": 8905.519608506753, "Mean Reward": 48.39956308971061, "Episode": 1725, "Episode Step": 184}
{"Training time": 3.484431420829561, "Episode Reward": 5337.087090235425, "Mean Reward": 43.39095195313354, "Episode": 1726, "Episode Step": 123}
{"Training time": 3.493899981379509, "Episode Reward": 39779.62211725389, "Mean Reward": 48.86931464036105, "Episode": 1727, "Episode Step": 814}
{"Training time": 3.496572142177158, "Episode Reward": 8944.09003059602, "Mean Reward": 47.32322767511122, "Episode": 1728, "Episode Step": 189}
{"Training time": 3.4979649949736067, "Episode Reward": 5480.9277992342195, "Mean Reward": 45.67439832695183, "Episode": 1729, "Episode Step": 120}
{"Training time": 3.500778511895074, "Episode Reward": 12154.536542920041, "Mean Reward": 49.813674356229676, "Episode": 1730, "Episode Step": 244}
{"Training time": 3.5311131966114044, "Episode Reward": 141383.1333758949, "Mean Reward": 54.54596195057673, "Episode": 1731, "Episode Step": 2592}
{"Training time": 3.53313963578807, "Episode Reward": 7773.7736752438295, "Mean Reward": 44.42156385853617, "Episode": 1732, "Episode Step": 175}
{"Training time": 3.5357765816317666, "Episode Reward": 11184.27451391647, "Mean Reward": 48.8396266983252, "Episode": 1733, "Episode Step": 229}
{"Training time": 3.5424230052365195, "Episode Reward": 31093.16094438842, "Mean Reward": 59.22506846550175, "Episode": 1734, "Episode Step": 525}
{"Training time": 3.5460253313514922, "Episode Reward": 16503.433947832353, "Mean Reward": 53.58257775270244, "Episode": 1735, "Episode Step": 308}
{"Training time": 3.550512293047375, "Episode Reward": 21336.66895050709, "Mean Reward": 54.85004871595653, "Episode": 1736, "Episode Step": 389}
{"Training time": 3.559499737487899, "Episode Reward": 38227.91834848976, "Mean Reward": 52.43884547117937, "Episode": 1737, "Episode Step": 729}
{"Training time": 3.561530500782861, "Episode Reward": 8434.28712841987, "Mean Reward": 48.472914531148675, "Episode": 1738, "Episode Step": 174}
{"Training time": 3.57397796690464, "Episode Reward": 56453.52686041008, "Mean Reward": 52.563805270400444, "Episode": 1739, "Episode Step": 1074}
{"Training time": 3.5767037394311694, "Episode Reward": 8994.640088777836, "Mean Reward": 47.092356485747835, "Episode": 1740, "Episode Step": 191}
{"Training time": 3.5824332757790884, "Episode Reward": 28357.409476114215, "Mean Reward": 57.63701113031345, "Episode": 1741, "Episode Step": 492}
{"Training time": 3.58591521581014, "Episode Reward": 13668.450835543783, "Mean Reward": 46.021719984995904, "Episode": 1742, "Episode Step": 297}
{"Training time": 3.5881131188737023, "Episode Reward": 6410.486959627171, "Mean Reward": 42.73657973084781, "Episode": 1743, "Episode Step": 150}
{"Training time": 3.589115397731463, "Episode Reward": 4857.929220179994, "Mean Reward": 57.15210847270582, "Episode": 1744, "Episode Step": 85}
{"Training time": 3.5979475263754526, "Episode Reward": 37745.72245770522, "Mean Reward": 50.1937798639697, "Episode": 1745, "Episode Step": 752}
{"Training time": 3.6013335447178947, "Episode Reward": 10746.678266713443, "Mean Reward": 42.986713066853774, "Episode": 1746, "Episode Step": 250}
{"Training time": 3.6033920468886693, "Episode Reward": 8467.330194864095, "Mean Reward": 48.1098306526369, "Episode": 1747, "Episode Step": 176}
{"Training time": 3.61899958272775, "Episode Reward": 74611.11197410103, "Mean Reward": 56.4807812067381, "Episode": 1748, "Episode Step": 1321}
{"Training time": 3.6219121427668464, "Episode Reward": 4753.234899140966, "Mean Reward": 46.1479116421453, "Episode": 1749, "Episode Step": 103}
{"Training time": 3.6236352780130177, "Episode Reward": 6427.655150740662, "Mean Reward": 53.121116948269936, "Episode": 1750, "Episode Step": 121}
{"Training time": 3.629860991107093, "Episode Reward": 28848.760946522918, "Mean Reward": 54.12525505914243, "Episode": 1751, "Episode Step": 533}
{"Training time": 3.6678102255529828, "Episode Reward": 175755.1794517421, "Mean Reward": 54.63325441459188, "Episode": 1752, "Episode Step": 3217}
{"Training time": 3.679171391924222, "Episode Reward": 55614.92751350309, "Mean Reward": 57.453437513949474, "Episode": 1753, "Episode Step": 968}
{"Training time": 3.681942389143838, "Episode Reward": 10948.247867464068, "Mean Reward": 46.39088079433927, "Episode": 1754, "Episode Step": 236}
{"Training time": 3.6900698510805765, "Episode Reward": 31675.197370563445, "Mean Reward": 47.77556164489207, "Episode": 1755, "Episode Step": 663}
{"Training time": 3.692439792222447, "Episode Reward": 9310.464460567355, "Mean Reward": 46.320718709290325, "Episode": 1756, "Episode Step": 201}
{"Training time": 3.6951872130235035, "Episode Reward": 10660.441489423214, "Mean Reward": 45.752967765764865, "Episode": 1757, "Episode Step": 233}
{"Training time": 3.698637582461039, "Episode Reward": 12125.170911519352, "Mean Reward": 46.99678647875718, "Episode": 1758, "Episode Step": 258}
{"Training time": 3.7009909719228746, "Episode Reward": 9304.506451391742, "Mean Reward": 46.29107687259573, "Episode": 1759, "Episode Step": 201}
{"Training time": 3.7042126424445048, "Episode Reward": 13843.589973416027, "Mean Reward": 49.61860205525458, "Episode": 1760, "Episode Step": 279}
{"Training time": 3.7249938530392117, "Episode Reward": 93234.59007994561, "Mean Reward": 53.8616927093851, "Episode": 1761, "Episode Step": 1731}
{"Training time": 3.727907636364301, "Episode Reward": 14237.378225281382, "Mean Reward": 58.11174785829135, "Episode": 1762, "Episode Step": 245}
{"Training time": 3.7307639849848218, "Episode Reward": 10687.73753920964, "Mean Reward": 44.34745866891967, "Episode": 1763, "Episode Step": 241}
{"Training time": 3.7404673557811314, "Episode Reward": 41325.384164969226, "Mean Reward": 51.52791043013619, "Episode": 1764, "Episode Step": 802}
{"Training time": 3.7433048602607517, "Episode Reward": 14358.932951172907, "Mean Reward": 58.607889596624105, "Episode": 1765, "Episode Step": 245}
{"Training time": 3.7465887541241116, "Episode Reward": 11869.413933777656, "Mean Reward": 42.2399072376429, "Episode": 1766, "Episode Step": 281}
{"Training time": 3.7661742416355346, "Episode Reward": 88851.12277169367, "Mean Reward": 54.11152422149432, "Episode": 1767, "Episode Step": 1642}
{"Training time": 3.7685471927457384, "Episode Reward": 9782.154276462124, "Mean Reward": 48.66743421125435, "Episode": 1768, "Episode Step": 201}
{"Training time": 3.777693589727084, "Episode Reward": 43526.85717277744, "Mean Reward": 55.66094267618598, "Episode": 1769, "Episode Step": 782}
{"Training time": 3.7804926241106456, "Episode Reward": 8581.610991559852, "Mean Reward": 43.34146965434269, "Episode": 1770, "Episode Step": 198}
{"Training time": 3.7830108063750796, "Episode Reward": 10600.99765039814, "Mean Reward": 49.078692825917315, "Episode": 1771, "Episode Step": 216}
{"Training time": 3.7856399841441046, "Episode Reward": 10051.08154675245, "Mean Reward": 44.671473541122, "Episode": 1772, "Episode Step": 225}
{"Training time": 3.7947671210765836, "Episode Reward": 43551.450028744184, "Mean Reward": 59.01280491699754, "Episode": 1773, "Episode Step": 738}
{"Training time": 3.797667435805003, "Episode Reward": 13774.467033323906, "Mean Reward": 56.68504951985147, "Episode": 1774, "Episode Step": 243}
{"Training time": 3.8120114307933384, "Episode Reward": 66984.52093054897, "Mean Reward": 55.22219367728687, "Episode": 1775, "Episode Step": 1213}
{"Training time": 3.8146507769160802, "Episode Reward": 8933.741535729774, "Mean Reward": 48.290494787728505, "Episode": 1776, "Episode Step": 185}
{"Training time": 3.817067105240292, "Episode Reward": 9563.445889717936, "Mean Reward": 46.87963671430361, "Episode": 1777, "Episode Step": 204}
{"Training time": 3.8256795977221594, "Episode Reward": 39655.38187314486, "Mean Reward": 53.66086856988479, "Episode": 1778, "Episode Step": 739}
{"Training time": 3.8340453035963904, "Episode Reward": 38962.68667057806, "Mean Reward": 57.38245459584398, "Episode": 1779, "Episode Step": 679}
{"Training time": 3.836097648276223, "Episode Reward": 8229.676877779031, "Mean Reward": 47.02672501588018, "Episode": 1780, "Episode Step": 175}
{"Training time": 3.8422011291318467, "Episode Reward": 28784.018069992082, "Mean Reward": 56.00003515562662, "Episode": 1781, "Episode Step": 514}
{"Training time": 3.8503798847066033, "Episode Reward": 35278.15440454789, "Mean Reward": 53.451749097799826, "Episode": 1782, "Episode Step": 660}
{"Training time": 3.8531472338570487, "Episode Reward": 12554.29384411626, "Mean Reward": 54.34759239877169, "Episode": 1783, "Episode Step": 231}
{"Training time": 3.856004499130779, "Episode Reward": 11663.069659573965, "Mean Reward": 47.799465817926084, "Episode": 1784, "Episode Step": 244}
{"Training time": 3.859406308333079, "Episode Reward": 13705.857168472658, "Mean Reward": 54.82342867389063, "Episode": 1785, "Episode Step": 250}
{"Training time": 3.8614431977272035, "Episode Reward": 9011.683621940023, "Mean Reward": 52.09065677421979, "Episode": 1786, "Episode Step": 173}
{"Training time": 3.8699904658397037, "Episode Reward": 40931.71591806197, "Mean Reward": 55.387978238243534, "Episode": 1787, "Episode Step": 739}
{"Training time": 3.880608151356379, "Episode Reward": 49512.07728740376, "Mean Reward": 57.90886232444884, "Episode": 1788, "Episode Step": 855}
{"Training time": 3.882692656053437, "Episode Reward": 8911.119986467123, "Mean Reward": 50.63136355947229, "Episode": 1789, "Episode Step": 176}
{"Training time": 3.8849367727835973, "Episode Reward": 8849.839020326264, "Mean Reward": 46.824545081091344, "Episode": 1790, "Episode Step": 189}
{"Training time": 3.9033208030462263, "Episode Reward": 87889.58673996403, "Mean Reward": 57.860162435789356, "Episode": 1791, "Episode Step": 1519}
{"Training time": 3.9054566880067187, "Episode Reward": 8118.707355685937, "Mean Reward": 45.355907015005236, "Episode": 1792, "Episode Step": 179}
{"Training time": 3.908911086652014, "Episode Reward": 15126.911644691618, "Mean Reward": 51.62768479416934, "Episode": 1793, "Episode Step": 293}
{"Training time": 3.9122809230619007, "Episode Reward": 12741.90837069978, "Mean Reward": 51.37866278507976, "Episode": 1794, "Episode Step": 248}
{"Training time": 3.9151339111063215, "Episode Reward": 14488.18190244762, "Mean Reward": 59.622147746698026, "Episode": 1795, "Episode Step": 243}
{"Training time": 3.91813822944959, "Episode Reward": 13554.22959975112, "Mean Reward": 54.21691839900448, "Episode": 1796, "Episode Step": 250}
{"Training time": 3.9231135055091646, "Episode Reward": 20930.95098049055, "Mean Reward": 54.79306539395432, "Episode": 1797, "Episode Step": 382}
{"Training time": 3.925736598836051, "Episode Reward": 10570.463652686167, "Mean Reward": 47.83015227459804, "Episode": 1798, "Episode Step": 221}
{"Training time": 3.9343595230579376, "Episode Reward": 32681.023310679346, "Mean Reward": 51.385256777797714, "Episode": 1799, "Episode Step": 636}
{"Training time": 3.9483971741464403, "Episode Reward": 66483.44164095042, "Mean Reward": 58.165740718241835, "Episode": 1800, "Episode Step": 1143}
{"Training time": 3.9505662199523712, "Episode Reward": 8898.367680128833, "Mean Reward": 49.43537600071574, "Episode": 1801, "Episode Step": 180}
{"Training time": 3.9570631724596024, "Episode Reward": 28554.21785247112, "Mean Reward": 51.44904117562364, "Episode": 1802, "Episode Step": 555}
{"Training time": 3.9607959446642136, "Episode Reward": 17381.862480233664, "Mean Reward": 62.52468518069663, "Episode": 1803, "Episode Step": 278}
{"Training time": 3.9628127749760944, "Episode Reward": 9020.20743736317, "Mean Reward": 51.84027262852396, "Episode": 1804, "Episode Step": 174}
{"Training time": 3.9777733282910455, "Episode Reward": 70283.74433534293, "Mean Reward": 55.42882045374048, "Episode": 1805, "Episode Step": 1268}
{"Training time": 3.9901934283309513, "Episode Reward": 61861.40940622728, "Mean Reward": 60.35259454266076, "Episode": 1806, "Episode Step": 1025}
{"Training time": 3.991250662472513, "Episode Reward": 4727.108237761192, "Mean Reward": 53.71713906546809, "Episode": 1807, "Episode Step": 88}
{"Training time": 3.9930933272176317, "Episode Reward": 6186.688148611136, "Mean Reward": 40.17329966630608, "Episode": 1808, "Episode Step": 154}
{"Training time": 4.019930341906018, "Episode Reward": 137589.22387489263, "Mean Reward": 61.25967225062005, "Episode": 1809, "Episode Step": 2246}
{"Training time": 4.022946346667077, "Episode Reward": 17225.985506242047, "Mean Reward": 67.02718095814026, "Episode": 1810, "Episode Step": 257}
{"Training time": 4.025698824392425, "Episode Reward": 11587.414818921094, "Mean Reward": 49.09921533441141, "Episode": 1811, "Episode Step": 236}
{"Training time": 4.028847753339344, "Episode Reward": 10720.011331292168, "Mean Reward": 47.857193443268606, "Episode": 1812, "Episode Step": 224}
{"Training time": 4.035216403603553, "Episode Reward": 35511.64649475896, "Mean Reward": 65.7623083236277, "Episode": 1813, "Episode Step": 540}
{"Training time": 4.049279797209634, "Episode Reward": 62721.02088093528, "Mean Reward": 52.35477535971225, "Episode": 1814, "Episode Step": 1198}
{"Training time": 4.058459047211541, "Episode Reward": 42952.21115156192, "Mean Reward": 58.200828118647586, "Episode": 1815, "Episode Step": 738}
{"Training time": 4.064088390270869, "Episode Reward": 30230.470772952256, "Mean Reward": 63.643096364110015, "Episode": 1816, "Episode Step": 475}
{"Training time": 4.06529021859169, "Episode Reward": 21.791773240779527, "Mean Reward": 0.21364483569391693, "Episode": 1817, "Episode Step": 102}
{"Training time": 4.067994374169244, "Episode Reward": 8881.372016112591, "Mean Reward": 46.99138632863805, "Episode": 1818, "Episode Step": 189}
{"Training time": 4.07387915637758, "Episode Reward": 32007.221908018437, "Mean Reward": 64.14272927458605, "Episode": 1819, "Episode Step": 499}
{"Training time": 4.091909893022644, "Episode Reward": 83545.42896234023, "Mean Reward": 54.783887844157526, "Episode": 1820, "Episode Step": 1525}
{"Training time": 4.1262039094501075, "Episode Reward": 174240.61209613612, "Mean Reward": 60.2075370062668, "Episode": 1821, "Episode Step": 2894}
{"Training time": 4.128250845803155, "Episode Reward": 9114.159361955948, "Mean Reward": 52.38022621813763, "Episode": 1822, "Episode Step": 174}
{"Training time": 4.137202072739601, "Episode Reward": 45203.965620830386, "Mean Reward": 58.782790144122735, "Episode": 1823, "Episode Step": 769}
{"Training time": 4.140542876919111, "Episode Reward": 13078.435253869642, "Mean Reward": 53.82072120934009, "Episode": 1824, "Episode Step": 243}
{"Training time": 4.144149868554539, "Episode Reward": 19573.249643548716, "Mean Reward": 63.756513496901356, "Episode": 1825, "Episode Step": 307}
{"Training time": 4.171285631391737, "Episode Reward": 126639.41506009072, "Mean Reward": 54.398374166705636, "Episode": 1826, "Episode Step": 2328}
{"Training time": 4.175506906112035, "Episode Reward": 17862.56356390192, "Mean Reward": 56.887145107967896, "Episode": 1827, "Episode Step": 314}
{"Training time": 4.177548164725303, "Episode Reward": 9222.64001185478, "Mean Reward": 53.31005787199295, "Episode": 1828, "Episode Step": 173}
{"Training time": 4.186097175280253, "Episode Reward": 43062.40066562663, "Mean Reward": 58.98958995291319, "Episode": 1829, "Episode Step": 730}
{"Training time": 4.189809503290388, "Episode Reward": 15532.159028749309, "Mean Reward": 56.275938509961264, "Episode": 1830, "Episode Step": 276}
{"Training time": 4.201812329689662, "Episode Reward": 64655.35092967767, "Mean Reward": 63.32551511231897, "Episode": 1831, "Episode Step": 1021}
{"Training time": 4.204819188581572, "Episode Reward": 14287.599743007731, "Mean Reward": 57.6112892863215, "Episode": 1832, "Episode Step": 248}
{"Training time": 4.236291846103138, "Episode Reward": 165462.4617426492, "Mean Reward": 62.62772965278168, "Episode": 1833, "Episode Step": 2642}
{"Training time": 4.240006419420243, "Episode Reward": 18980.02608823581, "Mean Reward": 60.25405107376447, "Episode": 1834, "Episode Step": 315}
{"Training time": 4.245301752752728, "Episode Reward": 24879.648008210774, "Mean Reward": 55.90932136676578, "Episode": 1835, "Episode Step": 445}
{"Training time": 4.268697065777249, "Episode Reward": 119936.3578952692, "Mean Reward": 61.16081483695523, "Episode": 1836, "Episode Step": 1961}
{"Training time": 4.272494333055285, "Episode Reward": 16416.457592970084, "Mean Reward": 50.35723188027633, "Episode": 1837, "Episode Step": 326}
{"Training time": 4.274706791374419, "Episode Reward": 8540.433598226664, "Mean Reward": 45.4278382884397, "Episode": 1838, "Episode Step": 188}
{"Training time": 4.304101843039195, "Episode Reward": 153693.20603268006, "Mean Reward": 61.94808788096737, "Episode": 1839, "Episode Step": 2481}
{"Training time": 4.306298588845465, "Episode Reward": 7935.346334664245, "Mean Reward": 42.43500713724195, "Episode": 1840, "Episode Step": 187}
{"Training time": 4.3087023288673825, "Episode Reward": 8332.844288739021, "Mean Reward": 40.64802092067815, "Episode": 1841, "Episode Step": 205}
{"Training time": 4.3340463452206714, "Episode Reward": 129163.83902562763, "Mean Reward": 60.104159621045895, "Episode": 1842, "Episode Step": 2149}
{"Training time": 4.337714640829298, "Episode Reward": 19025.88541518617, "Mean Reward": 60.208498149323326, "Episode": 1843, "Episode Step": 316}
{"Training time": 4.34708171553082, "Episode Reward": 47221.3992856808, "Mean Reward": 58.08290195040689, "Episode": 1844, "Episode Step": 813}
{"Training time": 4.353311954140663, "Episode Reward": 29804.529101797587, "Mean Reward": 60.08977641491449, "Episode": 1845, "Episode Step": 496}
{"Training time": 4.3631902819209625, "Episode Reward": 49134.48758027238, "Mean Reward": 57.737353208310665, "Episode": 1846, "Episode Step": 851}
{"Training time": 4.37171900914775, "Episode Reward": 38695.619060487035, "Mean Reward": 53.4469876526064, "Episode": 1847, "Episode Step": 724}
{"Training time": 4.377772957748837, "Episode Reward": 28904.2448288697, "Mean Reward": 61.76120689929424, "Episode": 1848, "Episode Step": 468}
{"Training time": 4.384137840270996, "Episode Reward": 24975.71276093205, "Mean Reward": 56.76298354757284, "Episode": 1849, "Episode Step": 440}
{"Training time": 4.393308803306685, "Episode Reward": 42346.413381869075, "Mean Reward": 55.86598071486685, "Episode": 1850, "Episode Step": 758}
{"Training time": 4.399592396352026, "Episode Reward": 27252.037905700847, "Mean Reward": 54.61330241623416, "Episode": 1851, "Episode Step": 499}
{"Training time": 4.407669168578254, "Episode Reward": 38149.48012027413, "Mean Reward": 54.812471437175475, "Episode": 1852, "Episode Step": 696}
{"Training time": 4.421995688610607, "Episode Reward": 76401.45843125206, "Mean Reward": 61.713617472739955, "Episode": 1853, "Episode Step": 1238}
{"Training time": 4.425634048316214, "Episode Reward": 15231.511157644769, "Mean Reward": 55.99820278545871, "Episode": 1854, "Episode Step": 272}
{"Training time": 4.428783097200924, "Episode Reward": 14780.15655139427, "Mean Reward": 55.35639157825569, "Episode": 1855, "Episode Step": 267}
{"Training time": 4.43000471578704, "Episode Reward": 5095.576640966948, "Mean Reward": 49.956633734970076, "Episode": 1856, "Episode Step": 102}
{"Training time": 4.432347871926096, "Episode Reward": 6541.694322538346, "Mean Reward": 40.631641754896556, "Episode": 1857, "Episode Step": 161}
{"Training time": 4.4766190722253585, "Episode Reward": 222111.18643245354, "Mean Reward": 58.88419576682225, "Episode": 1858, "Episode Step": 3772}
{"Training time": 4.483370010256767, "Episode Reward": 33543.78848921051, "Mean Reward": 58.23574390487935, "Episode": 1859, "Episode Step": 576}
{"Training time": 4.487322935528225, "Episode Reward": 16007.44589275177, "Mean Reward": 53.89712421801943, "Episode": 1860, "Episode Step": 297}
{"Training time": 4.4960821866326866, "Episode Reward": 43114.33674431641, "Mean Reward": 57.48578232575521, "Episode": 1861, "Episode Step": 750}
{"Training time": 4.503465451068348, "Episode Reward": 34742.366189423316, "Mean Reward": 54.7986848413617, "Episode": 1862, "Episode Step": 634}
{"Training time": 4.5084071183204655, "Episode Reward": 19513.006243350308, "Mean Reward": 50.947796980026915, "Episode": 1863, "Episode Step": 383}
{"Training time": 4.5243828210565775, "Episode Reward": 81466.47975275759, "Mean Reward": 59.46458376113692, "Episode": 1864, "Episode Step": 1370}
{"Training time": 4.528916232453453, "Episode Reward": 21242.21964238023, "Mean Reward": 54.32792747411823, "Episode": 1865, "Episode Step": 391}
{"Training time": 4.533803204165564, "Episode Reward": 21337.90194492577, "Mean Reward": 56.15237353927834, "Episode": 1866, "Episode Step": 380}
{"Training time": 4.534998642736011, "Episode Reward": 186.67365133079545, "Mean Reward": 1.830133836576426, "Episode": 1867, "Episode Step": 102}
{"Training time": 4.536719997458988, "Episode Reward": 6896.738908230603, "Mean Reward": 47.563716608486914, "Episode": 1868, "Episode Step": 145}
{"Training time": 4.540544024970797, "Episode Reward": 16277.106562628354, "Mean Reward": 56.51773112023734, "Episode": 1869, "Episode Step": 288}
{"Training time": 4.541735006372134, "Episode Reward": 128.88083484159984, "Mean Reward": 1.263537596486273, "Episode": 1870, "Episode Step": 102}
{"Training time": 4.545009462767177, "Episode Reward": 16397.252783116248, "Mean Reward": 58.56161708255803, "Episode": 1871, "Episode Step": 280}
{"Training time": 4.548962201078733, "Episode Reward": 15663.987720059304, "Mean Reward": 52.91887743263278, "Episode": 1872, "Episode Step": 296}
{"Training time": 4.5500124024682576, "Episode Reward": 76.97476879149906, "Mean Reward": 0.8847674573735524, "Episode": 1873, "Episode Step": 87}
{"Training time": 4.553115554120805, "Episode Reward": 15534.811223001838, "Mean Reward": 58.621929143403165, "Episode": 1874, "Episode Step": 265}
{"Training time": 4.555857828325696, "Episode Reward": 8618.029770090501, "Mean Reward": 43.96953964331888, "Episode": 1875, "Episode Step": 196}
{"Training time": 4.557071631948153, "Episode Reward": 129.46194440772666, "Mean Reward": 1.2692347490953595, "Episode": 1876, "Episode Step": 102}
{"Training time": 4.569142470558484, "Episode Reward": 58579.76407164313, "Mean Reward": 57.71405327255481, "Episode": 1877, "Episode Step": 1015}
{"Training time": 4.573469428883659, "Episode Reward": 18451.747316192133, "Mean Reward": 56.42736182321753, "Episode": 1878, "Episode Step": 327}
{"Training time": 4.574698416392009, "Episode Reward": 185.24823594314114, "Mean Reward": 1.8161591759131483, "Episode": 1879, "Episode Step": 102}
{"Training time": 4.577579760816362, "Episode Reward": 13443.534071631633, "Mean Reward": 55.782299052413414, "Episode": 1880, "Episode Step": 241}
{"Training time": 4.581140807999505, "Episode Reward": 14304.969786365835, "Mean Reward": 54.599121322007, "Episode": 1881, "Episode Step": 262}
{"Training time": 4.582354488306575, "Episode Reward": 206.4631505720669, "Mean Reward": 2.0241485350202635, "Episode": 1882, "Episode Step": 102}
{"Training time": 4.584230202767584, "Episode Reward": 6847.43653063739, "Mean Reward": 43.61424541807255, "Episode": 1883, "Episode Step": 157}
{"Training time": 4.58748194747501, "Episode Reward": 12265.770778355401, "Mean Reward": 52.19476926959745, "Episode": 1884, "Episode Step": 235}
{"Training time": 4.5886932238605285, "Episode Reward": 124.92430557601229, "Mean Reward": 1.2247480938824733, "Episode": 1885, "Episode Step": 102}
{"Training time": 4.5979927294121845, "Episode Reward": 49786.47336703164, "Mean Reward": 62.467344249726025, "Episode": 1886, "Episode Step": 797}
{"Training time": 4.601755130224758, "Episode Reward": 16083.189441658384, "Mean Reward": 57.64584029268238, "Episode": 1887, "Episode Step": 279}
{"Training time": 4.602983501089944, "Episode Reward": 74.33671542895868, "Mean Reward": 0.7287913277348891, "Episode": 1888, "Episode Step": 102}
{"Training time": 4.605702366630236, "Episode Reward": 12312.632632688981, "Mean Reward": 53.07169238228009, "Episode": 1889, "Episode Step": 232}
{"Training time": 4.619180579715305, "Episode Reward": 57671.16499438397, "Mean Reward": 51.35455475902402, "Episode": 1890, "Episode Step": 1123}
{"Training time": 4.620382393333647, "Episode Reward": 126.1735097996337, "Mean Reward": 1.236995194114056, "Episode": 1891, "Episode Step": 102}
{"Training time": 4.625634135007858, "Episode Reward": 26086.80652159556, "Mean Reward": 57.84214306340479, "Episode": 1892, "Episode Step": 451}
{"Training time": 4.634992186890708, "Episode Reward": 43565.58169983262, "Mean Reward": 56.72601783832372, "Episode": 1893, "Episode Step": 768}
{"Training time": 4.636202239990235, "Episode Reward": 109.82279316277935, "Mean Reward": 1.0766940506154838, "Episode": 1894, "Episode Step": 102}
{"Training time": 4.639108601609866, "Episode Reward": 14038.599902429647, "Mean Reward": 55.93067690211015, "Episode": 1895, "Episode Step": 251}
{"Training time": 4.640774065256119, "Episode Reward": 7.545308875464214, "Mean Reward": 0.07397361642611974, "Episode": 1896, "Episode Step": 102}
{"Training time": 4.6419802141189574, "Episode Reward": -75.67472267897357, "Mean Reward": -0.7419090458722899, "Episode": 1897, "Episode Step": 102}
{"Training time": 4.644210961063703, "Episode Reward": 8796.228252318475, "Mean Reward": 46.540890223907276, "Episode": 1898, "Episode Step": 189}
{"Training time": 4.646476798852285, "Episode Reward": -471.9396400595588, "Mean Reward": -8.739622964065903, "Episode": 1899, "Episode Step": 54}
{"Training time": 4.647967421942287, "Episode Reward": 113.93217530720358, "Mean Reward": 1.1169821108549371, "Episode": 1900, "Episode Step": 102}
{"Training time": 4.651684644950761, "Episode Reward": 19364.473316618427, "Mean Reward": 60.13811589011934, "Episode": 1901, "Episode Step": 322}
{"Training time": 4.652739486098289, "Episode Reward": -467.5802202135119, "Mean Reward": -9.168239612029645, "Episode": 1902, "Episode Step": 51}
{"Training time": 4.653923507730166, "Episode Reward": 100.0012831909583, "Mean Reward": 0.9804047371662579, "Episode": 1903, "Episode Step": 102}
{"Training time": 4.662858115832011, "Episode Reward": 45786.056996867796, "Mean Reward": 59.231639064512024, "Episode": 1904, "Episode Step": 773}
{"Training time": 4.664008920788765, "Episode Reward": -615.6870479459525, "Mean Reward": -10.435373693999194, "Episode": 1905, "Episode Step": 59}
{"Training time": 4.66496089776357, "Episode Reward": -79.21404656013304, "Mean Reward": -0.990175582001663, "Episode": 1906, "Episode Step": 80}
{"Training time": 4.668059334953626, "Episode Reward": 15230.21748569992, "Mean Reward": 58.3533236999997, "Episode": 1907, "Episode Step": 261}
{"Training time": 4.669335031376945, "Episode Reward": -918.299335328539, "Mean Reward": -13.308686019254187, "Episode": 1908, "Episode Step": 69}
{"Training time": 4.670524004962709, "Episode Reward": 233.13992639823294, "Mean Reward": 2.2856855529238524, "Episode": 1909, "Episode Step": 102}
{"Training time": 4.673823301063644, "Episode Reward": 17445.201672989668, "Mean Reward": 62.08256823127996, "Episode": 1910, "Episode Step": 281}
{"Training time": 4.674870171083344, "Episode Reward": -442.5165050422336, "Mean Reward": -9.219093855046532, "Episode": 1911, "Episode Step": 48}
{"Training time": 4.676090148886045, "Episode Reward": 292.50899983543474, "Mean Reward": 2.8677352925042623, "Episode": 1912, "Episode Step": 102}
{"Training time": 4.67827481938733, "Episode Reward": 9019.64244931308, "Mean Reward": 48.75482405034097, "Episode": 1913, "Episode Step": 185}
{"Training time": 4.679397556384404, "Episode Reward": -535.52121863552, "Mean Reward": -9.917059604361482, "Episode": 1914, "Episode Step": 54}
{"Training time": 4.680631991624832, "Episode Reward": 385.9292197159059, "Mean Reward": 3.7836198011363322, "Episode": 1915, "Episode Step": 102}
{"Training time": 4.684604295823309, "Episode Reward": 19718.570092925976, "Mean Reward": 58.51207742708005, "Episode": 1916, "Episode Step": 337}
{"Training time": 4.685764324135251, "Episode Reward": -606.9256178915473, "Mean Reward": -10.647817857746444, "Episode": 1917, "Episode Step": 57}
{"Training time": 4.705435826381048, "Episode Reward": 94304.29358117384, "Mean Reward": 56.301070794730656, "Episode": 1918, "Episode Step": 1675}
{"Training time": 4.707762898868984, "Episode Reward": 8586.267149019, "Mean Reward": 44.03213922573846, "Episode": 1919, "Episode Step": 195}
{"Training time": 4.708890183303091, "Episode Reward": -524.3298956281901, "Mean Reward": -9.70981288200352, "Episode": 1920, "Episode Step": 54}
{"Training time": 4.7100991458363, "Episode Reward": 632.9549900333618, "Mean Reward": 6.205441078758449, "Episode": 1921, "Episode Step": 102}
{"Training time": 4.719507039388021, "Episode Reward": 46714.85448387613, "Mean Reward": 58.10305284064195, "Episode": 1922, "Episode Step": 804}
{"Training time": 4.720595267746184, "Episode Reward": -513.6603966914054, "Mean Reward": -9.51222956835936, "Episode": 1923, "Episode Step": 54}
{"Training time": 4.721829189989302, "Episode Reward": 378.32891644319034, "Mean Reward": 3.7091070239528463, "Episode": 1924, "Episode Step": 102}
{"Training time": 4.727770961390601, "Episode Reward": 29262.493122182175, "Mean Reward": 57.26515288098273, "Episode": 1925, "Episode Step": 511}
{"Training time": 4.728853165507316, "Episode Reward": -509.7728363934731, "Mean Reward": -9.803323776797559, "Episode": 1926, "Episode Step": 52}
{"Training time": 4.730060693025589, "Episode Reward": 303.9173202974039, "Mean Reward": 2.979581571543175, "Episode": 1927, "Episode Step": 102}
{"Training time": 4.732196244133843, "Episode Reward": 8337.955521628144, "Mean Reward": 46.32197512015636, "Episode": 1928, "Episode Step": 180}
{"Training time": 4.733298060827785, "Episode Reward": -549.642851377256, "Mean Reward": -10.178571321801037, "Episode": 1929, "Episode Step": 54}
{"Training time": 4.734506308568848, "Episode Reward": 457.58754515729726, "Mean Reward": 4.486152403502914, "Episode": 1930, "Episode Step": 102}
{"Training time": 4.740286196072896, "Episode Reward": 27507.743142378757, "Mean Reward": 55.683690571616914, "Episode": 1931, "Episode Step": 494}
{"Training time": 4.7413472933239404, "Episode Reward": -486.9922653850291, "Mean Reward": -9.54886794872606, "Episode": 1932, "Episode Step": 51}
{"Training time": 4.742545867760976, "Episode Reward": 348.399501811587, "Mean Reward": 3.4156813903096768, "Episode": 1933, "Episode Step": 102}
{"Training time": 4.745404516922103, "Episode Reward": 15554.599743782102, "Mean Reward": 63.23008025927684, "Episode": 1934, "Episode Step": 246}
{"Training time": 4.746606079406209, "Episode Reward": -563.5255659008442, "Mean Reward": -9.089122030658777, "Episode": 1935, "Episode Step": 62}
{"Training time": 4.747811868853039, "Episode Reward": 315.8846168838487, "Mean Reward": 3.0969080086651832, "Episode": 1936, "Episode Step": 102}
{"Training time": 4.749981322487195, "Episode Reward": 8998.84545355912, "Mean Reward": 48.64240785707633, "Episode": 1937, "Episode Step": 185}
{"Training time": 4.751129143304295, "Episode Reward": -554.3968309466227, "Mean Reward": -9.55856605080384, "Episode": 1938, "Episode Step": 58}
{"Training time": 4.75234074248208, "Episode Reward": 293.6037500808755, "Mean Reward": 2.878468138047799, "Episode": 1939, "Episode Step": 102}
{"Training time": 4.754500751097997, "Episode Reward": 9158.737963086433, "Mean Reward": 50.0477484321663, "Episode": 1940, "Episode Step": 183}
{"Training time": 4.7555326991611055, "Episode Reward": -259.8934088607249, "Mean Reward": -5.414446017931769, "Episode": 1941, "Episode Step": 48}
{"Training time": 4.756755772497919, "Episode Reward": 410.71411189131595, "Mean Reward": 4.026608940110941, "Episode": 1942, "Episode Step": 102}
{"Training time": 4.758240251673593, "Episode Reward": 6234.138589087306, "Mean Reward": 49.477290389581796, "Episode": 1943, "Episode Step": 126}
{"Training time": 4.759359899693065, "Episode Reward": -249.68814004411345, "Mean Reward": -4.62385444526136, "Episode": 1944, "Episode Step": 54}
{"Training time": 4.760609671076139, "Episode Reward": 555.6423373204409, "Mean Reward": 5.44747389529844, "Episode": 1945, "Episode Step": 102}
{"Training time": 4.762761683596505, "Episode Reward": 9542.267521859056, "Mean Reward": 53.91111594270653, "Episode": 1946, "Episode Step": 177}
{"Training time": 4.763876555230882, "Episode Reward": -243.97202020741958, "Mean Reward": -4.518000374211474, "Episode": 1947, "Episode Step": 54}
{"Training time": 4.76510952744219, "Episode Reward": 354.72861622948653, "Mean Reward": 3.477731531661633, "Episode": 1948, "Episode Step": 102}
{"Training time": 4.773574486639765, "Episode Reward": 38219.91862651487, "Mean Reward": 59.255687793046306, "Episode": 1949, "Episode Step": 645}
{"Training time": 4.774607596066263, "Episode Reward": -252.14368964984033, "Mean Reward": -5.603193103329785, "Episode": 1950, "Episode Step": 45}
{"Training time": 4.775732238027785, "Episode Reward": 203.52483874934893, "Mean Reward": 2.212226508145097, "Episode": 1951, "Episode Step": 92}
{"Training time": 4.779495488868819, "Episode Reward": 19393.012920601315, "Mean Reward": 60.414370469162975, "Episode": 1952, "Episode Step": 321}
{"Training time": 4.7809372172090745, "Episode Reward": -1101.4628985438349, "Mean Reward": -13.94256833599791, "Episode": 1953, "Episode Step": 79}
{"Training time": 4.782180859115389, "Episode Reward": 359.8900441977877, "Mean Reward": 3.528333766644977, "Episode": 1954, "Episode Step": 102}
{"Training time": 4.791580369141367, "Episode Reward": 49207.48959339456, "Mean Reward": 62.5253997374772, "Episode": 1955, "Episode Step": 787}
{"Training time": 4.793004473845164, "Episode Reward": -1194.2099581941557, "Mean Reward": -15.11658174929311, "Episode": 1956, "Episode Step": 79}
{"Training time": 4.799006766080856, "Episode Reward": 24269.08320793289, "Mean Reward": 48.53816641586578, "Episode": 1957, "Episode Step": 500}
{"Training time": 4.802311639123492, "Episode Reward": 15633.565374537844, "Mean Reward": 56.84932863468307, "Episode": 1958, "Episode Step": 275}
{"Training time": 4.803687838051054, "Episode Reward": -1029.6317751441452, "Mean Reward": -13.728423668588603, "Episode": 1959, "Episode Step": 75}
{"Training time": 4.80494341439671, "Episode Reward": 216.29511571473876, "Mean Reward": 2.1205403501444975, "Episode": 1960, "Episode Step": 102}
{"Training time": 4.808205614950921, "Episode Reward": 16436.89191873551, "Mean Reward": 60.87737747679818, "Episode": 1961, "Episode Step": 270}
{"Training time": 4.809208497471279, "Episode Reward": -246.55348826582983, "Mean Reward": -5.733802052693717, "Episode": 1962, "Episode Step": 43}
{"Training time": 4.8104606813854645, "Episode Reward": 346.9730033872264, "Mean Reward": 3.401696111639475, "Episode": 1963, "Episode Step": 102}
{"Training time": 4.826103138062689, "Episode Reward": 78038.95234069464, "Mean Reward": 59.84582234715847, "Episode": 1964, "Episode Step": 1304}
{"Training time": 4.82708952082528, "Episode Reward": -258.3540562833772, "Mean Reward": -5.871683097349481, "Episode": 1965, "Episode Step": 44}
{"Training time": 4.8281291405359905, "Episode Reward": 0.9543818532364412, "Mean Reward": 0.010969906359039555, "Episode": 1966, "Episode Step": 87}
{"Training time": 4.848848417202632, "Episode Reward": 108292.34258049194, "Mean Reward": 61.216700158559604, "Episode": 1967, "Episode Step": 1769}
{"Training time": 4.849748591383298, "Episode Reward": -222.74174760900578, "Mean Reward": -6.187270766916828, "Episode": 1968, "Episode Step": 36}
{"Training time": 4.850940593017472, "Episode Reward": 364.59819429716623, "Mean Reward": 3.57449210095261, "Episode": 1969, "Episode Step": 102}
{"Training time": 4.854137880007426, "Episode Reward": 15671.31685832899, "Mean Reward": 57.61513550856246, "Episode": 1970, "Episode Step": 272}
{"Training time": 4.855030915803379, "Episode Reward": -224.32467887087765, "Mean Reward": -6.231241079746601, "Episode": 1971, "Episode Step": 36}
{"Training time": 4.856217073599497, "Episode Reward": 289.064554513475, "Mean Reward": 2.833966220720343, "Episode": 1972, "Episode Step": 102}
{"Training time": 4.864646481076877, "Episode Reward": 43459.65783746807, "Mean Reward": 60.02715170921004, "Episode": 1973, "Episode Step": 724}
{"Training time": 4.865626066658232, "Episode Reward": -257.0608068107733, "Mean Reward": -5.97815829792496, "Episode": 1974, "Episode Step": 43}
{"Training time": 4.866828543013996, "Episode Reward": 355.07002098166583, "Mean Reward": 3.4810786370751554, "Episode": 1975, "Episode Step": 102}
{"Training time": 4.870134713583522, "Episode Reward": 16159.85327504054, "Mean Reward": 56.701239561545755, "Episode": 1976, "Episode Step": 285}
{"Training time": 4.871111028856701, "Episode Reward": -254.12025296831013, "Mean Reward": -5.909773324844422, "Episode": 1977, "Episode Step": 43}
{"Training time": 4.8723352741532855, "Episode Reward": 946.5676243935501, "Mean Reward": 9.280074748956373, "Episode": 1978, "Episode Step": 102}
{"Training time": 4.879950685501099, "Episode Reward": 35023.70231204163, "Mean Reward": 53.717334834419674, "Episode": 1979, "Episode Step": 652}
{"Training time": 4.881147076090177, "Episode Reward": -181.44302919244507, "Mean Reward": -3.024050486540751, "Episode": 1980, "Episode Step": 60}
{"Training time": 4.882366535796059, "Episode Reward": 466.36201167923997, "Mean Reward": 4.572176585090588, "Episode": 1981, "Episode Step": 102}
{"Training time": 4.884625297188759, "Episode Reward": 7981.424622321886, "Mean Reward": 41.354531721875055, "Episode": 1982, "Episode Step": 193}
{"Training time": 4.8855933772193065, "Episode Reward": -250.68065425851978, "Mean Reward": -5.829782657174879, "Episode": 1983, "Episode Step": 43}
{"Training time": 4.886793759134081, "Episode Reward": 361.6017417448454, "Mean Reward": 3.5451151151455433, "Episode": 1984, "Episode Step": 102}
{"Training time": 4.888110838333765, "Episode Reward": 5171.138075423029, "Mean Reward": 46.1708756734199, "Episode": 1985, "Episode Step": 112}
{"Training time": 4.8890070149633615, "Episode Reward": -221.64777543785758, "Mean Reward": -6.1568826510516, "Episode": 1986, "Episode Step": 36}
{"Training time": 4.890262440509266, "Episode Reward": 255.76326655900522, "Mean Reward": 2.5074830054804433, "Episode": 1987, "Episode Step": 102}
{"Training time": 4.8925399696826934, "Episode Reward": 8430.43756131444, "Mean Reward": 44.84275298571511, "Episode": 1988, "Episode Step": 188}
{"Training time": 4.893441494968203, "Episode Reward": -221.47583909819826, "Mean Reward": -6.152106641616618, "Episode": 1989, "Episode Step": 36}
{"Training time": 4.894664381610022, "Episode Reward": 560.7412949212257, "Mean Reward": 5.497463675698292, "Episode": 1990, "Episode Step": 102}
{"Training time": 4.90256638692485, "Episode Reward": 37630.89451139875, "Mean Reward": 56.587811295336465, "Episode": 1991, "Episode Step": 665}
{"Training time": 4.903466617729928, "Episode Reward": -225.7420330066803, "Mean Reward": -6.270612027963342, "Episode": 1992, "Episode Step": 36}
{"Training time": 4.907225296629799, "Episode Reward": 13467.763599515361, "Mean Reward": 42.0867612484855, "Episode": 1993, "Episode Step": 320}
{"Training time": 4.9140518018934465, "Episode Reward": 34006.24594703579, "Mean Reward": 59.03862143582603, "Episode": 1994, "Episode Step": 576}
{"Training time": 4.914971620837847, "Episode Reward": -225.71504524942048, "Mean Reward": -6.269862368039458, "Episode": 1995, "Episode Step": 36}
{"Training time": 4.918690646621916, "Episode Reward": 19248.154403922414, "Mean Reward": 60.7197299808278, "Episode": 1996, "Episode Step": 317}
{"Training time": 4.936266916394234, "Episode Reward": 83804.73580492486, "Mean Reward": 55.94441642518348, "Episode": 1997, "Episode Step": 1498}
{"Training time": 4.937183424697982, "Episode Reward": -230.57630100919684, "Mean Reward": -6.231791919167482, "Episode": 1998, "Episode Step": 37}
{"Training time": 4.939748944706387, "Episode Reward": 4687.153807019634, "Mean Reward": 41.47923723026225, "Episode": 1999, "Episode Step": 113}
{"Training time": 4.943564210269186, "Episode Reward": 16329.28626240342, "Mean Reward": 54.796262625514835, "Episode": 2000, "Episode Step": 298}
{"Training time": 4.944600811335776, "Episode Reward": -254.47494750877718, "Mean Reward": -5.414360585293132, "Episode": 2001, "Episode Step": 47}
{"Training time": 4.9469045002592935, "Episode Reward": 7645.598723146877, "Mean Reward": 40.66807831461105, "Episode": 2002, "Episode Step": 188}
{"Training time": 4.9475362261136375, "Episode Reward": 2570.700308970415, "Mean Reward": 49.43654440327721, "Episode": 2003, "Episode Step": 52}
{"Training time": 4.948506410519282, "Episode Reward": -228.2198254485504, "Mean Reward": -5.566337206062205, "Episode": 2004, "Episode Step": 41}
{"Training time": 4.949622628026538, "Episode Reward": 3545.336612095665, "Mean Reward": 38.95974299006225, "Episode": 2005, "Episode Step": 91}
{"Training time": 4.9529386655489605, "Episode Reward": 16542.305488784372, "Mean Reward": 60.15383814103408, "Episode": 2006, "Episode Step": 275}
{"Training time": 4.95394529832734, "Episode Reward": -254.54801357593715, "Mean Reward": -5.533652469042112, "Episode": 2007, "Episode Step": 46}
{"Training time": 4.955554523004426, "Episode Reward": 4236.895157668884, "Mean Reward": 31.61862057961854, "Episode": 2008, "Episode Step": 134}
{"Training time": 4.9562140235635965, "Episode Reward": 2663.4700907428787, "Mean Reward": 50.25415265552601, "Episode": 2009, "Episode Step": 53}
{"Training time": 4.957105073597696, "Episode Reward": -223.8738172907235, "Mean Reward": -6.218717146964542, "Episode": 2010, "Episode Step": 36}
{"Training time": 4.959814180268181, "Episode Reward": 7154.550705740006, "Mean Reward": 31.242579501048063, "Episode": 2011, "Episode Step": 229}
{"Training time": 4.96304377661811, "Episode Reward": 17421.186526088364, "Mean Reward": 64.04847987532487, "Episode": 2012, "Episode Step": 272}
{"Training time": 4.9639503119389214, "Episode Reward": -225.315124331548, "Mean Reward": -6.0895979549067025, "Episode": 2013, "Episode Step": 37}
{"Training time": 4.966139533850882, "Episode Reward": 7448.420044320114, "Mean Reward": 41.15149195756969, "Episode": 2014, "Episode Step": 181}
{"Training time": 4.968271248870426, "Episode Reward": 8586.13817214506, "Mean Reward": 48.50925520985909, "Episode": 2015, "Episode Step": 177}
{"Training time": 4.969184572762913, "Episode Reward": -222.92705266756258, "Mean Reward": -6.025055477501692, "Episode": 2016, "Episode Step": 37}
{"Training time": 4.9725817635986544, "Episode Reward": 13548.634158942987, "Mean Reward": 47.37284670959086, "Episode": 2017, "Episode Step": 286}
{"Training time": 4.976834965546926, "Episode Reward": 16976.95442607974, "Mean Reward": 47.15820673911039, "Episode": 2018, "Episode Step": 360}
{"Training time": 4.977844514714347, "Episode Reward": -247.90736433990557, "Mean Reward": -5.765287542788502, "Episode": 2019, "Episode Step": 43}
{"Training time": 4.990970968008042, "Episode Reward": 53616.600170172525, "Mean Reward": 47.95760301446558, "Episode": 2020, "Episode Step": 1118}
{"Training time": 4.994768295552995, "Episode Reward": 17839.926271480745, "Mean Reward": 54.892080835325366, "Episode": 2021, "Episode Step": 325}
{"Training time": 4.996211089425617, "Episode Reward": -1125.1932767109402, "Mean Reward": -13.556545502541448, "Episode": 2022, "Episode Step": 83}
{"Training time": 4.997838844988081, "Episode Reward": 6462.052727540383, "Mean Reward": 47.515093584855755, "Episode": 2023, "Episode Step": 136}
{"Training time": 5.012303869128227, "Episode Reward": 67989.32476174505, "Mean Reward": 55.2309705619375, "Episode": 2024, "Episode Step": 1231}
{"Training time": 5.015912787781821, "Episode Reward": 15514.57660119097, "Mean Reward": 58.10702846888004, "Episode": 2025, "Episode Step": 267}
{"Training time": 5.017637896074189, "Episode Reward": 6422.569375602095, "Mean Reward": 43.99020120275407, "Episode": 2026, "Episode Step": 146}
{"Training time": 5.021505631340874, "Episode Reward": 18552.761587651985, "Mean Reward": 56.39137260684494, "Episode": 2027, "Episode Step": 329}
{"Training time": 5.022928516334957, "Episode Reward": -1262.364139830782, "Mean Reward": -15.584742467046691, "Episode": 2028, "Episode Step": 81}
{"Training time": 5.050171988606453, "Episode Reward": 135505.61414702144, "Mean Reward": 57.93313986619129, "Episode": 2029, "Episode Step": 2339}
{"Training time": 5.051763643556171, "Episode Reward": 6378.487881755411, "Mean Reward": 47.95855550192038, "Episode": 2030, "Episode Step": 133}
{"Training time": 5.053390243318346, "Episode Reward": -1401.7511801911614, "Mean Reward": -14.601574793657932, "Episode": 2031, "Episode Step": 96}
{"Training time": 5.054435572226843, "Episode Reward": 4483.249524785007, "Mean Reward": 51.531603733161006, "Episode": 2032, "Episode Step": 87}
{"Training time": 5.055079180002212, "Episode Reward": 2648.238273464341, "Mean Reward": 51.92624065616355, "Episode": 2033, "Episode Step": 51}
{"Training time": 5.059647637473212, "Episode Reward": 18067.097477183408, "Mean Reward": 52.36839848458959, "Episode": 2034, "Episode Step": 345}
{"Training time": 5.062070174415906, "Episode Reward": 9999.133302288177, "Mean Reward": 48.539482049942606, "Episode": 2035, "Episode Step": 206}
{"Training time": 5.063407600257132, "Episode Reward": 5929.466504971594, "Mean Reward": 52.94166522296066, "Episode": 2036, "Episode Step": 112}
{"Training time": 5.067637450562583, "Episode Reward": 17127.24165415355, "Mean Reward": 53.690412708945296, "Episode": 2037, "Episode Step": 319}
{"Training time": 5.075095491343075, "Episode Reward": 37222.51764476398, "Mean Reward": 57.709329681804626, "Episode": 2038, "Episode Step": 645}
{"Training time": 5.079039886395137, "Episode Reward": 19495.512486925087, "Mean Reward": 57.85018542114269, "Episode": 2039, "Episode Step": 337}
{"Training time": 5.087285904950566, "Episode Reward": 38967.87821105232, "Mean Reward": 58.68656357086192, "Episode": 2040, "Episode Step": 664}
{"Training time": 5.0882943932877644, "Episode Reward": 3701.3897722956276, "Mean Reward": 43.545762027007385, "Episode": 2041, "Episode Step": 85}
{"Training time": 5.089851204421785, "Episode Reward": 6344.22974742802, "Mean Reward": 49.18007556145752, "Episode": 2042, "Episode Step": 129}
{"Training time": 5.094478571083811, "Episode Reward": 20495.44735239761, "Mean Reward": 57.73365451379608, "Episode": 2043, "Episode Step": 355}
{"Training time": 5.0961002394225865, "Episode Reward": 6738.607604572467, "Mean Reward": 48.83048988820628, "Episode": 2044, "Episode Step": 138}
{"Training time": 5.103547663887341, "Episode Reward": 37203.72906565574, "Mean Reward": 58.95995097568263, "Episode": 2045, "Episode Step": 631}
{"Training time": 5.107014195786582, "Episode Reward": 14026.953894174232, "Mean Reward": 55.88427846284554, "Episode": 2046, "Episode Step": 251}
{"Training time": 5.108042146099939, "Episode Reward": 5334.169091124809, "Mean Reward": 62.75493048382128, "Episode": 2047, "Episode Step": 85}
{"Training time": 5.111057999398973, "Episode Reward": 14878.091232751405, "Mean Reward": 58.57516233366695, "Episode": 2048, "Episode Step": 254}
{"Training time": 5.1186874071757, "Episode Reward": 28298.060913510886, "Mean Reward": 55.05459321694725, "Episode": 2049, "Episode Step": 514}
{"Training time": 5.119987566669782, "Episode Reward": 5147.633456558142, "Mean Reward": 61.281350673311216, "Episode": 2050, "Episode Step": 84}
{"Training time": 5.123007912503349, "Episode Reward": 15511.751264563169, "Mean Reward": 60.35700881152984, "Episode": 2051, "Episode Step": 257}
{"Training time": 5.124983152482245, "Episode Reward": 6266.1797336699565, "Mean Reward": 50.12943786935965, "Episode": 2052, "Episode Step": 125}
{"Training time": 5.125595374173588, "Episode Reward": 2405.2677568471404, "Mean Reward": 48.105355136942805, "Episode": 2053, "Episode Step": 50}
{"Training time": 5.132641847729683, "Episode Reward": 36034.62859199212, "Mean Reward": 59.95778467885544, "Episode": 2054, "Episode Step": 601}
{"Training time": 5.138984751105308, "Episode Reward": 29249.191805296367, "Mean Reward": 59.44957684003327, "Episode": 2055, "Episode Step": 492}
{"Training time": 5.140018951892853, "Episode Reward": 4777.280357546053, "Mean Reward": 57.55759466922955, "Episode": 2056, "Episode Step": 83}
{"Training time": 5.1437859349780615, "Episode Reward": 19070.907488125133, "Mean Reward": 60.160591445189695, "Episode": 2057, "Episode Step": 317}
{"Training time": 5.146132116913796, "Episode Reward": 7056.202443263097, "Mean Reward": 44.10126527039436, "Episode": 2058, "Episode Step": 160}
{"Training time": 5.14675288690461, "Episode Reward": 2318.849968815277, "Mean Reward": 45.46764644735837, "Episode": 2059, "Episode Step": 51}
{"Training time": 5.1503333832820255, "Episode Reward": 18985.724254984547, "Mean Reward": 62.45304031244917, "Episode": 2060, "Episode Step": 304}
{"Training time": 5.158448853890101, "Episode Reward": 36858.45532880802, "Mean Reward": 56.27245088367637, "Episode": 2061, "Episode Step": 655}
{"Training time": 5.160675035251511, "Episode Reward": 8710.020172395822, "Mean Reward": 45.84221143366222, "Episode": 2062, "Episode Step": 190}
{"Training time": 5.162154613865747, "Episode Reward": 5559.760019651737, "Mean Reward": 44.12507952104553, "Episode": 2063, "Episode Step": 126}
{"Training time": 5.1672559927569495, "Episode Reward": 23582.414592019606, "Mean Reward": 59.10379596997395, "Episode": 2064, "Episode Step": 399}
{"Training time": 5.168850336074829, "Episode Reward": 6645.846130681311, "Mean Reward": 48.50982577139643, "Episode": 2065, "Episode Step": 137}
{"Training time": 5.172477318578296, "Episode Reward": 19605.9107595366, "Mean Reward": 63.041513696259166, "Episode": 2066, "Episode Step": 311}
{"Training time": 5.174690463874075, "Episode Reward": 7142.064650359458, "Mean Reward": 47.93331980107019, "Episode": 2067, "Episode Step": 149}
{"Training time": 5.175693074994617, "Episode Reward": 5139.492451681038, "Mean Reward": 60.46461707860045, "Episode": 2068, "Episode Step": 85}
{"Training time": 5.177242656350136, "Episode Reward": 6151.459638781779, "Mean Reward": 47.68573363396728, "Episode": 2069, "Episode Step": 129}
{"Training time": 5.18336597972446, "Episode Reward": 28243.133052159432, "Mean Reward": 57.4047419759338, "Episode": 2070, "Episode Step": 492}
{"Training time": 5.18438117245833, "Episode Reward": 4938.121085898443, "Mean Reward": 57.420012626726084, "Episode": 2071, "Episode Step": 86}
{"Training time": 5.188108974960115, "Episode Reward": 18333.922641381225, "Mean Reward": 57.47311172846779, "Episode": 2072, "Episode Step": 319}
{"Training time": 5.191532126333978, "Episode Reward": 14660.686622956971, "Mean Reward": 57.947377956351666, "Episode": 2073, "Episode Step": 253}
{"Training time": 5.192498249146674, "Episode Reward": 5134.593740220424, "Mean Reward": 62.616996831956385, "Episode": 2074, "Episode Step": 82}
{"Training time": 5.1940085983276365, "Episode Reward": 6189.918847089601, "Mean Reward": 47.98386703170233, "Episode": 2075, "Episode Step": 129}
{"Training time": 5.1979809866348905, "Episode Reward": 16947.624611859483, "Mean Reward": 56.3044007038521, "Episode": 2076, "Episode Step": 301}
{"Training time": 5.204387583335241, "Episode Reward": 35276.96374963026, "Mean Reward": 63.9075430246925, "Episode": 2077, "Episode Step": 552}
{"Training time": 5.2074129524495865, "Episode Reward": 16960.495216752963, "Mean Reward": 65.73835355330606, "Episode": 2078, "Episode Step": 258}
{"Training time": 5.209927442736096, "Episode Reward": 8826.83292684511, "Mean Reward": 49.588949027219726, "Episode": 2079, "Episode Step": 178}
{"Training time": 5.212012296915054, "Episode Reward": 9079.831551476742, "Mean Reward": 49.889184348773306, "Episode": 2080, "Episode Step": 182}
{"Training time": 5.213502994974454, "Episode Reward": 6112.09336930867, "Mean Reward": 47.750729447723984, "Episode": 2081, "Episode Step": 128}
{"Training time": 5.22150383134683, "Episode Reward": 36314.25666279779, "Mean Reward": 58.19592413909902, "Episode": 2082, "Episode Step": 624}
{"Training time": 5.223160407212045, "Episode Reward": 6982.757305815267, "Mean Reward": 50.59969062184976, "Episode": 2083, "Episode Step": 138}
{"Training time": 5.226390900280741, "Episode Reward": 17450.392959499655, "Mean Reward": 66.0999733314381, "Episode": 2084, "Episode Step": 264}
{"Training time": 5.232392557462057, "Episode Reward": 27514.649443583214, "Mean Reward": 58.791985990562424, "Episode": 2085, "Episode Step": 468}
{"Training time": 5.234004732767741, "Episode Reward": 6684.912937030376, "Mean Reward": 49.15377159581159, "Episode": 2086, "Episode Step": 136}
{"Training time": 5.2377541652652955, "Episode Reward": 20218.382154046714, "Mean Reward": 64.80250690399588, "Episode": 2087, "Episode Step": 312}
{"Training time": 5.244080151650641, "Episode Reward": 29475.8250329121, "Mean Reward": 60.52530807579487, "Episode": 2088, "Episode Step": 487}
{"Training time": 5.24566977944639, "Episode Reward": 6886.799894087954, "Mean Reward": 52.17272647036329, "Episode": 2089, "Episode Step": 132}
{"Training time": 5.248973338007927, "Episode Reward": 16743.848850188664, "Mean Reward": 61.10893740944768, "Episode": 2090, "Episode Step": 274}
{"Training time": 5.26224453581704, "Episode Reward": 67313.13268925766, "Mean Reward": 62.442609173708405, "Episode": 2091, "Episode Step": 1078}
{"Training time": 5.265813083582454, "Episode Reward": 18803.956555116445, "Mean Reward": 62.26475680502134, "Episode": 2092, "Episode Step": 302}
{"Training time": 5.268984871639145, "Episode Reward": 15778.431565392713, "Mean Reward": 59.317411899972605, "Episode": 2093, "Episode Step": 266}
{"Training time": 5.296796084112591, "Episode Reward": 147726.23854961837, "Mean Reward": 64.08947442499712, "Episode": 2094, "Episode Step": 2305}
{"Training time": 5.298390572733349, "Episode Reward": 6532.514904855482, "Mean Reward": 48.75011123026479, "Episode": 2095, "Episode Step": 134}
{"Training time": 5.302143154409197, "Episode Reward": 19377.406908882236, "Mean Reward": 60.93524185183093, "Episode": 2096, "Episode Step": 318}
{"Training time": 5.304864764677154, "Episode Reward": 9396.072025329295, "Mean Reward": 49.7146668006841, "Episode": 2097, "Episode Step": 189}
{"Training time": 5.307048596673542, "Episode Reward": 8733.996696694676, "Mean Reward": 48.793277635165786, "Episode": 2098, "Episode Step": 179}
{"Training time": 5.3161810299423005, "Episode Reward": 39162.48756331517, "Mean Reward": 58.36436298556657, "Episode": 2099, "Episode Step": 671}
{"Training time": 5.319713031914499, "Episode Reward": 15345.076751471339, "Mean Reward": 59.247400584831425, "Episode": 2100, "Episode Step": 259}
{"Training time": 5.322808670004209, "Episode Reward": 17222.57141937001, "Mean Reward": 66.49641474660235, "Episode": 2101, "Episode Step": 259}
{"Training time": 5.325078382756975, "Episode Reward": 8919.173649281645, "Mean Reward": 46.697244237076674, "Episode": 2102, "Episode Step": 191}
{"Training time": 5.3301455422242485, "Episode Reward": 22916.06859093637, "Mean Reward": 60.62452008184225, "Episode": 2103, "Episode Step": 378}
{"Training time": 5.331168194413185, "Episode Reward": 4844.422178800548, "Mean Reward": 58.3665322747054, "Episode": 2104, "Episode Step": 83}
{"Training time": 5.337468340264427, "Episode Reward": 31740.90550914925, "Mean Reward": 60.45886763647476, "Episode": 2105, "Episode Step": 525}
{"Training time": 5.340916952225897, "Episode Reward": 16268.312753799877, "Mean Reward": 63.79730491686227, "Episode": 2106, "Episode Step": 255}
{"Training time": 5.345266342229313, "Episode Reward": 23492.207725864584, "Mean Reward": 65.07536766167475, "Episode": 2107, "Episode Step": 361}
{"Training time": 5.3484396321905985, "Episode Reward": 16084.094632760924, "Mean Reward": 61.38967417084322, "Episode": 2108, "Episode Step": 262}
{"Training time": 5.365405651926994, "Episode Reward": 90923.10256984424, "Mean Reward": 65.60108410522672, "Episode": 2109, "Episode Step": 1386}
{"Training time": 5.367571550806363, "Episode Reward": 9405.95130522076, "Mean Reward": 52.54721399564671, "Episode": 2110, "Episode Step": 179}
{"Training time": 5.369766983058717, "Episode Reward": 9375.514389536467, "Mean Reward": 50.67845615965658, "Episode": 2111, "Episode Step": 185}
{"Training time": 5.373226662476857, "Episode Reward": 16611.438439598736, "Mean Reward": 65.6578594450543, "Episode": 2112, "Episode Step": 253}
{"Training time": 5.375458041628201, "Episode Reward": 8344.600940888578, "Mean Reward": 45.10595103183015, "Episode": 2113, "Episode Step": 185}
{"Training time": 5.376140016913414, "Episode Reward": 2538.9422635664487, "Mean Reward": 47.017449325304604, "Episode": 2114, "Episode Step": 54}
{"Training time": 5.3793036963542304, "Episode Reward": 14014.593214885525, "Mean Reward": 62.84570948379159, "Episode": 2115, "Episode Step": 223}
{"Training time": 5.3815700893931915, "Episode Reward": 9236.438345693789, "Mean Reward": 49.39271842616999, "Episode": 2116, "Episode Step": 187}
{"Training time": 5.382158059676488, "Episode Reward": 2739.7739723539107, "Mean Reward": 57.07862442403981, "Episode": 2117, "Episode Step": 48}
{"Training time": 5.406266219682164, "Episode Reward": 124792.26805845872, "Mean Reward": 62.023990088697175, "Episode": 2118, "Episode Step": 2012}
{"Training time": 5.409166763027509, "Episode Reward": 14134.961941362793, "Mean Reward": 57.459194883588594, "Episode": 2119, "Episode Step": 246}
{"Training time": 5.412265609701475, "Episode Reward": 16956.80769212871, "Mean Reward": 63.98795355520268, "Episode": 2120, "Episode Step": 265}
{"Training time": 5.414392736355464, "Episode Reward": 7005.546378138609, "Mean Reward": 49.334833648863444, "Episode": 2121, "Episode Step": 142}
{"Training time": 5.415608456333478, "Episode Reward": 6187.217614566303, "Mean Reward": 59.492477063137535, "Episode": 2122, "Episode Step": 104}
{"Training time": 5.4177289607789785, "Episode Reward": 8743.95479157339, "Mean Reward": 48.309142494880604, "Episode": 2123, "Episode Step": 181}
{"Training time": 5.430130068858465, "Episode Reward": 63995.81565270672, "Mean Reward": 62.92607242154053, "Episode": 2124, "Episode Step": 1017}
{"Training time": 5.4323530849483275, "Episode Reward": 9311.7209469197, "Mean Reward": 49.268364798516934, "Episode": 2125, "Episode Step": 189}
{"Training time": 5.436144004397922, "Episode Reward": 18198.19194656661, "Mean Reward": 56.34115153735793, "Episode": 2126, "Episode Step": 323}
{"Training time": 5.4606402502457305, "Episode Reward": 127060.63378316743, "Mean Reward": 62.071633504234214, "Episode": 2127, "Episode Step": 2047}
{"Training time": 5.462930201358265, "Episode Reward": 8554.509608083696, "Mean Reward": 45.26195559832643, "Episode": 2128, "Episode Step": 189}
{"Training time": 5.465086810522609, "Episode Reward": 9274.142790059475, "Mean Reward": 50.678375901964344, "Episode": 2129, "Episode Step": 183}
{"Training time": 5.467842049996058, "Episode Reward": 9469.717276141557, "Mean Reward": 49.06589262249511, "Episode": 2130, "Episode Step": 193}
{"Training time": 5.469522585802608, "Episode Reward": 6792.172545318843, "Mean Reward": 48.171436491623, "Episode": 2131, "Episode Step": 141}
{"Training time": 5.473778425521321, "Episode Reward": 22473.146788521444, "Mean Reward": 61.90949528518304, "Episode": 2132, "Episode Step": 363}
{"Training time": 5.4816910110579595, "Episode Reward": 33956.09525852458, "Mean Reward": 53.390086884472616, "Episode": 2133, "Episode Step": 636}
{"Training time": 5.483549024727609, "Episode Reward": 7032.899093497407, "Mean Reward": 44.51201957909751, "Episode": 2134, "Episode Step": 158}
{"Training time": 5.4841741213533615, "Episode Reward": 2684.4020928372383, "Mean Reward": 52.63533515367134, "Episode": 2135, "Episode Step": 51}
{"Training time": 5.486617577738232, "Episode Reward": 7083.128195934039, "Mean Reward": 43.189806072768526, "Episode": 2136, "Episode Step": 164}
{"Training time": 5.488920469946332, "Episode Reward": 9263.683972201841, "Mean Reward": 47.99836255026861, "Episode": 2137, "Episode Step": 193}
{"Training time": 5.491128303872214, "Episode Reward": 8650.047836953163, "Mean Reward": 46.50563353200625, "Episode": 2138, "Episode Step": 186}
{"Training time": 5.4933549641238315, "Episode Reward": 7030.634633451974, "Mean Reward": 46.87089755634649, "Episode": 2139, "Episode Step": 150}
{"Training time": 5.495610331628058, "Episode Reward": 9160.503563736025, "Mean Reward": 48.46827282400013, "Episode": 2140, "Episode Step": 189}
{"Training time": 5.498723494145605, "Episode Reward": 16536.30055646456, "Mean Reward": 64.34358193176872, "Episode": 2141, "Episode Step": 257}
{"Training time": 5.501131423579322, "Episode Reward": 6703.08776716685, "Mean Reward": 40.872486385163725, "Episode": 2142, "Episode Step": 164}
{"Training time": 5.501751054392921, "Episode Reward": 2253.5884030317525, "Mean Reward": 43.3382385198414, "Episode": 2143, "Episode Step": 52}
{"Training time": 5.5048088222079805, "Episode Reward": 16949.093020446475, "Mean Reward": 65.69415899397859, "Episode": 2144, "Episode Step": 258}
{"Training time": 5.507519047723876, "Episode Reward": 9259.924576569574, "Mean Reward": 48.48128050559986, "Episode": 2145, "Episode Step": 191}
{"Training time": 5.510716199411286, "Episode Reward": 17414.183208509025, "Mean Reward": 64.97829555413816, "Episode": 2146, "Episode Step": 268}
{"Training time": 5.514530540837182, "Episode Reward": 19413.763923962157, "Mean Reward": 60.66801226238174, "Episode": 2147, "Episode Step": 320}
{"Training time": 5.517223903338114, "Episode Reward": 9192.758920498563, "Mean Reward": 48.12962785601342, "Episode": 2148, "Episode Step": 191}
{"Training time": 5.519962657756276, "Episode Reward": 9041.057711935671, "Mean Reward": 51.66318692534669, "Episode": 2149, "Episode Step": 175}
{"Training time": 5.52240854885843, "Episode Reward": 9201.453185671568, "Mean Reward": 50.00789774821504, "Episode": 2150, "Episode Step": 184}
{"Training time": 5.524967564145724, "Episode Reward": 8615.078426554019, "Mean Reward": 48.12892975728502, "Episode": 2151, "Episode Step": 179}
{"Training time": 5.525997441940837, "Episode Reward": 4791.520746318113, "Mean Reward": 55.7153575153269, "Episode": 2152, "Episode Step": 86}
{"Training time": 5.5281400794453095, "Episode Reward": 9148.420872539842, "Mean Reward": 50.54376172673946, "Episode": 2153, "Episode Step": 181}
{"Training time": 5.541879458891021, "Episode Reward": 67474.47861517155, "Mean Reward": 59.71192797802792, "Episode": 2154, "Episode Step": 1130}
{"Training time": 5.542482315831714, "Episode Reward": 2621.164338869294, "Mean Reward": 52.42328677738588, "Episode": 2155, "Episode Step": 50}
{"Training time": 5.544219757782089, "Episode Reward": 6986.066890043104, "Mean Reward": 47.84977321947331, "Episode": 2156, "Episode Step": 146}
{"Training time": 5.548252179423968, "Episode Reward": 19608.263127678816, "Mean Reward": 65.36087709226273, "Episode": 2157, "Episode Step": 300}
{"Training time": 5.549267503884104, "Episode Reward": 5077.490824295979, "Mean Reward": 59.73518616818799, "Episode": 2158, "Episode Step": 85}
{"Training time": 5.5580242947075105, "Episode Reward": 47206.20226224421, "Mean Reward": 63.36402988220699, "Episode": 2159, "Episode Step": 745}
{"Training time": 5.56064238693979, "Episode Reward": 8784.307399971462, "Mean Reward": 48.00167978126482, "Episode": 2160, "Episode Step": 183}
{"Training time": 5.561268532474836, "Episode Reward": 1885.535661149393, "Mean Reward": 36.97128747351751, "Episode": 2161, "Episode Step": 51}
{"Training time": 5.570658649139934, "Episode Reward": 50420.41944923574, "Mean Reward": 63.10440481756664, "Episode": 2162, "Episode Step": 799}
{"Training time": 5.573268136911922, "Episode Reward": 9190.92152568871, "Mean Reward": 50.22361489447382, "Episode": 2163, "Episode Step": 183}
{"Training time": 5.576440185838275, "Episode Reward": 16401.80239358016, "Mean Reward": 61.89359393803834, "Episode": 2164, "Episode Step": 265}
{"Training time": 5.5776726882987555, "Episode Reward": 128.82023831778065, "Mean Reward": 1.2629435129194182, "Episode": 2165, "Episode Step": 102}
{"Training time": 5.579960324962934, "Episode Reward": 7070.76687570837, "Mean Reward": 45.91407062148292, "Episode": 2166, "Episode Step": 154}
{"Training time": 5.583787475824356, "Episode Reward": 19319.034826760915, "Mean Reward": 59.811253333625125, "Episode": 2167, "Episode Step": 323}
{"Training time": 5.592391081386142, "Episode Reward": 39198.16663934856, "Mean Reward": 53.33083896510008, "Episode": 2168, "Episode Step": 735}
{"Training time": 5.594718960788515, "Episode Reward": 7345.232348806734, "Mean Reward": 45.90770218004209, "Episode": 2169, "Episode Step": 160}
{"Training time": 5.59701737774743, "Episode Reward": 9565.957074951308, "Mean Reward": 50.08354489503302, "Episode": 2170, "Episode Step": 191}
{"Training time": 5.597628272506926, "Episode Reward": 2327.638471243214, "Mean Reward": 47.50282594373906, "Episode": 2171, "Episode Step": 49}
{"Training time": 5.600476474430826, "Episode Reward": 9233.158891632182, "Mean Reward": 45.0397994713765, "Episode": 2172, "Episode Step": 205}
{"Training time": 5.602845002214114, "Episode Reward": 9340.526560817054, "Mean Reward": 48.39651067780857, "Episode": 2173, "Episode Step": 193}
{"Training time": 5.603471791346868, "Episode Reward": 2478.2310332147686, "Mean Reward": 50.576143534995275, "Episode": 2174, "Episode Step": 49}
{"Training time": 5.605772447188695, "Episode Reward": 6671.273521272151, "Mean Reward": 45.693654255288706, "Episode": 2175, "Episode Step": 146}
{"Training time": 5.6079269619120495, "Episode Reward": 9109.30030461946, "Mean Reward": 51.757388094428755, "Episode": 2176, "Episode Step": 176}
{"Training time": 5.608591021630499, "Episode Reward": 2749.397170752303, "Mean Reward": 53.90974844612359, "Episode": 2177, "Episode Step": 51}
{"Training time": 5.61141167667177, "Episode Reward": 7180.74278450663, "Mean Reward": 36.63644277809505, "Episode": 2178, "Episode Step": 196}
{"Training time": 5.613605469663938, "Episode Reward": 9020.1612203381, "Mean Reward": 50.39196212479385, "Episode": 2179, "Episode Step": 179}
{"Training time": 5.615195823311805, "Episode Reward": 6035.3383772922925, "Mean Reward": 46.07128532284193, "Episode": 2180, "Episode Step": 131}
{"Training time": 5.61785721136464, "Episode Reward": 8599.017053789381, "Mean Reward": 48.03920141781777, "Episode": 2181, "Episode Step": 179}
{"Training time": 5.620147409968906, "Episode Reward": 9395.984760751284, "Mean Reward": 50.24590781150419, "Episode": 2182, "Episode Step": 187}
{"Training time": 5.620788064400355, "Episode Reward": 2747.5956454694247, "Mean Reward": 53.87442442096911, "Episode": 2183, "Episode Step": 51}
{"Training time": 5.623727524942822, "Episode Reward": 9786.343375965824, "Mean Reward": 47.04972776906646, "Episode": 2184, "Episode Step": 208}
{"Training time": 5.624777087171872, "Episode Reward": 5214.0174076980575, "Mean Reward": 62.071635805929255, "Episode": 2185, "Episode Step": 84}
{"Training time": 5.62704134106636, "Episode Reward": 9173.840650446517, "Mean Reward": 49.85782962199194, "Episode": 2186, "Episode Step": 184}
{"Training time": 5.63030198805862, "Episode Reward": 12902.751678652265, "Mean Reward": 55.13996443868489, "Episode": 2187, "Episode Step": 234}
{"Training time": 5.632549854119619, "Episode Reward": 9105.424618228695, "Mean Reward": 49.218511449884836, "Episode": 2188, "Episode Step": 185}
{"Training time": 5.637621248298221, "Episode Reward": 25812.74939385045, "Mean Reward": 61.31294392838586, "Episode": 2189, "Episode Step": 421}
{"Training time": 5.64042639500565, "Episode Reward": 9064.138129648085, "Mean Reward": 47.20905275858377, "Episode": 2190, "Episode Step": 192}
{"Training time": 5.642669110563066, "Episode Reward": 9532.809246543171, "Mean Reward": 51.80874590512593, "Episode": 2191, "Episode Step": 184}
{"Training time": 5.6459591102600095, "Episode Reward": 16685.731894737735, "Mean Reward": 60.896831732619475, "Episode": 2192, "Episode Step": 274}
{"Training time": 5.648537464406755, "Episode Reward": 8884.71040048877, "Mean Reward": 50.19610395756367, "Episode": 2193, "Episode Step": 177}
{"Training time": 5.65068750831816, "Episode Reward": 9495.16640357924, "Mean Reward": 52.45948289270299, "Episode": 2194, "Episode Step": 181}
{"Training time": 5.655728092193604, "Episode Reward": 26213.49622107057, "Mean Reward": 60.961619118768766, "Episode": 2195, "Episode Step": 430}
{"Training time": 5.658313553863102, "Episode Reward": 8540.746179992084, "Mean Reward": 47.98172011231508, "Episode": 2196, "Episode Step": 178}
{"Training time": 5.660474949412876, "Episode Reward": 9197.9960311104, "Mean Reward": 51.09997795061334, "Episode": 2197, "Episode Step": 180}
{"Training time": 5.662130695515208, "Episode Reward": 6818.07468622922, "Mean Reward": 49.40633830600884, "Episode": 2198, "Episode Step": 138}
{"Training time": 5.669455542498165, "Episode Reward": 30233.7822617482, "Mean Reward": 62.209428522115644, "Episode": 2199, "Episode Step": 486}
{"Training time": 5.671795647210545, "Episode Reward": 9381.66300752389, "Mean Reward": 53.30490345184028, "Episode": 2200, "Episode Step": 176}
{"Training time": 5.67455126106739, "Episode Reward": 8631.265798707318, "Mean Reward": 36.885751276527, "Episode": 2201, "Episode Step": 234}
{"Training time": 5.675611969961061, "Episode Reward": 2715.481375941226, "Mean Reward": 55.41798726410665, "Episode": 2202, "Episode Step": 49}
{"Training time": 5.677780870000522, "Episode Reward": 8844.490221011783, "Mean Reward": 47.296739149795634, "Episode": 2203, "Episode Step": 187}
{"Training time": 5.682955574128363, "Episode Reward": 26088.496410865162, "Mean Reward": 59.42709888579763, "Episode": 2204, "Episode Step": 439}
{"Training time": 5.699369653330909, "Episode Reward": 82238.8975655811, "Mean Reward": 60.60346172850486, "Episode": 2205, "Episode Step": 1357}
{"Training time": 5.701564410792456, "Episode Reward": 9309.902038773764, "Mean Reward": 50.59729368898785, "Episode": 2206, "Episode Step": 184}
{"Training time": 5.703694762720002, "Episode Reward": 9241.589706168117, "Mean Reward": 51.34216503426732, "Episode": 2207, "Episode Step": 180}
{"Training time": 5.715375662446022, "Episode Reward": 58228.66837237248, "Mean Reward": 60.78149099412576, "Episode": 2208, "Episode Step": 958}
{"Training time": 5.7187766716215345, "Episode Reward": 17208.581667097085, "Mean Reward": 59.9602148679341, "Episode": 2209, "Episode Step": 287}
{"Training time": 5.72085897664229, "Episode Reward": 8985.724226603308, "Mean Reward": 51.34699558059033, "Episode": 2210, "Episode Step": 175}
{"Training time": 5.724891151057349, "Episode Reward": 19205.242707317993, "Mean Reward": 63.59351889840395, "Episode": 2211, "Episode Step": 302}
{"Training time": 5.728063752187623, "Episode Reward": 16787.5110760368, "Mean Reward": 62.17596694828445, "Episode": 2212, "Episode Step": 270}
{"Training time": 5.731100163857142, "Episode Reward": 17001.38325406498, "Mean Reward": 65.89683431808132, "Episode": 2213, "Episode Step": 258}
{"Training time": 5.73364440911346, "Episode Reward": 9169.160190398683, "Mean Reward": 51.512135901116196, "Episode": 2214, "Episode Step": 178}
{"Training time": 5.734842536118295, "Episode Reward": 5115.6930035858795, "Mean Reward": 50.15385297633215, "Episode": 2215, "Episode Step": 102}
{"Training time": 5.73808979358938, "Episode Reward": 16953.683198437866, "Mean Reward": 61.87475619867834, "Episode": 2216, "Episode Step": 274}
{"Training time": 5.740673418839773, "Episode Reward": 9289.447659407095, "Mean Reward": 51.60804255226164, "Episode": 2217, "Episode Step": 180}
{"Training time": 5.743786576920085, "Episode Reward": 16784.854070063808, "Mean Reward": 63.57899268963563, "Episode": 2218, "Episode Step": 264}
{"Training time": 5.744397349688742, "Episode Reward": 2293.273001625638, "Mean Reward": 45.86546003251276, "Episode": 2219, "Episode Step": 50}
{"Training time": 5.745464198324416, "Episode Reward": 2528.7621077546323, "Mean Reward": 50.575242155092646, "Episode": 2220, "Episode Step": 50}
{"Training time": 5.747592316071192, "Episode Reward": 8336.694143364643, "Mean Reward": 45.8060117767288, "Episode": 2221, "Episode Step": 182}
{"Training time": 5.750769712726275, "Episode Reward": 16085.712767069974, "Mean Reward": 59.798188725167186, "Episode": 2222, "Episode Step": 269}
{"Training time": 5.757134804990557, "Episode Reward": 32479.253768429182, "Mean Reward": 64.57108105055504, "Episode": 2223, "Episode Step": 503}
{"Training time": 5.759368132750193, "Episode Reward": 8705.924026655237, "Mean Reward": 46.06309008812295, "Episode": 2224, "Episode Step": 189}
{"Training time": 5.764373532997237, "Episode Reward": 24245.852615435553, "Mean Reward": 56.51713896371924, "Episode": 2225, "Episode Step": 429}
{"Training time": 5.770620066920916, "Episode Reward": 32559.548659855947, "Mean Reward": 65.51217034176247, "Episode": 2226, "Episode Step": 497}
{"Training time": 5.77166168583764, "Episode Reward": 4616.18391679264, "Mean Reward": 51.867235020142026, "Episode": 2227, "Episode Step": 89}
{"Training time": 5.77376911494467, "Episode Reward": 8560.841284249316, "Mean Reward": 47.82592896228668, "Episode": 2228, "Episode Step": 179}
{"Training time": 5.776318870253033, "Episode Reward": 9094.009785049486, "Mean Reward": 51.08994261263756, "Episode": 2229, "Episode Step": 178}
{"Training time": 5.777362872494591, "Episode Reward": 3841.7867233443894, "Mean Reward": 43.6566673107317, "Episode": 2230, "Episode Step": 88}
{"Training time": 5.780608787470394, "Episode Reward": 17460.253600980723, "Mean Reward": 63.03340650173546, "Episode": 2231, "Episode Step": 277}
{"Training time": 5.784064651926358, "Episode Reward": 17565.02830156094, "Mean Reward": 68.61339180297242, "Episode": 2232, "Episode Step": 256}
{"Training time": 5.7850920910967725, "Episode Reward": 4479.835866292772, "Mean Reward": 50.907225753326955, "Episode": 2233, "Episode Step": 88}
{"Training time": 5.787308162185881, "Episode Reward": 9301.015404498761, "Mean Reward": 48.95271265525664, "Episode": 2234, "Episode Step": 190}
{"Training time": 5.789838102459908, "Episode Reward": 8998.504170810356, "Mean Reward": 50.270973021286906, "Episode": 2235, "Episode Step": 179}
{"Training time": 5.791958805786239, "Episode Reward": 8866.42734251968, "Mean Reward": 49.257929680664894, "Episode": 2236, "Episode Step": 180}
{"Training time": 5.794101549122068, "Episode Reward": 9004.149240508175, "Mean Reward": 49.47334747531964, "Episode": 2237, "Episode Step": 182}
{"Training time": 5.797586128049427, "Episode Reward": 17199.271114834257, "Mean Reward": 66.66384153036533, "Episode": 2238, "Episode Step": 258}
{"Training time": 5.8005552483267255, "Episode Reward": 15850.928484162014, "Mean Reward": 62.65189124174709, "Episode": 2239, "Episode Step": 253}
{"Training time": 5.801523994141155, "Episode Reward": 4990.069265266555, "Mean Reward": 60.121316448994634, "Episode": 2240, "Episode Step": 83}
{"Training time": 5.815125696659088, "Episode Reward": 70911.60542562247, "Mean Reward": 62.80921649745126, "Episode": 2241, "Episode Step": 1129}
{"Training time": 5.818066699173715, "Episode Reward": 16766.59251838509, "Mean Reward": 65.7513432093533, "Episode": 2242, "Episode Step": 255}
{"Training time": 5.82016918943988, "Episode Reward": 9097.603795240168, "Mean Reward": 50.54224330688982, "Episode": 2243, "Episode Step": 180}
{"Training time": 5.8319440211190114, "Episode Reward": 62134.04688818153, "Mean Reward": 63.79265594269151, "Episode": 2244, "Episode Step": 974}
{"Training time": 5.834081033600701, "Episode Reward": 9102.337101165647, "Mean Reward": 49.739547000905176, "Episode": 2245, "Episode Step": 183}
{"Training time": 5.83672525273429, "Episode Reward": 13906.277404527147, "Mean Reward": 60.726102203175316, "Episode": 2246, "Episode Step": 229}
{"Training time": 5.839437856939104, "Episode Reward": 9855.316283259031, "Mean Reward": 51.063814939165965, "Episode": 2247, "Episode Step": 193}
{"Training time": 5.841097880005837, "Episode Reward": 7254.973980356526, "Mean Reward": 51.09136605884878, "Episode": 2248, "Episode Step": 142}
{"Training time": 5.844716460506121, "Episode Reward": 16802.309317450094, "Mean Reward": 64.87378114845596, "Episode": 2249, "Episode Step": 259}
{"Training time": 5.861227955818176, "Episode Reward": 87990.27501142527, "Mean Reward": 63.302356123327534, "Episode": 2250, "Episode Step": 1390}
{"Training time": 5.866895116898749, "Episode Reward": 29889.48079325912, "Mean Reward": 61.12368260380188, "Episode": 2251, "Episode Step": 489}
{"Training time": 5.869115821917852, "Episode Reward": 9094.404544548563, "Mean Reward": 48.374492258237034, "Episode": 2252, "Episode Step": 188}
{"Training time": 5.876943108571901, "Episode Reward": 36916.05703779532, "Mean Reward": 58.69007478186855, "Episode": 2253, "Episode Step": 629}
{"Training time": 5.880044242474768, "Episode Reward": 16691.63394924051, "Mean Reward": 64.1985921124635, "Episode": 2254, "Episode Step": 260}
{"Training time": 5.8821213555336, "Episode Reward": 8851.077214413219, "Mean Reward": 49.725152889961905, "Episode": 2255, "Episode Step": 178}
{"Training time": 5.891969128847122, "Episode Reward": 48012.96279567848, "Mean Reward": 59.42198365801792, "Episode": 2256, "Episode Step": 808}
{"Training time": 5.913710169394811, "Episode Reward": 112488.58454294283, "Mean Reward": 60.80464029348261, "Episode": 2257, "Episode Step": 1850}
{"Training time": 5.914722481634882, "Episode Reward": 4877.825925881748, "Mean Reward": 56.718906114904044, "Episode": 2258, "Episode Step": 86}
{"Training time": 5.918311023049885, "Episode Reward": 16281.78755626459, "Mean Reward": 60.75293864277832, "Episode": 2259, "Episode Step": 268}
{"Training time": 5.929487237466706, "Episode Reward": 58604.428467242244, "Mean Reward": 61.43021851912185, "Episode": 2260, "Episode Step": 954}
{"Training time": 5.932495517730713, "Episode Reward": 16388.928718624866, "Mean Reward": 63.77015065612788, "Episode": 2261, "Episode Step": 257}
{"Training time": 5.935029879411061, "Episode Reward": 8260.447462758986, "Mean Reward": 46.66919470485303, "Episode": 2262, "Episode Step": 177}
{"Training time": 5.938026887178421, "Episode Reward": 15378.998971931162, "Mean Reward": 59.840462925802186, "Episode": 2263, "Episode Step": 257}
{"Training time": 5.941235608061155, "Episode Reward": 17677.489831039264, "Mean Reward": 64.75271000380683, "Episode": 2264, "Episode Step": 273}
{"Training time": 5.944571261935764, "Episode Reward": 13194.050352054419, "Mean Reward": 54.747096896491364, "Episode": 2265, "Episode Step": 241}
{"Training time": 5.958911170562108, "Episode Reward": 77293.40024327146, "Mean Reward": 64.14390061682279, "Episode": 2266, "Episode Step": 1205}
{"Training time": 5.961948738296827, "Episode Reward": 16991.411570992575, "Mean Reward": 65.10119375859225, "Episode": 2267, "Episode Step": 261}
{"Training time": 5.966835368606779, "Episode Reward": 20366.128512897412, "Mean Reward": 54.60088073162845, "Episode": 2268, "Episode Step": 373}
{"Training time": 5.969443516929944, "Episode Reward": 11620.038124290786, "Mean Reward": 52.579358028465094, "Episode": 2269, "Episode Step": 221}
{"Training time": 5.971612411075168, "Episode Reward": 8596.897985239737, "Mean Reward": 47.23570321560295, "Episode": 2270, "Episode Step": 182}
{"Training time": 5.976229291094674, "Episode Reward": 22530.52991495364, "Mean Reward": 63.11072805309143, "Episode": 2271, "Episode Step": 357}
{"Training time": 5.98992394136058, "Episode Reward": 72393.35964649958, "Mean Reward": 61.980616135701695, "Episode": 2272, "Episode Step": 1168}
{"Training time": 5.991120816071828, "Episode Reward": 5083.14775709155, "Mean Reward": 49.834781932270104, "Episode": 2273, "Episode Step": 102}
{"Training time": 5.996437197724978, "Episode Reward": 25029.2653470421, "Mean Reward": 60.60354805579201, "Episode": 2274, "Episode Step": 413}
{"Training time": 6.00731603052881, "Episode Reward": 60617.90920414803, "Mean Reward": 65.25070958465881, "Episode": 2275, "Episode Step": 929}
{"Training time": 6.010350637171004, "Episode Reward": 16121.500356291006, "Mean Reward": 62.486435489500025, "Episode": 2276, "Episode Step": 258}
{"Training time": 6.013827276892132, "Episode Reward": 17099.098251993364, "Mean Reward": 66.01968437063076, "Episode": 2277, "Episode Step": 259}
{"Training time": 6.026682574947675, "Episode Reward": 68504.93478859353, "Mean Reward": 62.964094474810224, "Episode": 2278, "Episode Step": 1088}
{"Training time": 6.028756203055382, "Episode Reward": 9005.020676297041, "Mean Reward": 51.45726100741167, "Episode": 2279, "Episode Step": 175}
{"Training time": 6.038671202460924, "Episode Reward": 50846.04388034752, "Mean Reward": 63.16278742900313, "Episode": 2280, "Episode Step": 805}
{"Training time": 6.040861780511008, "Episode Reward": 9155.297808800835, "Mean Reward": 50.58175584972837, "Episode": 2281, "Episode Step": 181}
{"Training time": 6.043038066095776, "Episode Reward": 8602.996572929002, "Mean Reward": 47.53036780623758, "Episode": 2282, "Episode Step": 181}
{"Training time": 6.045645288295216, "Episode Reward": 8631.200867429963, "Mean Reward": 47.424180590274524, "Episode": 2283, "Episode Step": 182}
{"Training time": 6.056616592738363, "Episode Reward": 57856.92335120726, "Mean Reward": 61.74698329904724, "Episode": 2284, "Episode Step": 937}
{"Training time": 6.060287728309631, "Episode Reward": 19041.78100254405, "Mean Reward": 61.425100008206606, "Episode": 2285, "Episode Step": 310}
{"Training time": 6.070089325507482, "Episode Reward": 50246.68880541721, "Mean Reward": 62.72994857105769, "Episode": 2286, "Episode Step": 801}
{"Training time": 6.077259138027827, "Episode Reward": 37756.85015647072, "Mean Reward": 61.29358791634857, "Episode": 2287, "Episode Step": 616}
{"Training time": 6.080366757180956, "Episode Reward": 17223.973571939277, "Mean Reward": 64.75178034563638, "Episode": 2288, "Episode Step": 266}
{"Training time": 6.082885809673203, "Episode Reward": 8686.774743269747, "Mean Reward": 49.07782340830366, "Episode": 2289, "Episode Step": 177}
{"Training time": 6.111095391379463, "Episode Reward": 155799.32835313078, "Mean Reward": 64.64702421291733, "Episode": 2290, "Episode Step": 2410}
{"Training time": 6.114197725521193, "Episode Reward": 16960.672870617742, "Mean Reward": 64.00253913440658, "Episode": 2291, "Episode Step": 265}
{"Training time": 6.122294488880369, "Episode Reward": 37933.02083067004, "Mean Reward": 58.902206258804405, "Episode": 2292, "Episode Step": 644}
{"Training time": 6.135337605542607, "Episode Reward": 72074.69730572612, "Mean Reward": 64.35240830868403, "Episode": 2293, "Episode Step": 1120}
{"Training time": 6.142639089955224, "Episode Reward": 38588.73219461777, "Mean Reward": 61.84091697855412, "Episode": 2294, "Episode Step": 624}
{"Training time": 6.146166636347771, "Episode Reward": 15077.728586126914, "Mean Reward": 58.2151682862043, "Episode": 2295, "Episode Step": 259}
{"Training time": 6.167309242222045, "Episode Reward": 115257.70341536895, "Mean Reward": 63.18953038123298, "Episode": 2296, "Episode Step": 1824}
{"Training time": 6.169387266900804, "Episode Reward": 9109.011338940825, "Mean Reward": 51.46334089797077, "Episode": 2297, "Episode Step": 177}
{"Training time": 6.172910952501827, "Episode Reward": 17246.845649948238, "Mean Reward": 66.07986839060628, "Episode": 2298, "Episode Step": 261}
{"Training time": 6.1975975002845125, "Episode Reward": 125693.14107533741, "Mean Reward": 63.09896640328183, "Episode": 2299, "Episode Step": 1992}
{"Training time": 6.200012140538957, "Episode Reward": 9184.949090988795, "Mean Reward": 51.89236774569941, "Episode": 2300, "Episode Step": 177}
{"Training time": 6.20263164361318, "Episode Reward": 8852.254187020271, "Mean Reward": 48.907481696244595, "Episode": 2301, "Episode Step": 181}
{"Training time": 6.210432417194048, "Episode Reward": 37937.03386387414, "Mean Reward": 57.742821710615125, "Episode": 2302, "Episode Step": 657}
{"Training time": 6.218062342736456, "Episode Reward": 39261.335335249445, "Mean Reward": 60.87028734147201, "Episode": 2303, "Episode Step": 645}
{"Training time": 6.219110564390818, "Episode Reward": 2712.6408580306174, "Mean Reward": 57.71576293682165, "Episode": 2304, "Episode Step": 47}
{"Training time": 6.221309724715021, "Episode Reward": 9503.456378515646, "Mean Reward": 52.21679328854751, "Episode": 2305, "Episode Step": 182}
{"Training time": 6.224446587165197, "Episode Reward": 17080.77492213518, "Mean Reward": 65.94893792330186, "Episode": 2306, "Episode Step": 259}
{"Training time": 6.229883798559507, "Episode Reward": 26237.697149085623, "Mean Reward": 62.76961040451106, "Episode": 2307, "Episode Step": 418}
{"Training time": 6.232185952464739, "Episode Reward": 9588.375479796845, "Mean Reward": 50.46513410419392, "Episode": 2308, "Episode Step": 190}
{"Training time": 6.235344163841671, "Episode Reward": 17491.69996877549, "Mean Reward": 66.7622136212805, "Episode": 2309, "Episode Step": 262}
{"Training time": 6.240006930828095, "Episode Reward": 22783.00807527782, "Mean Reward": 64.35877987366615, "Episode": 2310, "Episode Step": 354}
{"Training time": 6.281353105240398, "Episode Reward": 218066.86168743967, "Mean Reward": 61.066049198386914, "Episode": 2311, "Episode Step": 3571}
{"Training time": 6.283419091105461, "Episode Reward": 9241.573701359188, "Mean Reward": 52.21228079863948, "Episode": 2312, "Episode Step": 177}
{"Training time": 6.285886812739902, "Episode Reward": 8590.221473326466, "Mean Reward": 49.65445938338998, "Episode": 2313, "Episode Step": 173}
{"Training time": 6.30484515077538, "Episode Reward": 106081.07945517499, "Mean Reward": 64.88139416218654, "Episode": 2314, "Episode Step": 1635}
{"Training time": 6.3069320921765435, "Episode Reward": 8567.989175363271, "Mean Reward": 47.599939863129286, "Episode": 2315, "Episode Step": 180}
{"Training time": 6.3114662205510665, "Episode Reward": 22501.396409100955, "Mean Reward": 63.743332603685424, "Episode": 2316, "Episode Step": 353}
{"Training time": 6.322694660822551, "Episode Reward": 60075.397527891204, "Mean Reward": 62.31887710362158, "Episode": 2317, "Episode Step": 964}
{"Training time": 6.3257704013586045, "Episode Reward": 16934.047419675033, "Mean Reward": 64.63376877738563, "Episode": 2318, "Episode Step": 262}
{"Training time": 6.3422565416495, "Episode Reward": 91500.63393242311, "Mean Reward": 66.2088523389458, "Episode": 2319, "Episode Step": 1382}
{"Training time": 6.371649379995134, "Episode Reward": 164554.00329060596, "Mean Reward": 64.55629787783678, "Episode": 2320, "Episode Step": 2549}
{"Training time": 6.3804114691416425, "Episode Reward": 45982.587246429786, "Mean Reward": 60.74317998207369, "Episode": 2321, "Episode Step": 757}
{"Training time": 6.3830204382869935, "Episode Reward": 9204.257597378355, "Mean Reward": 49.485255899883626, "Episode": 2322, "Episode Step": 186}
{"Training time": 6.396506095263693, "Episode Reward": 76574.3067090704, "Mean Reward": 66.2407497483308, "Episode": 2323, "Episode Step": 1156}
{"Training time": 6.404172776672575, "Episode Reward": 38853.72170601441, "Mean Reward": 58.602898500775886, "Episode": 2324, "Episode Step": 663}
{"Training time": 6.413051115804248, "Episode Reward": 47653.98784081534, "Mean Reward": 66.37045660280688, "Episode": 2325, "Episode Step": 718}
{"Training time": 6.416036154429118, "Episode Reward": 16621.404681512417, "Mean Reward": 64.67472638720784, "Episode": 2326, "Episode Step": 257}
{"Training time": 6.430214954151047, "Episode Reward": 69954.93303708723, "Mean Reward": 57.528727826552, "Episode": 2327, "Episode Step": 1216}
{"Training time": 6.43654410024484, "Episode Reward": 32703.18803255996, "Mean Reward": 64.75878818328705, "Episode": 2328, "Episode Step": 505}
{"Training time": 6.4424318285783135, "Episode Reward": 31428.797360327735, "Mean Reward": 62.98356184434416, "Episode": 2329, "Episode Step": 499}
{"Training time": 6.443635112775697, "Episode Reward": 100.95446145131291, "Mean Reward": 0.9897496220716951, "Episode": 2330, "Episode Step": 102}
{"Training time": 6.446153873867459, "Episode Reward": 8809.002567466026, "Mean Reward": 50.05115095151152, "Episode": 2331, "Episode Step": 176}
{"Training time": 6.447429935004976, "Episode Reward": 5928.456772192937, "Mean Reward": 54.893118261045714, "Episode": 2332, "Episode Step": 108}
{"Training time": 6.450352433853679, "Episode Reward": 14684.146939102679, "Mean Reward": 59.93529362899052, "Episode": 2333, "Episode Step": 245}
{"Training time": 6.46053693195184, "Episode Reward": 52334.885472394824, "Mean Reward": 62.5267448893606, "Episode": 2334, "Episode Step": 837}
{"Training time": 6.4621405213409, "Episode Reward": 6981.094991334785, "Mean Reward": 51.71181475062804, "Episode": 2335, "Episode Step": 135}
{"Training time": 6.464414061374135, "Episode Reward": 9052.144017494224, "Mean Reward": 47.393424175362426, "Episode": 2336, "Episode Step": 191}
{"Training time": 6.467767795523008, "Episode Reward": 14762.846760894088, "Mean Reward": 59.76861036799226, "Episode": 2337, "Episode Step": 247}
{"Training time": 6.477056610782941, "Episode Reward": 47386.77700466948, "Mean Reward": 59.681079350969114, "Episode": 2338, "Episode Step": 794}
{"Training time": 6.477864786651399, "Episode Reward": -171.33786033510484, "Mean Reward": -2.5572814975388782, "Episode": 2339, "Episode Step": 67}
{"Training time": 6.480826689667172, "Episode Reward": 10353.738430636695, "Mean Reward": 50.506041125057045, "Episode": 2340, "Episode Step": 205}
{"Training time": 6.482395829161008, "Episode Reward": 6147.240498886401, "Mean Reward": 45.87492909616717, "Episode": 2341, "Episode Step": 134}
{"Training time": 6.483611040512721, "Episode Reward": 68.52423126916426, "Mean Reward": 0.6718061889133751, "Episode": 2342, "Episode Step": 102}
{"Training time": 6.486077446076605, "Episode Reward": 8144.420566980884, "Mean Reward": 48.1918376744431, "Episode": 2343, "Episode Step": 169}
{"Training time": 6.487617319689857, "Episode Reward": 6731.0011454872065, "Mean Reward": 51.38168813349012, "Episode": 2344, "Episode Step": 131}
{"Training time": 6.488833764129215, "Episode Reward": 46.61589558659176, "Mean Reward": 0.4570185841822722, "Episode": 2345, "Episode Step": 102}
{"Training time": 6.493376857770814, "Episode Reward": 20595.895871907782, "Mean Reward": 58.845416776879375, "Episode": 2346, "Episode Step": 350}
{"Training time": 6.510827814671728, "Episode Reward": 90817.99005521696, "Mean Reward": 59.906325893942586, "Episode": 2347, "Episode Step": 1516}
{"Training time": 6.512030741373698, "Episode Reward": 67.85945393180397, "Mean Reward": 0.6652887640372939, "Episode": 2348, "Episode Step": 102}
{"Training time": 6.515002161926693, "Episode Reward": 6448.069382259354, "Mean Reward": 53.289829605449206, "Episode": 2349, "Episode Step": 121}
{"Training time": 6.526495058602757, "Episode Reward": 58713.35600216668, "Mean Reward": 60.905970956604435, "Episode": 2350, "Episode Step": 964}
{"Training time": 6.527260762453079, "Episode Reward": -178.88393862481593, "Mean Reward": -2.8394275972193004, "Episode": 2351, "Episode Step": 63}
{"Training time": 6.566391648583942, "Episode Reward": 206227.86080057238, "Mean Reward": 61.57893723516643, "Episode": 2352, "Episode Step": 3349}
{"Training time": 6.574189668032858, "Episode Reward": 42014.96979879058, "Mean Reward": 62.33675044330947, "Episode": 2353, "Episode Step": 674}
{"Training time": 6.582313603891267, "Episode Reward": 38852.65467650327, "Mean Reward": 55.42461437446971, "Episode": 2354, "Episode Step": 701}
{"Training time": 6.585799873007669, "Episode Reward": 16336.187393285774, "Mean Reward": 62.351860279716696, "Episode": 2355, "Episode Step": 262}
{"Training time": 6.587016682757271, "Episode Reward": 6004.688887565056, "Mean Reward": 58.29795036470928, "Episode": 2356, "Episode Step": 103}
{"Training time": 6.5882139241695405, "Episode Reward": -554.2186433984168, "Mean Reward": -5.542186433984168, "Episode": 2357, "Episode Step": 100}
{"Training time": 6.590847460561329, "Episode Reward": 8540.165544058893, "Mean Reward": 45.669334460207985, "Episode": 2358, "Episode Step": 187}
{"Training time": 6.602783639430999, "Episode Reward": 64365.34458200751, "Mean Reward": 63.16520567419775, "Episode": 2359, "Episode Step": 1019}
{"Training time": 6.603886148598459, "Episode Reward": -543.1201323104267, "Mean Reward": -5.903479699026377, "Episode": 2360, "Episode Step": 92}
{"Training time": 6.610217201113701, "Episode Reward": 31820.983408659304, "Mean Reward": 63.13687184257798, "Episode": 2361, "Episode Step": 504}
{"Training time": 6.623760375248061, "Episode Reward": 64400.76172450956, "Mean Reward": 55.13763846276503, "Episode": 2362, "Episode Step": 1168}
{"Training time": 6.6248442049821215, "Episode Reward": -420.7034219093293, "Mean Reward": -4.6231145264761455, "Episode": 2363, "Episode Step": 91}
{"Training time": 6.628291130794419, "Episode Reward": 16772.20882091057, "Mean Reward": 65.26151292183101, "Episode": 2364, "Episode Step": 257}
{"Training time": 6.63625438577599, "Episode Reward": 38785.18658182977, "Mean Reward": 55.806023858747864, "Episode": 2365, "Episode Step": 695}
{"Training time": 6.637363926900758, "Episode Reward": -370.09366912015685, "Mean Reward": -3.937166692767626, "Episode": 2366, "Episode Step": 94}
{"Training time": 6.639906352758407, "Episode Reward": 9027.214037448783, "Mean Reward": 50.4313633377027, "Episode": 2367, "Episode Step": 179}
{"Training time": 6.651351662741767, "Episode Reward": 53431.075709952966, "Mean Reward": 54.74495462085345, "Episode": 2368, "Episode Step": 976}
{"Training time": 6.652603933016459, "Episode Reward": -506.3361216853508, "Mean Reward": -4.964079624366184, "Episode": 2369, "Episode Step": 102}
{"Training time": 6.656656051079432, "Episode Reward": 20033.818504521576, "Mean Reward": 65.68465083449696, "Episode": 2370, "Episode Step": 305}
{"Training time": 6.667105515797933, "Episode Reward": 50054.91432938108, "Mean Reward": 55.86485974261281, "Episode": 2371, "Episode Step": 896}
{"Training time": 6.668235937489404, "Episode Reward": -357.1864643701157, "Mean Reward": -3.7998560039374008, "Episode": 2372, "Episode Step": 94}
{"Training time": 6.687217636903127, "Episode Reward": 97005.06395136319, "Mean Reward": 60.401658749292146, "Episode": 2373, "Episode Step": 1606}
{"Training time": 6.689440257747968, "Episode Reward": 8729.108597161015, "Mean Reward": 45.702139252151916, "Episode": 2374, "Episode Step": 191}
{"Training time": 6.690515329970254, "Episode Reward": -308.85980814727054, "Mean Reward": -3.431775646080784, "Episode": 2375, "Episode Step": 90}
{"Training time": 6.6945057127210825, "Episode Reward": 16561.15646705433, "Mean Reward": 54.12142636292265, "Episode": 2376, "Episode Step": 306}
{"Training time": 6.74366815328598, "Episode Reward": 241806.8751956128, "Mean Reward": 56.78883870258638, "Episode": 2377, "Episode Step": 4258}
{"Training time": 6.744661103553242, "Episode Reward": -371.4904115102755, "Mean Reward": -4.319655947793901, "Episode": 2378, "Episode Step": 86}
{"Training time": 6.7481414335966114, "Episode Reward": 15229.145388064457, "Mean Reward": 58.57363610794022, "Episode": 2379, "Episode Step": 260}
{"Training time": 6.761442032456398, "Episode Reward": 64084.442553298955, "Mean Reward": 55.82268515095728, "Episode": 2380, "Episode Step": 1148}
{"Training time": 6.762470329668787, "Episode Reward": -388.6821552351603, "Mean Reward": -4.467610979714486, "Episode": 2381, "Episode Step": 87}
{"Training time": 6.777809243864484, "Episode Reward": 79355.14992109733, "Mean Reward": 62.78097303884282, "Episode": 2382, "Episode Step": 1264}
{"Training time": 6.779037577443653, "Episode Reward": 5866.655865275705, "Mean Reward": 56.41015255072793, "Episode": 2383, "Episode Step": 104}
{"Training time": 6.780191446608967, "Episode Reward": -340.8690222180179, "Mean Reward": -3.5141136311135868, "Episode": 2384, "Episode Step": 97}
{"Training time": 6.78435360385312, "Episode Reward": 19197.992123989654, "Mean Reward": 60.75313963287865, "Episode": 2385, "Episode Step": 316}
{"Training time": 6.787361162503561, "Episode Reward": 15185.846724090286, "Mean Reward": 58.63261283432543, "Episode": 2386, "Episode Step": 259}
{"Training time": 6.788560992479324, "Episode Reward": -37.762829691161784, "Mean Reward": -0.37022382050158614, "Episode": 2387, "Episode Step": 102}
{"Training time": 6.8022394263744355, "Episode Reward": 69570.07987269707, "Mean Reward": 61.34927678368348, "Episode": 2388, "Episode Step": 1134}
{"Training time": 6.804413937197792, "Episode Reward": 9182.283592086864, "Mean Reward": 49.367116086488515, "Episode": 2389, "Episode Step": 186}
{"Training time": 6.805533243881332, "Episode Reward": -294.74341561929646, "Mean Reward": -3.1355682512691114, "Episode": 2390, "Episode Step": 94}
{"Training time": 6.809606125222312, "Episode Reward": 19720.694484261065, "Mean Reward": 62.80475950401613, "Episode": 2391, "Episode Step": 314}
{"Training time": 6.81082296748956, "Episode Reward": 5844.752254529888, "Mean Reward": 56.19954090894123, "Episode": 2392, "Episode Step": 104}
{"Training time": 6.811838828060362, "Episode Reward": -363.4714329520218, "Mean Reward": -4.226412011070021, "Episode": 2393, "Episode Step": 86}
{"Training time": 6.820795334710015, "Episode Reward": 47999.90507468339, "Mean Reward": 66.11557172821404, "Episode": 2394, "Episode Step": 726}
{"Training time": 6.825043575233884, "Episode Reward": 20363.15391896934, "Mean Reward": 56.096842751981654, "Episode": 2395, "Episode Step": 363}
{"Training time": 6.826145596636666, "Episode Reward": -367.5130494189949, "Mean Reward": -3.9947070589021187, "Episode": 2396, "Episode Step": 92}
{"Training time": 6.846695672472318, "Episode Reward": 111397.89566462091, "Mean Reward": 64.95504120386059, "Episode": 2397, "Episode Step": 1715}
{"Training time": 6.847949584722519, "Episode Reward": 5738.194906403107, "Mean Reward": 54.13391421135007, "Episode": 2398, "Episode Step": 106}
{"Training time": 6.849681590530608, "Episode Reward": -315.5947031614395, "Mean Reward": -3.7570797995409464, "Episode": 2399, "Episode Step": 84}
{"Training time": 6.853798329167896, "Episode Reward": 20019.553400804507, "Mean Reward": 64.1652352589888, "Episode": 2400, "Episode Step": 312}
{"Training time": 6.857916180226538, "Episode Reward": 21240.418591581598, "Mean Reward": 60.514013081429056, "Episode": 2401, "Episode Step": 351}
{"Training time": 6.85888869550493, "Episode Reward": -285.8168861817509, "Mean Reward": -3.617935268123429, "Episode": 2402, "Episode Step": 79}
{"Training time": 6.861401486661699, "Episode Reward": 8667.723156653841, "Mean Reward": 49.81450090030943, "Episode": 2403, "Episode Step": 174}
{"Training time": 6.863562543061044, "Episode Reward": 9087.840745873666, "Mean Reward": 49.123463491209, "Episode": 2404, "Episode Step": 185}
{"Training time": 6.864518708321783, "Episode Reward": -299.0485440325024, "Mean Reward": -3.6469334638110045, "Episode": 2405, "Episode Step": 82}
{"Training time": 6.866654573016697, "Episode Reward": 6661.650214103284, "Mean Reward": 47.24574619931407, "Episode": 2406, "Episode Step": 141}
{"Training time": 6.8808262205123905, "Episode Reward": 77073.92483157998, "Mean Reward": 62.81493466306436, "Episode": 2407, "Episode Step": 1227}
{"Training time": 6.8818166357941095, "Episode Reward": -325.81549568187813, "Mean Reward": -3.9254878997816642, "Episode": 2408, "Episode Step": 83}
{"Training time": 6.886596546636687, "Episode Reward": 22050.802760164825, "Mean Reward": 61.422848914108144, "Episode": 2409, "Episode Step": 359}
{"Training time": 6.899301307466295, "Episode Reward": 69067.10665797777, "Mean Reward": 63.5977041049519, "Episode": 2410, "Episode Step": 1086}
{"Training time": 6.900363223883841, "Episode Reward": -302.4673063952928, "Mean Reward": -3.4371284817646908, "Episode": 2411, "Episode Step": 88}
{"Training time": 6.902940855556064, "Episode Reward": 9354.937747457596, "Mean Reward": 52.26222205283573, "Episode": 2412, "Episode Step": 179}
{"Training time": 6.911334786083963, "Episode Reward": 46887.93055851609, "Mean Reward": 65.39460328942272, "Episode": 2413, "Episode Step": 717}
{"Training time": 6.912448459400071, "Episode Reward": -361.18717972782383, "Mean Reward": -3.9259476057372154, "Episode": 2414, "Episode Step": 92}
{"Training time": 6.91591339217292, "Episode Reward": 14804.83173936551, "Mean Reward": 58.51712149946842, "Episode": 2415, "Episode Step": 253}
{"Training time": 6.961142526666324, "Episode Reward": 243712.10911998313, "Mean Reward": 63.64902301383733, "Episode": 2416, "Episode Step": 3829}
{"Training time": 6.96235838022497, "Episode Reward": -446.0792316095063, "Mean Reward": -4.416626055539666, "Episode": 2417, "Episode Step": 101}
{"Training time": 6.9671073852645025, "Episode Reward": 21712.89601055753, "Mean Reward": 59.980375719772184, "Episode": 2418, "Episode Step": 362}
{"Training time": 6.975826983319388, "Episode Reward": 48913.21967985754, "Mean Reward": 66.18838928262184, "Episode": 2419, "Episode Step": 739}
{"Training time": 6.976802825000551, "Episode Reward": -288.8272388156426, "Mean Reward": -3.5222834001907635, "Episode": 2420, "Episode Step": 82}
{"Training time": 6.980278829402394, "Episode Reward": 16307.550807068634, "Mean Reward": 63.70137034011185, "Episode": 2421, "Episode Step": 256}
{"Training time": 6.982394096917576, "Episode Reward": 9136.337171182955, "Mean Reward": 50.757428728794196, "Episode": 2422, "Episode Step": 180}
{"Training time": 6.983467698560821, "Episode Reward": -356.8319193780606, "Mean Reward": -3.964799104200673, "Episode": 2423, "Episode Step": 90}
{"Training time": 6.9922151574823594, "Episode Reward": 44289.40188957675, "Mean Reward": 62.732863866256025, "Episode": 2424, "Episode Step": 706}
{"Training time": 6.992821803291639, "Episode Reward": 2536.3329897640233, "Mean Reward": 51.76189775028619, "Episode": 2425, "Episode Step": 49}
{"Training time": 6.993841935528649, "Episode Reward": -445.31214823639414, "Mean Reward": -5.178048235306909, "Episode": 2426, "Episode Step": 86}
{"Training time": 6.997065630224016, "Episode Reward": 14730.586743406862, "Mean Reward": 64.04602931916027, "Episode": 2427, "Episode Step": 230}
{"Training time": 7.000673461887572, "Episode Reward": 18297.752829281802, "Mean Reward": 61.81673253135744, "Episode": 2428, "Episode Step": 296}
{"Training time": 7.001731506917212, "Episode Reward": -361.88694895456626, "Mean Reward": -4.207987778541468, "Episode": 2429, "Episode Step": 86}
{"Training time": 7.00368088444074, "Episode Reward": 6314.789450778884, "Mean Reward": 50.51831560623107, "Episode": 2430, "Episode Step": 125}
{"Training time": 7.012218094666799, "Episode Reward": 45488.3948963616, "Mean Reward": 63.09070027234618, "Episode": 2431, "Episode Step": 721}
{"Training time": 7.013337815536393, "Episode Reward": -350.3872626754248, "Mean Reward": -3.8085572029937476, "Episode": 2432, "Episode Step": 92}
{"Training time": 7.027641419437196, "Episode Reward": 76340.66667457952, "Mean Reward": 64.58601241504189, "Episode": 2433, "Episode Step": 1182}
{"Training time": 7.028245824707879, "Episode Reward": 2111.0324813771576, "Mean Reward": 41.39279375249329, "Episode": 2434, "Episode Step": 51}
{"Training time": 7.029327323834101, "Episode Reward": -348.52402498694244, "Mean Reward": -3.8724891665215826, "Episode": 2435, "Episode Step": 90}
{"Training time": 7.040254478587045, "Episode Reward": 55119.785342418225, "Mean Reward": 61.65524087518817, "Episode": 2436, "Episode Step": 894}
{"Training time": 7.047522123058637, "Episode Reward": 34713.405602609746, "Mean Reward": 55.89920386893679, "Episode": 2437, "Episode Step": 621}
{"Training time": 7.04874760415819, "Episode Reward": -183.44846060730262, "Mean Reward": -1.7985143196794375, "Episode": 2438, "Episode Step": 102}
{"Training time": 7.056088787780868, "Episode Reward": 36197.66971406719, "Mean Reward": 61.351982566215575, "Episode": 2439, "Episode Step": 590}
{"Training time": 7.059094053573078, "Episode Reward": 15922.380872070833, "Mean Reward": 61.7146545429102, "Episode": 2440, "Episode Step": 258}
{"Training time": 7.06199837161435, "Episode Reward": 13842.794529187659, "Mean Reward": 56.271522476372596, "Episode": 2441, "Episode Step": 246}
{"Training time": 7.065458790792359, "Episode Reward": 16672.890525121154, "Mean Reward": 65.38388441223982, "Episode": 2442, "Episode Step": 255}
{"Training time": 7.070103760825263, "Episode Reward": 21511.86908782536, "Mean Reward": 55.158638686731685, "Episode": 2443, "Episode Step": 390}
{"Training time": 7.073804379701614, "Episode Reward": 16435.71282352073, "Mean Reward": 53.36270397246991, "Episode": 2444, "Episode Step": 308}
{"Training time": 7.079451453288396, "Episode Reward": 25998.393106147403, "Mean Reward": 59.766420933672194, "Episode": 2445, "Episode Step": 435}
{"Training time": 7.083713185522291, "Episode Reward": 20743.012925384228, "Mean Reward": 57.94137688654812, "Episode": 2446, "Episode Step": 358}
{"Training time": 7.084808655778567, "Episode Reward": -421.40014935014483, "Mean Reward": -4.682223881668276, "Episode": 2447, "Episode Step": 90}
{"Training time": 7.086914127469063, "Episode Reward": 6890.914072646705, "Mean Reward": 51.04380794553115, "Episode": 2448, "Episode Step": 135}
{"Training time": 7.09059993273682, "Episode Reward": 16084.048259753086, "Mean Reward": 61.1560770332817, "Episode": 2449, "Episode Step": 263}
{"Training time": 7.091937941908836, "Episode Reward": -427.35374560255946, "Mean Reward": -4.969229600029761, "Episode": 2450, "Episode Step": 86}
{"Training time": 7.094543633328544, "Episode Reward": 8983.547442001447, "Mean Reward": 49.90859690000804, "Episode": 2451, "Episode Step": 180}
{"Training time": 7.09516311970022, "Episode Reward": 1999.0950366909387, "Mean Reward": 40.79785789165181, "Episode": 2452, "Episode Step": 49}
{"Training time": 7.096437088582251, "Episode Reward": -297.01573092965236, "Mean Reward": -2.9119189306828663, "Episode": 2453, "Episode Step": 102}
{"Training time": 7.09851555665334, "Episode Reward": 6891.177410411464, "Mean Reward": 51.04575859564047, "Episode": 2454, "Episode Step": 135}
{"Training time": 7.101734356350369, "Episode Reward": 15603.819455252562, "Mean Reward": 58.44127136798712, "Episode": 2455, "Episode Step": 267}
{"Training time": 7.102725413309203, "Episode Reward": -364.1562190826277, "Mean Reward": -4.5519527385328455, "Episode": 2456, "Episode Step": 80}
{"Training time": 7.111743108563953, "Episode Reward": 45710.70742539595, "Mean Reward": 64.2004317772415, "Episode": 2457, "Episode Step": 712}
{"Training time": 7.114678847458627, "Episode Reward": 15756.424794569743, "Mean Reward": 64.31193793701935, "Episode": 2458, "Episode Step": 245}
{"Training time": 7.115675505532159, "Episode Reward": -358.88439620256486, "Mean Reward": -4.323908387982709, "Episode": 2459, "Episode Step": 83}
{"Training time": 7.118201770782471, "Episode Reward": 9363.752679295543, "Mean Reward": 53.81467057066404, "Episode": 2460, "Episode Step": 174}
{"Training time": 7.1202388469378155, "Episode Reward": 8414.904256884449, "Mean Reward": 49.20996641452894, "Episode": 2461, "Episode Step": 171}
{"Training time": 7.121239700516065, "Episode Reward": -399.2382354273625, "Mean Reward": -4.752836136040029, "Episode": 2462, "Episode Step": 84}
{"Training time": 7.132268481387032, "Episode Reward": 55384.36790274896, "Mean Reward": 61.26589369773115, "Episode": 2463, "Episode Step": 904}
{"Training time": 7.1349131482839585, "Episode Reward": 12412.73875767938, "Mean Reward": 55.41401231106867, "Episode": 2464, "Episode Step": 224}
{"Training time": 7.136146469977167, "Episode Reward": -357.07481721222024, "Mean Reward": -3.5007335020805908, "Episode": 2465, "Episode Step": 102}
{"Training time": 7.1397453619374165, "Episode Reward": 16709.02118647929, "Mean Reward": 64.01923826237277, "Episode": 2466, "Episode Step": 261}
{"Training time": 7.143245296941863, "Episode Reward": 17859.80173190374, "Mean Reward": 61.16370456131418, "Episode": 2467, "Episode Step": 292}
{"Training time": 7.144382364683681, "Episode Reward": -401.2381348165644, "Mean Reward": -4.268490795920898, "Episode": 2468, "Episode Step": 94}
{"Training time": 7.15888247470061, "Episode Reward": 75317.79430753955, "Mean Reward": 62.66039459861859, "Episode": 2469, "Episode Step": 1202}
{"Training time": 7.16092333469126, "Episode Reward": 8474.735543670917, "Mean Reward": 48.4270602495481, "Episode": 2470, "Episode Step": 175}
{"Training time": 7.162012981110149, "Episode Reward": -388.73391325297234, "Mean Reward": -4.271801244538158, "Episode": 2471, "Episode Step": 91}
{"Training time": 7.171909206642045, "Episode Reward": 47742.93373830257, "Mean Reward": 59.97855997274192, "Episode": 2472, "Episode Step": 796}
{"Training time": 7.1753659330474004, "Episode Reward": 18241.256700676637, "Mean Reward": 62.25684880777009, "Episode": 2473, "Episode Step": 293}
{"Training time": 7.1764518847068155, "Episode Reward": -426.8888284281807, "Mean Reward": -4.691086026683305, "Episode": 2474, "Episode Step": 91}
{"Training time": 7.180065266092618, "Episode Reward": 16671.556754708683, "Mean Reward": 62.911534923428995, "Episode": 2475, "Episode Step": 265}
{"Training time": 7.1847903427812785, "Episode Reward": 23516.88315458827, "Mean Reward": 58.49970933977182, "Episode": 2476, "Episode Step": 402}
{"Training time": 7.185893844697211, "Episode Reward": -460.43887193414207, "Mean Reward": -5.115987465934912, "Episode": 2477, "Episode Step": 90}
{"Training time": 7.195058571365145, "Episode Reward": 46115.64029964267, "Mean Reward": 62.40276089261525, "Episode": 2478, "Episode Step": 739}
{"Training time": 7.197733391655816, "Episode Reward": 13999.430741909733, "Mean Reward": 62.49745866923988, "Episode": 2479, "Episode Step": 224}
{"Training time": 7.198782119684749, "Episode Reward": -401.04520317441734, "Mean Reward": -4.557331854254742, "Episode": 2480, "Episode Step": 88}
{"Training time": 7.201391041080157, "Episode Reward": 8581.182561051126, "Mean Reward": 47.93956738017389, "Episode": 2481, "Episode Step": 179}
{"Training time": 7.203442623880174, "Episode Reward": 8667.836443838682, "Mean Reward": 50.68910201075252, "Episode": 2482, "Episode Step": 171}
{"Training time": 7.2046492466661665, "Episode Reward": -582.7043995297186, "Mean Reward": -5.712788230683516, "Episode": 2483, "Episode Step": 102}
{"Training time": 7.220437001652188, "Episode Reward": 71060.61239061825, "Mean Reward": 54.74623450741005, "Episode": 2484, "Episode Step": 1298}
{"Training time": 7.223320793045891, "Episode Reward": 15830.555262473583, "Mean Reward": 64.8793248462032, "Episode": 2485, "Episode Step": 244}
{"Training time": 7.2243695641226235, "Episode Reward": -436.42683070091937, "Mean Reward": -4.9036722550665095, "Episode": 2486, "Episode Step": 89}
{"Training time": 7.227854687770208, "Episode Reward": 16876.75621022335, "Mean Reward": 65.16122088889324, "Episode": 2487, "Episode Step": 259}
{"Training time": 7.231309916641977, "Episode Reward": 19149.595910421554, "Mean Reward": 64.47675390714328, "Episode": 2488, "Episode Step": 297}
{"Training time": 7.232542213002841, "Episode Reward": -555.5677894620623, "Mean Reward": -5.446743033941787, "Episode": 2489, "Episode Step": 102}
{"Training time": 7.236125552720494, "Episode Reward": 16213.298766722823, "Mean Reward": 62.358841410472394, "Episode": 2490, "Episode Step": 260}
{"Training time": 7.2377631813950005, "Episode Reward": 6573.101832750275, "Mean Reward": 48.33163112316379, "Episode": 2491, "Episode Step": 136}
{"Training time": 7.238986984425121, "Episode Reward": -512.5466426948965, "Mean Reward": -5.024967085244083, "Episode": 2492, "Episode Step": 102}
{"Training time": 7.240376070539156, "Episode Reward": 4856.292767476998, "Mean Reward": 61.4720603478101, "Episode": 2493, "Episode Step": 79}
{"Training time": 7.242485491898325, "Episode Reward": 8467.99328085747, "Mean Reward": 47.307225032723295, "Episode": 2494, "Episode Step": 179}
{"Training time": 7.243635688887702, "Episode Reward": -772.7979546068555, "Mean Reward": -7.806039945523793, "Episode": 2495, "Episode Step": 99}
{"Training time": 7.249140097167757, "Episode Reward": 25764.709357760414, "Mean Reward": 59.77890802264597, "Episode": 2496, "Episode Step": 431}
{"Training time": 7.256899554729461, "Episode Reward": 41946.26629432311, "Mean Reward": 63.748125067360355, "Episode": 2497, "Episode Step": 658}
{"Training time": 7.2581680097182595, "Episode Reward": -642.7654826655859, "Mean Reward": -6.301622379074371, "Episode": 2498, "Episode Step": 102}
{"Training time": 7.267596576611201, "Episode Reward": 38819.47628822771, "Mean Reward": 58.551246286919614, "Episode": 2499, "Episode Step": 663}
{"Training time": 7.2736133549610775, "Episode Reward": 30484.63112300707, "Mean Reward": 62.98477504753527, "Episode": 2500, "Episode Step": 484}
{"Training time": 7.274845554961098, "Episode Reward": -665.1824160303546, "Mean Reward": -6.521396235591712, "Episode": 2501, "Episode Step": 102}
{"Training time": 7.282830585837364, "Episode Reward": 35983.99960148745, "Mean Reward": 56.93670823020166, "Episode": 2502, "Episode Step": 632}
{"Training time": 7.306245477464464, "Episode Reward": 131764.43146472023, "Mean Reward": 66.41352392375012, "Episode": 2503, "Episode Step": 1984}
{"Training time": 7.3072693824768065, "Episode Reward": -372.6620705501341, "Mean Reward": -4.3842596535309895, "Episode": 2504, "Episode Step": 85}
{"Training time": 7.310102992720074, "Episode Reward": 8801.398498156608, "Mean Reward": 44.45150756644752, "Episode": 2505, "Episode Step": 198}
{"Training time": 7.317892903288206, "Episode Reward": 38645.24514064071, "Mean Reward": 58.64225362767938, "Episode": 2506, "Episode Step": 659}
{"Training time": 7.319133736358749, "Episode Reward": -350.9410247446745, "Mean Reward": -3.4405982818105345, "Episode": 2507, "Episode Step": 102}
{"Training time": 7.325427292452918, "Episode Reward": 31170.626571561883, "Mean Reward": 62.84400518460057, "Episode": 2508, "Episode Step": 496}
{"Training time": 7.34982661889659, "Episode Reward": 126079.22745335898, "Mean Reward": 60.64416904923472, "Episode": 2509, "Episode Step": 2079}
{"Training time": 7.351050813595454, "Episode Reward": -492.39002708604875, "Mean Reward": -4.827353206725968, "Episode": 2510, "Episode Step": 102}
{"Training time": 7.35443926996655, "Episode Reward": 17002.79026563712, "Mean Reward": 68.28429825557076, "Episode": 2511, "Episode Step": 249}
{"Training time": 7.3566651938358945, "Episode Reward": 8772.460737367432, "Mean Reward": 46.41513617654726, "Episode": 2512, "Episode Step": 189}
{"Training time": 7.357734744946162, "Episode Reward": -470.12258842866527, "Mean Reward": -5.342302141234833, "Episode": 2513, "Episode Step": 88}
{"Training time": 7.3596282980177135, "Episode Reward": 6617.828983141416, "Mean Reward": 54.69280151356542, "Episode": 2514, "Episode Step": 121}
{"Training time": 7.368611425558726, "Episode Reward": 47301.10972211536, "Mean Reward": 61.5098956074322, "Episode": 2515, "Episode Step": 769}
{"Training time": 7.369715027742916, "Episode Reward": -499.3599874699692, "Mean Reward": -5.427825950760535, "Episode": 2516, "Episode Step": 92}
{"Training time": 7.371580170790354, "Episode Reward": 6665.60298208632, "Mean Reward": 56.013470437700164, "Episode": 2517, "Episode Step": 119}
{"Training time": 7.378938231931793, "Episode Reward": 38387.28512753349, "Mean Reward": 61.02907015506119, "Episode": 2518, "Episode Step": 629}
{"Training time": 7.380137694146898, "Episode Reward": -540.4529948537595, "Mean Reward": -5.514826478099587, "Episode": 2519, "Episode Step": 98}
{"Training time": 7.388185140821669, "Episode Reward": 38192.52747907739, "Mean Reward": 59.30516689297732, "Episode": 2520, "Episode Step": 644}
{"Training time": 7.3911227960719, "Episode Reward": 15414.121984617199, "Mean Reward": 61.904104355892365, "Episode": 2521, "Episode Step": 249}
{"Training time": 7.3922381885846455, "Episode Reward": -479.5684468557567, "Mean Reward": -5.212700509301703, "Episode": 2522, "Episode Step": 92}
{"Training time": 7.395720855792363, "Episode Reward": 15959.150570774811, "Mean Reward": 61.38134834913389, "Episode": 2523, "Episode Step": 260}
{"Training time": 7.431564218600591, "Episode Reward": 193736.23573502814, "Mean Reward": 63.04465855353991, "Episode": 2524, "Episode Step": 3073}
{"Training time": 7.432714747720294, "Episode Reward": -519.4129559140572, "Mean Reward": -5.525669743766566, "Episode": 2525, "Episode Step": 94}
{"Training time": 7.435307581093576, "Episode Reward": 8852.55291343729, "Mean Reward": 49.18084951909606, "Episode": 2526, "Episode Step": 180}
{"Training time": 7.4365241150061285, "Episode Reward": -284.6425009298729, "Mean Reward": -2.79061275421444, "Episode": 2527, "Episode Step": 102}
{"Training time": 7.437773830559519, "Episode Reward": -3.8533717093461863, "Mean Reward": -0.0377781540131979, "Episode": 2528, "Episode Step": 102}
{"Training time": 7.440421290530098, "Episode Reward": 8943.635692209858, "Mean Reward": 48.34397671464788, "Episode": 2529, "Episode Step": 185}
{"Training time": 7.4416413916481865, "Episode Reward": -90.11991492691901, "Mean Reward": -0.8835285777148922, "Episode": 2530, "Episode Step": 102}
{"Training time": 7.442874100804329, "Episode Reward": -376.1673999782283, "Mean Reward": -3.6879156860610616, "Episode": 2531, "Episode Step": 102}
{"Training time": 7.445471931364801, "Episode Reward": 9215.793388693151, "Mean Reward": 50.91598557289034, "Episode": 2532, "Episode Step": 181}
{"Training time": 7.446675858563847, "Episode Reward": -326.6671095500715, "Mean Reward": -3.202618721079132, "Episode": 2533, "Episode Step": 102}
{"Training time": 7.447907185819414, "Episode Reward": -169.60828725733893, "Mean Reward": -1.6628263456601855, "Episode": 2534, "Episode Step": 102}
{"Training time": 7.454167313045925, "Episode Reward": 26825.46109207529, "Mean Reward": 54.083590911442116, "Episode": 2535, "Episode Step": 496}
{"Training time": 7.4553910319010415, "Episode Reward": -132.14686145712125, "Mean Reward": -1.2955574652658945, "Episode": 2536, "Episode Step": 102}
{"Training time": 7.456619528598256, "Episode Reward": -252.3617433349022, "Mean Reward": -2.4741347385774723, "Episode": 2537, "Episode Step": 102}
{"Training time": 7.459315235548549, "Episode Reward": 8206.8919986041, "Mean Reward": 44.123075261312366, "Episode": 2538, "Episode Step": 186}
{"Training time": 7.460562304125892, "Episode Reward": -248.4361668525617, "Mean Reward": -2.435648694632958, "Episode": 2539, "Episode Step": 102}
{"Training time": 7.461811727748977, "Episode Reward": -232.60083588771462, "Mean Reward": -2.2804003518403393, "Episode": 2540, "Episode Step": 102}
{"Training time": 7.468124896354145, "Episode Reward": 30623.67170048907, "Mean Reward": 61.493316667648735, "Episode": 2541, "Episode Step": 498}
{"Training time": 7.469366139173507, "Episode Reward": -191.6157183741626, "Mean Reward": -1.8785854742564962, "Episode": 2542, "Episode Step": 102}
{"Training time": 7.470417689416144, "Episode Reward": -394.9726184617625, "Mean Reward": -4.488325209792756, "Episode": 2543, "Episode Step": 88}
{"Training time": 7.478229522506396, "Episode Reward": 37119.66733839109, "Mean Reward": 59.39146774142574, "Episode": 2544, "Episode Step": 625}
{"Training time": 7.4794577652215954, "Episode Reward": -20.892578117480287, "Mean Reward": -0.2048291972301989, "Episode": 2545, "Episode Step": 102}
{"Training time": 7.480534913606114, "Episode Reward": -349.4067580492409, "Mean Reward": -3.797899544013488, "Episode": 2546, "Episode Step": 92}
{"Training time": 7.499814508027501, "Episode Reward": 97384.7515732149, "Mean Reward": 61.32541031058873, "Episode": 2547, "Episode Step": 1588}
{"Training time": 7.501022360788451, "Episode Reward": -5.227222854881705, "Mean Reward": -0.05124728289099711, "Episode": 2548, "Episode Step": 102}
{"Training time": 7.503364673588011, "Episode Reward": -325.4302248606783, "Mean Reward": -3.53728505283346, "Episode": 2549, "Episode Step": 92}
{"Training time": 7.506104448835055, "Episode Reward": 8685.6679396211, "Mean Reward": 45.474701254560735, "Episode": 2550, "Episode Step": 191}
{"Training time": 7.50732560939259, "Episode Reward": -15.892488486648553, "Mean Reward": -0.15580871065341717, "Episode": 2551, "Episode Step": 102}
{"Training time": 7.508440610501501, "Episode Reward": -329.85558284187925, "Mean Reward": -3.509101945126375, "Episode": 2552, "Episode Step": 94}
{"Training time": 7.511015667186843, "Episode Reward": 7767.535340804109, "Mean Reward": 43.63783899328151, "Episode": 2553, "Episode Step": 178}
{"Training time": 7.512237239148882, "Episode Reward": -10.261092708585448, "Mean Reward": -0.10059894812338674, "Episode": 2554, "Episode Step": 102}
{"Training time": 7.513399623566204, "Episode Reward": -337.355064073803, "Mean Reward": -3.4778872584928147, "Episode": 2555, "Episode Step": 97}
{"Training time": 7.516093493037753, "Episode Reward": 7921.678408513259, "Mean Reward": 42.136587279325845, "Episode": 2556, "Episode Step": 188}
{"Training time": 7.51732743885782, "Episode Reward": 8.705418453348312, "Mean Reward": 0.08534723973870893, "Episode": 2557, "Episode Step": 102}
{"Training time": 7.52120038886865, "Episode Reward": 15277.523928441626, "Mean Reward": 46.29552705588372, "Episode": 2558, "Episode Step": 330}
{"Training time": 7.523824586669604, "Episode Reward": 8596.75518320418, "Mean Reward": 46.721495560892286, "Episode": 2559, "Episode Step": 184}
{"Training time": 7.525034809708595, "Episode Reward": -25.215194738013295, "Mean Reward": -0.24720779154914996, "Episode": 2560, "Episode Step": 102}
{"Training time": 7.526065971652667, "Episode Reward": -149.23297878939363, "Mean Reward": -1.7352671952255072, "Episode": 2561, "Episode Step": 86}
{"Training time": 7.53360542886787, "Episode Reward": 35007.61024802971, "Mean Reward": 58.05573838810898, "Episode": 2562, "Episode Step": 603}
{"Training time": 7.534799214137925, "Episode Reward": 21.469632856838768, "Mean Reward": 0.2104865966356742, "Episode": 2563, "Episode Step": 102}
{"Training time": 7.538564681079652, "Episode Reward": 15043.983292243327, "Mean Reward": 46.43204719828187, "Episode": 2564, "Episode Step": 324}
{"Training time": 7.5410852335559, "Episode Reward": 8446.358042078227, "Mean Reward": 47.71953696089394, "Episode": 2565, "Episode Step": 177}
{"Training time": 7.542296325829294, "Episode Reward": -20.140906985611377, "Mean Reward": -0.19745987240795468, "Episode": 2566, "Episode Step": 102}
{"Training time": 7.543504034678142, "Episode Reward": -177.20654054274675, "Mean Reward": -1.7373190249288897, "Episode": 2567, "Episode Step": 102}
{"Training time": 7.546090140541395, "Episode Reward": 8016.441836020444, "Mean Reward": 45.29063184192341, "Episode": 2568, "Episode Step": 177}
{"Training time": 7.547341119117207, "Episode Reward": 6.38032291500545, "Mean Reward": 0.0625521854412299, "Episode": 2569, "Episode Step": 102}
{"Training time": 7.548572112785445, "Episode Reward": -225.9567453723062, "Mean Reward": -2.2152622095324137, "Episode": 2570, "Episode Step": 102}
{"Training time": 7.55115086555481, "Episode Reward": 8619.65063982466, "Mean Reward": 49.25514651328377, "Episode": 2571, "Episode Step": 175}
{"Training time": 7.558808799982071, "Episode Reward": 39164.16945467632, "Mean Reward": 60.531946606918574, "Episode": 2572, "Episode Step": 647}
{"Training time": 7.5600480630000435, "Episode Reward": 76.49292444332363, "Mean Reward": 0.7499306317972905, "Episode": 2573, "Episode Step": 102}
{"Training time": 7.573242931630876, "Episode Reward": 61086.81373945567, "Mean Reward": 56.61428520802193, "Episode": 2574, "Episode Step": 1079}
{"Training time": 7.57595031996568, "Episode Reward": 8735.150645400308, "Mean Reward": 37.814504958442896, "Episode": 2575, "Episode Step": 231}
{"Training time": 7.577027355233828, "Episode Reward": -359.6100252535788, "Mean Reward": -3.9956669472619866, "Episode": 2576, "Episode Step": 90}
{"Training time": 7.579587344725927, "Episode Reward": 8294.682787780788, "Mean Reward": 47.12887947602721, "Episode": 2577, "Episode Step": 176}
{"Training time": 7.5825469593869315, "Episode Reward": 15822.580885091562, "Mean Reward": 62.049336804280635, "Episode": 2578, "Episode Step": 255}
{"Training time": 7.584634309146139, "Episode Reward": 3853.6272160184335, "Mean Reward": 22.147282850680654, "Episode": 2579, "Episode Step": 174}
{"Training time": 7.598045946359634, "Episode Reward": 67599.35725440674, "Mean Reward": 61.34242945045984, "Episode": 2580, "Episode Step": 1102}
{"Training time": 7.600880699422625, "Episode Reward": 16425.619660767643, "Mean Reward": 68.44008191986518, "Episode": 2581, "Episode Step": 240}
{"Training time": 7.601975404156579, "Episode Reward": -365.57549885042874, "Mean Reward": -4.0173131741805355, "Episode": 2582, "Episode Step": 91}
{"Training time": 7.604568323890368, "Episode Reward": 8498.958788241815, "Mean Reward": 47.48021669408835, "Episode": 2583, "Episode Step": 179}
{"Training time": 7.61724127497938, "Episode Reward": 66364.99090242076, "Mean Reward": 61.620232964178975, "Episode": 2584, "Episode Step": 1077}
{"Training time": 7.619514066378276, "Episode Reward": 5563.334356419692, "Mean Reward": 28.825566613573535, "Episode": 2585, "Episode Step": 193}
{"Training time": 7.622219572464625, "Episode Reward": 8664.192838484887, "Mean Reward": 46.086132119600464, "Episode": 2586, "Episode Step": 188}
{"Training time": 7.63081759777334, "Episode Reward": 46963.64967561401, "Mean Reward": 64.3337666789233, "Episode": 2587, "Episode Step": 730}
{"Training time": 7.632030066914028, "Episode Reward": -269.20098640895833, "Mean Reward": -2.639225356950572, "Episode": 2588, "Episode Step": 102}
{"Training time": 7.633781519664659, "Episode Reward": 5683.667738357981, "Mean Reward": 55.72223272899981, "Episode": 2589, "Episode Step": 102}
{"Training time": 7.6400427832868365, "Episode Reward": 32524.575841327573, "Mean Reward": 61.83379437514748, "Episode": 2590, "Episode Step": 526}
{"Training time": 7.64128416551484, "Episode Reward": -500.0735695905345, "Mean Reward": -4.902682054809161, "Episode": 2591, "Episode Step": 102}
{"Training time": 7.647748000224431, "Episode Reward": 29092.915862939968, "Mean Reward": 56.71133696479526, "Episode": 2592, "Episode Step": 513}
{"Training time": 7.655111018286811, "Episode Reward": 39096.44336800028, "Mean Reward": 62.85601827652778, "Episode": 2593, "Episode Step": 622}
{"Training time": 7.6563320019510055, "Episode Reward": -566.1620197720458, "Mean Reward": -5.550608036980841, "Episode": 2594, "Episode Step": 102}
{"Training time": 7.658986468844944, "Episode Reward": 8134.904249258494, "Mean Reward": 43.73604435085212, "Episode": 2595, "Episode Step": 186}
{"Training time": 7.660514606899685, "Episode Reward": 6020.771951271855, "Mean Reward": 46.672650785053136, "Episode": 2596, "Episode Step": 129}
{"Training time": 7.661738059719403, "Episode Reward": -305.1403574762948, "Mean Reward": -2.9915721321205373, "Episode": 2597, "Episode Step": 102}
{"Training time": 7.664351275232103, "Episode Reward": 7880.153902996706, "Mean Reward": 43.778632794426144, "Episode": 2598, "Episode Step": 180}
{"Training time": 7.6683539249499635, "Episode Reward": 14151.380969914098, "Mean Reward": 59.71046822748565, "Episode": 2599, "Episode Step": 237}
{"Training time": 7.66986559689045, "Episode Reward": -605.5433463298708, "Mean Reward": -5.936699473822263, "Episode": 2600, "Episode Step": 102}
{"Training time": 7.678067248000039, "Episode Reward": 35780.1888680508, "Mean Reward": 54.459952614993604, "Episode": 2601, "Episode Step": 657}
{"Training time": 7.681039958000183, "Episode Reward": 15256.56188364578, "Mean Reward": 59.829654445669725, "Episode": 2602, "Episode Step": 255}
{"Training time": 7.682235106362237, "Episode Reward": -669.5239835988513, "Mean Reward": -6.56396062351815, "Episode": 2603, "Episode Step": 102}
{"Training time": 7.684852644138866, "Episode Reward": 8649.339790717226, "Mean Reward": 47.26415186184276, "Episode": 2604, "Episode Step": 183}
{"Training time": 7.686410758031739, "Episode Reward": 5549.509567360954, "Mean Reward": 42.6885351335458, "Episode": 2605, "Episode Step": 130}
{"Training time": 7.687371711929639, "Episode Reward": -423.71287035635555, "Mean Reward": -5.432216286619943, "Episode": 2606, "Episode Step": 78}
{"Training time": 7.689916631910536, "Episode Reward": 8428.223430427724, "Mean Reward": 46.82346350237625, "Episode": 2607, "Episode Step": 180}
{"Training time": 7.691394338872698, "Episode Reward": 6226.9181388014085, "Mean Reward": 48.270683246522545, "Episode": 2608, "Episode Step": 129}
{"Training time": 7.692352899445428, "Episode Reward": -396.4814528406951, "Mean Reward": -4.894832751119693, "Episode": 2609, "Episode Step": 81}
{"Training time": 7.694882874952422, "Episode Reward": 9049.154312602328, "Mean Reward": 51.415649503422316, "Episode": 2610, "Episode Step": 176}
{"Training time": 7.697997442483902, "Episode Reward": 16902.97543890755, "Mean Reward": 64.26986858900209, "Episode": 2611, "Episode Step": 263}
{"Training time": 7.6992291969060895, "Episode Reward": -504.8902518410457, "Mean Reward": -4.949904429814174, "Episode": 2612, "Episode Step": 102}
{"Training time": 7.707706078886986, "Episode Reward": 40122.47191324513, "Mean Reward": 59.44069913073352, "Episode": 2613, "Episode Step": 675}
{"Training time": 7.708941758606169, "Episode Reward": -39.15803523651926, "Mean Reward": -0.3839023062403849, "Episode": 2614, "Episode Step": 102}
{"Training time": 7.710111335515976, "Episode Reward": -691.4035191582366, "Mean Reward": -7.055137950594251, "Episode": 2615, "Episode Step": 98}
{"Training time": 7.712637691100438, "Episode Reward": 8657.630505160647, "Mean Reward": 49.19108241568549, "Episode": 2616, "Episode Step": 176}
{"Training time": 7.7142468030585185, "Episode Reward": 5828.379126646149, "Mean Reward": 43.49536661676231, "Episode": 2617, "Episode Step": 134}
{"Training time": 7.71547438773844, "Episode Reward": -684.4395310618189, "Mean Reward": -6.710191480998224, "Episode": 2618, "Episode Step": 102}
{"Training time": 7.732874924143156, "Episode Reward": 87761.94882653322, "Mean Reward": 61.11556324967494, "Episode": 2619, "Episode Step": 1436}
{"Training time": 7.73689590745502, "Episode Reward": 21578.17006644858, "Mean Reward": 63.65241907506956, "Episode": 2620, "Episode Step": 339}
{"Training time": 7.738156923585468, "Episode Reward": -467.3459289325525, "Mean Reward": -4.581822832672083, "Episode": 2621, "Episode Step": 102}
{"Training time": 7.747336820231544, "Episode Reward": 41755.72986058031, "Mean Reward": 56.35051263236209, "Episode": 2622, "Episode Step": 741}
{"Training time": 7.750436933570438, "Episode Reward": 14608.551041594168, "Mean Reward": 55.54582145092839, "Episode": 2623, "Episode Step": 263}
{"Training time": 7.751649662454923, "Episode Reward": -565.682516109903, "Mean Reward": -5.545907020685323, "Episode": 2624, "Episode Step": 102}
{"Training time": 7.763839639425278, "Episode Reward": 60954.00601621055, "Mean Reward": 61.569703046677326, "Episode": 2625, "Episode Step": 990}
{"Training time": 7.7653173827462725, "Episode Reward": 6605.644826146877, "Mean Reward": 53.27132924311997, "Episode": 2626, "Episode Step": 124}
{"Training time": 7.7665489861038, "Episode Reward": -375.0426989925023, "Mean Reward": -3.6768892058088465, "Episode": 2627, "Episode Step": 102}
{"Training time": 7.7730839808119665, "Episode Reward": 30926.326737934338, "Mean Reward": 60.402981910028004, "Episode": 2628, "Episode Step": 512}
{"Training time": 7.780624040828811, "Episode Reward": 36718.77787092923, "Mean Reward": 56.577469754898665, "Episode": 2629, "Episode Step": 649}
{"Training time": 7.781835303571489, "Episode Reward": -719.0089404215037, "Mean Reward": -7.04910725903435, "Episode": 2630, "Episode Step": 102}
{"Training time": 7.788240618838204, "Episode Reward": 32160.65285296126, "Mean Reward": 63.06010363325737, "Episode": 2631, "Episode Step": 510}
{"Training time": 7.788772722217772, "Episode Reward": -258.15941914028866, "Mean Reward": -5.867259525915651, "Episode": 2632, "Episode Step": 44}
{"Training time": 7.789970539145999, "Episode Reward": -433.62180794284575, "Mean Reward": -4.251194195518096, "Episode": 2633, "Episode Step": 102}
{"Training time": 7.796530259980096, "Episode Reward": 28739.630500990865, "Mean Reward": 54.43111837308876, "Episode": 2634, "Episode Step": 528}
{"Training time": 7.797784973846541, "Episode Reward": -181.4056820918241, "Mean Reward": -1.7784870793316088, "Episode": 2635, "Episode Step": 102}
{"Training time": 7.7989901274442675, "Episode Reward": -374.19664940184214, "Mean Reward": -3.6685946019788447, "Episode": 2636, "Episode Step": 102}
{"Training time": 7.805490550531282, "Episode Reward": 29836.712043291223, "Mean Reward": 57.26816131149947, "Episode": 2637, "Episode Step": 521}
{"Training time": 7.806021032465829, "Episode Reward": -249.8623920628385, "Mean Reward": -5.678690728700875, "Episode": 2638, "Episode Step": 44}
{"Training time": 7.8072222805023195, "Episode Reward": -482.1397516740358, "Mean Reward": -4.726860310529762, "Episode": 2639, "Episode Step": 102}
{"Training time": 7.819316853284835, "Episode Reward": 57221.36284903607, "Mean Reward": 56.65481470201591, "Episode": 2640, "Episode Step": 1010}
{"Training time": 7.819802723328272, "Episode Reward": -239.3587606333611, "Mean Reward": -5.9839690158340275, "Episode": 2641, "Episode Step": 40}
{"Training time": 7.821008434957928, "Episode Reward": -553.7691996968016, "Mean Reward": -5.4291098009490355, "Episode": 2642, "Episode Step": 102}
{"Training time": 7.869320529434416, "Episode Reward": 226622.6752717056, "Mean Reward": 55.233408547820034, "Episode": 2643, "Episode Step": 4103}
{"Training time": 7.869835017191039, "Episode Reward": -252.06227598213178, "Mean Reward": -6.001482761479328, "Episode": 2644, "Episode Step": 42}
{"Training time": 7.8710340185960135, "Episode Reward": -632.7110223705757, "Mean Reward": -6.203049238927213, "Episode": 2645, "Episode Step": 102}
{"Training time": 7.896414632466104, "Episode Reward": 117741.5679857776, "Mean Reward": 54.63645846207777, "Episode": 2646, "Episode Step": 2155}
{"Training time": 7.896937071614795, "Episode Reward": -246.33217361599563, "Mean Reward": -5.728655200371992, "Episode": 2647, "Episode Step": 43}
{"Training time": 7.8981385949585174, "Episode Reward": -501.90559902498416, "Mean Reward": -4.920643127695923, "Episode": 2648, "Episode Step": 102}
{"Training time": 7.899925850232442, "Episode Reward": 4172.65826962959, "Mean Reward": 40.12171413105375, "Episode": 2649, "Episode Step": 104}
{"Training time": 7.900706646111276, "Episode Reward": -249.60264807377152, "Mean Reward": -5.804712745901663, "Episode": 2650, "Episode Step": 43}
{"Training time": 7.90192336195045, "Episode Reward": -721.6580026765855, "Mean Reward": -7.075078457613583, "Episode": 2651, "Episode Step": 102}
{"Training time": 7.922751966913541, "Episode Reward": 101988.6861215435, "Mean Reward": 58.81700468370445, "Episode": 2652, "Episode Step": 1734}
{"Training time": 7.923315538565318, "Episode Reward": -254.33259828533897, "Mean Reward": -5.528969527942151, "Episode": 2653, "Episode Step": 46}
{"Training time": 7.9245307811101275, "Episode Reward": -619.0406582495772, "Mean Reward": -6.069026061270365, "Episode": 2654, "Episode Step": 102}
{"Training time": 7.9480637774864835, "Episode Reward": 111053.56867033253, "Mean Reward": 55.86195607159584, "Episode": 2655, "Episode Step": 1988}
{"Training time": 7.948613199989001, "Episode Reward": -254.87344054400657, "Mean Reward": -5.663854234311257, "Episode": 2656, "Episode Step": 45}
{"Training time": 7.949816839430067, "Episode Reward": -618.3223901349526, "Mean Reward": -6.061984217009339, "Episode": 2657, "Episode Step": 102}
{"Training time": 7.951494180560112, "Episode Reward": 30.529450039598416, "Mean Reward": 0.2993083337215531, "Episode": 2658, "Episode Step": 102}
{"Training time": 7.952106820808517, "Episode Reward": -294.0444254856423, "Mean Reward": -5.765576970306712, "Episode": 2659, "Episode Step": 51}
{"Training time": 7.953313912749291, "Episode Reward": -660.2465853285961, "Mean Reward": -6.473005738515648, "Episode": 2660, "Episode Step": 102}
{"Training time": 7.954442221919695, "Episode Reward": -178.29509103466157, "Mean Reward": -3.183840911333242, "Episode": 2661, "Episode Step": 56}
{"Training time": 7.955084065794945, "Episode Reward": -304.5036373563105, "Mean Reward": -5.7453516482322735, "Episode": 2662, "Episode Step": 53}
{"Training time": 7.956297523578008, "Episode Reward": -574.9559949525396, "Mean Reward": -5.636823479926859, "Episode": 2663, "Episode Step": 102}
{"Training time": 7.957324686381552, "Episode Reward": -180.2446657944235, "Mean Reward": -3.7550972040504895, "Episode": 2664, "Episode Step": 48}
{"Training time": 7.958545031348864, "Episode Reward": -147.75859093713512, "Mean Reward": -1.4486136366385796, "Episode": 2665, "Episode Step": 102}
{"Training time": 7.959771447777748, "Episode Reward": -630.1625465545451, "Mean Reward": -6.178064181907305, "Episode": 2666, "Episode Step": 102}
{"Training time": 7.960861243605613, "Episode Reward": -181.5649805347945, "Mean Reward": -3.3623144543480463, "Episode": 2667, "Episode Step": 54}
{"Training time": 7.961964288022783, "Episode Reward": -283.76096168125196, "Mean Reward": -3.084358279144043, "Episode": 2668, "Episode Step": 92}
{"Training time": 7.963168881932894, "Episode Reward": -651.2612160697587, "Mean Reward": -6.38491388303685, "Episode": 2669, "Episode Step": 102}
{"Training time": 7.970538595252567, "Episode Reward": 30993.08934755465, "Mean Reward": 51.91472252521717, "Episode": 2670, "Episode Step": 597}
{"Training time": 7.971160652769936, "Episode Reward": -291.5528637623404, "Mean Reward": -5.606785841583469, "Episode": 2671, "Episode Step": 52}
{"Training time": 7.972345575822724, "Episode Reward": -432.9486400572583, "Mean Reward": -4.244594510365277, "Episode": 2672, "Episode Step": 102}
{"Training time": 7.974007632997301, "Episode Reward": -14.309197704193831, "Mean Reward": -0.1402862520019003, "Episode": 2673, "Episode Step": 102}
{"Training time": 7.974534253610505, "Episode Reward": -282.35641877545334, "Mean Reward": -6.417191335805757, "Episode": 2674, "Episode Step": 44}
{"Training time": 7.975763254695469, "Episode Reward": -443.57812512814087, "Mean Reward": -4.3488051483151065, "Episode": 2675, "Episode Step": 102}
{"Training time": 7.97692537718349, "Episode Reward": -164.29620429834722, "Mean Reward": -2.784681428785546, "Episode": 2676, "Episode Step": 59}
{"Training time": 7.977573396894667, "Episode Reward": -455.8257474237097, "Mean Reward": -8.441217544883513, "Episode": 2677, "Episode Step": 54}
{"Training time": 7.978775902191798, "Episode Reward": -339.0935489387036, "Mean Reward": -3.324446558222584, "Episode": 2678, "Episode Step": 102}
{"Training time": 7.980439803335401, "Episode Reward": 29.198486571523933, "Mean Reward": 0.2862596722698425, "Episode": 2679, "Episode Step": 102}
{"Training time": 7.981025008559227, "Episode Reward": -305.9821755802108, "Mean Reward": -6.3746286579210585, "Episode": 2680, "Episode Step": 48}
{"Training time": 7.982233956919776, "Episode Reward": -638.3042135953248, "Mean Reward": -6.257884447012988, "Episode": 2681, "Episode Step": 102}
{"Training time": 7.994270316627291, "Episode Reward": 50326.018530121124, "Mean Reward": 50.175492053959246, "Episode": 2682, "Episode Step": 1003}
{"Training time": 7.994787317448192, "Episode Reward": -295.8415985754558, "Mean Reward": -7.0438475851299005, "Episode": 2683, "Episode Step": 42}
{"Training time": 7.995978282756275, "Episode Reward": -647.5544377426532, "Mean Reward": -6.34857291904562, "Episode": 2684, "Episode Step": 102}
{"Training time": 7.997621922492981, "Episode Reward": 74.68655471176095, "Mean Reward": 0.7322211246251074, "Episode": 2685, "Episode Step": 102}
{"Training time": 7.998162524700165, "Episode Reward": -278.0812075606005, "Mean Reward": -6.467004826990709, "Episode": 2686, "Episode Step": 43}
{"Training time": 7.999355543322033, "Episode Reward": -689.3383427433238, "Mean Reward": -6.758219046503174, "Episode": 2687, "Episode Step": 102}
{"Training time": 8.000746139950223, "Episode Reward": -176.61258705891638, "Mean Reward": -2.2076573382364546, "Episode": 2688, "Episode Step": 80}
{"Training time": 8.001364295283953, "Episode Reward": -389.72460488204456, "Mean Reward": -7.641658919255776, "Episode": 2689, "Episode Step": 51}
{"Training time": 8.00255952861574, "Episode Reward": -502.9306167541223, "Mean Reward": -4.930692321118846, "Episode": 2690, "Episode Step": 102}
{"Training time": 8.004213788575596, "Episode Reward": -176.45784355574165, "Mean Reward": -1.729978858389624, "Episode": 2691, "Episode Step": 102}
{"Training time": 8.00490856912401, "Episode Reward": -394.32258261897016, "Mean Reward": -6.683433603711358, "Episode": 2692, "Episode Step": 59}
{"Training time": 8.006999007728364, "Episode Reward": 5302.081821880959, "Mean Reward": 29.9552645304009, "Episode": 2693, "Episode Step": 177}
{"Training time": 8.008128012484974, "Episode Reward": -177.88880604055407, "Mean Reward": -3.067048380009553, "Episode": 2694, "Episode Step": 58}
{"Training time": 8.008946017225583, "Episode Reward": -389.252240273644, "Mean Reward": -5.6413368155600585, "Episode": 2695, "Episode Step": 69}
{"Training time": 8.01015593720807, "Episode Reward": -548.2548893402028, "Mean Reward": -5.375047934707871, "Episode": 2696, "Episode Step": 102}
{"Training time": 8.011359718044599, "Episode Reward": -174.91560964264707, "Mean Reward": -2.6910093791176473, "Episode": 2697, "Episode Step": 65}
{"Training time": 8.01220400777128, "Episode Reward": -348.1709248479645, "Mean Reward": -4.835707289555063, "Episode": 2698, "Episode Step": 72}
{"Training time": 8.013651265237067, "Episode Reward": -434.0550627788692, "Mean Reward": -4.255441791949698, "Episode": 2699, "Episode Step": 102}
{"Training time": 8.014946484168371, "Episode Reward": -178.29419952028763, "Mean Reward": -2.5470599931469664, "Episode": 2700, "Episode Step": 70}
{"Training time": 8.015521109700202, "Episode Reward": -310.8186717959735, "Mean Reward": -6.613163229701564, "Episode": 2701, "Episode Step": 47}
{"Training time": 8.01670780301094, "Episode Reward": -490.9045156839124, "Mean Reward": -4.812789369450122, "Episode": 2702, "Episode Step": 102}
{"Training time": 8.01794526245859, "Episode Reward": -170.0917647788582, "Mean Reward": -2.616796381213203, "Episode": 2703, "Episode Step": 65}
{"Training time": 8.018535252743296, "Episode Reward": -290.6711425765576, "Mean Reward": -5.932064134215461, "Episode": 2704, "Episode Step": 49}
{"Training time": 8.019374615550042, "Episode Reward": 1293.6029314964685, "Mean Reward": 18.48004187852098, "Episode": 2705, "Episode Step": 70}
{"Training time": 8.020434969994756, "Episode Reward": -176.1480873026771, "Mean Reward": -3.4538840647583746, "Episode": 2706, "Episode Step": 51}
{"Training time": 8.021177890499432, "Episode Reward": -267.54687801718933, "Mean Reward": -4.315272226083699, "Episode": 2707, "Episode Step": 62}
{"Training time": 8.022528409163158, "Episode Reward": 3638.0686216992326, "Mean Reward": 31.094603604266947, "Episode": 2708, "Episode Step": 117}
{"Training time": 8.035666890541712, "Episode Reward": 56684.28126296121, "Mean Reward": 51.81378543232286, "Episode": 2709, "Episode Step": 1094}
{"Training time": 8.040552795794275, "Episode Reward": 20009.7523823766, "Mean Reward": 47.52910304602518, "Episode": 2710, "Episode Step": 421}
{"Training time": 8.043189067443212, "Episode Reward": 7514.331096846236, "Mean Reward": 33.39702709709438, "Episode": 2711, "Episode Step": 225}
{"Training time": 8.052244129710727, "Episode Reward": 35603.763419900984, "Mean Reward": 48.04826372456273, "Episode": 2712, "Episode Step": 741}
{"Training time": 8.053415488004685, "Episode Reward": -91.75747793117506, "Mean Reward": -0.8995831169723045, "Episode": 2713, "Episode Step": 102}
{"Training time": 8.054616039395333, "Episode Reward": -789.2785989061829, "Mean Reward": -7.738025479472381, "Episode": 2714, "Episode Step": 102}
{"Training time": 8.063528583844503, "Episode Reward": 37787.71418656984, "Mean Reward": 51.906200805727806, "Episode": 2715, "Episode Step": 728}
{"Training time": 8.068398468560643, "Episode Reward": 22447.482330612296, "Mean Reward": 53.702110838785394, "Episode": 2716, "Episode Step": 418}
{"Training time": 8.069624202781254, "Episode Reward": -594.9898499483367, "Mean Reward": -5.833233823022908, "Episode": 2717, "Episode Step": 102}
{"Training time": 8.075571163296699, "Episode Reward": 24098.73806873216, "Mean Reward": 50.73418540785718, "Episode": 2718, "Episode Step": 475}
{"Training time": 8.077451250221994, "Episode Reward": 6568.332411857856, "Mean Reward": 41.31026674124438, "Episode": 2719, "Episode Step": 159}
{"Training time": 8.080202916926808, "Episode Reward": 7460.546594647365, "Mean Reward": 31.479099555474114, "Episode": 2720, "Episode Step": 237}
{"Training time": 8.083799550798204, "Episode Reward": 8259.391568749783, "Mean Reward": 30.365410179227144, "Episode": 2721, "Episode Step": 272}
{"Training time": 8.08544572022226, "Episode Reward": 6204.937545901719, "Mean Reward": 45.29151493358919, "Episode": 2722, "Episode Step": 137}
{"Training time": 8.086636941366725, "Episode Reward": -372.07314907135066, "Mean Reward": -3.6477759712877513, "Episode": 2723, "Episode Step": 102}
{"Training time": 8.090827902754148, "Episode Reward": 13930.47735121009, "Mean Reward": 43.26235202239158, "Episode": 2724, "Episode Step": 322}
{"Training time": 8.092377512190078, "Episode Reward": 6033.104064590133, "Mean Reward": 46.408492804539485, "Episode": 2725, "Episode Step": 130}
{"Training time": 8.093570812741916, "Episode Reward": 50.27551009093766, "Mean Reward": 0.49289715775429077, "Episode": 2726, "Episode Step": 102}
{"Training time": 8.106227986945047, "Episode Reward": 53951.57131961653, "Mean Reward": 51.6777503061461, "Episode": 2727, "Episode Step": 1044}
{"Training time": 8.10801614748107, "Episode Reward": 5272.8758473699, "Mean Reward": 34.23945355435, "Episode": 2728, "Episode Step": 154}
{"Training time": 8.109214063617918, "Episode Reward": -283.721019779767, "Mean Reward": -2.7815786252918335, "Episode": 2729, "Episode Step": 102}
{"Training time": 8.116114470826256, "Episode Reward": 29093.314460504724, "Mean Reward": 52.89693538273586, "Episode": 2730, "Episode Step": 550}
{"Training time": 8.122925784389178, "Episode Reward": 33270.95471163642, "Mean Reward": 57.462788793845284, "Episode": 2731, "Episode Step": 579}
{"Training time": 8.125548564990362, "Episode Reward": 7670.503774715741, "Mean Reward": 34.396877913523504, "Episode": 2732, "Episode Step": 223}
{"Training time": 8.128762698041069, "Episode Reward": 7972.852161362368, "Mean Reward": 34.514511521049215, "Episode": 2733, "Episode Step": 231}
{"Training time": 8.131099609136582, "Episode Reward": 9596.453466864732, "Mean Reward": 48.71296176073468, "Episode": 2734, "Episode Step": 197}
{"Training time": 8.132334486113654, "Episode Reward": -476.86604661455556, "Mean Reward": -4.675157319750545, "Episode": 2735, "Episode Step": 102}
{"Training time": 8.134400167465209, "Episode Reward": 4860.475426722867, "Mean Reward": 36.27220467703632, "Episode": 2736, "Episode Step": 134}
{"Training time": 8.13610033247206, "Episode Reward": 5723.32521908089, "Mean Reward": 40.30510717662599, "Episode": 2737, "Episode Step": 142}
{"Training time": 8.137322389152315, "Episode Reward": -148.63861620217867, "Mean Reward": -1.4572413353154772, "Episode": 2738, "Episode Step": 102}
{"Training time": 8.143158763051034, "Episode Reward": 22520.377120685633, "Mean Reward": 49.38679193132814, "Episode": 2739, "Episode Step": 456}
{"Training time": 8.14452609161536, "Episode Reward": 6004.463496538623, "Mean Reward": 51.76261634947089, "Episode": 2740, "Episode Step": 116}
{"Training time": 8.149863887760374, "Episode Reward": 24445.730664933504, "Mean Reward": 53.49175200204268, "Episode": 2741, "Episode Step": 457}
{"Training time": 8.152980902459886, "Episode Reward": 7779.486179784199, "Mean Reward": 34.422505220284066, "Episode": 2742, "Episode Step": 226}
{"Training time": 8.15580832110511, "Episode Reward": 14571.91515172921, "Mean Reward": 60.464378222942784, "Episode": 2743, "Episode Step": 241}
{"Training time": 8.15702031744851, "Episode Reward": -527.7852296184418, "Mean Reward": -5.174364996259233, "Episode": 2744, "Episode Step": 102}
{"Training time": 8.166080814666218, "Episode Reward": 38661.68938907651, "Mean Reward": 52.245526201454744, "Episode": 2745, "Episode Step": 740}
{"Training time": 8.17034439192878, "Episode Reward": 21428.02713646391, "Mean Reward": 58.706923661544955, "Episode": 2746, "Episode Step": 365}
{"Training time": 8.171567658053505, "Episode Reward": -608.3102518735197, "Mean Reward": -5.963825998759997, "Episode": 2747, "Episode Step": 102}
{"Training time": 8.183896887765991, "Episode Reward": 46292.75720516625, "Mean Reward": 46.06244498026493, "Episode": 2748, "Episode Step": 1005}
{"Training time": 8.185738299687703, "Episode Reward": 5754.346521021126, "Mean Reward": 43.26576331594832, "Episode": 2749, "Episode Step": 133}
{"Training time": 8.187239025500086, "Episode Reward": -667.5249401506842, "Mean Reward": -6.544362158340041, "Episode": 2750, "Episode Step": 102}
{"Training time": 8.193992653025521, "Episode Reward": 26326.766210392823, "Mean Reward": 48.84372209720375, "Episode": 2751, "Episode Step": 539}
{"Training time": 8.213457830813196, "Episode Reward": 91825.26887570324, "Mean Reward": 54.91941918403304, "Episode": 2752, "Episode Step": 1672}
{"Training time": 8.214366457462312, "Episode Reward": 1841.4053490730498, "Mean Reward": 24.22901775096118, "Episode": 2753, "Episode Step": 76}
{"Training time": 8.216557555529807, "Episode Reward": 5080.2624142713075, "Mean Reward": 34.79631790596786, "Episode": 2754, "Episode Step": 146}
{"Training time": 8.216768909427854, "Episode Reward": -146.2880779873997, "Mean Reward": -9.143004874212481, "Episode": 2755, "Episode Step": 16}
{"Training time": 8.217356084717645, "Episode Reward": -167.78195729816238, "Mean Reward": -3.4954574437117163, "Episode": 2756, "Episode Step": 48}
{"Training time": 8.21902551194032, "Episode Reward": 0.43943426035977273, "Mean Reward": 0.0043081790231350265, "Episode": 2757, "Episode Step": 102}
{"Training time": 8.224067639708519, "Episode Reward": 21638.538507824214, "Mean Reward": 49.973530041164466, "Episode": 2758, "Episode Step": 433}
{"Training time": 8.22528773691919, "Episode Reward": -488.2888097419133, "Mean Reward": -4.78714519354817, "Episode": 2759, "Episode Step": 102}
{"Training time": 8.22745663497183, "Episode Reward": 4830.3297055945895, "Mean Reward": 33.31261865927303, "Episode": 2760, "Episode Step": 145}
{"Training time": 8.22782031443384, "Episode Reward": -135.57894208382135, "Mean Reward": -4.675135933924874, "Episode": 2761, "Episode Step": 29}
{"Training time": 8.228902196089427, "Episode Reward": 1993.7227946136304, "Mean Reward": 21.670899941452504, "Episode": 2762, "Episode Step": 92}
{"Training time": 8.2349952366617, "Episode Reward": 22817.89008737305, "Mean Reward": 47.34002092815985, "Episode": 2763, "Episode Step": 482}
{"Training time": 8.235295106901063, "Episode Reward": -120.14848846433911, "Mean Reward": -5.223847324536483, "Episode": 2764, "Episode Step": 23}
{"Training time": 8.23783831079801, "Episode Reward": 8209.41461879244, "Mean Reward": 37.65786522381853, "Episode": 2765, "Episode Step": 218}
{"Training time": 8.246878698335754, "Episode Reward": 34666.70632587448, "Mean Reward": 47.358888423325794, "Episode": 2766, "Episode Step": 732}
{"Training time": 8.24714966721005, "Episode Reward": -125.34307782832104, "Mean Reward": -5.6974126285600475, "Episode": 2767, "Episode Step": 22}
{"Training time": 8.248438818322288, "Episode Reward": 4217.494072419429, "Mean Reward": 38.69260616898559, "Episode": 2768, "Episode Step": 109}
{"Training time": 8.255465198556582, "Episode Reward": 25910.98221075274, "Mean Reward": 47.02537606307212, "Episode": 2769, "Episode Step": 551}
{"Training time": 8.256394359668096, "Episode Reward": 45.18845738567421, "Mean Reward": 0.6025127651423229, "Episode": 2770, "Episode Step": 75}
{"Training time": 8.257889170779123, "Episode Reward": 4416.902378427785, "Mean Reward": 35.620180471191816, "Episode": 2771, "Episode Step": 124}
{"Training time": 8.259558857215776, "Episode Reward": -177.17111554232534, "Mean Reward": -1.7369717210031896, "Episode": 2772, "Episode Step": 102}
{"Training time": 8.259868229958746, "Episode Reward": -96.74770676324542, "Mean Reward": -3.869908270529817, "Episode": 2773, "Episode Step": 25}
{"Training time": 8.261183322999212, "Episode Reward": 4206.116346129971, "Mean Reward": 37.89294005522496, "Episode": 2774, "Episode Step": 111}
{"Training time": 8.262858296102948, "Episode Reward": -1002.7317787148147, "Mean Reward": -9.83070371289034, "Episode": 2775, "Episode Step": 102}
{"Training time": 8.264059357775583, "Episode Reward": 242.40817513673153, "Mean Reward": 2.376550736634623, "Episode": 2776, "Episode Step": 102}
{"Training time": 8.266630700230598, "Episode Reward": 6817.543780053428, "Mean Reward": 31.857681215202934, "Episode": 2777, "Episode Step": 214}
{"Training time": 8.273449131912656, "Episode Reward": 25394.962189953003, "Mean Reward": 47.378660802151124, "Episode": 2778, "Episode Step": 536}
{"Training time": 8.273738961352242, "Episode Reward": -146.62041411800413, "Mean Reward": -6.664564278091097, "Episode": 2779, "Episode Step": 22}
{"Training time": 8.276092435518901, "Episode Reward": 7693.0214272524945, "Mean Reward": 38.65839913192208, "Episode": 2780, "Episode Step": 199}
{"Training time": 8.277789537774192, "Episode Reward": -970.7097753983247, "Mean Reward": -9.516762503905145, "Episode": 2781, "Episode Step": 102}
{"Training time": 8.278085050251748, "Episode Reward": -153.07131665398285, "Mean Reward": -6.957787120635584, "Episode": 2782, "Episode Step": 22}
{"Training time": 8.279335380262799, "Episode Reward": -488.4112938241465, "Mean Reward": -4.788346017883789, "Episode": 2783, "Episode Step": 102}
{"Training time": 8.28103412191073, "Episode Reward": -716.0879469990089, "Mean Reward": -7.020470068617734, "Episode": 2784, "Episode Step": 102}
{"Training time": 8.281391354997952, "Episode Reward": -143.73273633523692, "Mean Reward": -5.133312011972747, "Episode": 2785, "Episode Step": 28}
{"Training time": 8.282626210252443, "Episode Reward": -72.85488325936835, "Mean Reward": -0.7142635613663564, "Episode": 2786, "Episode Step": 102}
{"Training time": 8.284329736895032, "Episode Reward": -619.535581396274, "Mean Reward": -6.073878248983078, "Episode": 2787, "Episode Step": 102}
{"Training time": 8.284638040794267, "Episode Reward": -133.99946883549774, "Mean Reward": -5.826063862412945, "Episode": 2788, "Episode Step": 23}
{"Training time": 8.285889585283067, "Episode Reward": -673.995966124266, "Mean Reward": -6.607803589453589, "Episode": 2789, "Episode Step": 102}
{"Training time": 8.289641286664539, "Episode Reward": 14504.332119895866, "Mean Reward": 52.551927970637195, "Episode": 2790, "Episode Step": 276}
{"Training time": 8.289925141665671, "Episode Reward": -126.23705441657413, "Mean Reward": -5.738047928026097, "Episode": 2791, "Episode Step": 22}
{"Training time": 8.291225648588604, "Episode Reward": 217.6500300829773, "Mean Reward": 2.0533021705941255, "Episode": 2792, "Episode Step": 106}
{"Training time": 8.292901585234537, "Episode Reward": -727.5508573695322, "Mean Reward": -7.132851542838551, "Episode": 2793, "Episode Step": 102}
{"Training time": 8.293257714708647, "Episode Reward": -113.6484459676356, "Mean Reward": -3.918911929918469, "Episode": 2794, "Episode Step": 29}
{"Training time": 8.294538879990577, "Episode Reward": -183.4625334033641, "Mean Reward": -1.69872716114226, "Episode": 2795, "Episode Step": 108}
{"Training time": 8.296228858563635, "Episode Reward": -700.0073410272408, "Mean Reward": -6.862817068894518, "Episode": 2796, "Episode Step": 102}
{"Training time": 8.299545710550413, "Episode Reward": 11735.982519680709, "Mean Reward": 42.064453475558096, "Episode": 2797, "Episode Step": 279}
{"Training time": 8.300773543847932, "Episode Reward": -10.7921561246534, "Mean Reward": -0.10580545220248432, "Episode": 2798, "Episode Step": 102}
{"Training time": 8.302720093329748, "Episode Reward": -818.8313850877348, "Mean Reward": -8.027758677330734, "Episode": 2799, "Episode Step": 102}
{"Training time": 8.303334529664781, "Episode Reward": -117.07710178473006, "Mean Reward": -4.502965453258849, "Episode": 2800, "Episode Step": 26}
{"Training time": 8.30453936941094, "Episode Reward": -322.5657421380602, "Mean Reward": -3.1624092366476493, "Episode": 2801, "Episode Step": 102}
{"Training time": 8.306223534676764, "Episode Reward": -619.5537304217877, "Mean Reward": -6.074056180605762, "Episode": 2802, "Episode Step": 102}
{"Training time": 8.306568771070904, "Episode Reward": -100.53095602375227, "Mean Reward": -3.723368741620454, "Episode": 2803, "Episode Step": 27}
{"Training time": 8.307806861665513, "Episode Reward": -209.6194707183004, "Mean Reward": -2.0550928501794155, "Episode": 2804, "Episode Step": 102}
{"Training time": 8.320061067740122, "Episode Reward": 53227.39774036709, "Mean Reward": 52.75262412325777, "Episode": 2805, "Episode Step": 1009}
{"Training time": 8.321302490234375, "Episode Reward": 242.5854582765265, "Mean Reward": 2.3782888066326127, "Episode": 2806, "Episode Step": 102}
{"Training time": 8.32251463883453, "Episode Reward": 36.764390765642965, "Mean Reward": 0.36043520358473496, "Episode": 2807, "Episode Step": 102}
{"Training time": 8.325723541643885, "Episode Reward": 13536.83701099485, "Mean Reward": 57.84973081621731, "Episode": 2808, "Episode Step": 234}
{"Training time": 8.327106750276354, "Episode Reward": 6035.278455496199, "Mean Reward": 52.028262547381026, "Episode": 2809, "Episode Step": 116}
{"Training time": 8.328421204421256, "Episode Reward": -252.5153953617148, "Mean Reward": -2.2955945032883163, "Episode": 2810, "Episode Step": 110}
{"Training time": 8.331966730819808, "Episode Reward": 14552.302526076051, "Mean Reward": 56.186496239675876, "Episode": 2811, "Episode Step": 259}
{"Training time": 8.335515280498399, "Episode Reward": 17183.86283816479, "Mean Reward": 57.08924530951758, "Episode": 2812, "Episode Step": 301}
{"Training time": 8.336717782484161, "Episode Reward": 116.15896167649404, "Mean Reward": 1.1388133497695494, "Episode": 2813, "Episode Step": 102}
{"Training time": 8.339846068289544, "Episode Reward": 10423.035003359571, "Mean Reward": 46.11962390867067, "Episode": 2814, "Episode Step": 226}
{"Training time": 8.341041676070954, "Episode Reward": -227.28978517188727, "Mean Reward": -2.2283312271753655, "Episode": 2815, "Episode Step": 102}
{"Training time": 8.343699659970072, "Episode Reward": 8399.088864545392, "Mean Reward": 37.000391473768246, "Episode": 2816, "Episode Step": 227}
{"Training time": 8.346243201361762, "Episode Reward": 7198.876861000403, "Mean Reward": 40.21718916760001, "Episode": 2817, "Episode Step": 179}
{"Training time": 8.347465581364101, "Episode Reward": -169.161984810189, "Mean Reward": -1.6584508314724413, "Episode": 2818, "Episode Step": 102}
{"Training time": 8.35185008638435, "Episode Reward": 17420.315447418106, "Mean Reward": 47.08193364167056, "Episode": 2819, "Episode Step": 370}
{"Training time": 8.354507508277893, "Episode Reward": 7751.380636113258, "Mean Reward": 42.357271235591575, "Episode": 2820, "Episode Step": 183}
{"Training time": 8.35574574165874, "Episode Reward": 90.14588170500382, "Mean Reward": 0.8837831539706257, "Episode": 2821, "Episode Step": 102}
{"Training time": 8.356976438297165, "Episode Reward": 4569.793492750649, "Mean Reward": 43.94032204567932, "Episode": 2822, "Episode Step": 104}
{"Training time": 8.35952812300788, "Episode Reward": 7937.593146041183, "Mean Reward": 45.09996105705218, "Episode": 2823, "Episode Step": 176}
{"Training time": 8.360751590794987, "Episode Reward": 182.0658353384986, "Mean Reward": 1.7849591699852805, "Episode": 2824, "Episode Step": 102}
{"Training time": 8.364078877170881, "Episode Reward": 15177.758019339924, "Mean Reward": 54.20627864049973, "Episode": 2825, "Episode Step": 280}
{"Training time": 8.370873373614417, "Episode Reward": 25747.249781262857, "Mean Reward": 48.76373064633117, "Episode": 2826, "Episode Step": 528}
{"Training time": 8.372088389727804, "Episode Reward": 231.0069434249598, "Mean Reward": 2.2647739551466644, "Episode": 2827, "Episode Step": 102}
{"Training time": 8.374574468599425, "Episode Reward": 8531.952173510359, "Mean Reward": 40.822737672298366, "Episode": 2828, "Episode Step": 209}
{"Training time": 8.387157319717938, "Episode Reward": 51863.422708007514, "Mean Reward": 50.64787373828859, "Episode": 2829, "Episode Step": 1024}
{"Training time": 8.388404369420476, "Episode Reward": -483.7722991439701, "Mean Reward": -4.74286567788206, "Episode": 2830, "Episode Step": 102}
{"Training time": 8.390361184411578, "Episode Reward": 5699.535383828053, "Mean Reward": 34.753264535536914, "Episode": 2831, "Episode Step": 164}
{"Training time": 8.396837524970373, "Episode Reward": 28699.32520144487, "Mean Reward": 55.94410370652022, "Episode": 2832, "Episode Step": 513}
{"Training time": 8.39805163582166, "Episode Reward": -168.5428885055916, "Mean Reward": -1.6523812598587413, "Episode": 2833, "Episode Step": 102}
{"Training time": 8.401972591347164, "Episode Reward": 16875.259101798772, "Mean Reward": 50.98265589667303, "Episode": 2834, "Episode Step": 331}
{"Training time": 8.404660858578152, "Episode Reward": 7699.874747406112, "Mean Reward": 41.17580078826798, "Episode": 2835, "Episode Step": 187}
{"Training time": 8.40588458802965, "Episode Reward": 100.91319288919169, "Mean Reward": 0.9893450283254087, "Episode": 2836, "Episode Step": 102}
{"Training time": 8.408222713867824, "Episode Reward": 8514.106378936465, "Mean Reward": 43.218814106276476, "Episode": 2837, "Episode Step": 197}
{"Training time": 8.421625226073795, "Episode Reward": 56827.78702007568, "Mean Reward": 51.15012333040115, "Episode": 2838, "Episode Step": 1111}
{"Training time": 8.422838329672814, "Episode Reward": 129.12371020658733, "Mean Reward": 1.2659187275155621, "Episode": 2839, "Episode Step": 102}
{"Training time": 8.424942486948437, "Episode Reward": 8597.931427143545, "Mean Reward": 48.033136464489075, "Episode": 2840, "Episode Step": 179}
{"Training time": 8.43710576163398, "Episode Reward": 51664.8084372329, "Mean Reward": 50.75128530180049, "Episode": 2841, "Episode Step": 1018}
{"Training time": 8.438320967223909, "Episode Reward": 108.33599721845029, "Mean Reward": 1.0621176197887283, "Episode": 2842, "Episode Step": 102}
{"Training time": 8.440378451082442, "Episode Reward": 8476.507674742545, "Mean Reward": 47.620829633385085, "Episode": 2843, "Episode Step": 178}
{"Training time": 8.448592231339878, "Episode Reward": 34957.50553203518, "Mean Reward": 52.646845680775876, "Episode": 2844, "Episode Step": 664}
{"Training time": 8.449810333053271, "Episode Reward": -147.61234423070624, "Mean Reward": -1.4471798453990807, "Episode": 2845, "Episode Step": 102}
{"Training time": 8.452026436063978, "Episode Reward": 8631.099606383237, "Mean Reward": 45.667193684567394, "Episode": 2846, "Episode Step": 189}
{"Training time": 8.455518438882297, "Episode Reward": 13333.060460414867, "Mean Reward": 50.889543742041475, "Episode": 2847, "Episode Step": 262}
{"Training time": 8.45673043721252, "Episode Reward": -589.562619276735, "Mean Reward": -5.780025679183676, "Episode": 2848, "Episode Step": 102}
{"Training time": 8.460077045228747, "Episode Reward": 8161.650728328764, "Mean Reward": 43.645191060581624, "Episode": 2849, "Episode Step": 187}
{"Training time": 8.46628205941783, "Episode Reward": 28214.263231125795, "Mean Reward": 56.883595224043944, "Episode": 2850, "Episode Step": 496}
{"Training time": 8.467476398282582, "Episode Reward": -292.77383346916673, "Mean Reward": -2.870331700678105, "Episode": 2851, "Episode Step": 102}
{"Training time": 8.471100156638357, "Episode Reward": 16856.958188816665, "Mean Reward": 54.202437906162906, "Episode": 2852, "Episode Step": 311}
{"Training time": 8.473211903307172, "Episode Reward": 5541.002562273758, "Mean Reward": 39.86332778614214, "Episode": 2853, "Episode Step": 139}
{"Training time": 8.474434281653828, "Episode Reward": -285.1844240198025, "Mean Reward": -2.7959257256843384, "Episode": 2854, "Episode Step": 102}
{"Training time": 8.476585371361839, "Episode Reward": 7389.578536335972, "Mean Reward": 41.74903127873431, "Episode": 2855, "Episode Step": 177}
{"Training time": 8.485107076366743, "Episode Reward": 31970.350626673837, "Mean Reward": 46.672044710472754, "Episode": 2856, "Episode Step": 685}
{"Training time": 8.486314681371054, "Episode Reward": -115.26453123790397, "Mean Reward": -1.1300444239010192, "Episode": 2857, "Episode Step": 102}
{"Training time": 8.487313063608276, "Episode Reward": 3617.853336823964, "Mean Reward": 42.56298043322311, "Episode": 2858, "Episode Step": 85}
{"Training time": 8.50656274775664, "Episode Reward": 89211.82840429147, "Mean Reward": 55.171198765795594, "Episode": 2859, "Episode Step": 1617}
{"Training time": 8.50778057191107, "Episode Reward": -133.49958688583024, "Mean Reward": -1.3088194792728456, "Episode": 2860, "Episode Step": 102}
{"Training time": 8.509906907743877, "Episode Reward": 7409.759987025033, "Mean Reward": 40.71296696167601, "Episode": 2861, "Episode Step": 182}
{"Training time": 8.516288954681821, "Episode Reward": 29315.29934403029, "Mean Reward": 58.165276476250575, "Episode": 2862, "Episode Step": 504}
{"Training time": 8.517521866096391, "Episode Reward": -451.8177936068846, "Mean Reward": -4.429586211832202, "Episode": 2863, "Episode Step": 102}
{"Training time": 8.51873311718305, "Episode Reward": 3740.7150071587293, "Mean Reward": 36.67367654077186, "Episode": 2864, "Episode Step": 102}
{"Training time": 8.532382368048031, "Episode Reward": 61833.419117188656, "Mean Reward": 55.2084099260613, "Episode": 2865, "Episode Step": 1120}
{"Training time": 8.533603434960048, "Episode Reward": -374.68712490048995, "Mean Reward": -3.673403185298921, "Episode": 2866, "Episode Step": 102}
{"Training time": 8.5357285652558, "Episode Reward": 8277.60729344188, "Mean Reward": 45.73263698034188, "Episode": 2867, "Episode Step": 181}
{"Training time": 8.537944615549511, "Episode Reward": 6768.7874096147525, "Mean Reward": 45.428103420233235, "Episode": 2868, "Episode Step": 149}
{"Training time": 8.539169351392323, "Episode Reward": -280.7710185859589, "Mean Reward": -2.7526570449603818, "Episode": 2869, "Episode Step": 102}
{"Training time": 8.541173083848424, "Episode Reward": 7859.130110491836, "Mean Reward": 45.69261692146416, "Episode": 2870, "Episode Step": 172}
{"Training time": 8.54391697300805, "Episode Reward": 8416.586693095478, "Mean Reward": 43.38446749018288, "Episode": 2871, "Episode Step": 194}
{"Training time": 8.545121956335175, "Episode Reward": -235.37442548159166, "Mean Reward": -2.307592406682271, "Episode": 2872, "Episode Step": 102}
{"Training time": 8.547230592171351, "Episode Reward": 8256.648132778004, "Mean Reward": 45.616840512585654, "Episode": 2873, "Episode Step": 181}
{"Training time": 8.560768536925316, "Episode Reward": 64977.78312174061, "Mean Reward": 57.96412410503177, "Episode": 2874, "Episode Step": 1121}
{"Training time": 8.56199208524492, "Episode Reward": 181.29697501744536, "Mean Reward": 1.7774213237004448, "Episode": 2875, "Episode Step": 102}
{"Training time": 8.56520439916187, "Episode Reward": 13874.474533732962, "Mean Reward": 51.00909755048883, "Episode": 2876, "Episode Step": 272}
{"Training time": 8.57295483218299, "Episode Reward": 36508.535801315455, "Mean Reward": 59.26710357356405, "Episode": 2877, "Episode Step": 616}
{"Training time": 8.574158774150742, "Episode Reward": 168.65083157168047, "Mean Reward": 1.6534395252125536, "Episode": 2878, "Episode Step": 102}
{"Training time": 8.577820295227898, "Episode Reward": 16808.371601519895, "Mean Reward": 54.04621093736301, "Episode": 2879, "Episode Step": 311}
{"Training time": 8.580058111945789, "Episode Reward": 7321.889640764365, "Mean Reward": 48.81259760509577, "Episode": 2880, "Episode Step": 150}
{"Training time": 8.58296862218115, "Episode Reward": 6692.234672813375, "Mean Reward": 26.98481722908619, "Episode": 2881, "Episode Step": 248}
{"Training time": 8.58511557744609, "Episode Reward": 7775.369992459069, "Mean Reward": 42.7218131453795, "Episode": 2882, "Episode Step": 182}
{"Training time": 8.587791465255949, "Episode Reward": 9214.126342264864, "Mean Reward": 49.27340289981211, "Episode": 2883, "Episode Step": 187}
{"Training time": 8.588988694945972, "Episode Reward": -270.77083291689326, "Mean Reward": -2.6546160089891497, "Episode": 2884, "Episode Step": 102}
{"Training time": 8.591213697724871, "Episode Reward": 8214.845828889864, "Mean Reward": 43.00966402560138, "Episode": 2885, "Episode Step": 191}
{"Training time": 8.597639252742132, "Episode Reward": 32654.68559688851, "Mean Reward": 65.04917449579385, "Episode": 2886, "Episode Step": 502}
{"Training time": 8.598850854436556, "Episode Reward": -300.0859877805454, "Mean Reward": -2.9420194880445627, "Episode": 2887, "Episode Step": 102}
{"Training time": 8.600905869139565, "Episode Reward": 8031.621084551643, "Mean Reward": 46.42555540203262, "Episode": 2888, "Episode Step": 173}
{"Training time": 8.621164727740817, "Episode Reward": 100947.3534656928, "Mean Reward": 59.83838379709116, "Episode": 2889, "Episode Step": 1687}
{"Training time": 8.622391059994698, "Episode Reward": -370.51758017305326, "Mean Reward": -3.6325252958142475, "Episode": 2890, "Episode Step": 102}
{"Training time": 8.622968386941485, "Episode Reward": 1721.384798187343, "Mean Reward": 36.62520847207113, "Episode": 2891, "Episode Step": 47}
{"Training time": 8.64673344804181, "Episode Reward": 119296.77035131765, "Mean Reward": 60.64909524723826, "Episode": 2892, "Episode Step": 1967}
{"Training time": 8.647937367227343, "Episode Reward": 138.9682758918807, "Mean Reward": 1.3624340773713794, "Episode": 2893, "Episode Step": 102}
{"Training time": 8.648471644123395, "Episode Reward": 1538.36594673715, "Mean Reward": 35.77595224970116, "Episode": 2894, "Episode Step": 43}
{"Training time": 8.662740839123726, "Episode Reward": 74392.43121952446, "Mean Reward": 63.31270742087188, "Episode": 2895, "Episode Step": 1175}
{"Training time": 8.663966449962722, "Episode Reward": -249.75910757389556, "Mean Reward": -2.4486187017048584, "Episode": 2896, "Episode Step": 102}
{"Training time": 8.666171081331042, "Episode Reward": 7934.055812359884, "Mean Reward": 42.656214044945614, "Episode": 2897, "Episode Step": 186}
{"Training time": 8.673825347224872, "Episode Reward": 38113.69194528516, "Mean Reward": 60.981907112456256, "Episode": 2898, "Episode Step": 625}
{"Training time": 8.676204336351818, "Episode Reward": 225.2489641288679, "Mean Reward": 2.208323177733999, "Episode": 2899, "Episode Step": 102}
{"Training time": 8.680042917463515, "Episode Reward": 16821.172778711858, "Mean Reward": 55.515421711920325, "Episode": 2900, "Episode Step": 303}
{"Training time": 8.687380101614528, "Episode Reward": 35347.50758057593, "Mean Reward": 60.01274631676729, "Episode": 2901, "Episode Step": 589}
{"Training time": 8.688597843050957, "Episode Reward": -295.3542660402267, "Mean Reward": -2.895630059217909, "Episode": 2902, "Episode Step": 102}
{"Training time": 8.692354766660266, "Episode Reward": 15877.299949272336, "Mean Reward": 49.4619936114403, "Episode": 2903, "Episode Step": 321}
{"Training time": 8.708134092224968, "Episode Reward": 84181.46271157307, "Mean Reward": 64.06504011535242, "Episode": 2904, "Episode Step": 1314}
{"Training time": 8.709347287482686, "Episode Reward": -383.95432154872253, "Mean Reward": -3.7642580543992405, "Episode": 2905, "Episode Step": 102}
{"Training time": 8.710385826892322, "Episode Reward": 3158.492135803497, "Mean Reward": 37.60109685480354, "Episode": 2906, "Episode Step": 84}
{"Training time": 8.71293978717592, "Episode Reward": 9083.945920438602, "Mean Reward": 50.74830123150057, "Episode": 2907, "Episode Step": 179}
{"Training time": 8.714158712757959, "Episode Reward": -383.14349877152193, "Mean Reward": -3.756308811485509, "Episode": 2908, "Episode Step": 102}
{"Training time": 8.716290091077486, "Episode Reward": 7311.520692325528, "Mean Reward": 40.17319061717323, "Episode": 2909, "Episode Step": 182}
{"Training time": 8.719825144145224, "Episode Reward": 15662.206607185291, "Mean Reward": 60.70622715963291, "Episode": 2910, "Episode Step": 258}
{"Training time": 8.721058031055662, "Episode Reward": -395.79530347556147, "Mean Reward": -3.8803461125055048, "Episode": 2911, "Episode Step": 102}
{"Training time": 8.723838464683956, "Episode Reward": 9978.076523176385, "Mean Reward": 42.45990009862292, "Episode": 2912, "Episode Step": 235}
{"Training time": 8.726381199161212, "Episode Reward": 8102.667587408485, "Mean Reward": 46.037884019366395, "Episode": 2913, "Episode Step": 176}
{"Training time": 8.727617909709613, "Episode Reward": 163.3092491797549, "Mean Reward": 1.6010710703897537, "Episode": 2914, "Episode Step": 102}
{"Training time": 8.729835211104817, "Episode Reward": 8610.522802527486, "Mean Reward": 45.31854106593414, "Episode": 2915, "Episode Step": 190}
{"Training time": 8.734403408037291, "Episode Reward": 20311.763466989985, "Mean Reward": 58.19989532088821, "Episode": 2916, "Episode Step": 349}
{"Training time": 8.735649426115884, "Episode Reward": -504.3997680058229, "Mean Reward": -4.94509576476297, "Episode": 2917, "Episode Step": 102}
{"Training time": 8.737744041350153, "Episode Reward": 8192.53504107805, "Mean Reward": 46.54849455157983, "Episode": 2918, "Episode Step": 176}
{"Training time": 8.741136351625125, "Episode Reward": 15031.197033542323, "Mean Reward": 60.609665457831944, "Episode": 2919, "Episode Step": 248}
{"Training time": 8.742346446646584, "Episode Reward": -222.314964859615, "Mean Reward": -2.1795584790158333, "Episode": 2920, "Episode Step": 102}
{"Training time": 8.744463182224168, "Episode Reward": 7831.9258657597575, "Mean Reward": 43.75377578636736, "Episode": 2921, "Episode Step": 179}
{"Training time": 8.770216506653362, "Episode Reward": 132109.58266729038, "Mean Reward": 61.41775112379841, "Episode": 2922, "Episode Step": 2151}
{"Training time": 8.77142663889461, "Episode Reward": -255.2764319326411, "Mean Reward": -2.5027101169866772, "Episode": 2923, "Episode Step": 102}
{"Training time": 8.773576689163844, "Episode Reward": 8317.366991767649, "Mean Reward": 45.952303821920715, "Episode": 2924, "Episode Step": 181}
{"Training time": 8.776118044720755, "Episode Reward": 8959.759446142152, "Mean Reward": 51.19862540652658, "Episode": 2925, "Episode Step": 175}
{"Training time": 8.777370373275545, "Episode Reward": -233.38871322958178, "Mean Reward": -2.2881246395057038, "Episode": 2926, "Episode Step": 102}
{"Training time": 8.779517263306511, "Episode Reward": 7909.133204714347, "Mean Reward": 44.68436838821665, "Episode": 2927, "Episode Step": 177}
{"Training time": 8.782027585837577, "Episode Reward": 7953.072978664778, "Mean Reward": 46.23879638758592, "Episode": 2928, "Episode Step": 172}
{"Training time": 8.783240073588159, "Episode Reward": -428.5392822498886, "Mean Reward": -4.201365512253809, "Episode": 2929, "Episode Step": 102}
{"Training time": 8.78690496550666, "Episode Reward": 17637.837919344354, "Mean Reward": 56.89625135272372, "Episode": 2930, "Episode Step": 310}
{"Training time": 8.78901878522502, "Episode Reward": 6345.353199208878, "Mean Reward": 45.98082028412231, "Episode": 2931, "Episode Step": 138}
{"Training time": 8.790243468615744, "Episode Reward": -276.2799825650294, "Mean Reward": -2.7086272800493076, "Episode": 2932, "Episode Step": 102}
{"Training time": 8.793247728281552, "Episode Reward": 14753.35012898697, "Mean Reward": 58.54504019439273, "Episode": 2933, "Episode Step": 252}
{"Training time": 8.794974751671155, "Episode Reward": 5141.250410839652, "Mean Reward": 51.412504108396526, "Episode": 2934, "Episode Step": 100}
{"Training time": 8.796181625260248, "Episode Reward": -416.0939662215975, "Mean Reward": -4.079352610015662, "Episode": 2935, "Episode Step": 102}
{"Training time": 8.798230528566572, "Episode Reward": 8831.356329549104, "Mean Reward": 50.17816096334718, "Episode": 2936, "Episode Step": 176}
{"Training time": 8.827806476950645, "Episode Reward": 153486.41988592377, "Mean Reward": 61.46832995030988, "Episode": 2937, "Episode Step": 2497}
{"Training time": 8.829006372491518, "Episode Reward": -484.4295687717811, "Mean Reward": -4.749309497762559, "Episode": 2938, "Episode Step": 102}
{"Training time": 8.836504560245407, "Episode Reward": 35909.76583081412, "Mean Reward": 55.84722524232367, "Episode": 2939, "Episode Step": 643}
{"Training time": 8.839079530239106, "Episode Reward": 8467.422353987444, "Mean Reward": 47.04123529993024, "Episode": 2940, "Episode Step": 180}
{"Training time": 8.840300454696019, "Episode Reward": -416.2096817515067, "Mean Reward": -4.080487075995164, "Episode": 2941, "Episode Step": 102}
{"Training time": 8.842504646645652, "Episode Reward": 8483.975582225783, "Mean Reward": 45.36885338088654, "Episode": 2942, "Episode Step": 187}
{"Training time": 8.845060161948204, "Episode Reward": 8518.484252017652, "Mean Reward": 49.23979336426388, "Episode": 2943, "Episode Step": 173}
{"Training time": 8.846273447208935, "Episode Reward": -511.7372406453543, "Mean Reward": -5.017031771032885, "Episode": 2944, "Episode Step": 102}
{"Training time": 8.848395069705115, "Episode Reward": 9066.171378056717, "Mean Reward": 50.367618766981764, "Episode": 2945, "Episode Step": 180}
{"Training time": 8.861911127501063, "Episode Reward": 68274.44967776147, "Mean Reward": 61.342722082445164, "Episode": 2946, "Episode Step": 1113}
{"Training time": 8.863142433895005, "Episode Reward": -654.7903165222427, "Mean Reward": -6.4195129070808115, "Episode": 2947, "Episode Step": 102}
{"Training time": 8.86525683078501, "Episode Reward": 8328.962013518501, "Mean Reward": 46.79192142426125, "Episode": 2948, "Episode Step": 178}
{"Training time": 8.898178875247638, "Episode Reward": 162172.26046853882, "Mean Reward": 60.264682448360766, "Episode": 2949, "Episode Step": 2691}
{"Training time": 8.899659184681045, "Episode Reward": -287.26298522926453, "Mean Reward": -2.816303776757495, "Episode": 2950, "Episode Step": 102}
{"Training time": 8.902647355794906, "Episode Reward": 15767.100925112005, "Mean Reward": 61.35058725724515, "Episode": 2951, "Episode Step": 257}
{"Training time": 8.960900013049443, "Episode Reward": 305629.970652207, "Mean Reward": 61.1259941304414, "Episode": 2952, "Episode Step": 5000}
{"Training time": 8.962388143340746, "Episode Reward": -350.76526314344903, "Mean Reward": -3.4388751288573434, "Episode": 2953, "Episode Step": 102}
{"Training time": 8.96454768107997, "Episode Reward": 8965.189656408991, "Mean Reward": 48.46048462923779, "Episode": 2954, "Episode Step": 185}
{"Training time": 9.023183944953812, "Episode Reward": 303966.0062971848, "Mean Reward": 60.79320125943696, "Episode": 2955, "Episode Step": 5000}
{"Training time": 9.024665901660919, "Episode Reward": -295.3892198945405, "Mean Reward": -2.8959727440641223, "Episode": 2956, "Episode Step": 102}
{"Training time": 9.027387617495325, "Episode Reward": 12978.476832369239, "Mean Reward": 55.22756098880527, "Episode": 2957, "Episode Step": 235}
{"Training time": 9.04080637746387, "Episode Reward": 61211.00523333884, "Mean Reward": 54.799467532084904, "Episode": 2958, "Episode Step": 1117}
{"Training time": 9.041994365519948, "Episode Reward": -350.97830704174555, "Mean Reward": -3.440963794526917, "Episode": 2959, "Episode Step": 102}
{"Training time": 9.04416914999485, "Episode Reward": 9192.918952823096, "Mean Reward": 48.89850506820796, "Episode": 2960, "Episode Step": 188}
{"Training time": 9.046858486069572, "Episode Reward": 8584.43363877777, "Mean Reward": 44.944678737056385, "Episode": 2961, "Episode Step": 191}
{"Training time": 9.048052562475204, "Episode Reward": -285.11653305563607, "Mean Reward": -2.795260127996432, "Episode": 2962, "Episode Step": 102}
{"Training time": 9.056375279956393, "Episode Reward": 42944.962803358525, "Mean Reward": 59.23443145290831, "Episode": 2963, "Episode Step": 725}
{"Training time": 9.067928919394811, "Episode Reward": 52664.243755319934, "Mean Reward": 54.574345860435166, "Episode": 2964, "Episode Step": 965}
{"Training time": 9.069104264113639, "Episode Reward": -203.57380644715198, "Mean Reward": -1.9958216318348234, "Episode": 2965, "Episode Step": 102}
{"Training time": 9.072774344417784, "Episode Reward": 18644.773887042382, "Mean Reward": 59.189758371563116, "Episode": 2966, "Episode Step": 315}
{"Training time": 9.104085238046116, "Episode Reward": 154285.529788252, "Mean Reward": 57.89325695619212, "Episode": 2967, "Episode Step": 2665}
{"Training time": 9.105271678566933, "Episode Reward": -379.2414770956985, "Mean Reward": -3.718053697016652, "Episode": 2968, "Episode Step": 102}
{"Training time": 9.112793045242627, "Episode Reward": 35560.25495375282, "Mean Reward": 54.373478522557825, "Episode": 2969, "Episode Step": 654}
{"Training time": 9.12328274110953, "Episode Reward": 50053.59824717131, "Mean Reward": 58.81738924461963, "Episode": 2970, "Episode Step": 851}
{"Training time": 9.124505792193943, "Episode Reward": -293.51894048923424, "Mean Reward": -2.877636671463081, "Episode": 2971, "Episode Step": 102}
{"Training time": 9.145169066919221, "Episode Reward": 98034.49942224441, "Mean Reward": 54.95207366717736, "Episode": 2972, "Episode Step": 1784}
{"Training time": 9.14776642051008, "Episode Reward": 8684.908498872977, "Mean Reward": 47.45851638728403, "Episode": 2973, "Episode Step": 183}
{"Training time": 9.148956088291275, "Episode Reward": -247.59629313799294, "Mean Reward": -2.427414638607774, "Episode": 2974, "Episode Step": 102}
{"Training time": 9.152662679155668, "Episode Reward": 17800.096061306405, "Mean Reward": 55.62530019158252, "Episode": 2975, "Episode Step": 320}
{"Training time": 9.164485266076193, "Episode Reward": 53416.6175921672, "Mean Reward": 54.395740928887165, "Episode": 2976, "Episode Step": 982}
{"Training time": 9.16568594250414, "Episode Reward": -169.33992680747323, "Mean Reward": -1.6601953608575808, "Episode": 2977, "Episode Step": 102}
{"Training time": 9.167895456353824, "Episode Reward": 8876.770951841278, "Mean Reward": 46.71984711495409, "Episode": 2978, "Episode Step": 190}
{"Training time": 9.206891861359278, "Episode Reward": 192488.4949899058, "Mean Reward": 57.839091042639964, "Episode": 2979, "Episode Step": 3328}
{"Training time": 9.208080901106198, "Episode Reward": -161.84051799550573, "Mean Reward": -1.5866717450539778, "Episode": 2980, "Episode Step": 102}
{"Training time": 9.213983423577414, "Episode Reward": 28625.986815063283, "Mean Reward": 55.801143889012245, "Episode": 2981, "Episode Step": 513}
{"Training time": 9.217986291117139, "Episode Reward": 16663.472047610507, "Mean Reward": 54.99495725283995, "Episode": 2982, "Episode Step": 303}
{"Training time": 9.219170733292897, "Episode Reward": -93.0014727750753, "Mean Reward": -0.9117791448536794, "Episode": 2983, "Episode Step": 102}
{"Training time": 9.227883450521363, "Episode Reward": 43645.74758909354, "Mean Reward": 57.88560688208692, "Episode": 2984, "Episode Step": 754}
{"Training time": 9.253152018056975, "Episode Reward": 130076.92517491349, "Mean Reward": 60.529048475995104, "Episode": 2985, "Episode Step": 2149}
{"Training time": 9.254369130002127, "Episode Reward": -174.608674193158, "Mean Reward": -1.711849746991745, "Episode": 2986, "Episode Step": 102}
{"Training time": 9.26338939388593, "Episode Reward": 47570.35224667553, "Mean Reward": 61.0659207274397, "Episode": 2987, "Episode Step": 779}
{"Training time": 9.26594137026204, "Episode Reward": 7865.823038703638, "Mean Reward": 43.69901688168688, "Episode": 2988, "Episode Step": 180}
{"Training time": 9.267159563038085, "Episode Reward": -124.6001699113628, "Mean Reward": -1.221570293248655, "Episode": 2989, "Episode Step": 102}
{"Training time": 9.270178836915228, "Episode Reward": 12715.876592262835, "Mean Reward": 50.45982774707474, "Episode": 2990, "Episode Step": 252}
{"Training time": 9.2998220955001, "Episode Reward": 144244.7350345388, "Mean Reward": 57.81352105592738, "Episode": 2991, "Episode Step": 2495}
{"Training time": 9.301062269144587, "Episode Reward": -158.96902640409138, "Mean Reward": -1.5585198667067783, "Episode": 2992, "Episode Step": 102}
{"Training time": 9.321776550809542, "Episode Reward": 104152.28618705881, "Mean Reward": 58.644305285506086, "Episode": 2993, "Episode Step": 1776}
{"Training time": 9.33597326748901, "Episode Reward": 67704.73728049456, "Mean Reward": 57.42556173069937, "Episode": 2994, "Episode Step": 1179}
{"Training time": 9.337150975267093, "Episode Reward": -171.05377633925877, "Mean Reward": -1.676997807247635, "Episode": 2995, "Episode Step": 102}
{"Training time": 9.350840974450112, "Episode Reward": 74380.78743233113, "Mean Reward": 62.45238239490439, "Episode": 2996, "Episode Step": 1191}
{"Training time": 9.380109481612841, "Episode Reward": 149253.59101100048, "Mean Reward": 59.7971117832534, "Episode": 2997, "Episode Step": 2496}
{"Training time": 9.381304003331396, "Episode Reward": -238.03111289985648, "Mean Reward": -2.333638361763299, "Episode": 2998, "Episode Step": 102}
{"Training time": 9.384759201672342, "Episode Reward": 8938.796018203675, "Mean Reward": 45.60610213369222, "Episode": 2999, "Episode Step": 196}
{"Training time": 9.404694185256957, "Episode Reward": 103308.13389748652, "Mean Reward": 60.98473075412427, "Episode": 3000, "Episode Step": 1694}
{"Training time": 9.405896993014547, "Episode Reward": -197.53788092407495, "Mean Reward": -1.9366458914124995, "Episode": 3001, "Episode Step": 102}
{"Training time": 9.41485541244348, "Episode Reward": 46041.77309108218, "Mean Reward": 59.255821224043984, "Episode": 3002, "Episode Step": 777}
{"Training time": 9.417366622487704, "Episode Reward": 8655.14478752357, "Mean Reward": 48.8991230933535, "Episode": 3003, "Episode Step": 177}
{"Training time": 9.418576483329137, "Episode Reward": -177.34910454168866, "Mean Reward": -1.7387167111930262, "Episode": 3004, "Episode Step": 102}
{"Training time": 9.421665374437968, "Episode Reward": 15823.724124146684, "Mean Reward": 58.82425324961592, "Episode": 3005, "Episode Step": 269}
{"Training time": 9.46578547888332, "Episode Reward": 232572.55493312926, "Mean Reward": 61.300093551167436, "Episode": 3006, "Episode Step": 3794}
{"Training time": 9.46699062857363, "Episode Reward": -144.98799560484514, "Mean Reward": -1.4214509373024034, "Episode": 3007, "Episode Step": 102}
{"Training time": 9.469236540529463, "Episode Reward": 9325.817949369572, "Mean Reward": 48.57196848629985, "Episode": 3008, "Episode Step": 192}
{"Training time": 9.475813262197706, "Episode Reward": 30138.2305704601, "Mean Reward": 58.407423586162984, "Episode": 3009, "Episode Step": 516}
{"Training time": 9.477039568887816, "Episode Reward": -193.30508545614254, "Mean Reward": -1.8951478966288484, "Episode": 3010, "Episode Step": 102}
{"Training time": 9.480166499416033, "Episode Reward": 16960.198443296827, "Mean Reward": 63.76014452367228, "Episode": 3011, "Episode Step": 266}
{"Training time": 9.519071275260714, "Episode Reward": 198086.37215045115, "Mean Reward": 60.099020676714545, "Episode": 3012, "Episode Step": 3296}
{"Training time": 9.520276504953703, "Episode Reward": -186.51727272979548, "Mean Reward": -1.8286007130372106, "Episode": 3013, "Episode Step": 102}
{"Training time": 9.525872047212388, "Episode Reward": 28087.722305215295, "Mean Reward": 58.394433066975665, "Episode": 3014, "Episode Step": 481}
{"Training time": 9.535785229404768, "Episode Reward": 47993.91689420487, "Mean Reward": 58.17444472024833, "Episode": 3015, "Episode Step": 825}
{"Training time": 9.536994635793898, "Episode Reward": -220.39982210757756, "Mean Reward": -2.160782569682133, "Episode": 3016, "Episode Step": 102}
{"Training time": 9.540579651064343, "Episode Reward": 19397.39944058034, "Mean Reward": 62.77475547113378, "Episode": 3017, "Episode Step": 309}
{"Training time": 9.546938437223435, "Episode Reward": 31199.53360464316, "Mean Reward": 61.53754162651511, "Episode": 3018, "Episode Step": 507}
{"Training time": 9.54814692583349, "Episode Reward": -375.6300227863976, "Mean Reward": -3.7191091364989863, "Episode": 3019, "Episode Step": 101}
{"Training time": 9.55177586581972, "Episode Reward": 17344.42006174416, "Mean Reward": 55.4134826253807, "Episode": 3020, "Episode Step": 313}
{"Training time": 9.552844454116292, "Episode Reward": 1978.084704771934, "Mean Reward": 38.78597460337125, "Episode": 3021, "Episode Step": 51}
{"Training time": 9.554003168278271, "Episode Reward": -403.58122298337355, "Mean Reward": -4.118175744728301, "Episode": 3022, "Episode Step": 98}
{"Training time": 9.56764260272185, "Episode Reward": 71147.49337220704, "Mean Reward": 60.65429955004863, "Episode": 3023, "Episode Step": 1173}
{"Training time": 9.572403710219595, "Episode Reward": 21716.388094736518, "Mean Reward": 58.220879610553666, "Episode": 3024, "Episode Step": 373}
{"Training time": 9.573619491391712, "Episode Reward": -407.94541276442817, "Mean Reward": -4.079454127644282, "Episode": 3025, "Episode Step": 100}
{"Training time": 9.576687927775913, "Episode Reward": 15479.679184595467, "Mean Reward": 58.858095758918125, "Episode": 3026, "Episode Step": 263}
{"Training time": 9.579304249684016, "Episode Reward": 8451.32017672113, "Mean Reward": 45.19422554396326, "Episode": 3027, "Episode Step": 187}
{"Training time": 9.580425647762087, "Episode Reward": -389.36630192425264, "Mean Reward": -4.098592651834238, "Episode": 3028, "Episode Step": 95}
{"Training time": 9.600775849421819, "Episode Reward": 107465.12591966691, "Mean Reward": 61.40864338266681, "Episode": 3029, "Episode Step": 1750}
{"Training time": 9.607060960531236, "Episode Reward": 31679.926712936325, "Mean Reward": 63.48682708003272, "Episode": 3030, "Episode Step": 499}
{"Training time": 9.608266784681215, "Episode Reward": -222.0099360425639, "Mean Reward": -2.1765680004172934, "Episode": 3031, "Episode Step": 102}
{"Training time": 9.614601499173377, "Episode Reward": 32535.139530431483, "Mean Reward": 59.9173840339438, "Episode": 3032, "Episode Step": 543}
{"Training time": 9.617160647776391, "Episode Reward": 8286.523486026026, "Mean Reward": 46.816516870203536, "Episode": 3033, "Episode Step": 177}
{"Training time": 9.618401680522496, "Episode Reward": -160.87124354077483, "Mean Reward": -1.577169054321322, "Episode": 3034, "Episode Step": 102}
{"Training time": 9.621456489695444, "Episode Reward": 16285.301439285979, "Mean Reward": 62.877611734694895, "Episode": 3035, "Episode Step": 259}
{"Training time": 9.628034308022922, "Episode Reward": 31610.096192450732, "Mean Reward": 60.5557398322811, "Episode": 3036, "Episode Step": 522}
{"Training time": 9.629239726662636, "Episode Reward": -179.79374280147334, "Mean Reward": -1.762683752955621, "Episode": 3037, "Episode Step": 102}
{"Training time": 9.646874697473313, "Episode Reward": 90548.94696641692, "Mean Reward": 59.92650361774779, "Episode": 3038, "Episode Step": 1511}
{"Training time": 9.652534903022978, "Episode Reward": 25237.755593801805, "Mean Reward": 56.970102920545834, "Episode": 3039, "Episode Step": 443}
{"Training time": 9.653770323594411, "Episode Reward": -147.00373226553026, "Mean Reward": -1.4412130614267673, "Episode": 3040, "Episode Step": 102}
{"Training time": 9.656100897722775, "Episode Reward": 8697.774030383813, "Mean Reward": 43.488870151919066, "Episode": 3041, "Episode Step": 200}
{"Training time": 9.660971914397345, "Episode Reward": 21422.082114445286, "Mean Reward": 56.3739003011718, "Episode": 3042, "Episode Step": 380}
{"Training time": 9.6621579196718, "Episode Reward": -352.1959409828801, "Mean Reward": -3.4870885245829712, "Episode": 3043, "Episode Step": 101}
{"Training time": 9.664316616389486, "Episode Reward": 8950.343971741719, "Mean Reward": 48.64317375946586, "Episode": 3044, "Episode Step": 184}
{"Training time": 9.67070639497704, "Episode Reward": 30174.1503874546, "Mean Reward": 59.1650007597149, "Episode": 3045, "Episode Step": 510}
{"Training time": 9.671901919709311, "Episode Reward": -187.5956202134434, "Mean Reward": -1.8391727471906216, "Episode": 3046, "Episode Step": 102}
{"Training time": 9.679068287213644, "Episode Reward": 34650.45074515105, "Mean Reward": 56.34219633357895, "Episode": 3047, "Episode Step": 615}
{"Training time": 9.685566460225317, "Episode Reward": 29092.82140099039, "Mean Reward": 55.41489790664836, "Episode": 3048, "Episode Step": 525}
{"Training time": 9.687634331650203, "Episode Reward": -349.88855849845055, "Mean Reward": -3.64467248435886, "Episode": 3049, "Episode Step": 96}
{"Training time": 9.696658733553356, "Episode Reward": 43799.940422954925, "Mean Reward": 58.167251557709065, "Episode": 3050, "Episode Step": 753}
{"Training time": 9.705604329970148, "Episode Reward": 44526.069187699504, "Mean Reward": 60.74497842796658, "Episode": 3051, "Episode Step": 733}
{"Training time": 9.706803387204806, "Episode Reward": -210.3473733525531, "Mean Reward": -2.0622291505152264, "Episode": 3052, "Episode Step": 102}
{"Training time": 9.708871912492645, "Episode Reward": 9160.529582685898, "Mean Reward": 51.17614292003295, "Episode": 3053, "Episode Step": 179}
{"Training time": 9.709991626342138, "Episode Reward": 2807.9989295603714, "Mean Reward": 50.142838027863775, "Episode": 3054, "Episode Step": 56}
{"Training time": 9.711091208590402, "Episode Reward": -355.5760835980965, "Mean Reward": -3.7429061431378576, "Episode": 3055, "Episode Step": 95}
{"Training time": 9.714331194427277, "Episode Reward": 15084.975125949988, "Mean Reward": 53.8749111641071, "Episode": 3056, "Episode Step": 280}
{"Training time": 9.715467251671685, "Episode Reward": 1930.7803983316994, "Mean Reward": 33.873340321608765, "Episode": 3057, "Episode Step": 57}
{"Training time": 9.716659807165463, "Episode Reward": -214.74281326229482, "Mean Reward": -2.105321698649949, "Episode": 3058, "Episode Step": 102}
{"Training time": 9.72240682972802, "Episode Reward": 27171.799822779405, "Mean Reward": 54.56184703369358, "Episode": 3059, "Episode Step": 498}
{"Training time": 9.727937561935848, "Episode Reward": 24852.48102209523, "Mean Reward": 55.84827195976457, "Episode": 3060, "Episode Step": 445}
{"Training time": 9.729108431339263, "Episode Reward": -173.8635621685699, "Mean Reward": -1.7045447271428422, "Episode": 3061, "Episode Step": 102}
{"Training time": 9.731426891949441, "Episode Reward": 8989.083405631163, "Mean Reward": 45.629865003203875, "Episode": 3062, "Episode Step": 197}
{"Training time": 9.755675841636128, "Episode Reward": 120941.09555306131, "Mean Reward": 58.45388861916931, "Episode": 3063, "Episode Step": 2069}
{"Training time": 9.756861479149924, "Episode Reward": -213.81026098254364, "Mean Reward": -2.096179029240624, "Episode": 3064, "Episode Step": 102}
{"Training time": 9.758487363855044, "Episode Reward": 7027.327481005205, "Mean Reward": 50.92266290583482, "Episode": 3065, "Episode Step": 138}
{"Training time": 9.764006143874592, "Episode Reward": 24667.17173822049, "Mean Reward": 56.31774369456733, "Episode": 3066, "Episode Step": 438}
{"Training time": 9.765211845503913, "Episode Reward": -179.1814173411077, "Mean Reward": -1.7566805621677226, "Episode": 3067, "Episode Step": 102}
{"Training time": 9.769033611946636, "Episode Reward": 19066.230496456774, "Mean Reward": 58.12875151358772, "Episode": 3068, "Episode Step": 328}
{"Training time": 9.775307287772497, "Episode Reward": 28001.44644654608, "Mean Reward": 56.00289289309216, "Episode": 3069, "Episode Step": 500}
{"Training time": 9.776493674119314, "Episode Reward": -283.58902023284475, "Mean Reward": -2.780284512086713, "Episode": 3070, "Episode Step": 102}
{"Training time": 9.778667807777722, "Episode Reward": 9002.081519527135, "Mean Reward": 49.46198637102822, "Episode": 3071, "Episode Step": 182}
{"Training time": 9.782094759411281, "Episode Reward": 11970.054782876572, "Mean Reward": 47.12619993258493, "Episode": 3072, "Episode Step": 254}
{"Training time": 9.783249741064177, "Episode Reward": -409.5885112573268, "Mean Reward": -4.137257689467948, "Episode": 3073, "Episode Step": 99}
{"Training time": 9.784920739134153, "Episode Reward": 6442.287538831656, "Mean Reward": 45.05096181001158, "Episode": 3074, "Episode Step": 143}
{"Training time": 9.804045118027263, "Episode Reward": 95950.40713921037, "Mean Reward": 59.6706512059766, "Episode": 3075, "Episode Step": 1608}
{"Training time": 9.805264944963985, "Episode Reward": -242.38727002061952, "Mean Reward": -2.3763457845158777, "Episode": 3076, "Episode Step": 102}
{"Training time": 9.80863515999582, "Episode Reward": 16620.384954965957, "Mean Reward": 57.3116722585033, "Episode": 3077, "Episode Step": 290}
{"Training time": 9.82300142745177, "Episode Reward": 70780.7172346316, "Mean Reward": 59.131760429934495, "Episode": 3078, "Episode Step": 1197}
{"Training time": 9.824229206641515, "Episode Reward": -189.8829608047279, "Mean Reward": -1.8615976549483129, "Episode": 3079, "Episode Step": 102}
{"Training time": 9.825917846626705, "Episode Reward": 6762.381962937052, "Mean Reward": 46.63711698577277, "Episode": 3080, "Episode Step": 145}
{"Training time": 9.827006213002734, "Episode Reward": -430.07365983325514, "Mean Reward": -7.964327033949169, "Episode": 3081, "Episode Step": 54}
{"Training time": 9.827991860244008, "Episode Reward": -305.0346619759209, "Mean Reward": -3.675116409348445, "Episode": 3082, "Episode Step": 83}
{"Training time": 9.830199491911465, "Episode Reward": 9063.292837085091, "Mean Reward": 47.95393035494757, "Episode": 3083, "Episode Step": 189}
{"Training time": 9.831310238573286, "Episode Reward": -418.0058067933418, "Mean Reward": -7.740848273950774, "Episode": 3084, "Episode Step": 54}
{"Training time": 9.832467102739546, "Episode Reward": -382.1436957736722, "Mean Reward": -3.9396257296254866, "Episode": 3085, "Episode Step": 97}
{"Training time": 9.83456962744395, "Episode Reward": 9168.370776538784, "Mean Reward": 51.79870495219652, "Episode": 3086, "Episode Step": 177}
{"Training time": 9.835638349718518, "Episode Reward": -411.4269852301205, "Mean Reward": -7.912057408271549, "Episode": 3087, "Episode Step": 52}
{"Training time": 9.836754950284957, "Episode Reward": -363.34751684810135, "Mean Reward": -3.8653991154053333, "Episode": 3088, "Episode Step": 94}
{"Training time": 9.838932324714131, "Episode Reward": 8968.268866679005, "Mean Reward": 48.4771290090757, "Episode": 3089, "Episode Step": 185}
{"Training time": 9.840104397734006, "Episode Reward": -434.0239182189388, "Mean Reward": -7.233731970315646, "Episode": 3090, "Episode Step": 60}
{"Training time": 9.841227381361856, "Episode Reward": -355.70080148245705, "Mean Reward": -3.7052166821089276, "Episode": 3091, "Episode Step": 96}
{"Training time": 9.8450147130092, "Episode Reward": 18683.410734769604, "Mean Reward": 59.124717515093685, "Episode": 3092, "Episode Step": 316}
{"Training time": 9.846144944164488, "Episode Reward": -423.8879719230274, "Mean Reward": -7.707054034964135, "Episode": 3093, "Episode Step": 55}
{"Training time": 9.847251086367502, "Episode Reward": -327.4989712374428, "Mean Reward": -3.6388774581938086, "Episode": 3094, "Episode Step": 90}
{"Training time": 9.850749927229351, "Episode Reward": 17496.04060555803, "Mean Reward": 59.308612222230614, "Episode": 3095, "Episode Step": 295}
{"Training time": 9.851931156118711, "Episode Reward": -435.16905785903606, "Mean Reward": -7.252817630983935, "Episode": 3096, "Episode Step": 60}
{"Training time": 9.853145203855302, "Episode Reward": -124.1482842387011, "Mean Reward": -1.217140041555893, "Episode": 3097, "Episode Step": 102}
{"Training time": 9.854816442463132, "Episode Reward": 6685.000968093489, "Mean Reward": 47.411354383641765, "Episode": 3098, "Episode Step": 141}
{"Training time": 9.856509455243746, "Episode Reward": -411.5352754778972, "Mean Reward": -7.76481651845089, "Episode": 3099, "Episode Step": 53}
{"Training time": 9.85798070218828, "Episode Reward": -137.53072543532332, "Mean Reward": -1.3483404454443462, "Episode": 3100, "Episode Step": 102}
{"Training time": 9.860114230248664, "Episode Reward": 8686.300159778368, "Mean Reward": 47.99060861756004, "Episode": 3101, "Episode Step": 181}
{"Training time": 9.861169976062245, "Episode Reward": -389.8769889980016, "Mean Reward": -7.956673244857176, "Episode": 3102, "Episode Step": 49}
{"Training time": 9.862383835249476, "Episode Reward": -219.43220709409619, "Mean Reward": -2.151296147981335, "Episode": 3103, "Episode Step": 102}
{"Training time": 9.864460318022305, "Episode Reward": 8971.697607739447, "Mean Reward": 50.68755710587258, "Episode": 3104, "Episode Step": 177}
{"Training time": 9.865523773299323, "Episode Reward": -396.1517169442794, "Mean Reward": -7.767680724397636, "Episode": 3105, "Episode Step": 51}
{"Training time": 9.866708766354455, "Episode Reward": -143.4643150983432, "Mean Reward": -1.4065128931210118, "Episode": 3106, "Episode Step": 102}
{"Training time": 9.868699220551385, "Episode Reward": 8675.667933222652, "Mean Reward": 51.03334078366266, "Episode": 3107, "Episode Step": 170}
{"Training time": 9.86978866385089, "Episode Reward": -401.9597554888237, "Mean Reward": -7.584146329977806, "Episode": 3108, "Episode Step": 53}
{"Training time": 9.870984472764864, "Episode Reward": -251.67728189206437, "Mean Reward": -2.467424332275141, "Episode": 3109, "Episode Step": 102}
{"Training time": 9.873162600530518, "Episode Reward": 8453.715748155577, "Mean Reward": 45.4500846675031, "Episode": 3110, "Episode Step": 186}
{"Training time": 9.876038523051474, "Episode Reward": 8898.034438149698, "Mean Reward": 44.49017219074849, "Episode": 3111, "Episode Step": 200}
{"Training time": 9.877263899445534, "Episode Reward": -249.06556103744924, "Mean Reward": -2.4418192258573455, "Episode": 3112, "Episode Step": 102}
{"Training time": 9.878488048579957, "Episode Reward": 5555.463158323727, "Mean Reward": 54.465325081605165, "Episode": 3113, "Episode Step": 102}
{"Training time": 9.884818989170922, "Episode Reward": 28694.597178673237, "Mean Reward": 57.389194357346476, "Episode": 3114, "Episode Step": 500}
{"Training time": 9.886049852768581, "Episode Reward": -251.7771464764738, "Mean Reward": -2.4684033968281747, "Episode": 3115, "Episode Step": 102}
{"Training time": 9.88762048555745, "Episode Reward": 6258.959408888087, "Mean Reward": 47.41635915824308, "Episode": 3116, "Episode Step": 132}
{"Training time": 9.88868503994412, "Episode Reward": -409.5134194313638, "Mean Reward": -8.190268388627276, "Episode": 3117, "Episode Step": 50}
{"Training time": 9.889881870283022, "Episode Reward": -200.1115235256117, "Mean Reward": -1.961877681623644, "Episode": 3118, "Episode Step": 102}
{"Training time": 9.891910754972034, "Episode Reward": 9264.21220691756, "Mean Reward": 53.86169887742768, "Episode": 3119, "Episode Step": 172}
{"Training time": 9.892982444432047, "Episode Reward": -412.7372257398006, "Mean Reward": -8.25474451479601, "Episode": 3120, "Episode Step": 50}
{"Training time": 9.89417720940378, "Episode Reward": -211.34684792098724, "Mean Reward": -2.0720279207939925, "Episode": 3121, "Episode Step": 102}
{"Training time": 9.896271912720469, "Episode Reward": 9075.369514266507, "Mean Reward": 50.70038834785758, "Episode": 3122, "Episode Step": 179}
{"Training time": 9.897317970262634, "Episode Reward": -403.6761515926977, "Mean Reward": -8.23828880801424, "Episode": 3123, "Episode Step": 49}
{"Training time": 9.898517141342163, "Episode Reward": -258.98268904408167, "Mean Reward": -2.5390459710204083, "Episode": 3124, "Episode Step": 102}
{"Training time": 9.900643668837018, "Episode Reward": 9076.81187612261, "Mean Reward": 49.87259272594841, "Episode": 3125, "Episode Step": 182}
{"Training time": 9.901699539422989, "Episode Reward": -423.2085464159451, "Mean Reward": -8.29820679246951, "Episode": 3126, "Episode Step": 51}
{"Training time": 9.902927937507629, "Episode Reward": -253.91690604411215, "Mean Reward": -2.489381431805021, "Episode": 3127, "Episode Step": 102}
{"Training time": 9.904159898294344, "Episode Reward": 5952.414868511824, "Mean Reward": 56.15485725011155, "Episode": 3128, "Episode Step": 106}
{"Training time": 9.905240185525683, "Episode Reward": -396.9712355694033, "Mean Reward": -7.783749717047123, "Episode": 3129, "Episode Step": 51}
{"Training time": 9.906305688884522, "Episode Reward": -338.374932252498, "Mean Reward": -3.801965530926944, "Episode": 3130, "Episode Step": 89}
{"Training time": 9.907582215004497, "Episode Reward": 6330.385083179976, "Mean Reward": 59.162477412896976, "Episode": 3131, "Episode Step": 107}
{"Training time": 9.908678772184583, "Episode Reward": -417.6725562891379, "Mean Reward": -7.880614269606376, "Episode": 3132, "Episode Step": 53}
{"Training time": 9.909571669167942, "Episode Reward": -299.6183564011554, "Mean Reward": -3.9423467947520443, "Episode": 3133, "Episode Step": 76}
{"Training time": 9.910826111634572, "Episode Reward": 6014.169219060879, "Mean Reward": 57.27780208629409, "Episode": 3134, "Episode Step": 105}
{"Training time": 9.91190107471413, "Episode Reward": -420.7116750748836, "Mean Reward": -8.090609136055454, "Episode": 3135, "Episode Step": 52}
{"Training time": 9.91290952278508, "Episode Reward": -366.824494218905, "Mean Reward": -4.315582284928294, "Episode": 3136, "Episode Step": 85}
{"Training time": 9.91494583023919, "Episode Reward": 8690.286770302178, "Mean Reward": 50.5249230831522, "Episode": 3137, "Episode Step": 172}
{"Training time": 9.916075114674038, "Episode Reward": -438.83389217256445, "Mean Reward": -7.9787980395011715, "Episode": 3138, "Episode Step": 55}
{"Training time": 9.91717807524734, "Episode Reward": -417.0491927054154, "Mean Reward": -4.436693539419313, "Episode": 3139, "Episode Step": 94}
{"Training time": 9.919269013868439, "Episode Reward": 8047.016546269402, "Mean Reward": 44.705647479274454, "Episode": 3140, "Episode Step": 180}
{"Training time": 9.920313169956207, "Episode Reward": -390.7143108259519, "Mean Reward": -7.814286216519037, "Episode": 3141, "Episode Step": 50}
{"Training time": 9.921402064694298, "Episode Reward": -439.64932064349557, "Mean Reward": -4.72741204993006, "Episode": 3142, "Episode Step": 93}
{"Training time": 9.922662056353357, "Episode Reward": 5766.09610077177, "Mean Reward": 55.44323173819009, "Episode": 3143, "Episode Step": 104}
{"Training time": 9.923775706092517, "Episode Reward": -426.4408426074789, "Mean Reward": -7.897052640879239, "Episode": 3144, "Episode Step": 54}
{"Training time": 9.92479976216952, "Episode Reward": -380.52215524862174, "Mean Reward": -4.373817876420939, "Episode": 3145, "Episode Step": 87}
{"Training time": 9.926908284160826, "Episode Reward": 9113.623885926876, "Mean Reward": 51.489400485462575, "Episode": 3146, "Episode Step": 177}
{"Training time": 9.928021981914839, "Episode Reward": -416.3828697657544, "Mean Reward": -7.710793884551007, "Episode": 3147, "Episode Step": 54}
{"Training time": 9.928944203323788, "Episode Reward": -326.25372154540906, "Mean Reward": -4.292812125597488, "Episode": 3148, "Episode Step": 76}
{"Training time": 9.931926633053356, "Episode Reward": 6809.21467487863, "Mean Reward": 47.95221602027204, "Episode": 3149, "Episode Step": 142}
{"Training time": 9.933015425801278, "Episode Reward": -400.70306660456833, "Mean Reward": -7.705828203934006, "Episode": 3150, "Episode Step": 52}
{"Training time": 9.934248570534917, "Episode Reward": -605.6850382315189, "Mean Reward": -5.93808861011293, "Episode": 3151, "Episode Step": 102}
{"Training time": 9.936468521091673, "Episode Reward": 9084.26324105164, "Mean Reward": 49.10412562730616, "Episode": 3152, "Episode Step": 185}
{"Training time": 9.937575949430466, "Episode Reward": -404.6331823754057, "Mean Reward": -7.7814073533731865, "Episode": 3153, "Episode Step": 52}
{"Training time": 9.938826512760587, "Episode Reward": -398.79869586131355, "Mean Reward": -3.909791135895231, "Episode": 3154, "Episode Step": 102}
{"Training time": 9.940086919400427, "Episode Reward": 6257.824481361883, "Mean Reward": 59.59832839392269, "Episode": 3155, "Episode Step": 105}
{"Training time": 9.941185045838356, "Episode Reward": -411.8506396297054, "Mean Reward": -7.77076678546614, "Episode": 3156, "Episode Step": 53}
{"Training time": 9.942340244981978, "Episode Reward": -481.476349935585, "Mean Reward": -5.015378645162344, "Episode": 3157, "Episode Step": 96}
{"Training time": 9.944508736928304, "Episode Reward": 9340.077973106778, "Mean Reward": 52.17920655366915, "Episode": 3158, "Episode Step": 179}
{"Training time": 9.953878170516756, "Episode Reward": 44213.20472025729, "Mean Reward": 58.872443036294655, "Episode": 3159, "Episode Step": 751}
{"Training time": 9.954981728858417, "Episode Reward": -456.5542365647484, "Mean Reward": -4.96254604961683, "Episode": 3160, "Episode Step": 92}
{"Training time": 9.957222293019294, "Episode Reward": 9291.19676869253, "Mean Reward": 49.421259407939, "Episode": 3161, "Episode Step": 188}
{"Training time": 9.963469917443064, "Episode Reward": 28118.403112469492, "Mean Reward": 57.384496147896925, "Episode": 3162, "Episode Step": 490}
{"Training time": 9.964437607460551, "Episode Reward": -361.5707561157484, "Mean Reward": -4.4093994648262, "Episode": 3163, "Episode Step": 82}
{"Training time": 9.966541858580378, "Episode Reward": 9250.790318097947, "Mean Reward": 51.680392838536015, "Episode": 3164, "Episode Step": 179}
{"Training time": 9.972857342759768, "Episode Reward": 28130.70862950939, "Mean Reward": 55.925862086499784, "Episode": 3165, "Episode Step": 503}
{"Training time": 9.973927128314973, "Episode Reward": -430.31507873856185, "Mean Reward": -4.835000884702942, "Episode": 3166, "Episode Step": 89}
{"Training time": 9.977012250820795, "Episode Reward": 15217.455651782444, "Mean Reward": 58.081891800696354, "Episode": 3167, "Episode Step": 262}
{"Training time": 9.979731494386991, "Episode Reward": 8995.26952695736, "Mean Reward": 46.12958731773005, "Episode": 3168, "Episode Step": 195}
{"Training time": 9.980592885812124, "Episode Reward": -316.93508439782426, "Mean Reward": -4.4018761721920034, "Episode": 3169, "Episode Step": 72}
{"Training time": 9.982665604684088, "Episode Reward": 9037.769071843763, "Mean Reward": 51.35096063547592, "Episode": 3170, "Episode Step": 176}
{"Training time": 9.98762981944614, "Episode Reward": 20319.110453651403, "Mean Reward": 52.36884137539021, "Episode": 3171, "Episode Step": 388}
{"Training time": 9.988435023294555, "Episode Reward": -276.06247784947345, "Mean Reward": -4.182764815901113, "Episode": 3172, "Episode Step": 66}
{"Training time": 9.98967722442415, "Episode Reward": 6095.434902742616, "Mean Reward": 58.05176097850111, "Episode": 3173, "Episode Step": 105}
{"Training time": 9.997287730243471, "Episode Reward": 34042.64867867852, "Mean Reward": 55.44405322260345, "Episode": 3174, "Episode Step": 614}
{"Training time": 9.998144084148937, "Episode Reward": -321.77767590383246, "Mean Reward": -4.532079942307499, "Episode": 3175, "Episode Step": 71}
{"Training time": 10.000191102491485, "Episode Reward": 8926.33930670883, "Mean Reward": 50.43129551812898, "Episode": 3176, "Episode Step": 177}
{"Training time": 10.002841800782416, "Episode Reward": 9657.043639188047, "Mean Reward": 51.91958945800025, "Episode": 3177, "Episode Step": 186}
{"Training time": 10.003689804143375, "Episode Reward": -330.46842430582547, "Mean Reward": -4.526964716518157, "Episode": 3178, "Episode Step": 73}
{"Training time": 10.004891906645563, "Episode Reward": 5850.665210857537, "Mean Reward": 56.802574862694534, "Episode": 3179, "Episode Step": 103}
{"Training time": 10.016676463021172, "Episode Reward": 55930.62586434645, "Mean Reward": 57.959197786887515, "Episode": 3180, "Episode Step": 965}
{"Training time": 10.017630947166019, "Episode Reward": -398.01870199940976, "Mean Reward": -5.038211417714048, "Episode": 3181, "Episode Step": 79}
{"Training time": 10.025347452494833, "Episode Reward": 38232.87806324728, "Mean Reward": 58.104677907670634, "Episode": 3182, "Episode Step": 658}
{"Training time": 10.02810208717982, "Episode Reward": 9681.925992350094, "Mean Reward": 49.90683501211389, "Episode": 3183, "Episode Step": 194}
{"Training time": 10.029071408576435, "Episode Reward": -438.7629645986484, "Mean Reward": -5.416826723440104, "Episode": 3184, "Episode Step": 81}
{"Training time": 10.038923457728492, "Episode Reward": 53044.2407033347, "Mean Reward": 63.3742421784166, "Episode": 3185, "Episode Step": 837}
{"Training time": 10.050616404679086, "Episode Reward": 55380.94803890113, "Mean Reward": 57.449116222926484, "Episode": 3186, "Episode Step": 964}
{"Training time": 10.051634846925735, "Episode Reward": -467.7456990173031, "Mean Reward": -5.635490349606061, "Episode": 3187, "Episode Step": 83}
{"Training time": 10.065963727169567, "Episode Reward": 78936.37654479283, "Mean Reward": 64.91478334275726, "Episode": 3188, "Episode Step": 1216}
{"Training time": 10.068889763024119, "Episode Reward": 8893.603312604499, "Mean Reward": 42.35049196478332, "Episode": 3189, "Episode Step": 210}
{"Training time": 10.069845851063729, "Episode Reward": -407.9644677497815, "Mean Reward": -5.164107186706095, "Episode": 3190, "Episode Step": 79}
{"Training time": 10.071959033608437, "Episode Reward": 9455.34113792234, "Mean Reward": 53.42000642893977, "Episode": 3191, "Episode Step": 177}
{"Training time": 10.080278898278872, "Episode Reward": 37065.11253351647, "Mean Reward": 55.156417460589985, "Episode": 3192, "Episode Step": 672}
{"Training time": 10.081207864946789, "Episode Reward": -387.3354867423213, "Mean Reward": -4.965839573619504, "Episode": 3193, "Episode Step": 78}
{"Training time": 10.082808556887839, "Episode Reward": 6670.637398558366, "Mean Reward": 48.33795216346642, "Episode": 3194, "Episode Step": 138}
{"Training time": 10.123896069725355, "Episode Reward": 210740.1813525788, "Mean Reward": 60.48799694390895, "Episode": 3195, "Episode Step": 3484}
{"Training time": 10.124940242502424, "Episode Reward": -531.5810362791974, "Mean Reward": -6.110126853783878, "Episode": 3196, "Episode Step": 87}
{"Training time": 10.12886504497793, "Episode Reward": 19004.76318549309, "Mean Reward": 56.56179519491992, "Episode": 3197, "Episode Step": 336}
{"Training time": 10.131564488609632, "Episode Reward": 9564.912853547616, "Mean Reward": 49.559133956205265, "Episode": 3198, "Episode Step": 193}
{"Training time": 10.133593748609226, "Episode Reward": -391.17335266016806, "Mean Reward": -5.080173411171014, "Episode": 3199, "Episode Step": 77}
{"Training time": 10.137067289153736, "Episode Reward": 15142.30100595705, "Mean Reward": 55.6702242866068, "Episode": 3200, "Episode Step": 272}
{"Training time": 10.161641963587867, "Episode Reward": 123272.13767715739, "Mean Reward": 59.98644169204739, "Episode": 3201, "Episode Step": 2055}
{"Training time": 10.162606548335818, "Episode Reward": -435.29762480188685, "Mean Reward": -5.374044750640579, "Episode": 3202, "Episode Step": 81}
{"Training time": 10.164185327490172, "Episode Reward": 6950.620638741182, "Mean Reward": 51.870303274187926, "Episode": 3203, "Episode Step": 134}
{"Training time": 10.167275529702504, "Episode Reward": 8791.358763463737, "Mean Reward": 39.24713733689168, "Episode": 3204, "Episode Step": 224}
{"Training time": 10.16812654554844, "Episode Reward": -337.62012771761715, "Mean Reward": -4.689168440522461, "Episode": 3205, "Episode Step": 72}
{"Training time": 10.169749934408399, "Episode Reward": 7182.946954539441, "Mean Reward": 51.67587737078735, "Episode": 3206, "Episode Step": 139}
{"Training time": 10.177830246090888, "Episode Reward": 32916.92208467178, "Mean Reward": 50.1782348851704, "Episode": 3207, "Episode Step": 656}
{"Training time": 10.178737913038995, "Episode Reward": -337.73181310344773, "Mean Reward": -4.443839646097996, "Episode": 3208, "Episode Step": 76}
{"Training time": 10.187069267763032, "Episode Reward": 45730.01263128845, "Mean Reward": 63.42581502259147, "Episode": 3209, "Episode Step": 721}
{"Training time": 10.195354068610403, "Episode Reward": 31693.377929855553, "Mean Reward": 47.02281591966699, "Episode": 3210, "Episode Step": 674}
{"Training time": 10.196124900513226, "Episode Reward": -293.91845352288635, "Mean Reward": -4.5218223618905595, "Episode": 3211, "Episode Step": 65}
{"Training time": 10.197688514126671, "Episode Reward": 7011.539157371555, "Mean Reward": 52.718339529109436, "Episode": 3212, "Episode Step": 133}
{"Training time": 10.200935169127252, "Episode Reward": 9084.42401788935, "Mean Reward": 38.16984881466114, "Episode": 3213, "Episode Step": 238}
{"Training time": 10.202009032169977, "Episode Reward": -435.72761275987193, "Mean Reward": -4.788215524833758, "Episode": 3214, "Episode Step": 91}
{"Training time": 10.205570956336127, "Episode Reward": 19348.579062976063, "Mean Reward": 64.28099356470453, "Episode": 3215, "Episode Step": 301}
{"Training time": 10.220071311924192, "Episode Reward": 65986.72430049715, "Mean Reward": 55.40447044542162, "Episode": 3216, "Episode Step": 1191}
{"Training time": 10.221304226915041, "Episode Reward": -495.8734243051004, "Mean Reward": -4.861504159853926, "Episode": 3217, "Episode Step": 102}
{"Training time": 10.224790523582035, "Episode Reward": 19047.874948336394, "Mean Reward": 65.00981211036311, "Episode": 3218, "Episode Step": 293}
{"Training time": 10.22646093805631, "Episode Reward": 44.940661859106704, "Mean Reward": 0.4405947241088893, "Episode": 3219, "Episode Step": 102}
{"Training time": 10.227486125561926, "Episode Reward": -369.3300033264733, "Mean Reward": -4.245172452028428, "Episode": 3220, "Episode Step": 87}
{"Training time": 10.235329871641264, "Episode Reward": 44861.32047070372, "Mean Reward": 66.26487514136443, "Episode": 3221, "Episode Step": 677}
{"Training time": 10.236978506909477, "Episode Reward": 23.406225534702955, "Mean Reward": 0.2294727993598329, "Episode": 3222, "Episode Step": 102}
{"Training time": 10.238183298839463, "Episode Reward": -287.3595120386172, "Mean Reward": -2.8172501180256586, "Episode": 3223, "Episode Step": 102}
{"Training time": 10.259314024448395, "Episode Reward": 123055.05022986387, "Mean Reward": 67.79892574648147, "Episode": 3224, "Episode Step": 1815}
{"Training time": 10.263428351349301, "Episode Reward": 15123.479276043703, "Mean Reward": 47.55811093095504, "Episode": 3225, "Episode Step": 318}
{"Training time": 10.264610410796271, "Episode Reward": -398.72178789882867, "Mean Reward": -3.9090371362630263, "Episode": 3226, "Episode Step": 102}
{"Training time": 10.266610547171698, "Episode Reward": 8915.908904860056, "Mean Reward": 53.070886338452716, "Episode": 3227, "Episode Step": 168}
{"Training time": 10.269831516610251, "Episode Reward": 9092.789794240105, "Mean Reward": 38.36620166346036, "Episode": 3228, "Episode Step": 237}
{"Training time": 10.271018101639218, "Episode Reward": -298.8441326615128, "Mean Reward": -2.9298444378579687, "Episode": 3229, "Episode Step": 102}
{"Training time": 10.274422281649377, "Episode Reward": 19455.119147172813, "Mean Reward": 66.39972405178435, "Episode": 3230, "Episode Step": 293}
{"Training time": 10.276107046670385, "Episode Reward": -533.2002488646245, "Mean Reward": -5.227453420241417, "Episode": 3231, "Episode Step": 102}
{"Training time": 10.277303895817862, "Episode Reward": -257.4258520063172, "Mean Reward": -2.5237828628070313, "Episode": 3232, "Episode Step": 102}
{"Training time": 10.285847370227177, "Episode Reward": 47157.773554857944, "Mean Reward": 63.899422161054126, "Episode": 3233, "Episode Step": 738}
{"Training time": 10.292815363340907, "Episode Reward": 31997.529129593055, "Mean Reward": 56.8339771395969, "Episode": 3234, "Episode Step": 563}
{"Training time": 10.294006683892674, "Episode Reward": -207.66803436331503, "Mean Reward": -2.0359611212089708, "Episode": 3235, "Episode Step": 102}
{"Training time": 10.30188842554887, "Episode Reward": 43429.83371645967, "Mean Reward": 64.24531614860898, "Episode": 3236, "Episode Step": 676}
{"Training time": 10.305076130231221, "Episode Reward": 8990.77255640274, "Mean Reward": 38.58700667984009, "Episode": 3237, "Episode Step": 233}
{"Training time": 10.306291685832871, "Episode Reward": -295.4753475882329, "Mean Reward": -2.89681713321797, "Episode": 3238, "Episode Step": 102}
{"Training time": 10.314898511634933, "Episode Reward": 48585.2538956124, "Mean Reward": 66.64643881428313, "Episode": 3239, "Episode Step": 729}
{"Training time": 10.316554713845253, "Episode Reward": -906.7555892864949, "Mean Reward": -8.889760679279362, "Episode": 3240, "Episode Step": 102}
{"Training time": 10.31775411605835, "Episode Reward": -448.28129637290215, "Mean Reward": -4.39491467032257, "Episode": 3241, "Episode Step": 102}
{"Training time": 10.321253195007642, "Episode Reward": 18805.722583047977, "Mean Reward": 62.89539325434106, "Episode": 3242, "Episode Step": 299}
{"Training time": 10.322902487450175, "Episode Reward": -763.1097705851588, "Mean Reward": -7.481468339070184, "Episode": 3243, "Episode Step": 102}
{"Training time": 10.324124349157016, "Episode Reward": -414.10568564269875, "Mean Reward": -4.059859663163714, "Episode": 3244, "Episode Step": 102}
{"Training time": 10.331407503022088, "Episode Reward": 39959.0289518257, "Mean Reward": 63.2263116326356, "Episode": 3245, "Episode Step": 632}
{"Training time": 10.333049940268198, "Episode Reward": -909.9549656707574, "Mean Reward": -8.921127114419189, "Episode": 3246, "Episode Step": 102}
{"Training time": 10.334256645242373, "Episode Reward": -410.20738733436315, "Mean Reward": -4.021641052297678, "Episode": 3247, "Episode Step": 102}
{"Training time": 10.341405418051613, "Episode Reward": 37627.833981438496, "Mean Reward": 60.78810013156461, "Episode": 3248, "Episode Step": 619}
{"Training time": 10.34416940940751, "Episode Reward": -665.3490413636728, "Mean Reward": -6.52302981729091, "Episode": 3249, "Episode Step": 102}
{"Training time": 10.345650814970334, "Episode Reward": -415.04471934059046, "Mean Reward": -4.069065875888142, "Episode": 3250, "Episode Step": 102}
{"Training time": 10.353490694959959, "Episode Reward": 45042.5145011819, "Mean Reward": 65.75549562216335, "Episode": 3251, "Episode Step": 685}
{"Training time": 10.355124505824513, "Episode Reward": -642.638233950934, "Mean Reward": -6.300374842656216, "Episode": 3252, "Episode Step": 102}
{"Training time": 10.356326629718145, "Episode Reward": -318.0851755478613, "Mean Reward": -3.1184821132143266, "Episode": 3253, "Episode Step": 102}
{"Training time": 10.372267587184906, "Episode Reward": 85738.82988120207, "Mean Reward": 62.12958687043628, "Episode": 3254, "Episode Step": 1380}
{"Training time": 10.373920906649696, "Episode Reward": -777.1019444768845, "Mean Reward": -7.618646514479259, "Episode": 3255, "Episode Step": 102}
{"Training time": 10.375110064678722, "Episode Reward": -300.963505056959, "Mean Reward": -2.950622598597637, "Episode": 3256, "Episode Step": 102}
{"Training time": 10.378662059969372, "Episode Reward": 16763.44495666868, "Mean Reward": 55.142911041673294, "Episode": 3257, "Episode Step": 304}
{"Training time": 10.380322483844227, "Episode Reward": -698.087993638257, "Mean Reward": -6.84399993762997, "Episode": 3258, "Episode Step": 102}
{"Training time": 10.381532021098666, "Episode Reward": -334.53652681031343, "Mean Reward": -3.279769870689347, "Episode": 3259, "Episode Step": 102}
{"Training time": 10.383733729124069, "Episode Reward": 9162.848591550171, "Mean Reward": 48.9991903291453, "Episode": 3260, "Episode Step": 187}
{"Training time": 10.385384014116394, "Episode Reward": -794.6323093795028, "Mean Reward": -7.7905128370539485, "Episode": 3261, "Episode Step": 102}
{"Training time": 10.386569531096352, "Episode Reward": -289.1834714288992, "Mean Reward": -2.8351320728323453, "Episode": 3262, "Episode Step": 102}
{"Training time": 10.388883435527484, "Episode Reward": 9028.543253165946, "Mean Reward": 45.83016879779668, "Episode": 3263, "Episode Step": 197}
{"Training time": 10.390532890227107, "Episode Reward": -834.5515619747395, "Mean Reward": -8.181878058575878, "Episode": 3264, "Episode Step": 102}
{"Training time": 10.39175448000431, "Episode Reward": -301.3497057007989, "Mean Reward": -2.954408879419597, "Episode": 3265, "Episode Step": 102}
{"Training time": 10.39912254664633, "Episode Reward": 38238.51721245056, "Mean Reward": 61.0838933106239, "Episode": 3266, "Episode Step": 626}
{"Training time": 10.400805309944683, "Episode Reward": -863.6322108817769, "Mean Reward": -8.466982459625264, "Episode": 3267, "Episode Step": 102}
{"Training time": 10.402069124976794, "Episode Reward": -394.48576743324105, "Mean Reward": -3.8675075238553043, "Episode": 3268, "Episode Step": 102}
{"Training time": 10.40970709833834, "Episode Reward": 38624.92871397209, "Mean Reward": 59.883610409259056, "Episode": 3269, "Episode Step": 645}
{"Training time": 10.41135789970557, "Episode Reward": -964.0233385960166, "Mean Reward": -9.451209201921731, "Episode": 3270, "Episode Step": 102}
{"Training time": 10.412581160797012, "Episode Reward": -448.42764225708487, "Mean Reward": -4.396349433892989, "Episode": 3271, "Episode Step": 102}
{"Training time": 10.418596775796678, "Episode Reward": 33300.559904355585, "Mean Reward": 64.53596880689066, "Episode": 3272, "Episode Step": 516}
{"Training time": 10.42026135219468, "Episode Reward": -667.4286747878075, "Mean Reward": -6.543418380272622, "Episode": 3273, "Episode Step": 102}
{"Training time": 10.421455735233096, "Episode Reward": -225.6423138708322, "Mean Reward": -2.212179547753257, "Episode": 3274, "Episode Step": 102}
{"Training time": 10.433612863553895, "Episode Reward": 66988.88277451109, "Mean Reward": 64.0429089622477, "Episode": 3275, "Episode Step": 1046}
{"Training time": 10.435265748567051, "Episode Reward": -695.8790808577021, "Mean Reward": -6.822343929977471, "Episode": 3276, "Episode Step": 102}
{"Training time": 10.436482465797, "Episode Reward": -213.0547195456433, "Mean Reward": -2.088771760251405, "Episode": 3277, "Episode Step": 102}
{"Training time": 10.437937489946684, "Episode Reward": 5952.298593164934, "Mean Reward": 48.00240800939463, "Episode": 3278, "Episode Step": 124}
{"Training time": 10.439609134991963, "Episode Reward": -673.4229036023305, "Mean Reward": -6.6021853294346124, "Episode": 3279, "Episode Step": 102}
{"Training time": 10.440807873010636, "Episode Reward": -282.7226763612228, "Mean Reward": -2.7717909447178704, "Episode": 3280, "Episode Step": 102}
{"Training time": 10.442273774411943, "Episode Reward": 5750.081639061105, "Mean Reward": 46.37162612146053, "Episode": 3281, "Episode Step": 124}
{"Training time": 10.4439401941167, "Episode Reward": -739.2028966763344, "Mean Reward": -7.2470872223170035, "Episode": 3282, "Episode Step": 102}
{"Training time": 10.445156298014853, "Episode Reward": -211.6997964781771, "Mean Reward": -2.075488200766442, "Episode": 3283, "Episode Step": 102}
{"Training time": 10.44639777580897, "Episode Reward": 5265.605004016753, "Mean Reward": 49.67551890581842, "Episode": 3284, "Episode Step": 106}
{"Training time": 10.44806672083007, "Episode Reward": -638.2464856450945, "Mean Reward": -6.2573184867166125, "Episode": 3285, "Episode Step": 102}
{"Training time": 10.449293758604261, "Episode Reward": -220.96705014377036, "Mean Reward": -2.166343628860494, "Episode": 3286, "Episode Step": 102}
{"Training time": 10.459738071627086, "Episode Reward": 55000.92791317718, "Mean Reward": 61.18012003690453, "Episode": 3287, "Episode Step": 899}
{"Training time": 10.461402828296025, "Episode Reward": -445.3458916404328, "Mean Reward": -4.366136192553263, "Episode": 3288, "Episode Step": 102}
{"Training time": 10.46261975162559, "Episode Reward": -204.4224158770426, "Mean Reward": -2.0041413321278685, "Episode": 3289, "Episode Step": 102}
{"Training time": 10.464751139415634, "Episode Reward": 8563.843625815012, "Mean Reward": 46.79695970390717, "Episode": 3290, "Episode Step": 183}
{"Training time": 10.466430430544747, "Episode Reward": -405.071537049672, "Mean Reward": -3.971289578918353, "Episode": 3291, "Episode Step": 102}
{"Training time": 10.467673118313154, "Episode Reward": -173.70251091364688, "Mean Reward": -1.7029657932710478, "Episode": 3292, "Episode Step": 102}
{"Training time": 10.47361119164361, "Episode Reward": 33356.93971524535, "Mean Reward": 66.5807179945017, "Episode": 3293, "Episode Step": 501}
{"Training time": 10.47532181415293, "Episode Reward": -739.6894173249887, "Mean Reward": -7.251857032597928, "Episode": 3294, "Episode Step": 102}
{"Training time": 10.476596256626976, "Episode Reward": -297.60448759778814, "Mean Reward": -2.917691054880276, "Episode": 3295, "Episode Step": 102}
{"Training time": 10.482534251345529, "Episode Reward": 30726.138397992392, "Mean Reward": 61.82321609254002, "Episode": 3296, "Episode Step": 497}
{"Training time": 10.484008815222316, "Episode Reward": -563.1179979908416, "Mean Reward": -6.7037856903671615, "Episode": 3297, "Episode Step": 84}
{"Training time": 10.485260599719153, "Episode Reward": -173.20932985818908, "Mean Reward": -1.6981306848842066, "Episode": 3298, "Episode Step": 102}
{"Training time": 10.488541083600786, "Episode Reward": 8513.993939971959, "Mean Reward": 47.564211955150604, "Episode": 3299, "Episode Step": 179}
{"Training time": 10.49011057721244, "Episode Reward": -645.7583953527928, "Mean Reward": -6.869770163327583, "Episode": 3300, "Episode Step": 94}
{"Training time": 10.491330449713601, "Episode Reward": -227.02236391134838, "Mean Reward": -2.2257094501112586, "Episode": 3301, "Episode Step": 102}
{"Training time": 10.50243899497721, "Episode Reward": 64451.545960377865, "Mean Reward": 68.63849410050891, "Episode": 3302, "Episode Step": 939}
{"Training time": 10.504060373836094, "Episode Reward": -598.3527012908014, "Mean Reward": -6.168584549389705, "Episode": 3303, "Episode Step": 97}
{"Training time": 10.505288353562355, "Episode Reward": -237.89224056476388, "Mean Reward": -2.332276868281999, "Episode": 3304, "Episode Step": 102}
{"Training time": 10.528570348024369, "Episode Reward": 128230.09275746757, "Mean Reward": 64.79539805834642, "Episode": 3305, "Episode Step": 1979}
{"Training time": 10.53007839606868, "Episode Reward": -565.1657408930866, "Mean Reward": -6.350176863967266, "Episode": 3306, "Episode Step": 89}
{"Training time": 10.531312144729826, "Episode Reward": -278.12415947471186, "Mean Reward": -2.7267074458305083, "Episode": 3307, "Episode Step": 102}
{"Training time": 10.533481840226385, "Episode Reward": 8467.416855109248, "Mean Reward": 47.838513305701966, "Episode": 3308, "Episode Step": 177}
{"Training time": 10.535102110505104, "Episode Reward": -538.7044811804695, "Mean Reward": -5.611505012296558, "Episode": 3309, "Episode Step": 96}
{"Training time": 10.536342476937506, "Episode Reward": -280.89331667315827, "Mean Reward": -2.753856045815277, "Episode": 3310, "Episode Step": 102}
{"Training time": 10.542563886377547, "Episode Reward": 31047.68121016039, "Mean Reward": 60.05354199257329, "Episode": 3311, "Episode Step": 517}
{"Training time": 10.544273957477676, "Episode Reward": -484.03157218860736, "Mean Reward": -4.745407570476543, "Episode": 3312, "Episode Step": 102}
{"Training time": 10.54553846306271, "Episode Reward": -242.18160679835617, "Mean Reward": -2.3743294784152567, "Episode": 3313, "Episode Step": 102}
{"Training time": 10.551575801902347, "Episode Reward": 32947.90885511662, "Mean Reward": 66.02787345714754, "Episode": 3314, "Episode Step": 499}
{"Training time": 10.55326879468229, "Episode Reward": -608.9775216180491, "Mean Reward": -5.970367859000481, "Episode": 3315, "Episode Step": 102}
{"Training time": 10.554531828893555, "Episode Reward": -262.31449985940037, "Mean Reward": -2.571710782935298, "Episode": 3316, "Episode Step": 102}
{"Training time": 10.560474788281653, "Episode Reward": 30826.252909029918, "Mean Reward": 62.401321678198215, "Episode": 3317, "Episode Step": 494}
{"Training time": 10.562199828028678, "Episode Reward": -527.427386885871, "Mean Reward": -5.170856734175206, "Episode": 3318, "Episode Step": 102}
{"Training time": 10.563473086092207, "Episode Reward": -224.5130178259697, "Mean Reward": -2.2011080179016638, "Episode": 3319, "Episode Step": 102}
{"Training time": 10.569264905518956, "Episode Reward": 32091.08946602476, "Mean Reward": 66.85643638755158, "Episode": 3320, "Episode Step": 480}
{"Training time": 10.570798553029697, "Episode Reward": -576.5453126973489, "Mean Reward": -6.704015263922662, "Episode": 3321, "Episode Step": 86}
{"Training time": 10.572079458038012, "Episode Reward": -237.3142902838533, "Mean Reward": -2.3266106890573854, "Episode": 3322, "Episode Step": 102}
{"Training time": 10.574215544992024, "Episode Reward": 9303.294788625408, "Mean Reward": 53.77627045448212, "Episode": 3323, "Episode Step": 173}
{"Training time": 10.575782871643701, "Episode Reward": -644.0020625068398, "Mean Reward": -7.235978230413931, "Episode": 3324, "Episode Step": 89}
{"Training time": 10.577034256656965, "Episode Reward": -274.1740756226047, "Mean Reward": -2.6879811335549477, "Episode": 3325, "Episode Step": 102}
{"Training time": 10.58059610856904, "Episode Reward": 19550.54404570375, "Mean Reward": 66.27303066340255, "Episode": 3326, "Episode Step": 295}
{"Training time": 10.582051910824246, "Episode Reward": -511.2361699602836, "Mean Reward": -6.234587438540044, "Episode": 3327, "Episode Step": 82}
{"Training time": 10.583309111396472, "Episode Reward": -200.58741076297832, "Mean Reward": -1.9665432427742973, "Episode": 3328, "Episode Step": 102}
{"Training time": 10.584967401358817, "Episode Reward": 6765.9177804861465, "Mean Reward": 49.38626117143173, "Episode": 3329, "Episode Step": 137}
{"Training time": 10.586666821638744, "Episode Reward": -586.8688661970439, "Mean Reward": -5.753616335265136, "Episode": 3330, "Episode Step": 102}
{"Training time": 10.58794309384293, "Episode Reward": -260.1130349588027, "Mean Reward": -2.550127793713752, "Episode": 3331, "Episode Step": 102}
{"Training time": 10.589664467175801, "Episode Reward": 6660.1526230936315, "Mean Reward": 46.57449386778763, "Episode": 3332, "Episode Step": 143}
{"Training time": 10.59134433693356, "Episode Reward": -760.5195398136262, "Mean Reward": -7.760403467485982, "Episode": 3333, "Episode Step": 98}
{"Training time": 10.592641875280274, "Episode Reward": -207.54864911808988, "Mean Reward": -2.034790677628332, "Episode": 3334, "Episode Step": 102}
{"Training time": 10.599231013324525, "Episode Reward": 35597.141262982455, "Mean Reward": 65.79878237150177, "Episode": 3335, "Episode Step": 541}
{"Training time": 10.600873826940854, "Episode Reward": -658.4453800945712, "Mean Reward": -6.931004000995486, "Episode": 3336, "Episode Step": 95}
{"Training time": 10.602145480778482, "Episode Reward": -219.0848670922537, "Mean Reward": -2.1478908538456243, "Episode": 3337, "Episode Step": 102}
{"Training time": 10.603808953563373, "Episode Reward": 7066.478746557079, "Mean Reward": 52.344287011533915, "Episode": 3338, "Episode Step": 135}
{"Training time": 10.60537253525522, "Episode Reward": -634.3258631010588, "Mean Reward": -6.894846338054987, "Episode": 3339, "Episode Step": 92}
{"Training time": 10.60662889831596, "Episode Reward": -182.93694723937236, "Mean Reward": -1.7934994827389448, "Episode": 3340, "Episode Step": 102}
{"Training time": 10.608241540524695, "Episode Reward": 6736.936759727042, "Mean Reward": 50.653659847571745, "Episode": 3341, "Episode Step": 133}
{"Training time": 10.609968835512797, "Episode Reward": -777.0322992027243, "Mean Reward": -7.617963717673767, "Episode": 3342, "Episode Step": 102}
{"Training time": 10.611237611108356, "Episode Reward": -157.03783066959767, "Mean Reward": -1.539586575192134, "Episode": 3343, "Episode Step": 102}
{"Training time": 10.612862504720688, "Episode Reward": 6508.088208436071, "Mean Reward": 49.30369854875811, "Episode": 3344, "Episode Step": 132}
{"Training time": 10.614407584998343, "Episode Reward": -593.1562983282245, "Mean Reward": -6.817888486531316, "Episode": 3345, "Episode Step": 87}
{"Training time": 10.615684618618753, "Episode Reward": -206.55249988253544, "Mean Reward": -2.0250245086523084, "Episode": 3346, "Episode Step": 102}
{"Training time": 10.627059187756645, "Episode Reward": 65016.01423762109, "Mean Reward": 68.72728777761215, "Episode": 3347, "Episode Step": 946}
{"Training time": 10.62874233411418, "Episode Reward": -696.3906232511822, "Mean Reward": -6.827359051482179, "Episode": 3348, "Episode Step": 102}
{"Training time": 10.631121238006486, "Episode Reward": -205.02497630851073, "Mean Reward": -2.0100487873383406, "Episode": 3349, "Episode Step": 102}
{"Training time": 10.633064773612553, "Episode Reward": 6804.723797875964, "Mean Reward": 49.66951677281725, "Episode": 3350, "Episode Step": 137}
{"Training time": 10.634640297227435, "Episode Reward": -683.0049043334027, "Mean Reward": -7.266009620568114, "Episode": 3351, "Episode Step": 94}
{"Training time": 10.63585829105642, "Episode Reward": -166.57214136216413, "Mean Reward": -1.6330602094329816, "Episode": 3352, "Episode Step": 102}
{"Training time": 10.637549524969526, "Episode Reward": 6196.917968707453, "Mean Reward": 44.58214365976585, "Episode": 3353, "Episode Step": 139}
{"Training time": 10.639207704398368, "Episode Reward": -731.4600505913181, "Mean Reward": -7.4638780672583485, "Episode": 3354, "Episode Step": 98}
{"Training time": 10.640427174170812, "Episode Reward": -172.04746162458264, "Mean Reward": -1.6867398198488495, "Episode": 3355, "Episode Step": 102}
{"Training time": 10.644015140798357, "Episode Reward": 17923.40020322971, "Mean Reward": 59.546180077175116, "Episode": 3356, "Episode Step": 301}
{"Training time": 10.645573014948104, "Episode Reward": -646.9845784990058, "Mean Reward": -7.188717538877842, "Episode": 3357, "Episode Step": 90}
{"Training time": 10.646816791627142, "Episode Reward": -213.8959866219986, "Mean Reward": -2.0970194766862607, "Episode": 3358, "Episode Step": 102}
{"Training time": 10.648526599142286, "Episode Reward": 6487.122279995664, "Mean Reward": 46.00795943259336, "Episode": 3359, "Episode Step": 141}
{"Training time": 10.65012621389495, "Episode Reward": -661.1999708577998, "Mean Reward": -6.959999693239999, "Episode": 3360, "Episode Step": 95}
{"Training time": 10.65136654774348, "Episode Reward": -195.75687059702304, "Mean Reward": -1.919185005853167, "Episode": 3361, "Episode Step": 102}
{"Training time": 10.673087168600825, "Episode Reward": 118647.16351271371, "Mean Reward": 64.13360189876417, "Episode": 3362, "Episode Step": 1850}
{"Training time": 10.674664334124989, "Episode Reward": -635.0066664423041, "Mean Reward": -6.684280699392675, "Episode": 3363, "Episode Step": 95}
{"Training time": 10.675879609121216, "Episode Reward": -197.47723369115405, "Mean Reward": -1.9360513106975887, "Episode": 3364, "Episode Step": 102}
{"Training time": 10.677519308858448, "Episode Reward": 6707.727506405538, "Mean Reward": 49.6868704178188, "Episode": 3365, "Episode Step": 135}
{"Training time": 10.678469662997458, "Episode Reward": -181.81782357584797, "Mean Reward": -4.661995476303794, "Episode": 3366, "Episode Step": 39}
{"Training time": 10.679718636671701, "Episode Reward": -192.60587226067076, "Mean Reward": -1.8882928653006938, "Episode": 3367, "Episode Step": 102}
{"Training time": 10.685532343056467, "Episode Reward": 31816.782564670226, "Mean Reward": 65.60161353540252, "Episode": 3368, "Episode Step": 485}
{"Training time": 10.68650844388538, "Episode Reward": -182.33299265973025, "Mean Reward": -4.2403021548774475, "Episode": 3369, "Episode Step": 43}
{"Training time": 10.687742436395752, "Episode Reward": -426.66585867022854, "Mean Reward": -4.1829986144140054, "Episode": 3370, "Episode Step": 102}
{"Training time": 10.69443686246872, "Episode Reward": 35778.092319666386, "Mean Reward": 62.22276925159372, "Episode": 3371, "Episode Step": 575}
{"Training time": 10.695427609946993, "Episode Reward": -182.43407383378658, "Mean Reward": -4.146228950767877, "Episode": 3372, "Episode Step": 44}
{"Training time": 10.696673024959034, "Episode Reward": -402.26835217733384, "Mean Reward": -3.9438073742875868, "Episode": 3373, "Episode Step": 102}
{"Training time": 10.698307146893606, "Episode Reward": 6135.5096939693285, "Mean Reward": 44.460215173690784, "Episode": 3374, "Episode Step": 138}
{"Training time": 10.699240509404076, "Episode Reward": -183.11000552025416, "Mean Reward": -4.8186843557961625, "Episode": 3375, "Episode Step": 38}
{"Training time": 10.700466778609488, "Episode Reward": -350.6435915410698, "Mean Reward": -3.437682270010488, "Episode": 3376, "Episode Step": 102}
{"Training time": 10.713758176631398, "Episode Reward": 76440.54728758364, "Mean Reward": 66.93568063711352, "Episode": 3377, "Episode Step": 1142}
{"Training time": 10.714754739668635, "Episode Reward": -183.06792884551288, "Mean Reward": -4.068176196566953, "Episode": 3378, "Episode Step": 45}
{"Training time": 10.71596356663439, "Episode Reward": -291.63269913356044, "Mean Reward": -2.8591441091525533, "Episode": 3379, "Episode Step": 102}
{"Training time": 10.728594966663255, "Episode Reward": 65631.51381363897, "Mean Reward": 61.223427064961726, "Episode": 3380, "Episode Step": 1072}
{"Training time": 10.729600924121009, "Episode Reward": -182.34158373108508, "Mean Reward": -4.052035194024113, "Episode": 3381, "Episode Step": 45}
{"Training time": 10.730817095836004, "Episode Reward": -279.3107671850615, "Mean Reward": -2.7383408547555046, "Episode": 3382, "Episode Step": 102}
{"Training time": 10.74172437078423, "Episode Reward": 62618.96962926635, "Mean Reward": 67.62307735341939, "Episode": 3383, "Episode Step": 926}
{"Training time": 10.7433163516389, "Episode Reward": -610.4723628450838, "Mean Reward": -6.426024872053514, "Episode": 3384, "Episode Step": 95}
{"Training time": 10.744540525277456, "Episode Reward": -315.5876058373294, "Mean Reward": -3.0939961356600922, "Episode": 3385, "Episode Step": 102}
{"Training time": 10.783248003323873, "Episode Reward": 222755.93889005127, "Mean Reward": 67.37929186026959, "Episode": 3386, "Episode Step": 3306}
{"Training time": 10.784758282502493, "Episode Reward": -565.3344536335123, "Mean Reward": -6.424255154926277, "Episode": 3387, "Episode Step": 88}
{"Training time": 10.785975880556636, "Episode Reward": -430.0349635215723, "Mean Reward": -4.216029054133062, "Episode": 3388, "Episode Step": 102}
{"Training time": 10.798817263046901, "Episode Reward": 67926.30824155721, "Mean Reward": 62.489703994072876, "Episode": 3389, "Episode Step": 1087}
{"Training time": 10.8003478316466, "Episode Reward": -589.05555369433, "Mean Reward": -6.618601726902584, "Episode": 3390, "Episode Step": 89}
{"Training time": 10.801572551396157, "Episode Reward": -444.99147627017305, "Mean Reward": -4.36266153206052, "Episode": 3391, "Episode Step": 102}
{"Training time": 10.82055316110452, "Episode Reward": 108592.59289169397, "Mean Reward": 67.40694779124394, "Episode": 3392, "Episode Step": 1611}
{"Training time": 10.822048217455546, "Episode Reward": -551.567629341176, "Mean Reward": -6.339857808519264, "Episode": 3393, "Episode Step": 87}
{"Training time": 10.823299246629078, "Episode Reward": -321.26671775729864, "Mean Reward": -3.149673703502928, "Episode": 3394, "Episode Step": 102}
{"Training time": 10.826208887497584, "Episode Reward": 17104.292387014422, "Mean Reward": 68.69193729724668, "Episode": 3395, "Episode Step": 249}
{"Training time": 10.82769563443131, "Episode Reward": -600.675651316518, "Mean Reward": -6.984600596703698, "Episode": 3396, "Episode Step": 86}
{"Training time": 10.828910115228759, "Episode Reward": -438.07114061717, "Mean Reward": -4.294815104089902, "Episode": 3397, "Episode Step": 102}
{"Training time": 10.831838751104144, "Episode Reward": 15253.939908328737, "Mean Reward": 61.507822211002974, "Episode": 3398, "Episode Step": 248}
{"Training time": 10.834587304724588, "Episode Reward": -706.4105585497447, "Mean Reward": -7.282583077832419, "Episode": 3399, "Episode Step": 97}
{"Training time": 10.836085390249888, "Episode Reward": -340.57469402711126, "Mean Reward": -3.3389675885010908, "Episode": 3400, "Episode Step": 102}
{"Training time": 10.838937359717157, "Episode Reward": 15259.343307534311, "Mean Reward": 63.055137634439305, "Episode": 3401, "Episode Step": 242}
{"Training time": 10.840537281102604, "Episode Reward": -577.7876373551051, "Mean Reward": -6.146676993139415, "Episode": 3402, "Episode Step": 94}
{"Training time": 10.841761915816202, "Episode Reward": -253.76635143494886, "Mean Reward": -2.487905406224989, "Episode": 3403, "Episode Step": 102}
{"Training time": 10.843246408568488, "Episode Reward": 6390.2248918752, "Mean Reward": 51.1217991350016, "Episode": 3404, "Episode Step": 125}
{"Training time": 10.844857100248337, "Episode Reward": -586.6245359062734, "Mean Reward": -6.110672249023682, "Episode": 3405, "Episode Step": 96}
{"Training time": 10.846067895227009, "Episode Reward": -289.8460708668645, "Mean Reward": -2.8416281457535737, "Episode": 3406, "Episode Step": 102}
{"Training time": 10.853367806077003, "Episode Reward": 38598.32300611985, "Mean Reward": 61.65866294907324, "Episode": 3407, "Episode Step": 626}
{"Training time": 10.85487798055013, "Episode Reward": -645.9490416060148, "Mean Reward": -7.1772115734001645, "Episode": 3408, "Episode Step": 90}
{"Training time": 10.856084441608854, "Episode Reward": -312.1318628835418, "Mean Reward": -3.060116302779822, "Episode": 3409, "Episode Step": 102}
{"Training time": 10.859099804957708, "Episode Reward": 16824.294680596187, "Mean Reward": 65.21044449843484, "Episode": 3410, "Episode Step": 258}
{"Training time": 10.860660374694401, "Episode Reward": -651.6829468497838, "Mean Reward": -7.007343514513804, "Episode": 3411, "Episode Step": 93}
{"Training time": 10.861904448601935, "Episode Reward": -477.7867706011914, "Mean Reward": -4.684184025501876, "Episode": 3412, "Episode Step": 102}
{"Training time": 10.886518217722575, "Episode Reward": 135304.58276873096, "Mean Reward": 64.30826177221053, "Episode": 3413, "Episode Step": 2104}
{"Training time": 10.888144042227003, "Episode Reward": -719.6306696277609, "Mean Reward": -7.196306696277609, "Episode": 3414, "Episode Step": 100}
{"Training time": 10.889349976645576, "Episode Reward": -598.9120415486314, "Mean Reward": -5.871686681849327, "Episode": 3415, "Episode Step": 102}
{"Training time": 10.911070148613717, "Episode Reward": 120588.44160359881, "Mean Reward": 64.83249548580581, "Episode": 3416, "Episode Step": 1860}
{"Training time": 10.912770635551876, "Episode Reward": -489.0331575430427, "Mean Reward": -4.794442721010222, "Episode": 3417, "Episode Step": 102}
{"Training time": 10.914009795784951, "Episode Reward": -585.5116576106219, "Mean Reward": -5.7403103687315875, "Episode": 3418, "Episode Step": 102}
{"Training time": 10.916132749981351, "Episode Reward": 8853.131523529237, "Mean Reward": 49.45883532697898, "Episode": 3419, "Episode Step": 179}
{"Training time": 10.917777226368587, "Episode Reward": -695.6226022008298, "Mean Reward": -7.026490931321513, "Episode": 3420, "Episode Step": 99}
{"Training time": 10.9190025646819, "Episode Reward": -727.4069305323272, "Mean Reward": -7.131440495414973, "Episode": 3421, "Episode Step": 102}
{"Training time": 10.93760992328326, "Episode Reward": 104253.65013934585, "Mean Reward": 64.71362516408804, "Episode": 3422, "Episode Step": 1611}
{"Training time": 10.939266589151488, "Episode Reward": -513.2675557850439, "Mean Reward": -5.032034860637685, "Episode": 3423, "Episode Step": 102}
{"Training time": 10.94045433110661, "Episode Reward": -880.9906245738243, "Mean Reward": -8.637162986017886, "Episode": 3424, "Episode Step": 102}
{"Training time": 10.948501143058142, "Episode Reward": 45478.33437075666, "Mean Reward": 65.34243444074232, "Episode": 3425, "Episode Step": 696}
{"Training time": 10.95018103049861, "Episode Reward": -434.0638745819869, "Mean Reward": -4.255528182176342, "Episode": 3426, "Episode Step": 102}
{"Training time": 10.95140021721522, "Episode Reward": -509.7841495093377, "Mean Reward": -4.9978838187189965, "Episode": 3427, "Episode Step": 102}
{"Training time": 10.973085893061427, "Episode Reward": 121535.02971386543, "Mean Reward": 65.76570871962414, "Episode": 3428, "Episode Step": 1848}
{"Training time": 10.974745616118113, "Episode Reward": -664.7229174394854, "Mean Reward": -6.581415024153321, "Episode": 3429, "Episode Step": 101}
{"Training time": 10.975954191618495, "Episode Reward": -917.7276677409509, "Mean Reward": -8.997330075891675, "Episode": 3430, "Episode Step": 102}
{"Training time": 10.977621125247744, "Episode Reward": 6731.658173477417, "Mean Reward": 47.74225654948523, "Episode": 3431, "Episode Step": 141}
{"Training time": 10.979213426113128, "Episode Reward": -753.973868614803, "Mean Reward": -7.693610904232684, "Episode": 3432, "Episode Step": 98}
{"Training time": 10.980426108837127, "Episode Reward": -1085.3910280879575, "Mean Reward": -10.64108851066625, "Episode": 3433, "Episode Step": 102}
{"Training time": 10.981828827460607, "Episode Reward": 6337.539854770798, "Mean Reward": 51.94704798992458, "Episode": 3434, "Episode Step": 122}
{"Training time": 10.983444280227026, "Episode Reward": -582.0313277648609, "Mean Reward": -6.126645555419588, "Episode": 3435, "Episode Step": 95}
{"Training time": 10.984687720537186, "Episode Reward": -837.1011490469798, "Mean Reward": -8.206874010264508, "Episode": 3436, "Episode Step": 102}
{"Training time": 10.987725757492914, "Episode Reward": 15844.897419937743, "Mean Reward": 61.41433108503001, "Episode": 3437, "Episode Step": 258}
{"Training time": 10.989362716078759, "Episode Reward": -670.4997174211032, "Mean Reward": -6.772724418394982, "Episode": 3438, "Episode Step": 99}
{"Training time": 10.990590286387338, "Episode Reward": -954.8092535831254, "Mean Reward": -9.36087503512868, "Episode": 3439, "Episode Step": 102}
{"Training time": 10.991824357178476, "Episode Reward": 5787.893817802228, "Mean Reward": 56.74405703727675, "Episode": 3440, "Episode Step": 102}
{"Training time": 10.993474002480507, "Episode Reward": -143.92734967568975, "Mean Reward": -1.41105244780088, "Episode": 3441, "Episode Step": 102}
{"Training time": 10.994698496659597, "Episode Reward": -1042.736585251253, "Mean Reward": -10.222907698541697, "Episode": 3442, "Episode Step": 102}
{"Training time": 10.997671343882878, "Episode Reward": 17064.708621451577, "Mean Reward": 67.18389221043928, "Episode": 3443, "Episode Step": 254}
{"Training time": 10.99916901912954, "Episode Reward": -587.9514725305743, "Mean Reward": -6.681266733301981, "Episode": 3444, "Episode Step": 88}
{"Training time": 11.000372585786714, "Episode Reward": -442.04443668633763, "Mean Reward": -4.3337689871209575, "Episode": 3445, "Episode Step": 102}
{"Training time": 11.003107656902737, "Episode Reward": 13640.444310362405, "Mean Reward": 59.56525899721574, "Episode": 3446, "Episode Step": 229}
{"Training time": 11.004773723880449, "Episode Reward": -632.805517011143, "Mean Reward": -6.265401158526169, "Episode": 3447, "Episode Step": 101}
{"Training time": 11.005982578595479, "Episode Reward": -699.8260734747195, "Mean Reward": -6.861039936026661, "Episode": 3448, "Episode Step": 102}
{"Training time": 11.028386217223273, "Episode Reward": 128067.2884761177, "Mean Reward": 67.54603822580047, "Episode": 3449, "Episode Step": 1896}
{"Training time": 11.030042160550753, "Episode Reward": -466.1594180252059, "Mean Reward": -4.570190372796136, "Episode": 3450, "Episode Step": 102}
{"Training time": 11.031255480779542, "Episode Reward": -931.8234787679392, "Mean Reward": -9.135524301646463, "Episode": 3451, "Episode Step": 102}
{"Training time": 11.03997781833013, "Episode Reward": 50245.98978060187, "Mean Reward": 66.81647577207696, "Episode": 3452, "Episode Step": 752}
{"Training time": 11.041544224156274, "Episode Reward": -644.6719247542721, "Mean Reward": -6.786020260571286, "Episode": 3453, "Episode Step": 95}
{"Training time": 11.042776758008532, "Episode Reward": -671.7594643017152, "Mean Reward": -6.585877100997208, "Episode": 3454, "Episode Step": 102}
{"Training time": 11.059798222449091, "Episode Reward": 99070.57797905896, "Mean Reward": 67.48676974050338, "Episode": 3455, "Episode Step": 1468}
{"Training time": 11.061379402478536, "Episode Reward": -573.1327756148075, "Mean Reward": -5.908585315616572, "Episode": 3456, "Episode Step": 97}
{"Training time": 11.062589963608318, "Episode Reward": -991.9128739190824, "Mean Reward": -9.724636018814532, "Episode": 3457, "Episode Step": 102}
{"Training time": 11.074482279419898, "Episode Reward": 68183.66129942416, "Mean Reward": 66.39110155737504, "Episode": 3458, "Episode Step": 1027}
{"Training time": 11.075981825788816, "Episode Reward": -581.8311775943419, "Mean Reward": -6.537428961734178, "Episode": 3459, "Episode Step": 89}
{"Training time": 11.077178428835339, "Episode Reward": -910.7414578277956, "Mean Reward": -8.928837821841134, "Episode": 3460, "Episode Step": 102}
{"Training time": 11.082019649412898, "Episode Reward": 27101.71195621314, "Mean Reward": 64.83663147419412, "Episode": 3461, "Episode Step": 418}
{"Training time": 11.083459877173105, "Episode Reward": -535.1775931887917, "Mean Reward": -6.371161823676092, "Episode": 3462, "Episode Step": 84}
{"Training time": 11.084637125796743, "Episode Reward": -1002.3947186202093, "Mean Reward": -9.827399202158915, "Episode": 3463, "Episode Step": 102}
{"Training time": 11.086717027756903, "Episode Reward": 9041.98806423993, "Mean Reward": 50.51389980022307, "Episode": 3464, "Episode Step": 179}
{"Training time": 11.088177721897761, "Episode Reward": -550.3157687603482, "Mean Reward": -6.551378199527955, "Episode": 3465, "Episode Step": 84}
{"Training time": 11.089379783007834, "Episode Reward": -1008.788848839287, "Mean Reward": -9.890086753326344, "Episode": 3466, "Episode Step": 102}
{"Training time": 11.098331050806575, "Episode Reward": 49312.931447337374, "Mean Reward": 63.87685420639556, "Episode": 3467, "Episode Step": 772}
{"Training time": 11.099854344129563, "Episode Reward": -546.3551256917145, "Mean Reward": -6.427707361078994, "Episode": 3468, "Episode Step": 85}
{"Training time": 11.101035688585705, "Episode Reward": -1028.4938010899423, "Mean Reward": -10.083272559705316, "Episode": 3469, "Episode Step": 102}
{"Training time": 11.10868141916063, "Episode Reward": 43587.15281093952, "Mean Reward": 65.54459069314214, "Episode": 3470, "Episode Step": 665}
{"Training time": 11.110146440002653, "Episode Reward": -568.2632963154372, "Mean Reward": -6.685450544887496, "Episode": 3471, "Episode Step": 85}
{"Training time": 11.111352562175856, "Episode Reward": -1022.3248583620166, "Mean Reward": -10.022792729039379, "Episode": 3472, "Episode Step": 102}
{"Training time": 11.114273910257552, "Episode Reward": 16627.761941931458, "Mean Reward": 65.46362969264354, "Episode": 3473, "Episode Step": 254}
{"Training time": 11.115837778846423, "Episode Reward": -595.5285447888141, "Mean Reward": -6.4035327396646675, "Episode": 3474, "Episode Step": 93}
{"Training time": 11.117025249401728, "Episode Reward": -1155.0371668105645, "Mean Reward": -11.323893792260437, "Episode": 3475, "Episode Step": 102}
{"Training time": 11.12241211745474, "Episode Reward": 31111.24933272023, "Mean Reward": 66.47702848871843, "Episode": 3476, "Episode Step": 468}
{"Training time": 11.123987137211694, "Episode Reward": -573.8071283489937, "Mean Reward": -6.10433115264887, "Episode": 3477, "Episode Step": 94}
{"Training time": 11.125196713606517, "Episode Reward": -1020.6223990168417, "Mean Reward": -10.006101951145506, "Episode": 3478, "Episode Step": 102}
{"Training time": 11.133860980007384, "Episode Reward": 50322.07965770305, "Mean Reward": 68.46541450027625, "Episode": 3479, "Episode Step": 735}
{"Training time": 11.135407564706272, "Episode Reward": -652.3776634099352, "Mean Reward": -7.16898531219709, "Episode": 3480, "Episode Step": 91}
{"Training time": 11.136655406355858, "Episode Reward": -1097.807187299697, "Mean Reward": -10.762815561761736, "Episode": 3481, "Episode Step": 102}
{"Training time": 11.138773510257403, "Episode Reward": 8855.060284148358, "Mean Reward": 50.31284252357022, "Episode": 3482, "Episode Step": 176}
{"Training time": 11.140300572183397, "Episode Reward": -557.0128062864342, "Mean Reward": -6.329690980527661, "Episode": 3483, "Episode Step": 88}
{"Training time": 11.141540996895896, "Episode Reward": -1104.3952256233042, "Mean Reward": -10.827404172777491, "Episode": 3484, "Episode Step": 102}
{"Training time": 11.148159108294381, "Episode Reward": 35552.853878989205, "Mean Reward": 63.148941170495924, "Episode": 3485, "Episode Step": 563}
{"Training time": 11.14974907471074, "Episode Reward": -565.062322758208, "Mean Reward": -5.9480244500863995, "Episode": 3486, "Episode Step": 95}
{"Training time": 11.150965826378929, "Episode Reward": -1068.4364526737754, "Mean Reward": -10.47486718307623, "Episode": 3487, "Episode Step": 102}
{"Training time": 11.159514940778415, "Episode Reward": 49134.03626232334, "Mean Reward": 67.39922669728853, "Episode": 3488, "Episode Step": 729}
{"Training time": 11.161017370223998, "Episode Reward": -541.1974613441912, "Mean Reward": -6.080870352181924, "Episode": 3489, "Episode Step": 89}
{"Training time": 11.162212282220523, "Episode Reward": -940.9273211249803, "Mean Reward": -9.224777658088042, "Episode": 3490, "Episode Step": 102}
{"Training time": 11.165662690533532, "Episode Reward": 20033.461322526135, "Mean Reward": 68.60774425522649, "Episode": 3491, "Episode Step": 292}
{"Training time": 11.16728242278099, "Episode Reward": -583.1582595535245, "Mean Reward": -5.8904874702376215, "Episode": 3492, "Episode Step": 99}
{"Training time": 11.168511088026895, "Episode Reward": -942.4523622696714, "Mean Reward": -9.239729041859524, "Episode": 3493, "Episode Step": 102}
{"Training time": 11.171963004403644, "Episode Reward": 20272.46979541167, "Mean Reward": 69.18931670788966, "Episode": 3494, "Episode Step": 293}
{"Training time": 11.173581804699367, "Episode Reward": -554.5372443575983, "Mean Reward": -5.716878807810292, "Episode": 3495, "Episode Step": 97}
{"Training time": 11.174824492732684, "Episode Reward": -861.6275728283688, "Mean Reward": -8.447329145376164, "Episode": 3496, "Episode Step": 102}
{"Training time": 11.178366417487462, "Episode Reward": 18920.287299508047, "Mean Reward": 64.13656711697644, "Episode": 3497, "Episode Step": 295}
{"Training time": 11.179953183001942, "Episode Reward": -598.9861069515223, "Mean Reward": -6.305116915279182, "Episode": 3498, "Episode Step": 95}
{"Training time": 11.181408004164696, "Episode Reward": -1081.3155513744368, "Mean Reward": -10.601132856612125, "Episode": 3499, "Episode Step": 102}
{"Training time": 11.1940455991692, "Episode Reward": 69129.15761513262, "Mean Reward": 65.58743606748826, "Episode": 3500, "Episode Step": 1054}
{"Training time": 11.195603571070565, "Episode Reward": -505.99162708438337, "Mean Reward": -5.440770183703047, "Episode": 3501, "Episode Step": 93}
{"Training time": 11.196787183615896, "Episode Reward": -853.777210944362, "Mean Reward": -8.37036481318002, "Episode": 3502, "Episode Step": 102}
{"Training time": 11.233210510545307, "Episode Reward": 213940.3176581197, "Mean Reward": 67.129061078795, "Episode": 3503, "Episode Step": 3187}
{"Training time": 11.234759947458903, "Episode Reward": -606.9262954055663, "Mean Reward": -6.669519729731498, "Episode": 3504, "Episode Step": 91}
{"Training time": 11.235989751617113, "Episode Reward": -1038.7080853259881, "Mean Reward": -10.183412601235178, "Episode": 3505, "Episode Step": 102}
{"Training time": 11.244422813587718, "Episode Reward": 47538.560941150885, "Mean Reward": 66.48749781979144, "Episode": 3506, "Episode Step": 715}
{"Training time": 11.246074341668024, "Episode Reward": -669.9330398304951, "Mean Reward": -6.633000394361337, "Episode": 3507, "Episode Step": 101}
{"Training time": 11.247283143334919, "Episode Reward": -696.5399832693962, "Mean Reward": -6.828823365386238, "Episode": 3508, "Episode Step": 102}
{"Training time": 11.259003539946344, "Episode Reward": 61046.5456156612, "Mean Reward": 60.803332286515136, "Episode": 3509, "Episode Step": 1004}
{"Training time": 11.260715115004116, "Episode Reward": -580.4119503393115, "Mean Reward": -5.690313238620701, "Episode": 3510, "Episode Step": 102}
{"Training time": 11.261939623885684, "Episode Reward": -674.3609970984837, "Mean Reward": -6.611382324494938, "Episode": 3511, "Episode Step": 102}
{"Training time": 11.274362082216475, "Episode Reward": 67904.99901429878, "Mean Reward": 64.48717855109096, "Episode": 3512, "Episode Step": 1053}
{"Training time": 11.275986296931903, "Episode Reward": -608.9022610131587, "Mean Reward": -6.213288377685293, "Episode": 3513, "Episode Step": 98}
{"Training time": 11.277202344139416, "Episode Reward": -876.8306536046575, "Mean Reward": -8.596378956908406, "Episode": 3514, "Episode Step": 102}
{"Training time": 11.30450258248382, "Episode Reward": 155337.69611590193, "Mean Reward": 66.89823260805423, "Episode": 3515, "Episode Step": 2322}
{"Training time": 11.306179480817583, "Episode Reward": -561.9352332420456, "Mean Reward": -5.509168953353388, "Episode": 3516, "Episode Step": 102}
{"Training time": 11.307392934428321, "Episode Reward": -651.2548549030108, "Mean Reward": -6.384851518656969, "Episode": 3517, "Episode Step": 102}
{"Training time": 11.309433992769984, "Episode Reward": 9437.480628510466, "Mean Reward": 54.86907342157247, "Episode": 3518, "Episode Step": 172}
{"Training time": 11.311065493888325, "Episode Reward": -614.7561050757287, "Mean Reward": -6.273021480364578, "Episode": 3519, "Episode Step": 98}
{"Training time": 11.312278489139345, "Episode Reward": -711.3182395022251, "Mean Reward": -6.973708230413972, "Episode": 3520, "Episode Step": 102}
{"Training time": 11.324608072506058, "Episode Reward": 67851.9799014608, "Mean Reward": 63.77065780212481, "Episode": 3521, "Episode Step": 1064}
{"Training time": 11.326109342177709, "Episode Reward": -569.2911088640616, "Mean Reward": -6.396529313079344, "Episode": 3522, "Episode Step": 89}
{"Training time": 11.327325106064478, "Episode Reward": -933.8830809917703, "Mean Reward": -9.155716480311474, "Episode": 3523, "Episode Step": 102}
{"Training time": 11.329521567490366, "Episode Reward": 9543.823438939322, "Mean Reward": 51.31087870397485, "Episode": 3524, "Episode Step": 186}
{"Training time": 11.331040398875873, "Episode Reward": -654.5551708969406, "Mean Reward": -7.272835232188228, "Episode": 3525, "Episode Step": 90}
{"Training time": 11.33223799970415, "Episode Reward": -903.2134944586985, "Mean Reward": -8.855034259399005, "Episode": 3526, "Episode Step": 102}
{"Training time": 11.348694033026696, "Episode Reward": 96133.04598094024, "Mean Reward": 67.36723614641923, "Episode": 3527, "Episode Step": 1427}
{"Training time": 11.35035576913092, "Episode Reward": -374.4922896617043, "Mean Reward": -3.671493035899062, "Episode": 3528, "Episode Step": 102}
{"Training time": 11.351562364697456, "Episode Reward": -771.4223267085347, "Mean Reward": -7.562963987338575, "Episode": 3529, "Episode Step": 102}
{"Training time": 11.354495207468668, "Episode Reward": 16185.744855691995, "Mean Reward": 64.74297942276799, "Episode": 3530, "Episode Step": 250}
{"Training time": 11.356178527209494, "Episode Reward": -388.42983592648915, "Mean Reward": -3.808135646338129, "Episode": 3531, "Episode Step": 102}
{"Training time": 11.357391124433942, "Episode Reward": -888.9619648727534, "Mean Reward": -8.715313381105425, "Episode": 3532, "Episode Step": 102}
{"Training time": 11.365106476346652, "Episode Reward": 43804.36016464791, "Mean Reward": 66.57197593411536, "Episode": 3533, "Episode Step": 658}
{"Training time": 11.366757671104537, "Episode Reward": -494.4457750049141, "Mean Reward": -4.847507598087393, "Episode": 3534, "Episode Step": 102}
{"Training time": 11.367944646345245, "Episode Reward": -638.1831422962695, "Mean Reward": -6.256697473492838, "Episode": 3535, "Episode Step": 102}
{"Training time": 11.410724605785475, "Episode Reward": 249938.62626024114, "Mean Reward": 67.6057955802654, "Episode": 3536, "Episode Step": 3697}
{"Training time": 11.412383871078491, "Episode Reward": -564.6583999800438, "Mean Reward": -5.535866666471017, "Episode": 3537, "Episode Step": 102}
{"Training time": 11.4135819438431, "Episode Reward": -896.5066196595315, "Mean Reward": -8.789280584897368, "Episode": 3538, "Episode Step": 102}
{"Training time": 11.421643879678514, "Episode Reward": 45760.71933344064, "Mean Reward": 66.03278403093887, "Episode": 3539, "Episode Step": 693}
{"Training time": 11.423291370272636, "Episode Reward": -392.8092578153333, "Mean Reward": -3.851071155052287, "Episode": 3540, "Episode Step": 102}
{"Training time": 11.424483377205002, "Episode Reward": -796.178918394356, "Mean Reward": -7.805675670532901, "Episode": 3541, "Episode Step": 102}
{"Training time": 11.42652470972803, "Episode Reward": 9021.356140744621, "Mean Reward": 51.2577053451399, "Episode": 3542, "Episode Step": 176}
{"Training time": 11.428100469112396, "Episode Reward": -607.3344612964542, "Mean Reward": -6.39299432943636, "Episode": 3543, "Episode Step": 95}
{"Training time": 11.429304303063287, "Episode Reward": -804.0771851321323, "Mean Reward": -7.883109658158159, "Episode": 3544, "Episode Step": 102}
{"Training time": 11.462071736653646, "Episode Reward": 187004.17383244899, "Mean Reward": 66.33706060037211, "Episode": 3545, "Episode Step": 2819}
{"Training time": 11.463646985557345, "Episode Reward": -622.6701897768318, "Mean Reward": -6.624150955072678, "Episode": 3546, "Episode Step": 94}
{"Training time": 11.46486969994174, "Episode Reward": -973.3970881402993, "Mean Reward": -9.543108707257836, "Episode": 3547, "Episode Step": 102}
{"Training time": 11.482231794397036, "Episode Reward": 92559.85975806562, "Mean Reward": 61.9129496709469, "Episode": 3548, "Episode Step": 1495}
{"Training time": 11.483999608887567, "Episode Reward": -611.7377777116053, "Mean Reward": -6.722393161665992, "Episode": 3549, "Episode Step": 91}
{"Training time": 11.485501390563117, "Episode Reward": -913.5710066076074, "Mean Reward": -8.956578496153014, "Episode": 3550, "Episode Step": 102}
{"Training time": 11.494807776080238, "Episode Reward": 50420.51876313875, "Mean Reward": 63.02564845392344, "Episode": 3551, "Episode Step": 800}
{"Training time": 11.496269660525853, "Episode Reward": -574.9057856518984, "Mean Reward": -6.844116495855934, "Episode": 3552, "Episode Step": 84}
{"Training time": 11.497460899949074, "Episode Reward": -726.0735151044134, "Mean Reward": -7.1183677951413085, "Episode": 3553, "Episode Step": 102}
{"Training time": 11.498960534996456, "Episode Reward": 7388.905957674313, "Mean Reward": 57.27834075716522, "Episode": 3554, "Episode Step": 129}
{"Training time": 11.500454727212588, "Episode Reward": -610.9178762558706, "Mean Reward": -7.10369623553338, "Episode": 3555, "Episode Step": 86}
{"Training time": 11.501653566625382, "Episode Reward": -1223.541877303608, "Mean Reward": -11.995508601015766, "Episode": 3556, "Episode Step": 102}
{"Training time": 11.503140569991535, "Episode Reward": 6633.9063483296495, "Mean Reward": 51.82739334632539, "Episode": 3557, "Episode Step": 128}
{"Training time": 11.504602283570502, "Episode Reward": -533.8482176999512, "Mean Reward": -6.207537415115712, "Episode": 3558, "Episode Step": 86}
{"Training time": 11.505808126065466, "Episode Reward": -1044.16915856919, "Mean Reward": -10.236952534992058, "Episode": 3559, "Episode Step": 102}
{"Training time": 11.507347166339557, "Episode Reward": 6713.05959838621, "Mean Reward": 51.638919987586235, "Episode": 3560, "Episode Step": 130}
{"Training time": 11.509000726077291, "Episode Reward": -665.7343559523038, "Mean Reward": -6.657343559523038, "Episode": 3561, "Episode Step": 100}
{"Training time": 11.510215881930458, "Episode Reward": -1264.8166404133453, "Mean Reward": -12.400163141307308, "Episode": 3562, "Episode Step": 102}
{"Training time": 11.542791622479756, "Episode Reward": 183021.43605185839, "Mean Reward": 64.67188553069201, "Episode": 3563, "Episode Step": 2830}
{"Training time": 11.54432476884789, "Episode Reward": -601.4288734147503, "Mean Reward": -6.75762779117697, "Episode": 3564, "Episode Step": 89}
{"Training time": 11.5455282107989, "Episode Reward": -1268.591387692506, "Mean Reward": -12.437170467573589, "Episode": 3565, "Episode Step": 102}
{"Training time": 11.552613770829307, "Episode Reward": 39311.029244312165, "Mean Reward": 64.55013012202326, "Episode": 3566, "Episode Step": 609}
{"Training time": 11.554130964676538, "Episode Reward": -521.7948087739817, "Mean Reward": -5.929486463340701, "Episode": 3567, "Episode Step": 88}
{"Training time": 11.555340257220799, "Episode Reward": -1326.773586110347, "Mean Reward": -13.007584177552422, "Episode": 3568, "Episode Step": 102}
{"Training time": 11.556589653558202, "Episode Reward": 5985.315905368766, "Mean Reward": 57.003008622559676, "Episode": 3569, "Episode Step": 105}
{"Training time": 11.558254180550575, "Episode Reward": -535.5718503874134, "Mean Reward": -5.250704415562876, "Episode": 3570, "Episode Step": 102}
{"Training time": 11.559465371370315, "Episode Reward": -1114.255560657302, "Mean Reward": -10.924074124091197, "Episode": 3571, "Episode Step": 102}
{"Training time": 11.56146840605471, "Episode Reward": 9252.55924012872, "Mean Reward": 54.108533568004205, "Episode": 3572, "Episode Step": 171}
{"Training time": 11.564856707453728, "Episode Reward": 8671.044931266955, "Mean Reward": 34.40890845740855, "Episode": 3573, "Episode Step": 252}
{"Training time": 11.566067293286324, "Episode Reward": -1275.3938580944932, "Mean Reward": -12.503861353867581, "Episode": 3574, "Episode Step": 102}
{"Training time": 11.593740422725677, "Episode Reward": 154004.38471537188, "Mean Reward": 64.6805479694968, "Episode": 3575, "Episode Step": 2381}
{"Training time": 11.597188465793927, "Episode Reward": 8773.45937182053, "Mean Reward": 34.67770502695862, "Episode": 3576, "Episode Step": 253}
{"Training time": 11.598402523332172, "Episode Reward": -1082.3728612085972, "Mean Reward": -10.611498639299972, "Episode": 3577, "Episode Step": 102}
{"Training time": 11.600415656632848, "Episode Reward": 8824.704978989224, "Mean Reward": 51.60646186543406, "Episode": 3578, "Episode Step": 171}
{"Training time": 11.6039569880565, "Episode Reward": 8587.93843475395, "Mean Reward": 32.653758307049245, "Episode": 3579, "Episode Step": 263}
{"Training time": 11.605166263845232, "Episode Reward": -1177.6221299270326, "Mean Reward": -11.545314999284633, "Episode": 3580, "Episode Step": 102}
{"Training time": 11.642296404110061, "Episode Reward": 211340.26399875732, "Mean Reward": 67.04957614173773, "Episode": 3581, "Episode Step": 3152}
{"Training time": 11.645743631389406, "Episode Reward": 8002.710081731286, "Mean Reward": 31.631265145182947, "Episode": 3582, "Episode Step": 253}
{"Training time": 11.646960581673516, "Episode Reward": -1185.0695121450408, "Mean Reward": -11.618328550441577, "Episode": 3583, "Episode Step": 102}
{"Training time": 11.660594032208126, "Episode Reward": 77010.33020321759, "Mean Reward": 66.10328772808377, "Episode": 3584, "Episode Step": 1165}
{"Training time": 11.663945996893776, "Episode Reward": 8239.133706356266, "Mean Reward": 33.492413440472625, "Episode": 3585, "Episode Step": 246}
{"Training time": 11.665152479145261, "Episode Reward": -1347.8130328292887, "Mean Reward": -13.213853263032242, "Episode": 3586, "Episode Step": 102}
{"Training time": 11.665759526888529, "Episode Reward": 1857.5186027745472, "Mean Reward": 37.90854291376627, "Episode": 3587, "Episode Step": 49}
{"Training time": 11.667427960501778, "Episode Reward": -3.1384964201831567, "Mean Reward": -0.03076957274689369, "Episode": 3588, "Episode Step": 102}
{"Training time": 11.668638565275405, "Episode Reward": -1234.613798820479, "Mean Reward": -12.104056851181166, "Episode": 3589, "Episode Step": 102}
{"Training time": 11.671580349140697, "Episode Reward": 15732.64330775184, "Mean Reward": 63.694912177132956, "Episode": 3590, "Episode Step": 247}
{"Training time": 11.676296096907722, "Episode Reward": 13920.322828453247, "Mean Reward": 38.34799677259848, "Episode": 3591, "Episode Step": 363}
{"Training time": 11.677518778045972, "Episode Reward": -980.5933829014482, "Mean Reward": -9.613660616680864, "Episode": 3592, "Episode Step": 102}
{"Training time": 11.736057136058808, "Episode Reward": 320108.61146332376, "Mean Reward": 64.02172229266475, "Episode": 3593, "Episode Step": 5000}
{"Training time": 11.739269913302527, "Episode Reward": 8500.687329233739, "Mean Reward": 36.1731375712074, "Episode": 3594, "Episode Step": 235}
{"Training time": 11.740454265541501, "Episode Reward": -1143.1148860696203, "Mean Reward": -11.207008686957062, "Episode": 3595, "Episode Step": 102}
{"Training time": 11.759243932167688, "Episode Reward": 101967.18534757204, "Mean Reward": 63.49139809935993, "Episode": 3596, "Episode Step": 1606}
{"Training time": 11.764041249685818, "Episode Reward": 16381.343642285588, "Mean Reward": 44.273901735906996, "Episode": 3597, "Episode Step": 370}
{"Training time": 11.76523766193125, "Episode Reward": -999.4873410550468, "Mean Reward": -9.798895500539675, "Episode": 3598, "Episode Step": 102}
{"Training time": 11.777369353837438, "Episode Reward": 64984.56956618795, "Mean Reward": 63.33778710154771, "Episode": 3599, "Episode Step": 1026}
{"Training time": 11.780798954168956, "Episode Reward": 7778.809348440475, "Mean Reward": 30.86829106523998, "Episode": 3600, "Episode Step": 252}
{"Training time": 11.782018796669112, "Episode Reward": -1186.0630911294031, "Mean Reward": -11.628069520876501, "Episode": 3601, "Episode Step": 102}
{"Training time": 11.790094887481795, "Episode Reward": 47257.111134325976, "Mean Reward": 68.29062302648262, "Episode": 3602, "Episode Step": 692}
{"Training time": 11.794734303885036, "Episode Reward": 16149.898861824198, "Mean Reward": 44.86083017173389, "Episode": 3603, "Episode Step": 360}
{"Training time": 11.795926690498987, "Episode Reward": -876.0549335683962, "Mean Reward": -8.588773858513688, "Episode": 3604, "Episode Step": 102}
{"Training time": 11.824415075778962, "Episode Reward": 161657.46377374118, "Mean Reward": 65.66103321435466, "Episode": 3605, "Episode Step": 2462}
{"Training time": 11.82789452638891, "Episode Reward": 8557.143773714291, "Mean Reward": 32.91209143736266, "Episode": 3606, "Episode Step": 260}
{"Training time": 11.82909519943926, "Episode Reward": -837.0353711511266, "Mean Reward": -8.206229128932614, "Episode": 3607, "Episode Step": 102}
{"Training time": 11.831890460782581, "Episode Reward": 16399.50496259423, "Mean Reward": 68.04773843400096, "Episode": 3608, "Episode Step": 241}
{"Training time": 11.832697573304177, "Episode Reward": -182.3529018410951, "Mean Reward": -6.288031097968797, "Episode": 3609, "Episode Step": 29}
{"Training time": 11.833911328315734, "Episode Reward": -972.9539877588061, "Mean Reward": -9.538764585870648, "Episode": 3610, "Episode Step": 102}
{"Training time": 11.840967500276037, "Episode Reward": 38848.156840681855, "Mean Reward": 63.58127142501122, "Episode": 3611, "Episode Step": 611}
{"Training time": 11.841799112757046, "Episode Reward": -181.76520136200597, "Mean Reward": -6.058840045400199, "Episode": 3612, "Episode Step": 30}
{"Training time": 11.842988848023944, "Episode Reward": 82.73874239700744, "Mean Reward": 0.8111641411471318, "Episode": 3613, "Episode Step": 102}
{"Training time": 11.86146044300662, "Episode Reward": 100008.20017876284, "Mean Reward": 62.54421524625568, "Episode": 3614, "Episode Step": 1599}
{"Training time": 11.86344551079803, "Episode Reward": 2654.6635053136315, "Mean Reward": 20.26460691079108, "Episode": 3615, "Episode Step": 131}
{"Training time": 11.86466878745291, "Episode Reward": -833.9064128846918, "Mean Reward": -8.175553067496978, "Episode": 3616, "Episode Step": 102}
{"Training time": 11.872655420237118, "Episode Reward": 45299.223967728074, "Mean Reward": 65.55604047428086, "Episode": 3617, "Episode Step": 691}
{"Training time": 11.873492214414808, "Episode Reward": -181.88217389097323, "Mean Reward": -6.2717990996887325, "Episode": 3618, "Episode Step": 29}
{"Training time": 11.874741766386562, "Episode Reward": -929.7165746359913, "Mean Reward": -9.114868378784228, "Episode": 3619, "Episode Step": 102}
{"Training time": 11.892896809710397, "Episode Reward": 99727.3678289845, "Mean Reward": 64.92667176366179, "Episode": 3620, "Episode Step": 1536}
{"Training time": 11.893658947745958, "Episode Reward": -181.45088603478646, "Mean Reward": -7.258035441391459, "Episode": 3621, "Episode Step": 25}
{"Training time": 11.894877566628987, "Episode Reward": -981.9498506364363, "Mean Reward": -9.626959319965062, "Episode": 3622, "Episode Step": 102}
{"Training time": 11.916475901934836, "Episode Reward": 122251.89935408898, "Mean Reward": 65.76218362242548, "Episode": 3623, "Episode Step": 1859}
{"Training time": 11.917326956060197, "Episode Reward": -181.73305807167992, "Mean Reward": -5.8623567119896745, "Episode": 3624, "Episode Step": 31}
{"Training time": 11.918528244958983, "Episode Reward": -1122.055813119229, "Mean Reward": -11.000547187443422, "Episode": 3625, "Episode Step": 102}
{"Training time": 11.928551753891838, "Episode Reward": 55606.07738360016, "Mean Reward": 64.43346162641966, "Episode": 3626, "Episode Step": 863}
{"Training time": 11.9294185472197, "Episode Reward": -182.3484128870352, "Mean Reward": -5.882206867323716, "Episode": 3627, "Episode Step": 31}
{"Training time": 11.930657907459471, "Episode Reward": -1104.5083626897533, "Mean Reward": -10.828513359703464, "Episode": 3628, "Episode Step": 102}
{"Training time": 11.94086112552219, "Episode Reward": 55706.74526642169, "Mean Reward": 65.38350383382827, "Episode": 3629, "Episode Step": 852}
{"Training time": 11.941707198553615, "Episode Reward": -180.2929870284676, "Mean Reward": -5.634155844639612, "Episode": 3630, "Episode Step": 32}
{"Training time": 11.942917915781338, "Episode Reward": -1176.233939100398, "Mean Reward": -11.531705285298019, "Episode": 3631, "Episode Step": 102}
{"Training time": 11.945856931938065, "Episode Reward": 16667.582024974006, "Mean Reward": 67.48008916993525, "Episode": 3632, "Episode Step": 247}
{"Training time": 11.946611780259344, "Episode Reward": -181.89715526824727, "Mean Reward": -7.5790481361769695, "Episode": 3633, "Episode Step": 24}
{"Training time": 11.947838747766284, "Episode Reward": -993.6924448025375, "Mean Reward": -9.74208279218174, "Episode": 3634, "Episode Step": 102}
{"Training time": 11.958653341068162, "Episode Reward": 57175.25046384078, "Mean Reward": 61.74433095447168, "Episode": 3635, "Episode Step": 926}
{"Training time": 11.96031742301252, "Episode Reward": -71.75105165486873, "Mean Reward": -0.70344168289087, "Episode": 3636, "Episode Step": 102}
{"Training time": 11.961527559426095, "Episode Reward": -1236.1266916005136, "Mean Reward": -12.118889133338369, "Episode": 3637, "Episode Step": 102}
{"Training time": 11.966446327765782, "Episode Reward": 26276.870742887793, "Mean Reward": 61.973751752093854, "Episode": 3638, "Episode Step": 424}
{"Training time": 11.96719078719616, "Episode Reward": -182.44205632364842, "Mean Reward": -7.601752346818684, "Episode": 3639, "Episode Step": 24}
{"Training time": 11.968405703571108, "Episode Reward": -796.0316315519697, "Mean Reward": -7.804231681882055, "Episode": 3640, "Episode Step": 102}
{"Training time": 11.97050652106603, "Episode Reward": 9260.894927389112, "Mean Reward": 52.02749959207367, "Episode": 3641, "Episode Step": 178}
{"Training time": 11.97131500661373, "Episode Reward": -182.45775489506684, "Mean Reward": -6.757694625743216, "Episode": 3642, "Episode Step": 27}
{"Training time": 11.972554232478142, "Episode Reward": -755.1011781850258, "Mean Reward": -7.402952727304174, "Episode": 3643, "Episode Step": 102}
{"Training time": 11.979420608613227, "Episode Reward": 35261.75580727911, "Mean Reward": 59.96897246135902, "Episode": 3644, "Episode Step": 588}
{"Training time": 11.98025652858946, "Episode Reward": -181.68924755089907, "Mean Reward": -6.056308251696636, "Episode": 3645, "Episode Step": 30}
{"Training time": 11.981478353010283, "Episode Reward": -936.1343324182363, "Mean Reward": -9.177787572727807, "Episode": 3646, "Episode Step": 102}
{"Training time": 11.989736217194134, "Episode Reward": 46841.634902464844, "Mean Reward": 66.53641321372847, "Episode": 3647, "Episode Step": 704}
{"Training time": 11.990521386067073, "Episode Reward": -182.70757067989348, "Mean Reward": -6.766947062218277, "Episode": 3648, "Episode Step": 27}
{"Training time": 11.992856476373143, "Episode Reward": -1088.927720007271, "Mean Reward": -10.6757619608556, "Episode": 3649, "Episode Step": 102}
{"Training time": 11.995244903299543, "Episode Reward": 9245.962924545134, "Mean Reward": 52.53388025309735, "Episode": 3650, "Episode Step": 176}
{"Training time": 11.998848677741156, "Episode Reward": 8209.464231725777, "Mean Reward": 31.45388594530949, "Episode": 3651, "Episode Step": 261}
{"Training time": 12.00008078886403, "Episode Reward": -630.2408666557806, "Mean Reward": -6.178832026037064, "Episode": 3652, "Episode Step": 102}
{"Training time": 12.013258566922612, "Episode Reward": 73420.40015337583, "Mean Reward": 65.20461825344212, "Episode": 3653, "Episode Step": 1126}
{"Training time": 12.014044617215792, "Episode Reward": -182.82115628850113, "Mean Reward": -6.771153936611153, "Episode": 3654, "Episode Step": 27}
{"Training time": 12.015275384717517, "Episode Reward": -654.3330860300618, "Mean Reward": -6.415030255196685, "Episode": 3655, "Episode Step": 102}
{"Training time": 12.017378935813904, "Episode Reward": 9759.915564097766, "Mean Reward": 54.52466795585344, "Episode": 3656, "Episode Step": 179}
{"Training time": 12.01818416774273, "Episode Reward": -182.57018699657712, "Mean Reward": -7.02193026909912, "Episode": 3657, "Episode Step": 26}
{"Training time": 12.019409468041525, "Episode Reward": -478.9654681276887, "Mean Reward": -4.695739883604792, "Episode": 3658, "Episode Step": 102}
{"Training time": 12.027484597497516, "Episode Reward": 46503.75569991159, "Mean Reward": 67.59266816847615, "Episode": 3659, "Episode Step": 688}
{"Training time": 12.028306915561359, "Episode Reward": -181.54805360418527, "Mean Reward": -6.260277710489147, "Episode": 3660, "Episode Step": 29}
{"Training time": 12.02954372578197, "Episode Reward": -579.0577640204899, "Mean Reward": -5.677036902161666, "Episode": 3661, "Episode Step": 102}
{"Training time": 12.030762070549859, "Episode Reward": 6290.99531058328, "Mean Reward": 61.67642461356157, "Episode": 3662, "Episode Step": 102}
{"Training time": 12.035458868609535, "Episode Reward": 13801.687426564207, "Mean Reward": 39.32104679932823, "Episode": 3663, "Episode Step": 351}
{"Training time": 12.036696893572808, "Episode Reward": -814.7628377487365, "Mean Reward": -7.987870958320946, "Episode": 3664, "Episode Step": 102}
{"Training time": 12.039609808590678, "Episode Reward": 16296.718024169431, "Mean Reward": 66.7898279679075, "Episode": 3665, "Episode Step": 244}
{"Training time": 12.042577412459586, "Episode Reward": 6579.769085179261, "Mean Reward": 31.33223373894886, "Episode": 3666, "Episode Step": 210}
{"Training time": 12.043804778589143, "Episode Reward": -998.6684902563634, "Mean Reward": -9.790867551532974, "Episode": 3667, "Episode Step": 102}
{"Training time": 12.045030750499832, "Episode Reward": 6258.013742040924, "Mean Reward": 61.353075902362, "Episode": 3668, "Episode Step": 102}
{"Training time": 12.046623987224367, "Episode Reward": -183.6933981414148, "Mean Reward": -1.9134728973064041, "Episode": 3669, "Episode Step": 96}
{"Training time": 12.047822149991989, "Episode Reward": -1053.1083288457771, "Mean Reward": -10.324591459272325, "Episode": 3670, "Episode Step": 102}
{"Training time": 12.049951559702555, "Episode Reward": 9497.408749176664, "Mean Reward": 52.47187154241251, "Episode": 3671, "Episode Step": 181}
{"Training time": 12.051659887168142, "Episode Reward": 19.29316013291717, "Mean Reward": 0.1891486287540899, "Episode": 3672, "Episode Step": 102}
{"Training time": 12.05290228691366, "Episode Reward": -1107.8232688217468, "Mean Reward": -10.86101243942889, "Episode": 3673, "Episode Step": 102}
{"Training time": 12.059160831901762, "Episode Reward": 33852.88827829357, "Mean Reward": 64.48169195865442, "Episode": 3674, "Episode Step": 525}
{"Training time": 12.06085727221436, "Episode Reward": 20.124562033410257, "Mean Reward": 0.19729962777853194, "Episode": 3675, "Episode Step": 102}
{"Training time": 12.062094672719638, "Episode Reward": -957.304742460808, "Mean Reward": -9.385340612360864, "Episode": 3676, "Episode Step": 102}
{"Training time": 12.064257541365095, "Episode Reward": 8949.383887290829, "Mean Reward": 48.90373708902092, "Episode": 3677, "Episode Step": 183}
{"Training time": 12.068622364997864, "Episode Reward": 15664.888615088325, "Mean Reward": 47.32594747760823, "Episode": 3678, "Episode Step": 331}
{"Training time": 12.069851064946917, "Episode Reward": -977.9867483340555, "Mean Reward": -9.588105375824073, "Episode": 3679, "Episode Step": 102}
{"Training time": 12.072817182739575, "Episode Reward": 16784.301063479823, "Mean Reward": 66.86972535250925, "Episode": 3680, "Episode Step": 251}
{"Training time": 12.077055590815014, "Episode Reward": 11413.967417347125, "Mean Reward": 35.44710378058113, "Episode": 3681, "Episode Step": 322}
{"Training time": 12.078274739980698, "Episode Reward": -1093.8187388423007, "Mean Reward": -10.72371312590491, "Episode": 3682, "Episode Step": 102}
{"Training time": 12.079483312500848, "Episode Reward": 5991.649597906886, "Mean Reward": 58.74166272457731, "Episode": 3683, "Episode Step": 102}
{"Training time": 12.083837195502387, "Episode Reward": 15074.135060718861, "Mean Reward": 45.2676728550116, "Episode": 3684, "Episode Step": 333}
{"Training time": 12.085045439402263, "Episode Reward": -892.3370230954831, "Mean Reward": -8.748402187210619, "Episode": 3685, "Episode Step": 102}
{"Training time": 12.086263296339247, "Episode Reward": 5954.961992016077, "Mean Reward": 58.381980313883105, "Episode": 3686, "Episode Step": 102}
{"Training time": 12.087961855795648, "Episode Reward": 33.33512323962946, "Mean Reward": 0.32681493372185744, "Episode": 3687, "Episode Step": 102}
{"Training time": 12.089191903339492, "Episode Reward": -795.7817425138915, "Mean Reward": -7.801781789351877, "Episode": 3688, "Episode Step": 102}
{"Training time": 12.092248259981472, "Episode Reward": 14480.516447930175, "Mean Reward": 57.235242877194366, "Episode": 3689, "Episode Step": 253}
{"Training time": 12.093932701084348, "Episode Reward": -8.793272210098257, "Mean Reward": -0.08620855107939468, "Episode": 3690, "Episode Step": 102}
{"Training time": 12.095163109170066, "Episode Reward": -994.6851243572692, "Mean Reward": -9.75181494467911, "Episode": 3691, "Episode Step": 102}
{"Training time": 12.096455759670999, "Episode Reward": 5941.8710928950495, "Mean Reward": 56.58924850376238, "Episode": 3692, "Episode Step": 105}
{"Training time": 12.097712699439791, "Episode Reward": -181.2794007520825, "Mean Reward": -2.746657587152765, "Episode": 3693, "Episode Step": 66}
{"Training time": 12.098942378295792, "Episode Reward": -785.761755898086, "Mean Reward": -7.703546626451823, "Episode": 3694, "Episode Step": 102}
{"Training time": 12.10714536746343, "Episode Reward": 45554.49300223412, "Mean Reward": 65.17094850105025, "Episode": 3695, "Episode Step": 699}
{"Training time": 12.1088243232833, "Episode Reward": -18.687459543702793, "Mean Reward": -0.18321038768336073, "Episode": 3696, "Episode Step": 102}
{"Training time": 12.110061806109217, "Episode Reward": -678.0100114180528, "Mean Reward": -6.6471569746867925, "Episode": 3697, "Episode Step": 102}
{"Training time": 12.11064778301451, "Episode Reward": 2581.1020047076977, "Mean Reward": 53.772958431410366, "Episode": 3698, "Episode Step": 48}
{"Training time": 12.112659283876418, "Episode Reward": 17.28940125242213, "Mean Reward": 0.1695039338472758, "Episode": 3699, "Episode Step": 102}
{"Training time": 12.114191537499428, "Episode Reward": -789.9891209194031, "Mean Reward": -7.744991381562776, "Episode": 3700, "Episode Step": 102}
{"Training time": 12.116274667779605, "Episode Reward": 9437.988587830581, "Mean Reward": 53.93136335903189, "Episode": 3701, "Episode Step": 175}
{"Training time": 12.117940570778316, "Episode Reward": -13.33889914183461, "Mean Reward": -0.13077352099837852, "Episode": 3702, "Episode Step": 102}
{"Training time": 12.119153755837017, "Episode Reward": -795.3597890266669, "Mean Reward": -7.797644990457519, "Episode": 3703, "Episode Step": 102}
{"Training time": 12.120385700530477, "Episode Reward": 6158.36846189255, "Mean Reward": 60.37616139110343, "Episode": 3704, "Episode Step": 102}
{"Training time": 12.121926564971606, "Episode Reward": -181.35739829554484, "Mean Reward": -2.0608795260857367, "Episode": 3705, "Episode Step": 88}
{"Training time": 12.123153725266457, "Episode Reward": -868.6659568061589, "Mean Reward": -8.516332909864303, "Episode": 3706, "Episode Step": 102}
{"Training time": 12.125328451395035, "Episode Reward": 8697.233575332219, "Mean Reward": 48.31796430740121, "Episode": 3707, "Episode Step": 180}
{"Training time": 12.126246238615778, "Episode Reward": -178.57917082431186, "Mean Reward": -4.826464076332753, "Episode": 3708, "Episode Step": 37}
{"Training time": 12.127487483289507, "Episode Reward": -989.856147713222, "Mean Reward": -9.704472036404137, "Episode": 3709, "Episode Step": 102}
{"Training time": 12.128975885775354, "Episode Reward": 6895.254222585945, "Mean Reward": 55.60688889182214, "Episode": 3710, "Episode Step": 124}
{"Training time": 12.129811825553576, "Episode Reward": -176.06875710851625, "Mean Reward": -5.868958570283875, "Episode": 3711, "Episode Step": 30}
{"Training time": 12.131024589406119, "Episode Reward": -707.6740555729349, "Mean Reward": -6.9379809369895575, "Episode": 3712, "Episode Step": 102}
{"Training time": 12.13345249944263, "Episode Reward": 9734.313095243255, "Mean Reward": 48.189668788332945, "Episode": 3713, "Episode Step": 202}
{"Training time": 12.135084817740653, "Episode Reward": 3178.989270171508, "Mean Reward": 32.773085259500085, "Episode": 3714, "Episode Step": 97}
{"Training time": 12.136314732498592, "Episode Reward": -786.4884473998202, "Mean Reward": -7.710671052939413, "Episode": 3715, "Episode Step": 102}
{"Training time": 12.137792986896303, "Episode Reward": 6365.605175331852, "Mean Reward": 51.752887604323995, "Episode": 3716, "Episode Step": 123}
{"Training time": 12.138648244407442, "Episode Reward": -179.53212438801154, "Mean Reward": -5.610378887125361, "Episode": 3717, "Episode Step": 32}
{"Training time": 12.139860732489161, "Episode Reward": -933.33272978692, "Mean Reward": -9.150320880263921, "Episode": 3718, "Episode Step": 102}
{"Training time": 12.146967922184203, "Episode Reward": 36730.02122910238, "Mean Reward": 61.42144018244545, "Episode": 3719, "Episode Step": 598}
{"Training time": 12.147832654449674, "Episode Reward": -178.48196324697915, "Mean Reward": -5.577561351468098, "Episode": 3720, "Episode Step": 32}
{"Training time": 12.149064495828416, "Episode Reward": 3.01052485206363, "Mean Reward": 0.02951494953003559, "Episode": 3721, "Episode Step": 102}
{"Training time": 12.150365205539597, "Episode Reward": 6045.3793912507945, "Mean Reward": 56.49887281542799, "Episode": 3722, "Episode Step": 107}
{"Training time": 12.151409632762274, "Episode Reward": -179.52985859274042, "Mean Reward": -3.740205387348759, "Episode": 3723, "Episode Step": 48}
{"Training time": 12.152650901940135, "Episode Reward": -1127.0718636739762, "Mean Reward": -11.049724153666434, "Episode": 3724, "Episode Step": 102}
{"Training time": 12.154147938291231, "Episode Reward": 6835.298781443124, "Mean Reward": 55.123377269702615, "Episode": 3725, "Episode Step": 124}
{"Training time": 12.155051659411853, "Episode Reward": -175.05127479761467, "Mean Reward": -4.731115535070667, "Episode": 3726, "Episode Step": 37}
{"Training time": 12.156265021893713, "Episode Reward": -1153.6020753217003, "Mean Reward": -11.309824267859808, "Episode": 3727, "Episode Step": 102}
{"Training time": 12.15776974360148, "Episode Reward": 6655.012478533603, "Mean Reward": 52.401673059319705, "Episode": 3728, "Episode Step": 127}
{"Training time": 12.158639744122823, "Episode Reward": -177.277880603328, "Mean Reward": -5.214055311862587, "Episode": 3729, "Episode Step": 34}
{"Training time": 12.159840749435954, "Episode Reward": -964.1793396660531, "Mean Reward": -9.452738624176991, "Episode": 3730, "Episode Step": 102}
{"Training time": 12.161336098843151, "Episode Reward": 6660.137348215404, "Mean Reward": 54.591289739470525, "Episode": 3731, "Episode Step": 122}
{"Training time": 12.162258953319656, "Episode Reward": -178.56250246482955, "Mean Reward": -4.578525704226399, "Episode": 3732, "Episode Step": 39}
{"Training time": 12.16350515305996, "Episode Reward": -697.7324644319467, "Mean Reward": -6.840514357175948, "Episode": 3733, "Episode Step": 102}
{"Training time": 12.1690792924828, "Episode Reward": 27552.058213799508, "Mean Reward": 58.00433308168317, "Episode": 3734, "Episode Step": 475}
{"Training time": 12.17000805079937, "Episode Reward": -177.77569066545084, "Mean Reward": -4.558351042703868, "Episode": 3735, "Episode Step": 39}
{"Training time": 12.171242848303583, "Episode Reward": -597.7543123958969, "Mean Reward": -5.860336396038205, "Episode": 3736, "Episode Step": 102}
{"Training time": 12.17415356748634, "Episode Reward": 15346.197310814458, "Mean Reward": 63.153075353145915, "Episode": 3737, "Episode Step": 243}
{"Training time": 12.175096167723337, "Episode Reward": -176.8221252907149, "Mean Reward": -4.533900648479869, "Episode": 3738, "Episode Step": 39}
{"Training time": 12.176309690276781, "Episode Reward": -1198.8448045684977, "Mean Reward": -11.753380436946056, "Episode": 3739, "Episode Step": 102}
{"Training time": 12.17788070499897, "Episode Reward": 6447.513994600996, "Mean Reward": 48.84480298940149, "Episode": 3740, "Episode Step": 132}
{"Training time": 12.179344903561804, "Episode Reward": -178.43981629235853, "Mean Reward": -2.1242835272899825, "Episode": 3741, "Episode Step": 84}
{"Training time": 12.18057237883409, "Episode Reward": -913.3254144467622, "Mean Reward": -8.954170729870219, "Episode": 3742, "Episode Step": 102}
{"Training time": 12.182120839423604, "Episode Reward": 6450.798640744749, "Mean Reward": 49.24273771560877, "Episode": 3743, "Episode Step": 131}
{"Training time": 12.1837901643912, "Episode Reward": 22.230908222802828, "Mean Reward": 0.217950080615714, "Episode": 3744, "Episode Step": 102}
{"Training time": 12.185001132223341, "Episode Reward": -786.400520616412, "Mean Reward": -7.709809025651098, "Episode": 3745, "Episode Step": 102}
{"Training time": 12.188009438580936, "Episode Reward": 15747.313454392766, "Mean Reward": 62.242345669536626, "Episode": 3746, "Episode Step": 253}
{"Training time": 12.189668546054099, "Episode Reward": 19.42693255237523, "Mean Reward": 0.19046012306250226, "Episode": 3747, "Episode Step": 102}
{"Training time": 12.190883981055684, "Episode Reward": -843.1441393231086, "Mean Reward": -8.266119012971652, "Episode": 3748, "Episode Step": 102}
{"Training time": 12.195011392765576, "Episode Reward": 15468.657530420074, "Mean Reward": 62.12312261212881, "Episode": 3749, "Episode Step": 249}
{"Training time": 12.196698744164573, "Episode Reward": 11.53649052506918, "Mean Reward": 0.11310284828499195, "Episode": 3750, "Episode Step": 102}
{"Training time": 12.197915467222531, "Episode Reward": -785.3869564351477, "Mean Reward": -7.699872121913213, "Episode": 3751, "Episode Step": 102}
{"Training time": 12.200195718606313, "Episode Reward": 9709.551157572558, "Mean Reward": 50.57057894569041, "Episode": 3752, "Episode Step": 192}
{"Training time": 12.201863879958788, "Episode Reward": 18.075798789184, "Mean Reward": 0.17721371361945096, "Episode": 3753, "Episode Step": 102}
{"Training time": 12.203081834978528, "Episode Reward": -993.3168457443398, "Mean Reward": -9.73840044847392, "Episode": 3754, "Episode Step": 102}
{"Training time": 12.204526416659355, "Episode Reward": 6342.456136316919, "Mean Reward": 52.416992862123294, "Episode": 3755, "Episode Step": 121}
{"Training time": 12.20618319272995, "Episode Reward": 17.62400246954443, "Mean Reward": 0.17278433793671008, "Episode": 3756, "Episode Step": 102}
{"Training time": 12.207433980239761, "Episode Reward": -1005.3770258744645, "Mean Reward": -9.856637508573181, "Episode": 3757, "Episode Step": 102}
{"Training time": 12.214899298614926, "Episode Reward": 37662.7154576397, "Mean Reward": 59.404913971040536, "Episode": 3758, "Episode Step": 634}
{"Training time": 12.216556318004926, "Episode Reward": -4.274645517530922, "Mean Reward": -0.041908289387558056, "Episode": 3759, "Episode Step": 102}
{"Training time": 12.217780118584633, "Episode Reward": -1048.6396079063477, "Mean Reward": -10.280780469670075, "Episode": 3760, "Episode Step": 102}
{"Training time": 12.220672286086613, "Episode Reward": 17045.74934606712, "Mean Reward": 69.57448712680457, "Episode": 3761, "Episode Step": 245}
{"Training time": 12.222355847226249, "Episode Reward": 26.227455512726475, "Mean Reward": 0.25713191679143604, "Episode": 3762, "Episode Step": 102}
{"Training time": 12.223594459427728, "Episode Reward": -1145.5339147648988, "Mean Reward": -11.23072465455783, "Episode": 3763, "Episode Step": 102}
{"Training time": 12.234572782781388, "Episode Reward": 62474.73605161264, "Mean Reward": 66.74651287565453, "Episode": 3764, "Episode Step": 936}
{"Training time": 12.236247091359562, "Episode Reward": 31.26913457325786, "Mean Reward": 0.30656014287507705, "Episode": 3765, "Episode Step": 102}
{"Training time": 12.237508590552542, "Episode Reward": -812.8841972212667, "Mean Reward": -7.969452913933988, "Episode": 3766, "Episode Step": 102}
{"Training time": 12.25532395693991, "Episode Reward": 96301.26177835077, "Mean Reward": 64.07269579397922, "Episode": 3767, "Episode Step": 1503}
{"Training time": 12.2570088771979, "Episode Reward": 26.2860769906757, "Mean Reward": 0.25770663716348724, "Episode": 3768, "Episode Step": 102}
{"Training time": 12.258211263881789, "Episode Reward": -838.802246314233, "Mean Reward": -8.223551434453265, "Episode": 3769, "Episode Step": 102}
{"Training time": 12.25949700527721, "Episode Reward": 5865.783683056479, "Mean Reward": 56.40176618323538, "Episode": 3770, "Episode Step": 104}
{"Training time": 12.261149555775855, "Episode Reward": 7.464207903147392, "Mean Reward": 0.07317850885438619, "Episode": 3771, "Episode Step": 102}
{"Training time": 12.262354358302222, "Episode Reward": -932.9419503385195, "Mean Reward": -9.146489709201171, "Episode": 3772, "Episode Step": 102}
{"Training time": 12.268114758862389, "Episode Reward": 31991.34358218306, "Mean Reward": 65.556031930703, "Episode": 3773, "Episode Step": 488}
{"Training time": 12.269779665801261, "Episode Reward": 3.4170144433840934, "Mean Reward": 0.03350014160180484, "Episode": 3774, "Episode Step": 102}
{"Training time": 12.270982937481667, "Episode Reward": -1203.1096674205942, "Mean Reward": -11.795192817848962, "Episode": 3775, "Episode Step": 102}
{"Training time": 12.272458407481512, "Episode Reward": 6230.26161553132, "Mean Reward": 49.84209292425056, "Episode": 3776, "Episode Step": 125}
{"Training time": 12.274109678599569, "Episode Reward": 18.49146252707805, "Mean Reward": 0.18128884830468675, "Episode": 3777, "Episode Step": 102}
{"Training time": 12.275295413600073, "Episode Reward": -1519.960092071759, "Mean Reward": -14.901569530115284, "Episode": 3778, "Episode Step": 102}
{"Training time": 12.28857104188866, "Episode Reward": 76818.96544098653, "Mean Reward": 67.38505740437415, "Episode": 3779, "Episode Step": 1140}
{"Training time": 12.290225688285298, "Episode Reward": 22.587510610344665, "Mean Reward": 0.22144618245435946, "Episode": 3780, "Episode Step": 102}
{"Training time": 12.291424724393421, "Episode Reward": -974.6989128060554, "Mean Reward": -9.555871694177014, "Episode": 3781, "Episode Step": 102}
{"Training time": 12.294285421901279, "Episode Reward": 16612.31838172078, "Mean Reward": 67.80538114988073, "Episode": 3782, "Episode Step": 245}
{"Training time": 12.295960932506455, "Episode Reward": 12.151889702892634, "Mean Reward": 0.11913617355777091, "Episode": 3783, "Episode Step": 102}
{"Training time": 12.297173969679408, "Episode Reward": -1230.444475673806, "Mean Reward": -12.063181134056922, "Episode": 3784, "Episode Step": 102}
{"Training time": 12.30647498137421, "Episode Reward": 52348.78317165062, "Mean Reward": 64.94886249584444, "Episode": 3785, "Episode Step": 806}
{"Training time": 12.308133098284403, "Episode Reward": 12.949669806918907, "Mean Reward": 0.12695754712665594, "Episode": 3786, "Episode Step": 102}
{"Training time": 12.309344726337327, "Episode Reward": -701.981522588032, "Mean Reward": -6.882171790078745, "Episode": 3787, "Episode Step": 102}
{"Training time": 12.312267376383145, "Episode Reward": 14997.413467709512, "Mean Reward": 60.23057617554021, "Episode": 3788, "Episode Step": 249}
{"Training time": 12.313936253057586, "Episode Reward": 17.749514894491828, "Mean Reward": 0.17401485190678262, "Episode": 3789, "Episode Step": 102}
{"Training time": 12.315169836084047, "Episode Reward": -887.8331258388376, "Mean Reward": -8.70424633175331, "Episode": 3790, "Episode Step": 102}
{"Training time": 12.31786881022983, "Episode Reward": 13132.601201807118, "Mean Reward": 58.10885487525273, "Episode": 3791, "Episode Step": 226}
{"Training time": 12.319570873843299, "Episode Reward": 12.441636890676389, "Mean Reward": 0.12197683226153322, "Episode": 3792, "Episode Step": 102}
{"Training time": 12.320816836092208, "Episode Reward": -1343.1446450760204, "Mean Reward": -13.168084755647259, "Episode": 3793, "Episode Step": 102}
{"Training time": 12.32208781666226, "Episode Reward": 5969.504527298159, "Mean Reward": 58.52455418919764, "Episode": 3794, "Episode Step": 102}
{"Training time": 12.323804225259357, "Episode Reward": -0.5818294964637792, "Mean Reward": -0.005704210749644894, "Episode": 3795, "Episode Step": 102}
{"Training time": 12.325042005512449, "Episode Reward": -1170.571549187095, "Mean Reward": -11.476191658697008, "Episode": 3796, "Episode Step": 102}
{"Training time": 12.327077443334792, "Episode Reward": 9273.379761103442, "Mean Reward": 55.198689054187156, "Episode": 3797, "Episode Step": 168}
{"Training time": 12.328761784169409, "Episode Reward": 5.448840246222801, "Mean Reward": 0.05342000241394903, "Episode": 3798, "Episode Step": 102}
{"Training time": 12.331184219121933, "Episode Reward": -1096.4869028083758, "Mean Reward": -10.749871596160547, "Episode": 3799, "Episode Step": 102}
{"Training time": 12.338711519108879, "Episode Reward": 39752.33598518572, "Mean Reward": 64.63794469135888, "Episode": 3800, "Episode Step": 615}
{"Training time": 12.340408254729377, "Episode Reward": 8.648158028892459, "Mean Reward": 0.08478586302835744, "Episode": 3801, "Episode Step": 102}
{"Training time": 12.341637697484758, "Episode Reward": -1194.0158925717851, "Mean Reward": -11.70603816246848, "Episode": 3802, "Episode Step": 102}
{"Training time": 12.343714878029294, "Episode Reward": 8419.301490877402, "Mean Reward": 48.66648260622776, "Episode": 3803, "Episode Step": 173}
{"Training time": 12.345402718053924, "Episode Reward": 6.0944068418342825, "Mean Reward": 0.05974908668464983, "Episode": 3804, "Episode Step": 102}
{"Training time": 12.346628567179044, "Episode Reward": -1179.3910358490689, "Mean Reward": -11.562657214206558, "Episode": 3805, "Episode Step": 102}
{"Training time": 12.349653080834283, "Episode Reward": 15759.994958446521, "Mean Reward": 61.56248030643172, "Episode": 3806, "Episode Step": 256}
{"Training time": 12.351349301338196, "Episode Reward": -9.667641146475146, "Mean Reward": -0.09478079555367791, "Episode": 3807, "Episode Step": 102}
{"Training time": 12.352570257451799, "Episode Reward": -1358.3565165014868, "Mean Reward": -13.317220750014576, "Episode": 3808, "Episode Step": 102}
{"Training time": 12.354673005541166, "Episode Reward": 8676.23384312996, "Mean Reward": 49.01827030016926, "Episode": 3809, "Episode Step": 177}
{"Training time": 12.356358668340578, "Episode Reward": 8.70142024111491, "Mean Reward": 0.08530804157955794, "Episode": 3810, "Episode Step": 102}
{"Training time": 12.35757593995995, "Episode Reward": -1231.8028491722014, "Mean Reward": -12.076498521296092, "Episode": 3811, "Episode Step": 102}
{"Training time": 12.363278539114528, "Episode Reward": 30948.721456251824, "Mean Reward": 64.74627919717955, "Episode": 3812, "Episode Step": 478}
{"Training time": 12.364943415787485, "Episode Reward": 8.937786002351457, "Mean Reward": 0.08762535296422996, "Episode": 3813, "Episode Step": 102}
{"Training time": 12.366169599162207, "Episode Reward": -1448.2786268623988, "Mean Reward": -14.19881006727842, "Episode": 3814, "Episode Step": 102}
{"Training time": 12.389566518333224, "Episode Reward": 132888.87003394673, "Mean Reward": 66.37805696001335, "Episode": 3815, "Episode Step": 2002}
{"Training time": 12.39121147301462, "Episode Reward": 7.556332394578134, "Mean Reward": 0.07408169014292289, "Episode": 3816, "Episode Step": 102}
{"Training time": 12.39243075913853, "Episode Reward": -1439.6932902042406, "Mean Reward": -14.114640100041575, "Episode": 3817, "Episode Step": 102}
{"Training time": 12.394666016631657, "Episode Reward": 10098.476915006551, "Mean Reward": 53.14987850003448, "Episode": 3818, "Episode Step": 190}
{"Training time": 12.39633082303736, "Episode Reward": 27.924131613303977, "Mean Reward": 0.27376599620886255, "Episode": 3819, "Episode Step": 102}
{"Training time": 12.397563690543175, "Episode Reward": -1343.797218693381, "Mean Reward": -13.174482536209617, "Episode": 3820, "Episode Step": 102}
{"Training time": 12.408362213306956, "Episode Reward": 61245.379255237654, "Mean Reward": 65.9971759215923, "Episode": 3821, "Episode Step": 928}
{"Training time": 12.410014166368379, "Episode Reward": 27.47890635392424, "Mean Reward": 0.2694010426855318, "Episode": 3822, "Episode Step": 102}
{"Training time": 12.411204566889339, "Episode Reward": -1261.2588630091477, "Mean Reward": -12.365282970677919, "Episode": 3823, "Episode Step": 102}
{"Training time": 12.413241439395481, "Episode Reward": 9115.551122657405, "Mean Reward": 51.79290410600799, "Episode": 3824, "Episode Step": 176}
{"Training time": 12.414884148836135, "Episode Reward": 26.818442210924694, "Mean Reward": 0.2629259040286735, "Episode": 3825, "Episode Step": 102}
{"Training time": 12.416099219984478, "Episode Reward": -1217.7254144945707, "Mean Reward": -11.938484455829125, "Episode": 3826, "Episode Step": 102}
{"Training time": 12.423309002783563, "Episode Reward": 39156.127436028604, "Mean Reward": 64.29577575702562, "Episode": 3827, "Episode Step": 609}
{"Training time": 12.424977315531837, "Episode Reward": 18.21998885119276, "Mean Reward": 0.1786273416783604, "Episode": 3828, "Episode Step": 102}
{"Training time": 12.426177169945506, "Episode Reward": -1210.3653251744408, "Mean Reward": -11.866326717396479, "Episode": 3829, "Episode Step": 102}
{"Training time": 12.43958711915546, "Episode Reward": 75784.93542464735, "Mean Reward": 66.59484659459345, "Episode": 3830, "Episode Step": 1138}
{"Training time": 12.441292544404666, "Episode Reward": 19.755822842074817, "Mean Reward": 0.19368453766740018, "Episode": 3831, "Episode Step": 102}
{"Training time": 12.44254927582211, "Episode Reward": -1318.2740168467133, "Mean Reward": -12.92425506712464, "Episode": 3832, "Episode Step": 102}
{"Training time": 12.443809758292304, "Episode Reward": 159.2112160492546, "Mean Reward": 1.5608942749926922, "Episode": 3833, "Episode Step": 102}
{"Training time": 12.445498546097014, "Episode Reward": 6.964721458637673, "Mean Reward": 0.06828158292782031, "Episode": 3834, "Episode Step": 102}
{"Training time": 12.446749655803044, "Episode Reward": -1260.3758777444755, "Mean Reward": -12.356626252396818, "Episode": 3835, "Episode Step": 102}
{"Training time": 12.470074464413855, "Episode Reward": 128281.69693009077, "Mean Reward": 65.71808244369404, "Episode": 3836, "Episode Step": 1952}
{"Training time": 12.471759063601494, "Episode Reward": 3.6523143742140465, "Mean Reward": 0.03580700366876516, "Episode": 3837, "Episode Step": 102}
{"Training time": 12.472977386116982, "Episode Reward": -1240.6093568451622, "Mean Reward": -12.162836831815316, "Episode": 3838, "Episode Step": 102}
{"Training time": 12.482077229155434, "Episode Reward": 46113.89458625845, "Mean Reward": 59.96605277796938, "Episode": 3839, "Episode Step": 769}
{"Training time": 12.483755280243026, "Episode Reward": 14.993270310388313, "Mean Reward": 0.14699284618027758, "Episode": 3840, "Episode Step": 102}
{"Training time": 12.484987219704522, "Episode Reward": -1095.0045326772579, "Mean Reward": -10.735338555659391, "Episode": 3841, "Episode Step": 102}
{"Training time": 12.488832106060451, "Episode Reward": 16753.556011434583, "Mean Reward": 51.708506208131425, "Episode": 3842, "Episode Step": 324}
{"Training time": 12.490520662466684, "Episode Reward": 12.075402398342636, "Mean Reward": 0.11838629802296702, "Episode": 3843, "Episode Step": 102}
{"Training time": 12.491760397752126, "Episode Reward": 40.86892978046837, "Mean Reward": 0.4006757821614546, "Episode": 3844, "Episode Step": 102}
{"Training time": 12.49296604666445, "Episode Reward": 122.0420148303158, "Mean Reward": 1.1964903414736843, "Episode": 3845, "Episode Step": 102}
{"Training time": 12.494651860528522, "Episode Reward": 9.046791302707566, "Mean Reward": 0.08869403237948595, "Episode": 3846, "Episode Step": 102}
{"Training time": 12.495867305530442, "Episode Reward": -1304.171268077029, "Mean Reward": -12.785992824284598, "Episode": 3847, "Episode Step": 102}
{"Training time": 12.499261931909455, "Episode Reward": 14912.971386818273, "Mean Reward": 52.32621539234482, "Episode": 3848, "Episode Step": 285}
{"Training time": 12.502188213335144, "Episode Reward": 14.953243119158612, "Mean Reward": 0.14660042273684915, "Episode": 3849, "Episode Step": 102}
{"Training time": 12.503676324950325, "Episode Reward": -1172.7546911238544, "Mean Reward": -11.49759501101818, "Episode": 3850, "Episode Step": 102}
{"Training time": 12.506737914946344, "Episode Reward": 16030.457563337342, "Mean Reward": 60.95231012675796, "Episode": 3851, "Episode Step": 263}
{"Training time": 12.508376866910194, "Episode Reward": 11.090093639008513, "Mean Reward": 0.10872640822557365, "Episode": 3852, "Episode Step": 102}
{"Training time": 12.509587000542217, "Episode Reward": -35.606307079250804, "Mean Reward": -0.34908144195343926, "Episode": 3853, "Episode Step": 102}
{"Training time": 12.516799040502972, "Episode Reward": 38274.83975519543, "Mean Reward": 62.13448012207051, "Episode": 3854, "Episode Step": 616}
{"Training time": 12.518474136061139, "Episode Reward": 11.677799393523447, "Mean Reward": 0.11448822934826909, "Episode": 3855, "Episode Step": 102}
{"Training time": 12.519678251941999, "Episode Reward": -1112.9714261065394, "Mean Reward": -10.911484569671956, "Episode": 3856, "Episode Step": 102}
{"Training time": 12.521984447770649, "Episode Reward": 8951.626172564887, "Mean Reward": 45.9057752439225, "Episode": 3857, "Episode Step": 195}
{"Training time": 12.523647506369485, "Episode Reward": -7.513303388194942, "Mean Reward": -0.07365983713916609, "Episode": 3858, "Episode Step": 102}
{"Training time": 12.524841683308283, "Episode Reward": -1300.819473307457, "Mean Reward": -12.753132091249578, "Episode": 3859, "Episode Step": 102}
{"Training time": 12.532586431635751, "Episode Reward": 40367.89144698185, "Mean Reward": 60.61244962009287, "Episode": 3860, "Episode Step": 666}
{"Training time": 12.5342614780532, "Episode Reward": -89.6833540232264, "Mean Reward": -0.8792485688551608, "Episode": 3861, "Episode Step": 102}
{"Training time": 12.535481819974052, "Episode Reward": -1212.2657640846342, "Mean Reward": -11.884958471417981, "Episode": 3862, "Episode Step": 102}
{"Training time": 12.53779310690032, "Episode Reward": 8752.625408020427, "Mean Reward": 44.205178828385996, "Episode": 3863, "Episode Step": 198}
{"Training time": 12.539461361898317, "Episode Reward": -2.948779801845006, "Mean Reward": -0.028909605900441237, "Episode": 3864, "Episode Step": 102}
{"Training time": 12.540671851899889, "Episode Reward": -947.7402204803248, "Mean Reward": -9.291570789022792, "Episode": 3865, "Episode Step": 102}
{"Training time": 12.543355945282512, "Episode Reward": 8676.370153136791, "Mean Reward": 37.723348491899095, "Episode": 3866, "Episode Step": 230}
{"Training time": 12.54501064578692, "Episode Reward": -2.6063761770824616, "Mean Reward": -0.025552707618455506, "Episode": 3867, "Episode Step": 102}
{"Training time": 12.546206912464566, "Episode Reward": -1075.5225956328984, "Mean Reward": -10.544339172871553, "Episode": 3868, "Episode Step": 102}
{"Training time": 12.549513862729073, "Episode Reward": 15623.470941990288, "Mean Reward": 55.40237922691592, "Episode": 3869, "Episode Step": 282}
{"Training time": 12.551201744675636, "Episode Reward": -7.1922026524076905, "Mean Reward": -0.07051179070987931, "Episode": 3870, "Episode Step": 102}
{"Training time": 12.552443652749062, "Episode Reward": -913.6236569066481, "Mean Reward": -8.957094675555373, "Episode": 3871, "Episode Step": 102}
{"Training time": 12.560251842737198, "Episode Reward": 36555.080630867495, "Mean Reward": 55.47053206504931, "Episode": 3872, "Episode Step": 659}
{"Training time": 12.561932472189268, "Episode Reward": -18.82943019682888, "Mean Reward": -0.18460225683165568, "Episode": 3873, "Episode Step": 102}
{"Training time": 12.563160737488005, "Episode Reward": -635.2563036567008, "Mean Reward": -6.228002977026478, "Episode": 3874, "Episode Step": 102}
{"Training time": 12.564406499995126, "Episode Reward": 94.31516323125557, "Mean Reward": 0.9246584630515252, "Episode": 3875, "Episode Step": 102}
{"Training time": 12.566073097189268, "Episode Reward": -0.07705455516931548, "Mean Reward": -0.0007554368153854459, "Episode": 3876, "Episode Step": 102}
{"Training time": 12.567275148034096, "Episode Reward": -1136.6923701135, "Mean Reward": -11.144042844249999, "Episode": 3877, "Episode Step": 102}
{"Training time": 12.576046413845486, "Episode Reward": 45792.17793298909, "Mean Reward": 61.79781097569378, "Episode": 3878, "Episode Step": 741}
{"Training time": 12.577711951070361, "Episode Reward": -22.60485925333785, "Mean Reward": -0.22161626718958677, "Episode": 3879, "Episode Step": 102}
{"Training time": 12.5789314769374, "Episode Reward": -1028.337346331961, "Mean Reward": -10.081738689529029, "Episode": 3880, "Episode Step": 102}
{"Training time": 12.582146848307715, "Episode Reward": 16025.755813432117, "Mean Reward": 58.275475685207695, "Episode": 3881, "Episode Step": 275}
{"Training time": 12.583821530805693, "Episode Reward": 3.5549719672864324, "Mean Reward": 0.034852666345945416, "Episode": 3882, "Episode Step": 102}
{"Training time": 12.585014037754801, "Episode Reward": -1073.51311932706, "Mean Reward": -10.524638424775098, "Episode": 3883, "Episode Step": 102}
{"Training time": 12.587279419170486, "Episode Reward": 8280.463260672663, "Mean Reward": 42.90395471851121, "Episode": 3884, "Episode Step": 193}
{"Training time": 12.588946167164378, "Episode Reward": -4.557066432977025, "Mean Reward": -0.04467712189193161, "Episode": 3885, "Episode Step": 102}
{"Training time": 12.590149728589587, "Episode Reward": -900.4650327905185, "Mean Reward": -8.82808855676979, "Episode": 3886, "Episode Step": 102}
{"Training time": 12.594083178838094, "Episode Reward": 17145.63248036787, "Mean Reward": 51.02866809633294, "Episode": 3887, "Episode Step": 336}
{"Training time": 12.595773360530535, "Episode Reward": -10.102055410789083, "Mean Reward": -0.09903975892930474, "Episode": 3888, "Episode Step": 102}
{"Training time": 12.596972778836886, "Episode Reward": -957.2752185409354, "Mean Reward": -9.385051162166032, "Episode": 3889, "Episode Step": 102}
{"Training time": 12.5986504018969, "Episode Reward": 2678.349645405787, "Mean Reward": 18.72971780004047, "Episode": 3890, "Episode Step": 143}
{"Training time": 12.600302070511711, "Episode Reward": 1.2408234357291978, "Mean Reward": 0.0121649356444039, "Episode": 3891, "Episode Step": 102}
{"Training time": 12.601507586903042, "Episode Reward": -1045.0342234000852, "Mean Reward": -10.245433562745934, "Episode": 3892, "Episode Step": 102}
{"Training time": 12.60425480802854, "Episode Reward": 8565.110664138103, "Mean Reward": 36.139707443620686, "Episode": 3893, "Episode Step": 237}
{"Training time": 12.605886717504925, "Episode Reward": 1.253241946674432, "Mean Reward": 0.012286685751710118, "Episode": 3894, "Episode Step": 102}
{"Training time": 12.607083922757043, "Episode Reward": -983.9335949737414, "Mean Reward": -9.64640779386021, "Episode": 3895, "Episode Step": 102}
{"Training time": 12.609579122463861, "Episode Reward": 8679.667463574337, "Mean Reward": 41.135864756276476, "Episode": 3896, "Episode Step": 211}
{"Training time": 12.611255619393456, "Episode Reward": 1.0397591383084324, "Mean Reward": 0.010193717042239533, "Episode": 3897, "Episode Step": 102}
{"Training time": 12.612474098602931, "Episode Reward": -964.8373853843684, "Mean Reward": -9.459190052787926, "Episode": 3898, "Episode Step": 102}
{"Training time": 12.616450479427973, "Episode Reward": 8231.496975057005, "Mean Reward": 37.759160436041306, "Episode": 3899, "Episode Step": 218}
{"Training time": 12.618135353061888, "Episode Reward": -12.1987746665245, "Mean Reward": -0.11959583006396568, "Episode": 3900, "Episode Step": 102}
{"Training time": 12.619050103293525, "Episode Reward": -350.27660033716165, "Mean Reward": -4.549046757625476, "Episode": 3901, "Episode Step": 77}
{"Training time": 12.622805230816205, "Episode Reward": 16372.033795237912, "Mean Reward": 51.0032205459125, "Episode": 3902, "Episode Step": 321}
{"Training time": 12.624486714402835, "Episode Reward": 0.18019366110350254, "Mean Reward": 0.0017666045206225739, "Episode": 3903, "Episode Step": 102}
{"Training time": 12.625534668564796, "Episode Reward": -527.4540251547387, "Mean Reward": -6.1331863390085894, "Episode": 3904, "Episode Step": 86}
{"Training time": 12.62884156551626, "Episode Reward": 16647.805646031175, "Mean Reward": 59.66955428685009, "Episode": 3905, "Episode Step": 279}
{"Training time": 12.630510204699304, "Episode Reward": -5.8054196747689595, "Mean Reward": -0.056915879164401564, "Episode": 3906, "Episode Step": 102}
{"Training time": 12.631714309387737, "Episode Reward": -1013.863080098752, "Mean Reward": -9.939834118615215, "Episode": 3907, "Episode Step": 102}
{"Training time": 12.6353525782956, "Episode Reward": 16500.056262889226, "Mean Reward": 53.05484328903288, "Episode": 3908, "Episode Step": 311}
{"Training time": 12.637024791902967, "Episode Reward": -23.174429449388292, "Mean Reward": -0.22720028871949305, "Episode": 3909, "Episode Step": 102}
{"Training time": 12.638210131923358, "Episode Reward": -816.6030203602189, "Mean Reward": -8.005911964315871, "Episode": 3910, "Episode Step": 102}
{"Training time": 12.641690333618058, "Episode Reward": 14819.633829916895, "Mean Reward": 50.578955050910906, "Episode": 3911, "Episode Step": 293}
{"Training time": 12.643384328020943, "Episode Reward": -15.107077215590252, "Mean Reward": -0.1481086001528456, "Episode": 3912, "Episode Step": 102}
{"Training time": 12.644604224960009, "Episode Reward": -961.8801500515567, "Mean Reward": -9.430197549525065, "Episode": 3913, "Episode Step": 102}
{"Training time": 12.648458618323009, "Episode Reward": 15744.193623653831, "Mean Reward": 48.147381112091225, "Episode": 3914, "Episode Step": 327}
{"Training time": 12.650120060775015, "Episode Reward": 4.513738652163968, "Mean Reward": 0.044252339727097724, "Episode": 3915, "Episode Step": 102}
{"Training time": 12.651336424946784, "Episode Reward": -1014.0706600220691, "Mean Reward": -9.941869215902639, "Episode": 3916, "Episode Step": 102}
{"Training time": 12.653988046116298, "Episode Reward": 9106.015203143928, "Mean Reward": 40.65185358546397, "Episode": 3917, "Episode Step": 224}
{"Training time": 12.655667101078564, "Episode Reward": -25.622262013254314, "Mean Reward": -0.2511986471887678, "Episode": 3918, "Episode Step": 102}
{"Training time": 12.656862488587697, "Episode Reward": -942.4447952201259, "Mean Reward": -9.239654855099273, "Episode": 3919, "Episode Step": 102}
{"Training time": 12.660536499155892, "Episode Reward": 16050.568745518121, "Mean Reward": 51.116460972987646, "Episode": 3920, "Episode Step": 314}
{"Training time": 12.662208361360761, "Episode Reward": -14.517850169964822, "Mean Reward": -0.14233186441141982, "Episode": 3921, "Episode Step": 102}
{"Training time": 12.663437310523458, "Episode Reward": -971.2379638324334, "Mean Reward": -9.521940821886602, "Episode": 3922, "Episode Step": 102}
{"Training time": 12.66584878332085, "Episode Reward": 9039.028268238746, "Mean Reward": 44.30896209920954, "Episode": 3923, "Episode Step": 204}
{"Training time": 12.667523518006007, "Episode Reward": -99.46954583556418, "Mean Reward": -0.9751916258388644, "Episode": 3924, "Episode Step": 102}
{"Training time": 12.668694368335936, "Episode Reward": -458.6872877067847, "Mean Reward": -4.777992580279007, "Episode": 3925, "Episode Step": 96}
{"Training time": 12.671547576387724, "Episode Reward": 15246.065211392975, "Mean Reward": 64.05909752686124, "Episode": 3926, "Episode Step": 238}
{"Training time": 12.673249979416529, "Episode Reward": -176.7166764206927, "Mean Reward": -1.732516435496987, "Episode": 3927, "Episode Step": 102}
{"Training time": 12.674472197228008, "Episode Reward": -697.4935959414537, "Mean Reward": -6.838172509229938, "Episode": 3928, "Episode Step": 102}
{"Training time": 12.67737796690729, "Episode Reward": 16404.433928856164, "Mean Reward": 66.68469076770799, "Episode": 3929, "Episode Step": 246}
{"Training time": 12.679049442741606, "Episode Reward": -48.224893278634006, "Mean Reward": -0.47279307135915694, "Episode": 3930, "Episode Step": 102}
{"Training time": 12.680244347784255, "Episode Reward": -644.2120288572465, "Mean Reward": -6.378336919378679, "Episode": 3931, "Episode Step": 101}
{"Training time": 12.683312281635072, "Episode Reward": 15567.980179856486, "Mean Reward": 60.10803158245747, "Episode": 3932, "Episode Step": 259}
{"Training time": 12.685000319944487, "Episode Reward": -195.0834517492578, "Mean Reward": -1.912582860286841, "Episode": 3933, "Episode Step": 102}
{"Training time": 12.686232441067695, "Episode Reward": -888.9831809147606, "Mean Reward": -8.715521381517261, "Episode": 3934, "Episode Step": 102}
{"Training time": 12.689164447784425, "Episode Reward": 15750.78091061778, "Mean Reward": 64.02756467730805, "Episode": 3935, "Episode Step": 246}
{"Training time": 12.690873224139214, "Episode Reward": -295.04472522689514, "Mean Reward": -2.892595345361717, "Episode": 3936, "Episode Step": 102}
{"Training time": 12.69213334388203, "Episode Reward": -911.4865134370127, "Mean Reward": -8.936142288598164, "Episode": 3937, "Episode Step": 102}
{"Training time": 12.6998793754975, "Episode Reward": 37246.376530586684, "Mean Reward": 56.778013003943116, "Episode": 3938, "Episode Step": 656}
{"Training time": 12.701567266053624, "Episode Reward": -227.02795910870552, "Mean Reward": -2.225764304987309, "Episode": 3939, "Episode Step": 102}
{"Training time": 12.70277786579397, "Episode Reward": -1095.0939861166844, "Mean Reward": -10.736215550163573, "Episode": 3940, "Episode Step": 102}
{"Training time": 12.704986170795229, "Episode Reward": 7961.249414968118, "Mean Reward": 41.90131271035852, "Episode": 3941, "Episode Step": 190}
{"Training time": 12.706671888894505, "Episode Reward": -290.76392070023456, "Mean Reward": -2.8506266735317114, "Episode": 3942, "Episode Step": 102}
{"Training time": 12.707902912166384, "Episode Reward": -1073.4234892455843, "Mean Reward": -10.52375969848612, "Episode": 3943, "Episode Step": 102}
{"Training time": 12.70931990802288, "Episode Reward": 3520.344822996052, "Mean Reward": 28.855285434393867, "Episode": 3944, "Episode Step": 122}
{"Training time": 12.710977107750045, "Episode Reward": -298.18228451422016, "Mean Reward": -2.9233557305315703, "Episode": 3945, "Episode Step": 102}
{"Training time": 12.71219805194272, "Episode Reward": -1020.4521378794632, "Mean Reward": -10.004432724308463, "Episode": 3946, "Episode Step": 102}
{"Training time": 12.714587244987488, "Episode Reward": 7410.453448423737, "Mean Reward": 36.50469679026472, "Episode": 3947, "Episode Step": 203}
{"Training time": 12.716282851099969, "Episode Reward": -261.26670454986265, "Mean Reward": -2.561438279900614, "Episode": 3948, "Episode Step": 102}
{"Training time": 12.71894711110327, "Episode Reward": -819.1192689284285, "Mean Reward": -8.03058106792577, "Episode": 3949, "Episode Step": 102}
{"Training time": 12.722486254109276, "Episode Reward": 15061.011922709986, "Mean Reward": 55.37136736290436, "Episode": 3950, "Episode Step": 272}
{"Training time": 12.724146540562312, "Episode Reward": -342.3115109630931, "Mean Reward": -3.3559952055205207, "Episode": 3951, "Episode Step": 102}
{"Training time": 12.725371056927575, "Episode Reward": -1108.525069866573, "Mean Reward": -10.867892841829146, "Episode": 3952, "Episode Step": 102}
{"Training time": 12.727448393305142, "Episode Reward": 8640.781434932022, "Mean Reward": 49.375893913897265, "Episode": 3953, "Episode Step": 175}
{"Training time": 12.729094502197372, "Episode Reward": -239.4977539431219, "Mean Reward": -2.3480171955208027, "Episode": 3954, "Episode Step": 102}
{"Training time": 12.73033249662982, "Episode Reward": -896.0676608433698, "Mean Reward": -8.78497706709186, "Episode": 3955, "Episode Step": 102}
{"Training time": 12.733127276102701, "Episode Reward": 9813.706078020401, "Mean Reward": 41.58350033059492, "Episode": 3956, "Episode Step": 236}
{"Training time": 12.734804845783446, "Episode Reward": -191.42932500057765, "Mean Reward": -1.8767580882409574, "Episode": 3957, "Episode Step": 102}
{"Training time": 12.73603035138713, "Episode Reward": -1083.8306804021893, "Mean Reward": -10.62579098433519, "Episode": 3958, "Episode Step": 102}
{"Training time": 12.737323104672962, "Episode Reward": 4517.755962039472, "Mean Reward": 41.8310737225877, "Episode": 3959, "Episode Step": 108}
{"Training time": 12.739038261108929, "Episode Reward": -347.0668356846249, "Mean Reward": -3.4026160361237734, "Episode": 3960, "Episode Step": 102}
{"Training time": 12.740262304676904, "Episode Reward": -1126.1711124578096, "Mean Reward": -11.040893259390291, "Episode": 3961, "Episode Step": 102}
{"Training time": 12.747852216362952, "Episode Reward": 34947.66209037444, "Mean Reward": 53.76563398519145, "Episode": 3962, "Episode Step": 650}
{"Training time": 12.749519745839967, "Episode Reward": -372.7182272026702, "Mean Reward": -3.6541002666928453, "Episode": 3963, "Episode Step": 102}
{"Training time": 12.750728618303935, "Episode Reward": -953.2073860661382, "Mean Reward": -9.345170451628805, "Episode": 3964, "Episode Step": 102}
{"Training time": 12.752949976921082, "Episode Reward": 8119.510197425837, "Mean Reward": 43.18888402886083, "Episode": 3965, "Episode Step": 188}
{"Training time": 12.754621460504001, "Episode Reward": -344.68986059214205, "Mean Reward": -3.379312358746491, "Episode": 3966, "Episode Step": 102}
{"Training time": 12.755825575523906, "Episode Reward": -1027.5320381524439, "Mean Reward": -10.073843511298469, "Episode": 3967, "Episode Step": 102}
{"Training time": 12.757114700277647, "Episode Reward": 4843.463495229525, "Mean Reward": 44.43544491036261, "Episode": 3968, "Episode Step": 109}
{"Training time": 12.75878053413497, "Episode Reward": -338.1033850190646, "Mean Reward": -3.314739068814359, "Episode": 3969, "Episode Step": 102}
{"Training time": 12.75999276386367, "Episode Reward": -892.3749558678348, "Mean Reward": -8.748774077135636, "Episode": 3970, "Episode Step": 102}
{"Training time": 12.762208742764262, "Episode Reward": 7876.808154747494, "Mean Reward": 41.67623362300262, "Episode": 3971, "Episode Step": 189}
{"Training time": 12.763862825234732, "Episode Reward": -330.5214242148262, "Mean Reward": -3.240406119753198, "Episode": 3972, "Episode Step": 102}
{"Training time": 12.765063625507885, "Episode Reward": -678.5665218133039, "Mean Reward": -6.652612958953959, "Episode": 3973, "Episode Step": 102}
{"Training time": 12.76744888133473, "Episode Reward": 8396.77294465819, "Mean Reward": 41.3634135204837, "Episode": 3974, "Episode Step": 203}
{"Training time": 12.769112136363983, "Episode Reward": -314.5202262705661, "Mean Reward": -3.0835316301035895, "Episode": 3975, "Episode Step": 102}
{"Training time": 12.770327028036117, "Episode Reward": -767.185208084973, "Mean Reward": -7.521423608676207, "Episode": 3976, "Episode Step": 102}
{"Training time": 12.771629705561532, "Episode Reward": 5238.629399961726, "Mean Reward": 47.6239036360157, "Episode": 3977, "Episode Step": 110}
{"Training time": 12.773283886379666, "Episode Reward": -358.2331187043585, "Mean Reward": -3.5120893990623383, "Episode": 3978, "Episode Step": 102}
{"Training time": 12.774493671655655, "Episode Reward": -991.7993965908947, "Mean Reward": -9.723523495989165, "Episode": 3979, "Episode Step": 102}
{"Training time": 12.775326892733574, "Episode Reward": -415.13188352420303, "Mean Reward": -6.01640410904642, "Episode": 3980, "Episode Step": 69}
{"Training time": 12.77699178914229, "Episode Reward": -301.95318518294147, "Mean Reward": -2.9603253449307987, "Episode": 3981, "Episode Step": 102}
{"Training time": 12.778201994962162, "Episode Reward": -622.1205871298397, "Mean Reward": -6.099221442449409, "Episode": 3982, "Episode Step": 102}
{"Training time": 12.779629566934373, "Episode Reward": 5259.555871081472, "Mean Reward": 43.829632259012264, "Episode": 3983, "Episode Step": 120}
{"Training time": 12.781278312206268, "Episode Reward": -283.9475498629639, "Mean Reward": -2.7837995084604303, "Episode": 3984, "Episode Step": 102}
{"Training time": 12.782510203586684, "Episode Reward": -854.2833943065092, "Mean Reward": -8.375327395161856, "Episode": 3985, "Episode Step": 102}
{"Training time": 12.783921092483732, "Episode Reward": 5335.059768336894, "Mean Reward": 45.21237091810927, "Episode": 3986, "Episode Step": 118}
{"Training time": 12.785592056380377, "Episode Reward": -320.97953982756763, "Mean Reward": -3.1468582336036044, "Episode": 3987, "Episode Step": 102}
{"Training time": 12.78680378443665, "Episode Reward": -1021.9184777852413, "Mean Reward": -10.018808605737659, "Episode": 3988, "Episode Step": 102}
{"Training time": 12.787703443831868, "Episode Reward": -373.59652642790576, "Mean Reward": -4.915743768788234, "Episode": 3989, "Episode Step": 76}
{"Training time": 12.789360015789669, "Episode Reward": -257.789454355525, "Mean Reward": -2.527347591720833, "Episode": 3990, "Episode Step": 102}
{"Training time": 12.790590736932225, "Episode Reward": -848.4317837414933, "Mean Reward": -8.317958664132288, "Episode": 3991, "Episode Step": 102}
{"Training time": 12.792940272490183, "Episode Reward": 8187.7026192998055, "Mean Reward": 41.56194222994825, "Episode": 3992, "Episode Step": 197}
{"Training time": 12.794519912468063, "Episode Reward": -257.23840994261377, "Mean Reward": -2.5219451955158214, "Episode": 3993, "Episode Step": 102}
{"Training time": 12.79574815167321, "Episode Reward": -697.4748405534845, "Mean Reward": -6.837988632877298, "Episode": 3994, "Episode Step": 102}
{"Training time": 12.797820126083161, "Episode Reward": 8452.248182545252, "Mean Reward": 48.024137400825296, "Episode": 3995, "Episode Step": 176}
{"Training time": 12.799466730819809, "Episode Reward": -296.581890227102, "Mean Reward": -2.9076655904617845, "Episode": 3996, "Episode Step": 102}
{"Training time": 12.800694996913274, "Episode Reward": -840.2978728429188, "Mean Reward": -8.238214439636458, "Episode": 3997, "Episode Step": 102}
{"Training time": 12.823463473055098, "Episode Reward": 124695.37798049452, "Mean Reward": 63.23295029436842, "Episode": 3998, "Episode Step": 1972}
{"Training time": 12.826534605224927, "Episode Reward": -359.1131997177969, "Mean Reward": -3.520717644292126, "Episode": 3999, "Episode Step": 102}
{"Training time": 12.828035440246264, "Episode Reward": -900.2073018793972, "Mean Reward": -8.825561783131345, "Episode": 4000, "Episode Step": 102}
{"Training time": 12.830104439722167, "Episode Reward": 8325.58352025231, "Mean Reward": 47.574762972870346, "Episode": 4001, "Episode Step": 175}
{"Training time": 12.831795035004616, "Episode Reward": -307.82890971869165, "Mean Reward": -3.0179304874381536, "Episode": 4002, "Episode Step": 102}
{"Training time": 12.833057951662276, "Episode Reward": -846.8847175437851, "Mean Reward": -8.302791348468482, "Episode": 4003, "Episode Step": 102}
{"Training time": 12.835129536059167, "Episode Reward": 8344.21994448603, "Mean Reward": 47.95528703727604, "Episode": 4004, "Episode Step": 174}
{"Training time": 12.836840552753872, "Episode Reward": -312.4345422963495, "Mean Reward": -3.0630837480034265, "Episode": 4005, "Episode Step": 102}
{"Training time": 12.838055476612515, "Episode Reward": -858.8408112356309, "Mean Reward": -8.420007953290499, "Episode": 4006, "Episode Step": 102}
{"Training time": 12.84022497832775, "Episode Reward": 8337.56925162134, "Mean Reward": 45.56048771377782, "Episode": 4007, "Episode Step": 183}
{"Training time": 12.841899301608404, "Episode Reward": -240.9389655543568, "Mean Reward": -2.362146721121145, "Episode": 4008, "Episode Step": 102}
{"Training time": 12.843109018868871, "Episode Reward": -883.9803518852535, "Mean Reward": -8.66647403809072, "Episode": 4009, "Episode Step": 102}
{"Training time": 12.845138190256225, "Episode Reward": 8389.939076679186, "Mean Reward": 49.35258280399521, "Episode": 4010, "Episode Step": 170}
{"Training time": 12.846838616927466, "Episode Reward": -271.31081152859207, "Mean Reward": -2.659909916946981, "Episode": 4011, "Episode Step": 102}
{"Training time": 12.8480705685748, "Episode Reward": -815.8533199844488, "Mean Reward": -7.998561960631851, "Episode": 4012, "Episode Step": 102}
{"Training time": 12.850149521893925, "Episode Reward": 8688.96016050446, "Mean Reward": 49.36909182104807, "Episode": 4013, "Episode Step": 176}
{"Training time": 12.851819551653332, "Episode Reward": -287.11749296555416, "Mean Reward": -2.814877382015237, "Episode": 4014, "Episode Step": 102}
{"Training time": 12.853022940225072, "Episode Reward": -852.1056158570233, "Mean Reward": -8.353976626049247, "Episode": 4015, "Episode Step": 102}
{"Training time": 12.855042343338331, "Episode Reward": 8203.41639005418, "Mean Reward": 47.418591850024164, "Episode": 4016, "Episode Step": 173}
{"Training time": 12.857815094126595, "Episode Reward": 5359.747812532731, "Mean Reward": 27.34565210475883, "Episode": 4017, "Episode Step": 196}
{"Training time": 12.859087425801489, "Episode Reward": -695.5480372707766, "Mean Reward": -6.819098404615457, "Episode": 4018, "Episode Step": 102}
{"Training time": 12.862318944997257, "Episode Reward": 15434.705745620842, "Mean Reward": 56.954633747678386, "Episode": 4019, "Episode Step": 271}
{"Training time": 12.864010619984732, "Episode Reward": -214.0323683429143, "Mean Reward": -2.098356552381513, "Episode": 4020, "Episode Step": 102}
{"Training time": 12.865230243603389, "Episode Reward": -842.3674931847565, "Mean Reward": -8.258504835144672, "Episode": 4021, "Episode Step": 102}
{"Training time": 12.867347977227634, "Episode Reward": 7632.372605978798, "Mean Reward": 42.87849778639774, "Episode": 4022, "Episode Step": 178}
{"Training time": 12.869041044976976, "Episode Reward": -265.936217747084, "Mean Reward": -2.607217821049843, "Episode": 4023, "Episode Step": 102}
{"Training time": 12.870267266631126, "Episode Reward": -847.9567931079088, "Mean Reward": -8.313301893214792, "Episode": 4024, "Episode Step": 102}
{"Training time": 12.873772248890665, "Episode Reward": 18706.871089562046, "Mean Reward": 63.62881322980288, "Episode": 4025, "Episode Step": 294}
{"Training time": 12.875448792444335, "Episode Reward": -318.3227132833366, "Mean Reward": -3.1208109145425156, "Episode": 4026, "Episode Step": 102}
{"Training time": 12.876673283047147, "Episode Reward": -795.3086621035484, "Mean Reward": -7.797143746113219, "Episode": 4027, "Episode Step": 102}
{"Training time": 12.883466400239202, "Episode Reward": 34330.607635391294, "Mean Reward": 59.498453440886124, "Episode": 4028, "Episode Step": 577}
{"Training time": 12.88515742805269, "Episode Reward": -325.9937701719132, "Mean Reward": -3.1345554824222424, "Episode": 4029, "Episode Step": 104}
{"Training time": 12.88637464357747, "Episode Reward": -797.4924348677495, "Mean Reward": -7.818553283017152, "Episode": 4030, "Episode Step": 102}
{"Training time": 12.90414416856236, "Episode Reward": 93878.06788545252, "Mean Reward": 61.84325947658269, "Episode": 4031, "Episode Step": 1518}
{"Training time": 12.905806141893068, "Episode Reward": -226.09839885184044, "Mean Reward": -2.216650969135691, "Episode": 4032, "Episode Step": 102}
{"Training time": 12.907004827194744, "Episode Reward": -910.6539500995667, "Mean Reward": -8.92797990293693, "Episode": 4033, "Episode Step": 102}
{"Training time": 12.919474379950099, "Episode Reward": 64307.70552713608, "Mean Reward": 59.71003298712728, "Episode": 4034, "Episode Step": 1077}
{"Training time": 12.921138846940465, "Episode Reward": -203.66168703827051, "Mean Reward": -1.9966832062575541, "Episode": 4035, "Episode Step": 102}
{"Training time": 12.922335047192044, "Episode Reward": -746.3464134650396, "Mean Reward": -7.317121700637643, "Episode": 4036, "Episode Step": 102}
{"Training time": 12.936233676340844, "Episode Reward": 76007.13563727083, "Mean Reward": 63.55111675357092, "Episode": 4037, "Episode Step": 1196}
{"Training time": 12.93790224995878, "Episode Reward": -193.8972893579262, "Mean Reward": -1.9009538172345708, "Episode": 4038, "Episode Step": 102}
{"Training time": 12.93910519666142, "Episode Reward": -838.7183558263905, "Mean Reward": -8.222728978690103, "Episode": 4039, "Episode Step": 102}
{"Training time": 12.941193640563224, "Episode Reward": 8412.745516462406, "Mean Reward": 47.262615261024756, "Episode": 4040, "Episode Step": 178}
{"Training time": 12.942865822182762, "Episode Reward": -331.86213943453515, "Mean Reward": -3.2535503866130897, "Episode": 4041, "Episode Step": 102}
{"Training time": 12.944079242481125, "Episode Reward": -788.3164002985011, "Mean Reward": -7.728592159789226, "Episode": 4042, "Episode Step": 102}
{"Training time": 12.947772966093487, "Episode Reward": 17864.320585319565, "Mean Reward": 57.25743777346015, "Episode": 4043, "Episode Step": 312}
{"Training time": 12.949434952470991, "Episode Reward": -195.58628369926413, "Mean Reward": -1.9175125852869033, "Episode": 4044, "Episode Step": 102}
{"Training time": 12.950624374945958, "Episode Reward": -863.741628721199, "Mean Reward": -8.468055183541168, "Episode": 4045, "Episode Step": 102}
{"Training time": 12.952835408581628, "Episode Reward": 8558.598578493586, "Mean Reward": 45.76790683686409, "Episode": 4046, "Episode Step": 187}
{"Training time": 12.95453203883436, "Episode Reward": -314.43661090474524, "Mean Reward": -3.0827118716151496, "Episode": 4047, "Episode Step": 102}
{"Training time": 12.955769639942382, "Episode Reward": -810.9837690774749, "Mean Reward": -7.95082126546544, "Episode": 4048, "Episode Step": 102}
{"Training time": 12.975136758022838, "Episode Reward": 100520.0089984409, "Mean Reward": 61.7444772717696, "Episode": 4049, "Episode Step": 1628}
{"Training time": 12.976828781896167, "Episode Reward": -338.9763457430006, "Mean Reward": -3.3232975072843196, "Episode": 4050, "Episode Step": 102}
{"Training time": 12.97805249247286, "Episode Reward": -1002.2706509641758, "Mean Reward": -9.826182852589959, "Episode": 4051, "Episode Step": 102}
{"Training time": 12.985764653616481, "Episode Reward": 37358.49314537068, "Mean Reward": 57.65199559470784, "Episode": 4052, "Episode Step": 648}
{"Training time": 12.98744433025519, "Episode Reward": -345.3909571186571, "Mean Reward": -3.3861858541044816, "Episode": 4053, "Episode Step": 102}
{"Training time": 12.98865828666422, "Episode Reward": -741.9937045159662, "Mean Reward": -7.274448083489865, "Episode": 4054, "Episode Step": 102}
{"Training time": 12.99569741083516, "Episode Reward": 34401.51049329179, "Mean Reward": 57.14536626792656, "Episode": 4055, "Episode Step": 602}
{"Training time": 12.997365707755089, "Episode Reward": -458.7082472331869, "Mean Reward": -4.497139678756734, "Episode": 4056, "Episode Step": 102}
{"Training time": 12.998579563299815, "Episode Reward": -672.4674939494812, "Mean Reward": -6.592818568132168, "Episode": 4057, "Episode Step": 102}
{"Training time": 13.02819499525759, "Episode Reward": 166217.68421563663, "Mean Reward": 65.8287858279749, "Episode": 4058, "Episode Step": 2525}
{"Training time": 13.02987137582567, "Episode Reward": -264.15295140898724, "Mean Reward": -2.589734817735169, "Episode": 4059, "Episode Step": 102}
{"Training time": 13.03107739885648, "Episode Reward": -689.7254657017564, "Mean Reward": -6.762014369625063, "Episode": 4060, "Episode Step": 102}
{"Training time": 13.043952224122153, "Episode Reward": 65059.40056632624, "Mean Reward": 58.9840440311208, "Episode": 4061, "Episode Step": 1103}
{"Training time": 13.045644649134742, "Episode Reward": -264.99902590321506, "Mean Reward": -2.523800246697286, "Episode": 4062, "Episode Step": 105}
{"Training time": 13.046851336095068, "Episode Reward": -651.4148694188372, "Mean Reward": -6.386420288419973, "Episode": 4063, "Episode Step": 102}
{"Training time": 13.08518382747968, "Episode Reward": 196054.64470778694, "Mean Reward": 59.518714240372475, "Episode": 4064, "Episode Step": 3294}
{"Training time": 13.086843076613214, "Episode Reward": -317.9830338672651, "Mean Reward": -3.1174807241888733, "Episode": 4065, "Episode Step": 102}
{"Training time": 13.088058410220675, "Episode Reward": -709.2935651828595, "Mean Reward": -6.953858482184898, "Episode": 4066, "Episode Step": 102}
{"Training time": 13.09397795524862, "Episode Reward": 30425.77033507125, "Mean Reward": 60.1299808993503, "Episode": 4067, "Episode Step": 506}
{"Training time": 13.095698670546215, "Episode Reward": 2233.572055226784, "Mean Reward": 20.681222733581333, "Episode": 4068, "Episode Step": 108}
{"Training time": 13.096883252461751, "Episode Reward": -684.4386934084031, "Mean Reward": -6.710183268709834, "Episode": 4069, "Episode Step": 102}
{"Training time": 13.102671963572503, "Episode Reward": 32057.211099001062, "Mean Reward": 64.89313987652037, "Episode": 4070, "Episode Step": 494}
{"Training time": 13.104773782491684, "Episode Reward": 2499.579727043596, "Mean Reward": 18.37926269884997, "Episode": 4071, "Episode Step": 136}
{"Training time": 13.106018934117424, "Episode Reward": -709.2779379163652, "Mean Reward": -6.953705273689855, "Episode": 4072, "Episode Step": 102}
{"Training time": 13.109044300516446, "Episode Reward": 16634.935705213833, "Mean Reward": 65.75073401270289, "Episode": 4073, "Episode Step": 253}
{"Training time": 13.111817179719607, "Episode Reward": 5463.69356065195, "Mean Reward": 27.734485079451524, "Episode": 4074, "Episode Step": 197}
{"Training time": 13.113025020559629, "Episode Reward": -678.866037587561, "Mean Reward": -6.655549388113343, "Episode": 4075, "Episode Step": 102}
{"Training time": 13.115218508044878, "Episode Reward": 8683.38951558585, "Mean Reward": 46.93724062478838, "Episode": 4076, "Episode Step": 185}
{"Training time": 13.116877171330982, "Episode Reward": -331.50156940039136, "Mean Reward": -3.2500153862783465, "Episode": 4077, "Episode Step": 102}
{"Training time": 13.118110972775353, "Episode Reward": -688.8209849314507, "Mean Reward": -6.753146911092654, "Episode": 4078, "Episode Step": 102}
{"Training time": 13.128860887487729, "Episode Reward": 58187.63020610552, "Mean Reward": 63.45434046467341, "Episode": 4079, "Episode Step": 917}
{"Training time": 13.130532982216941, "Episode Reward": -430.11165717037073, "Mean Reward": -4.216780952650693, "Episode": 4080, "Episode Step": 102}
{"Training time": 13.131742700272136, "Episode Reward": -432.7903076484387, "Mean Reward": -4.243042231847438, "Episode": 4081, "Episode Step": 102}
{"Training time": 13.135771524972386, "Episode Reward": 21615.177084336483, "Mean Reward": 62.2915766119207, "Episode": 4082, "Episode Step": 347}
{"Training time": 13.13742806163099, "Episode Reward": -430.4459705816454, "Mean Reward": -4.220058535114171, "Episode": 4083, "Episode Step": 102}
{"Training time": 13.138657380276257, "Episode Reward": -620.9951633501512, "Mean Reward": -6.088187875981874, "Episode": 4084, "Episode Step": 102}
{"Training time": 13.145957361393505, "Episode Reward": 35895.03796867024, "Mean Reward": 57.34031624388218, "Episode": 4085, "Episode Step": 626}
{"Training time": 13.147604264418284, "Episode Reward": -296.40512752983346, "Mean Reward": -2.9059326228415046, "Episode": 4086, "Episode Step": 102}
{"Training time": 13.148834367195764, "Episode Reward": -725.9706496722667, "Mean Reward": -7.117359310512419, "Episode": 4087, "Episode Step": 102}
{"Training time": 13.151016229722234, "Episode Reward": 8019.4711130719215, "Mean Reward": 42.88487226241669, "Episode": 4088, "Episode Step": 187}
{"Training time": 13.152682771616512, "Episode Reward": -355.59331222537173, "Mean Reward": -3.4862089433859973, "Episode": 4089, "Episode Step": 102}
{"Training time": 13.153891790509224, "Episode Reward": -704.8095865326804, "Mean Reward": -6.909897907183142, "Episode": 4090, "Episode Step": 102}
{"Training time": 13.155483217769198, "Episode Reward": 6009.049908955402, "Mean Reward": 44.84365603698061, "Episode": 4091, "Episode Step": 134}
{"Training time": 13.157143002748489, "Episode Reward": -366.9456969644014, "Mean Reward": -3.5975068329843274, "Episode": 4092, "Episode Step": 102}
{"Training time": 13.158354812728033, "Episode Reward": -723.774893427019, "Mean Reward": -7.095832288500187, "Episode": 4093, "Episode Step": 102}
{"Training time": 13.161432286103567, "Episode Reward": 14671.783722954846, "Mean Reward": 57.53640675668567, "Episode": 4094, "Episode Step": 255}
{"Training time": 13.16314952664905, "Episode Reward": -318.63699787574217, "Mean Reward": -3.123892136036688, "Episode": 4095, "Episode Step": 102}
{"Training time": 13.164399410552448, "Episode Reward": -610.983942533515, "Mean Reward": -5.990038652289363, "Episode": 4096, "Episode Step": 102}
{"Training time": 13.167287883294954, "Episode Reward": 14288.695486562461, "Mean Reward": 59.28919289030067, "Episode": 4097, "Episode Step": 241}
{"Training time": 13.168993599679736, "Episode Reward": -130.43798388413495, "Mean Reward": -1.2788037635699505, "Episode": 4098, "Episode Step": 102}
{"Training time": 13.170553618338372, "Episode Reward": -729.2159049384469, "Mean Reward": -7.149175538612225, "Episode": 4099, "Episode Step": 102}
{"Training time": 13.173958166903919, "Episode Reward": 15157.99065400033, "Mean Reward": 58.52506044015571, "Episode": 4100, "Episode Step": 259}
{"Training time": 13.17565407190058, "Episode Reward": -217.00702521442904, "Mean Reward": -2.127519855043422, "Episode": 4101, "Episode Step": 102}
{"Training time": 13.176894707745976, "Episode Reward": -641.5655726420528, "Mean Reward": -6.289858555314242, "Episode": 4102, "Episode Step": 102}
{"Training time": 13.188126616345512, "Episode Reward": 60843.40162342095, "Mean Reward": 63.911136159055616, "Episode": 4103, "Episode Step": 952}
{"Training time": 13.189782373574046, "Episode Reward": -445.2110820806591, "Mean Reward": -4.36481453020254, "Episode": 4104, "Episode Step": 102}
{"Training time": 13.191012387739287, "Episode Reward": -703.7698967783464, "Mean Reward": -6.8997048703759445, "Episode": 4105, "Episode Step": 102}
{"Training time": 13.19319527109464, "Episode Reward": 8509.095711057616, "Mean Reward": 46.75327313767921, "Episode": 4106, "Episode Step": 182}
{"Training time": 13.194905096358724, "Episode Reward": -290.3131965899796, "Mean Reward": -2.8462078097056827, "Episode": 4107, "Episode Step": 102}
{"Training time": 13.19615524219142, "Episode Reward": -815.4747381067159, "Mean Reward": -7.994850373595254, "Episode": 4108, "Episode Step": 102}
{"Training time": 13.199252245227497, "Episode Reward": 15286.60442924809, "Mean Reward": 59.48095108656844, "Episode": 4109, "Episode Step": 257}
{"Training time": 13.200943661332131, "Episode Reward": -135.01865790163507, "Mean Reward": -1.3237123323689712, "Episode": 4110, "Episode Step": 102}
{"Training time": 13.202174469696152, "Episode Reward": -768.4743225753343, "Mean Reward": -7.53406198603269, "Episode": 4111, "Episode Step": 102}
{"Training time": 13.2063148188591, "Episode Reward": 21163.81684114198, "Mean Reward": 59.95415535734272, "Episode": 4112, "Episode Step": 353}
{"Training time": 13.208026542199983, "Episode Reward": -180.84011444482135, "Mean Reward": -1.7729422984786407, "Episode": 4113, "Episode Step": 102}
{"Training time": 13.209253455268012, "Episode Reward": -855.1578795523802, "Mean Reward": -8.383900779925296, "Episode": 4114, "Episode Step": 102}
{"Training time": 13.211398520535893, "Episode Reward": 7870.299043472543, "Mean Reward": 43.00709859821062, "Episode": 4115, "Episode Step": 183}
{"Training time": 13.213056074447103, "Episode Reward": -345.0299033907011, "Mean Reward": -3.3826461116735405, "Episode": 4116, "Episode Step": 102}
{"Training time": 13.214237111343278, "Episode Reward": -636.8991762259294, "Mean Reward": -6.244109570842445, "Episode": 4117, "Episode Step": 102}
{"Training time": 13.220117342207168, "Episode Reward": 30140.098692422394, "Mean Reward": 60.159877629585615, "Episode": 4118, "Episode Step": 501}
{"Training time": 13.22179897778564, "Episode Reward": -169.09748798971756, "Mean Reward": -1.6578185097031133, "Episode": 4119, "Episode Step": 102}
{"Training time": 13.223045562505723, "Episode Reward": -742.400417423722, "Mean Reward": -7.278435464938451, "Episode": 4120, "Episode Step": 102}
{"Training time": 13.230460825562478, "Episode Reward": 36160.12939120779, "Mean Reward": 56.94508565544534, "Episode": 4121, "Episode Step": 635}
{"Training time": 13.23212467054526, "Episode Reward": -239.13940833704373, "Mean Reward": -2.3445040033043503, "Episode": 4122, "Episode Step": 102}
{"Training time": 13.233328074150615, "Episode Reward": -661.356498717621, "Mean Reward": -6.483887242329618, "Episode": 4123, "Episode Step": 102}
{"Training time": 13.23923617972268, "Episode Reward": 28567.077307687312, "Mean Reward": 56.45667452112117, "Episode": 4124, "Episode Step": 506}
{"Training time": 13.240904897782539, "Episode Reward": -272.8606341450648, "Mean Reward": -2.6751042563241647, "Episode": 4125, "Episode Step": 102}
{"Training time": 13.242139554156198, "Episode Reward": -729.6159731032116, "Mean Reward": -7.153097775521682, "Episode": 4126, "Episode Step": 102}
{"Training time": 13.252785928050677, "Episode Reward": 54189.134566528795, "Mean Reward": 59.02955835133856, "Episode": 4127, "Episode Step": 918}
{"Training time": 13.254431112209955, "Episode Reward": -211.4615871736017, "Mean Reward": -2.0731528154274677, "Episode": 4128, "Episode Step": 102}
{"Training time": 13.255635941624641, "Episode Reward": -888.7456477294357, "Mean Reward": -8.71319262479839, "Episode": 4129, "Episode Step": 102}
{"Training time": 13.258680412504408, "Episode Reward": 15042.447686288631, "Mean Reward": 58.530924849372106, "Episode": 4130, "Episode Step": 257}
{"Training time": 13.26033556467957, "Episode Reward": -84.32551797426815, "Mean Reward": -0.8267207644536093, "Episode": 4131, "Episode Step": 102}
{"Training time": 13.261554363833534, "Episode Reward": -955.9958457216804, "Mean Reward": -9.372508291389025, "Episode": 4132, "Episode Step": 102}
{"Training time": 13.271066364447275, "Episode Reward": 47410.167677864556, "Mean Reward": 58.10069568365754, "Episode": 4133, "Episode Step": 816}
{"Training time": 13.272729226085875, "Episode Reward": -264.03924764506564, "Mean Reward": -2.588620074951624, "Episode": 4134, "Episode Step": 102}
{"Training time": 13.273952131933637, "Episode Reward": -439.7934462952162, "Mean Reward": -4.311700453874669, "Episode": 4135, "Episode Step": 102}
{"Training time": 13.278707738055123, "Episode Reward": 24269.32535522834, "Mean Reward": 59.33820380251427, "Episode": 4136, "Episode Step": 409}
{"Training time": 13.280362578034401, "Episode Reward": -201.61143280689086, "Mean Reward": -1.9765826745773614, "Episode": 4137, "Episode Step": 102}
{"Training time": 13.281559851103358, "Episode Reward": -800.7008244893268, "Mean Reward": -7.850008083228694, "Episode": 4138, "Episode Step": 102}
{"Training time": 13.288931265804504, "Episode Reward": 36043.46631442577, "Mean Reward": 56.583149630181744, "Episode": 4139, "Episode Step": 637}
{"Training time": 13.290605263577568, "Episode Reward": -237.3560202414817, "Mean Reward": -2.3270198062890364, "Episode": 4140, "Episode Step": 102}
{"Training time": 13.29181933025519, "Episode Reward": -706.8702557855426, "Mean Reward": -6.9301005469170835, "Episode": 4141, "Episode Step": 102}
{"Training time": 13.294822263320286, "Episode Reward": 15124.785895402743, "Mean Reward": 58.62320114497187, "Episode": 4142, "Episode Step": 258}
{"Training time": 13.296486159960429, "Episode Reward": -202.11441629872635, "Mean Reward": -1.981513885281631, "Episode": 4143, "Episode Step": 102}
{"Training time": 13.297688080535995, "Episode Reward": -1051.3357669342877, "Mean Reward": -10.307213401316545, "Episode": 4144, "Episode Step": 102}
{"Training time": 13.299826970497767, "Episode Reward": 7890.709801809411, "Mean Reward": 42.884292401138104, "Episode": 4145, "Episode Step": 184}
{"Training time": 13.301473942465252, "Episode Reward": -168.99313381207594, "Mean Reward": -1.6567954295301563, "Episode": 4146, "Episode Step": 102}
{"Training time": 13.30268590523137, "Episode Reward": -1084.2612216017706, "Mean Reward": -10.630011976487946, "Episode": 4147, "Episode Step": 102}
{"Training time": 13.307413444121678, "Episode Reward": 21538.922541516848, "Mean Reward": 52.791476817443254, "Episode": 4148, "Episode Step": 408}
{"Training time": 13.30956814083788, "Episode Reward": -4.539299961318565, "Mean Reward": -0.044502940797240834, "Episode": 4149, "Episode Step": 102}
{"Training time": 13.31104856994417, "Episode Reward": -796.0774574925819, "Mean Reward": -7.804680955809626, "Episode": 4150, "Episode Step": 102}
{"Training time": 13.314098439415297, "Episode Reward": 15198.595997654355, "Mean Reward": 58.00990838799372, "Episode": 4151, "Episode Step": 262}
{"Training time": 13.315769625239902, "Episode Reward": -118.64941843064048, "Mean Reward": -1.1632295924572595, "Episode": 4152, "Episode Step": 102}
{"Training time": 13.316972366372744, "Episode Reward": -907.1314075087888, "Mean Reward": -8.893445171654792, "Episode": 4153, "Episode Step": 102}
{"Training time": 13.318695042729377, "Episode Reward": 5624.945024200803, "Mean Reward": 38.006385298654074, "Episode": 4154, "Episode Step": 148}
{"Training time": 13.320345068573952, "Episode Reward": -141.6061684237829, "Mean Reward": -1.3882957688606166, "Episode": 4155, "Episode Step": 102}
{"Training time": 13.321545694404179, "Episode Reward": -974.3815219778853, "Mean Reward": -9.552760019391032, "Episode": 4156, "Episode Step": 102}
{"Training time": 13.32906560745504, "Episode Reward": 34055.74671162872, "Mean Reward": 52.47418599634626, "Episode": 4157, "Episode Step": 649}
{"Training time": 13.330719904965825, "Episode Reward": -72.7486568588134, "Mean Reward": -0.7132221260667981, "Episode": 4158, "Episode Step": 102}
{"Training time": 13.33193046523465, "Episode Reward": -504.84033314213593, "Mean Reward": -4.9494150308052545, "Episode": 4159, "Episode Step": 102}
{"Training time": 13.333994447456465, "Episode Reward": 7486.8911204796095, "Mean Reward": 41.82620737698106, "Episode": 4160, "Episode Step": 179}
{"Training time": 13.33565943857034, "Episode Reward": 32.07606009853488, "Mean Reward": 0.3144711774366165, "Episode": 4161, "Episode Step": 102}
{"Training time": 13.336866919994355, "Episode Reward": -673.9385140038212, "Mean Reward": -6.607240333370796, "Episode": 4162, "Episode Step": 102}
{"Training time": 13.341824303865433, "Episode Reward": 22263.873373794388, "Mean Reward": 52.38558440892797, "Episode": 4163, "Episode Step": 425}
{"Training time": 13.343480861385663, "Episode Reward": -83.17390277043792, "Mean Reward": -0.8154304193180189, "Episode": 4164, "Episode Step": 102}
{"Training time": 13.344685346947776, "Episode Reward": -779.5209114630529, "Mean Reward": -7.642361877088754, "Episode": 4165, "Episode Step": 102}
{"Training time": 13.346808988849322, "Episode Reward": 8486.59000970082, "Mean Reward": 46.62961543791659, "Episode": 4166, "Episode Step": 182}
{"Training time": 13.34847593161795, "Episode Reward": 24.237770337434828, "Mean Reward": 0.23762519938661597, "Episode": 4167, "Episode Step": 102}
{"Training time": 13.349657772448328, "Episode Reward": -740.0146253566261, "Mean Reward": -7.255045346633589, "Episode": 4168, "Episode Step": 102}
{"Training time": 13.351773376332389, "Episode Reward": 8365.766913162033, "Mean Reward": 46.21970670255267, "Episode": 4169, "Episode Step": 181}
{"Training time": 13.353449350794156, "Episode Reward": -0.29033192427306054, "Mean Reward": -0.00284639141444177, "Episode": 4170, "Episode Step": 102}
{"Training time": 13.354656538565953, "Episode Reward": 49.28793083219377, "Mean Reward": 0.4832150081587625, "Episode": 4171, "Episode Step": 102}
{"Training time": 13.35681180609597, "Episode Reward": 7418.390865517554, "Mean Reward": 40.09941008387867, "Episode": 4172, "Episode Step": 185}
{"Training time": 13.358479668034448, "Episode Reward": 31.29973317938527, "Mean Reward": 0.3068601292096595, "Episode": 4173, "Episode Step": 102}
{"Training time": 13.359691384699609, "Episode Reward": -404.54068672195604, "Mean Reward": -3.9660851639407455, "Episode": 4174, "Episode Step": 102}
{"Training time": 13.372555540005367, "Episode Reward": 59106.02660367904, "Mean Reward": 53.683947868918295, "Episode": 4175, "Episode Step": 1101}
{"Training time": 13.374196031623416, "Episode Reward": -160.27157240429418, "Mean Reward": -1.5712899255322959, "Episode": 4176, "Episode Step": 102}
{"Training time": 13.37541192471981, "Episode Reward": -262.93834637979705, "Mean Reward": -2.5778269252921278, "Episode": 4177, "Episode Step": 102}
{"Training time": 13.377532971898715, "Episode Reward": 8946.973156359858, "Mean Reward": 50.26389413685313, "Episode": 4178, "Episode Step": 178}
{"Training time": 13.379220143556594, "Episode Reward": -667.2784539893089, "Mean Reward": -6.541945627346165, "Episode": 4179, "Episode Step": 102}
{"Training time": 13.380420268575351, "Episode Reward": -761.2675494816255, "Mean Reward": -7.463407347859073, "Episode": 4180, "Episode Step": 102}
{"Training time": 13.382480516367488, "Episode Reward": 8146.408585638808, "Mean Reward": 46.81844014734947, "Episode": 4181, "Episode Step": 174}
{"Training time": 13.384141668015056, "Episode Reward": -557.7622301761495, "Mean Reward": -5.468257158589701, "Episode": 4182, "Episode Step": 102}
{"Training time": 13.385352010793156, "Episode Reward": -692.9158205246013, "Mean Reward": -6.793292358084326, "Episode": 4183, "Episode Step": 102}
{"Training time": 13.385992896358172, "Episode Reward": 1643.0539090190396, "Mean Reward": 31.001017151302634, "Episode": 4184, "Episode Step": 53}
{"Training time": 13.3886278157764, "Episode Reward": 2988.3854533867348, "Mean Reward": 16.15343488317154, "Episode": 4185, "Episode Step": 185}
{"Training time": 13.38982781747977, "Episode Reward": -695.7200228483174, "Mean Reward": -6.820784537728602, "Episode": 4186, "Episode Step": 102}
{"Training time": 13.391938891940647, "Episode Reward": 6555.0704449528, "Mean Reward": 36.41705802751556, "Episode": 4187, "Episode Step": 180}
{"Training time": 13.395618309113715, "Episode Reward": 6881.6051509989165, "Mean Reward": 24.753975363305454, "Episode": 4188, "Episode Step": 278}
{"Training time": 13.396831590798167, "Episode Reward": -691.9639926669346, "Mean Reward": -6.783960712420927, "Episode": 4189, "Episode Step": 102}
{"Training time": 13.406332215269407, "Episode Reward": 44008.22224774809, "Mean Reward": 54.130654671276865, "Episode": 4190, "Episode Step": 813}
{"Training time": 13.408695632484225, "Episode Reward": 3907.6279481822316, "Mean Reward": 24.121160173964395, "Episode": 4191, "Episode Step": 162}
{"Training time": 13.409903886053296, "Episode Reward": -820.8494916706179, "Mean Reward": -8.04754403598645, "Episode": 4192, "Episode Step": 102}
{"Training time": 13.412597246368726, "Episode Reward": 10835.696276833207, "Mean Reward": 48.158650119258695, "Episode": 4193, "Episode Step": 225}
{"Training time": 13.414274856646855, "Episode Reward": -386.3144733082211, "Mean Reward": -3.7873967971394227, "Episode": 4194, "Episode Step": 102}
{"Training time": 13.415485916932424, "Episode Reward": -845.4075297561058, "Mean Reward": -8.288309115255938, "Episode": 4195, "Episode Step": 102}
{"Training time": 13.41898919582367, "Episode Reward": 17322.516480807124, "Mean Reward": 58.12924993559437, "Episode": 4196, "Episode Step": 298}
{"Training time": 13.420916310813691, "Episode Reward": 2172.395406700208, "Mean Reward": 17.519317795969418, "Episode": 4197, "Episode Step": 124}
{"Training time": 13.422172588573561, "Episode Reward": -1002.7233460848679, "Mean Reward": -9.830621040047724, "Episode": 4198, "Episode Step": 102}
{"Training time": 13.424862393008338, "Episode Reward": 8219.946331367675, "Mean Reward": 43.03636822705589, "Episode": 4199, "Episode Step": 191}
{"Training time": 13.430055948297182, "Episode Reward": 13297.386327910572, "Mean Reward": 33.326782776718225, "Episode": 4200, "Episode Step": 399}
{"Training time": 13.431259771386783, "Episode Reward": -925.6236360443752, "Mean Reward": -9.074741529846815, "Episode": 4201, "Episode Step": 102}
{"Training time": 13.43276076859898, "Episode Reward": 5937.8280965458725, "Mean Reward": 47.12561981385613, "Episode": 4202, "Episode Step": 126}
{"Training time": 13.434501605232557, "Episode Reward": -551.6795506205618, "Mean Reward": -5.462173768520414, "Episode": 4203, "Episode Step": 101}
{"Training time": 13.435708229144414, "Episode Reward": -1016.3790105762392, "Mean Reward": -9.96450010368862, "Episode": 4204, "Episode Step": 102}
{"Training time": 13.4372685444355, "Episode Reward": 6463.158803891515, "Mean Reward": 48.96332427190542, "Episode": 4205, "Episode Step": 132}
{"Training time": 13.438959307471912, "Episode Reward": -758.2315239998691, "Mean Reward": -7.433642392155579, "Episode": 4206, "Episode Step": 102}
{"Training time": 13.44019561999374, "Episode Reward": -774.1453274176783, "Mean Reward": -7.589660072722337, "Episode": 4207, "Episode Step": 102}
{"Training time": 13.443271017471949, "Episode Reward": 13432.905583284912, "Mean Reward": 51.86450032156336, "Episode": 4208, "Episode Step": 259}
{"Training time": 13.444930921660529, "Episode Reward": -1046.6158726125177, "Mean Reward": -10.260939927573704, "Episode": 4209, "Episode Step": 102}
{"Training time": 13.446139092180465, "Episode Reward": -760.9276355573337, "Mean Reward": -7.460074858405233, "Episode": 4210, "Episode Step": 102}
{"Training time": 13.448819466365709, "Episode Reward": 11302.696891721205, "Mean Reward": 49.79161626308901, "Episode": 4211, "Episode Step": 227}
{"Training time": 13.45048492471377, "Episode Reward": -163.15165808766923, "Mean Reward": -1.5995260596830316, "Episode": 4212, "Episode Step": 102}
{"Training time": 13.4516819843981, "Episode Reward": 76.01760973030595, "Mean Reward": 0.7452706836304505, "Episode": 4213, "Episode Step": 102}
{"Training time": 13.454777740240097, "Episode Reward": 14998.366367820267, "Mean Reward": 56.81199381750101, "Episode": 4214, "Episode Step": 264}
{"Training time": 13.456451079712973, "Episode Reward": -727.4708493017646, "Mean Reward": -7.1320671500173, "Episode": 4215, "Episode Step": 102}
{"Training time": 13.458614121344354, "Episode Reward": 2909.539833204605, "Mean Reward": 15.812716484807638, "Episode": 4216, "Episode Step": 184}
{"Training time": 13.468281099994977, "Episode Reward": 48235.21238639962, "Mean Reward": 58.89525321904715, "Episode": 4217, "Episode Step": 819}
{"Training time": 13.471297142505646, "Episode Reward": 4743.561839884792, "Mean Reward": 21.859731981035907, "Episode": 4218, "Episode Step": 217}
{"Training time": 13.47250657439232, "Episode Reward": 69.47995946977903, "Mean Reward": 0.6811760732331278, "Episode": 4219, "Episode Step": 102}
{"Training time": 13.479469949404399, "Episode Reward": 31727.11508883097, "Mean Reward": 53.41265166469861, "Episode": 4220, "Episode Step": 594}
{"Training time": 13.481138963301976, "Episode Reward": -651.17973504782, "Mean Reward": -6.384115049488432, "Episode": 4221, "Episode Step": 102}
{"Training time": 13.483185169696808, "Episode Reward": 2893.813673637205, "Mean Reward": 16.631113066880488, "Episode": 4222, "Episode Step": 174}
{"Training time": 13.487483397457336, "Episode Reward": 18509.29952395871, "Mean Reward": 51.55793739264265, "Episode": 4223, "Episode Step": 359}
{"Training time": 13.490515449444453, "Episode Reward": 5104.512865566733, "Mean Reward": 24.07789087531478, "Episode": 4224, "Episode Step": 212}
{"Training time": 13.492634380526013, "Episode Reward": 4419.617667517509, "Mean Reward": 24.829312738862413, "Episode": 4225, "Episode Step": 178}
{"Training time": 13.499555703600247, "Episode Reward": 35495.09153596961, "Mean Reward": 60.675370146956595, "Episode": 4226, "Episode Step": 585}
{"Training time": 13.501233586668969, "Episode Reward": -107.19027463254804, "Mean Reward": -1.0508850454171377, "Episode": 4227, "Episode Step": 102}
{"Training time": 13.502438224951426, "Episode Reward": 446.5243080758161, "Mean Reward": 4.335187457046758, "Episode": 4228, "Episode Step": 103}
{"Training time": 13.509322313865026, "Episode Reward": 34283.14702025452, "Mean Reward": 59.21096203843613, "Episode": 4229, "Episode Step": 579}
{"Training time": 13.511000632180108, "Episode Reward": -273.4142739571138, "Mean Reward": -2.6805320976187623, "Episode": 4230, "Episode Step": 102}
{"Training time": 13.513161532481512, "Episode Reward": 3842.6686826352725, "Mean Reward": 20.88406892736561, "Episode": 4231, "Episode Step": 184}
{"Training time": 13.51478304611312, "Episode Reward": 6813.171152589796, "Mean Reward": 49.370805453549245, "Episode": 4232, "Episode Step": 138}
{"Training time": 13.516421111358536, "Episode Reward": -205.48273738183488, "Mean Reward": -2.014536640998381, "Episode": 4233, "Episode Step": 102}
{"Training time": 13.518303196628889, "Episode Reward": 3759.788979732452, "Mean Reward": 23.498681123327824, "Episode": 4234, "Episode Step": 160}
{"Training time": 13.52044500556257, "Episode Reward": 8983.436772759898, "Mean Reward": 49.08981843038196, "Episode": 4235, "Episode Step": 183}
{"Training time": 13.52334549665451, "Episode Reward": 5118.779318408776, "Mean Reward": 24.969655211750126, "Episode": 4236, "Episode Step": 205}
{"Training time": 13.525688698026869, "Episode Reward": 3913.305156025982, "Mean Reward": 20.4885086702931, "Episode": 4237, "Episode Step": 191}
{"Training time": 13.527323747211032, "Episode Reward": 6607.763960613599, "Mean Reward": 48.58649971039411, "Episode": 4238, "Episode Step": 136}
{"Training time": 13.529002270499864, "Episode Reward": -282.27310191116925, "Mean Reward": -2.767383352070287, "Episode": 4239, "Episode Step": 102}
{"Training time": 13.532456559141478, "Episode Reward": 6509.928583656731, "Mean Reward": 22.52570444171879, "Episode": 4240, "Episode Step": 289}
{"Training time": 13.53472852051258, "Episode Reward": 8493.294461808375, "Mean Reward": 44.701549798991444, "Episode": 4241, "Episode Step": 190}
{"Training time": 13.536426981621318, "Episode Reward": -131.9503526435325, "Mean Reward": -1.2936309082699267, "Episode": 4242, "Episode Step": 102}
{"Training time": 13.538701407180891, "Episode Reward": 5142.560181127978, "Mean Reward": 26.78416761004155, "Episode": 4243, "Episode Step": 192}
{"Training time": 13.540892684989505, "Episode Reward": 9162.38703973247, "Mean Reward": 50.067688741707485, "Episode": 4244, "Episode Step": 183}
{"Training time": 13.542623942759302, "Episode Reward": -370.38095334415385, "Mean Reward": -3.6311858170995475, "Episode": 4245, "Episode Step": 102}
{"Training time": 13.544554091625743, "Episode Reward": 4689.610531579057, "Mean Reward": 28.770616758153725, "Episode": 4246, "Episode Step": 163}
{"Training time": 13.55686889661683, "Episode Reward": 64195.31927395136, "Mean Reward": 61.60779200955025, "Episode": 4247, "Episode Step": 1042}
{"Training time": 13.558561409976747, "Episode Reward": -101.82040944276424, "Mean Reward": -0.9982393082623946, "Episode": 4248, "Episode Step": 102}
{"Training time": 13.562055556111865, "Episode Reward": 4659.271261854834, "Mean Reward": 24.39409037620332, "Episode": 4249, "Episode Step": 191}
{"Training time": 13.564050558275646, "Episode Reward": 6290.305687021464, "Mean Reward": 43.98815165749276, "Episode": 4250, "Episode Step": 143}
{"Training time": 13.56574206855562, "Episode Reward": -109.8057828317359, "Mean Reward": -1.0765272826640775, "Episode": 4251, "Episode Step": 102}
{"Training time": 13.56828440606594, "Episode Reward": 4938.864730420558, "Mean Reward": 22.865114492687766, "Episode": 4252, "Episode Step": 216}
{"Training time": 13.569977365003691, "Episode Reward": 5837.646170605089, "Mean Reward": 41.11018430003583, "Episode": 4253, "Episode Step": 142}
{"Training time": 13.571662089692222, "Episode Reward": -188.98031206635915, "Mean Reward": -1.852748157513325, "Episode": 4254, "Episode Step": 102}
{"Training time": 13.573833712471856, "Episode Reward": 4232.419622759275, "Mean Reward": 23.255052872303708, "Episode": 4255, "Episode Step": 182}
{"Training time": 13.575503193868531, "Episode Reward": 6672.758290383772, "Mean Reward": 48.353320944809944, "Episode": 4256, "Episode Step": 138}
{"Training time": 13.577179811928007, "Episode Reward": -830.4244956090469, "Mean Reward": -8.141416623618106, "Episode": 4257, "Episode Step": 102}
{"Training time": 13.58282901916239, "Episode Reward": 13560.043769092645, "Mean Reward": 28.132870890233704, "Episode": 4258, "Episode Step": 482}
{"Training time": 13.607554764416482, "Episode Reward": 129682.7506053314, "Mean Reward": 61.37375797696706, "Episode": 4259, "Episode Step": 2113}
{"Training time": 13.609242480529678, "Episode Reward": -1100.7181783097662, "Mean Reward": -10.791354689311433, "Episode": 4260, "Episode Step": 102}
{"Training time": 13.611535899440447, "Episode Reward": 5195.416876541224, "Mean Reward": 27.201135479273425, "Episode": 4261, "Episode Step": 191}
{"Training time": 13.61373331911034, "Episode Reward": 9153.269258412269, "Mean Reward": 48.68760243836313, "Episode": 4262, "Episode Step": 188}
{"Training time": 13.61541392551528, "Episode Reward": -1004.8735982940168, "Mean Reward": -9.851701944058988, "Episode": 4263, "Episode Step": 102}
{"Training time": 13.617523158589998, "Episode Reward": 6144.491932721302, "Mean Reward": 34.519617599557876, "Episode": 4264, "Episode Step": 178}
{"Training time": 13.62603084411886, "Episode Reward": 45028.58623076484, "Mean Reward": 61.59861317478091, "Episode": 4265, "Episode Step": 731}
{"Training time": 13.627720670832527, "Episode Reward": -708.2684798927032, "Mean Reward": -6.9438086263990515, "Episode": 4266, "Episode Step": 102}
{"Training time": 13.629200310839547, "Episode Reward": 3484.726470557936, "Mean Reward": 28.331109516731185, "Episode": 4267, "Episode Step": 123}
{"Training time": 13.631355752746265, "Episode Reward": 8645.166339207584, "Mean Reward": 47.763349940373395, "Episode": 4268, "Episode Step": 181}
{"Training time": 13.633052895797624, "Episode Reward": -786.0809053408705, "Mean Reward": -7.706675542557553, "Episode": 4269, "Episode Step": 102}
{"Training time": 13.634894937210612, "Episode Reward": 4503.913948549474, "Mean Reward": 29.437346068950813, "Episode": 4270, "Episode Step": 153}
{"Training time": 13.637165340781213, "Episode Reward": 8238.11008598036, "Mean Reward": 42.906823364481035, "Episode": 4271, "Episode Step": 192}
{"Training time": 13.638845770226585, "Episode Reward": -937.6011623132802, "Mean Reward": -9.192168257973336, "Episode": 4272, "Episode Step": 102}
{"Training time": 13.640597063038085, "Episode Reward": 4435.107436297811, "Mean Reward": 29.96694213714737, "Episode": 4273, "Episode Step": 148}
{"Training time": 13.648210715254148, "Episode Reward": 37281.00416497969, "Mean Reward": 57.4437660477345, "Episode": 4274, "Episode Step": 649}
{"Training time": 13.649862767193053, "Episode Reward": -945.6811189809591, "Mean Reward": -9.271383519421168, "Episode": 4275, "Episode Step": 102}
{"Training time": 13.651798703604275, "Episode Reward": 5222.496889940433, "Mean Reward": 31.65149630266929, "Episode": 4276, "Episode Step": 165}
{"Training time": 13.654072083301015, "Episode Reward": 8768.043810512943, "Mean Reward": 45.90598853671698, "Episode": 4277, "Episode Step": 191}
{"Training time": 13.655737622446484, "Episode Reward": -340.5927268369477, "Mean Reward": -3.339144380754389, "Episode": 4278, "Episode Step": 102}
{"Training time": 13.658646087447803, "Episode Reward": 8160.671300310932, "Mean Reward": 32.64268520124373, "Episode": 4279, "Episode Step": 250}
{"Training time": 13.661844366060363, "Episode Reward": 15987.787737777602, "Mean Reward": 58.34959028385986, "Episode": 4280, "Episode Step": 274}
{"Training time": 13.663527785274718, "Episode Reward": -378.7673897712113, "Mean Reward": -3.713405782070699, "Episode": 4281, "Episode Step": 102}
{"Training time": 13.665259625779258, "Episode Reward": 5503.595801679278, "Mean Reward": 37.955833115029506, "Episode": 4282, "Episode Step": 145}
{"Training time": 13.667434751391411, "Episode Reward": 8748.5495351479, "Mean Reward": 47.546464864934244, "Episode": 4283, "Episode Step": 184}
{"Training time": 13.669092054168383, "Episode Reward": -291.09758321075526, "Mean Reward": -2.8538978746152477, "Episode": 4284, "Episode Step": 102}
{"Training time": 13.670551666617394, "Episode Reward": 5121.915656070313, "Mean Reward": 40.975325248562505, "Episode": 4285, "Episode Step": 125}
{"Training time": 13.672847241626846, "Episode Reward": 9141.636898462606, "Mean Reward": 46.404248215546225, "Episode": 4286, "Episode Step": 197}
{"Training time": 13.676099553306898, "Episode Reward": 5833.050806542341, "Mean Reward": 24.612028719587936, "Episode": 4287, "Episode Step": 237}
{"Training time": 13.677537020511098, "Episode Reward": 4893.74460356052, "Mean Reward": 40.44417027735967, "Episode": 4288, "Episode Step": 121}
{"Training time": 13.683848658866353, "Episode Reward": 31510.656117574075, "Mean Reward": 59.6792729499509, "Episode": 4289, "Episode Step": 528}
{"Training time": 13.685517908003595, "Episode Reward": -399.35500255728437, "Mean Reward": -3.915245123110631, "Episode": 4290, "Episode Step": 102}
{"Training time": 13.689042398863368, "Episode Reward": 11175.388317396315, "Mean Reward": 37.62757009224349, "Episode": 4291, "Episode Step": 297}
{"Training time": 13.697455679443147, "Episode Reward": 41796.7151240779, "Mean Reward": 58.13173174419735, "Episode": 4292, "Episode Step": 719}
{"Training time": 13.699117813573944, "Episode Reward": -600.7145037454503, "Mean Reward": -5.889357879857356, "Episode": 4293, "Episode Step": 102}
{"Training time": 13.701792194710837, "Episode Reward": 7838.999850618343, "Mean Reward": 34.231440395713285, "Episode": 4294, "Episode Step": 229}
{"Training time": 13.71118104967806, "Episode Reward": 45534.964012403834, "Mean Reward": 56.4249863846392, "Episode": 4295, "Episode Step": 807}
{"Training time": 13.712849021951358, "Episode Reward": -239.59918153673522, "Mean Reward": -2.3490115836934824, "Episode": 4296, "Episode Step": 102}
{"Training time": 13.714064004421234, "Episode Reward": -1045.5125756855518, "Mean Reward": -10.250123291034821, "Episode": 4297, "Episode Step": 102}
{"Training time": 13.721463042762544, "Episode Reward": 38023.33502676251, "Mean Reward": 59.411460979316416, "Episode": 4298, "Episode Step": 640}
{"Training time": 13.724311468336317, "Episode Reward": -817.1401945234676, "Mean Reward": -8.011178377681055, "Episode": 4299, "Episode Step": 102}
{"Training time": 13.725817431343927, "Episode Reward": -991.6615102762773, "Mean Reward": -9.722171669375268, "Episode": 4300, "Episode Step": 102}
{"Training time": 13.72804110440943, "Episode Reward": 8630.616071357574, "Mean Reward": 45.90753229445518, "Episode": 4301, "Episode Step": 188}
{"Training time": 13.729709779156579, "Episode Reward": -301.65889149007785, "Mean Reward": -2.9574401126478223, "Episode": 4302, "Episode Step": 102}
{"Training time": 13.730916489693854, "Episode Reward": -1077.9616568273627, "Mean Reward": -10.568251537523164, "Episode": 4303, "Episode Step": 102}
{"Training time": 13.733208126094606, "Episode Reward": 8917.308197772982, "Mean Reward": 45.036910089762536, "Episode": 4304, "Episode Step": 198}
{"Training time": 13.734859069387118, "Episode Reward": -322.59877933350145, "Mean Reward": -3.1627331307206026, "Episode": 4305, "Episode Step": 102}
{"Training time": 13.736048818561766, "Episode Reward": -992.5039077090762, "Mean Reward": -9.730430467736042, "Episode": 4306, "Episode Step": 102}
{"Training time": 13.748938031660186, "Episode Reward": 60448.04656169832, "Mean Reward": 54.11642485380333, "Episode": 4307, "Episode Step": 1117}
{"Training time": 13.750587714976735, "Episode Reward": -293.72516130934116, "Mean Reward": -2.8796584442092272, "Episode": 4308, "Episode Step": 102}
{"Training time": 13.75179193192058, "Episode Reward": -1008.8174291427611, "Mean Reward": -9.89036695238001, "Episode": 4309, "Episode Step": 102}
{"Training time": 13.769908874167337, "Episode Reward": 87796.1292386328, "Mean Reward": 56.171547817423416, "Episode": 4310, "Episode Step": 1563}
{"Training time": 13.771564180519846, "Episode Reward": -265.30349257587517, "Mean Reward": -2.6010146330968156, "Episode": 4311, "Episode Step": 102}
{"Training time": 13.774883832203017, "Episode Reward": 7697.6518266223, "Mean Reward": 27.20018313294099, "Episode": 4312, "Episode Step": 283}
{"Training time": 13.777186980777316, "Episode Reward": 8922.114551177721, "Mean Reward": 45.520992608049596, "Episode": 4313, "Episode Step": 196}
{"Training time": 13.778872214688196, "Episode Reward": -176.68708644677264, "Mean Reward": -1.68273415663593, "Episode": 4314, "Episode Step": 105}
{"Training time": 13.780067919161585, "Episode Reward": 190.2206760435761, "Mean Reward": 1.8649085886625107, "Episode": 4315, "Episode Step": 102}
{"Training time": 13.783316253291236, "Episode Reward": 15511.47599078916, "Mean Reward": 54.810869225403394, "Episode": 4316, "Episode Step": 283}
{"Training time": 13.78496113717556, "Episode Reward": -149.23148832235628, "Mean Reward": -1.4630538070819243, "Episode": 4317, "Episode Step": 102}
{"Training time": 13.786153930823009, "Episode Reward": -334.29133597521127, "Mean Reward": -3.2773660389726595, "Episode": 4318, "Episode Step": 102}
{"Training time": 13.788322437736722, "Episode Reward": 8528.819107856363, "Mean Reward": 46.35227776008893, "Episode": 4319, "Episode Step": 184}
{"Training time": 13.78998458855682, "Episode Reward": -115.86354652387361, "Mean Reward": -1.1359171227830747, "Episode": 4320, "Episode Step": 102}
{"Training time": 13.791177430285348, "Episode Reward": -106.64616567011299, "Mean Reward": -1.0455506438246371, "Episode": 4321, "Episode Step": 102}
{"Training time": 13.803075425227483, "Episode Reward": 57845.95176754713, "Mean Reward": 56.767371705149294, "Episode": 4322, "Episode Step": 1019}
{"Training time": 13.806116024984254, "Episode Reward": 6434.080063200994, "Mean Reward": 29.24581846909543, "Episode": 4323, "Episode Step": 220}
{"Training time": 13.808344368007448, "Episode Reward": 8380.5079004878, "Mean Reward": 44.10793631835685, "Episode": 4324, "Episode Step": 190}
{"Training time": 13.820594144397312, "Episode Reward": 63273.839242720926, "Mean Reward": 60.26079927878183, "Episode": 4325, "Episode Step": 1050}
{"Training time": 13.822551528281636, "Episode Reward": 2629.316656680983, "Mean Reward": 20.382299664193667, "Episode": 4326, "Episode Step": 129}
{"Training time": 13.82403213971191, "Episode Reward": 6074.323015042855, "Mean Reward": 48.20891281780044, "Episode": 4327, "Episode Step": 126}
{"Training time": 13.835869910253418, "Episode Reward": 60486.380014567934, "Mean Reward": 59.651262341782974, "Episode": 4328, "Episode Step": 1014}
{"Training time": 13.837510726054509, "Episode Reward": -542.892160577372, "Mean Reward": -5.322472162523255, "Episode": 4329, "Episode Step": 102}
{"Training time": 13.838975729942321, "Episode Reward": 6012.411728226256, "Mean Reward": 48.09929382581005, "Episode": 4330, "Episode Step": 125}
{"Training time": 13.8432045388884, "Episode Reward": 20314.345393061754, "Mean Reward": 56.116976223927495, "Episode": 4331, "Episode Step": 362}
{"Training time": 13.844870719114938, "Episode Reward": -223.63496267665752, "Mean Reward": -2.1924996340848777, "Episode": 4332, "Episode Step": 102}
{"Training time": 13.84707632250256, "Episode Reward": 8593.192818352727, "Mean Reward": 45.46662866853295, "Episode": 4333, "Episode Step": 189}
{"Training time": 13.849443918863932, "Episode Reward": 8940.280818867386, "Mean Reward": 43.61112594569457, "Episode": 4334, "Episode Step": 205}
{"Training time": 13.851086882750193, "Episode Reward": -401.84735776710204, "Mean Reward": -3.9396799781088436, "Episode": 4335, "Episode Step": 102}
{"Training time": 13.852269427445199, "Episode Reward": -619.0352614279657, "Mean Reward": -6.068973151254565, "Episode": 4336, "Episode Step": 102}
{"Training time": 13.88156873471207, "Episode Reward": 147261.88220919645, "Mean Reward": 58.022806228997815, "Episode": 4337, "Episode Step": 2538}
{"Training time": 13.883220719165273, "Episode Reward": -517.7073577947881, "Mean Reward": -5.075562331321452, "Episode": 4338, "Episode Step": 102}
{"Training time": 13.884426767759853, "Episode Reward": -1096.7818488585986, "Mean Reward": -10.752763224103907, "Episode": 4339, "Episode Step": 102}
{"Training time": 13.885626168052356, "Episode Reward": 5051.977515739514, "Mean Reward": 49.529191330779554, "Episode": 4340, "Episode Step": 102}
{"Training time": 13.887309076918497, "Episode Reward": -571.9410330781092, "Mean Reward": -5.607265030177541, "Episode": 4341, "Episode Step": 102}
{"Training time": 13.88860596968068, "Episode Reward": 4416.016648322124, "Mean Reward": 40.14560589383749, "Episode": 4342, "Episode Step": 110}
{"Training time": 13.895013621648152, "Episode Reward": 34037.601498830874, "Mean Reward": 61.55081645358205, "Episode": 4343, "Episode Step": 553}
{"Training time": 13.89663414272997, "Episode Reward": -464.5921906635245, "Mean Reward": -4.554825398662005, "Episode": 4344, "Episode Step": 102}
{"Training time": 13.897825333277384, "Episode Reward": -934.9839282486332, "Mean Reward": -9.166509100476796, "Episode": 4345, "Episode Step": 102}
{"Training time": 13.901105014681816, "Episode Reward": 15496.072023691457, "Mean Reward": 54.75643824625956, "Episode": 4346, "Episode Step": 283}
{"Training time": 13.902750938865873, "Episode Reward": -619.0971803493547, "Mean Reward": -6.069580199503478, "Episode": 4347, "Episode Step": 102}
{"Training time": 13.903995172778766, "Episode Reward": -758.6036767186807, "Mean Reward": -7.43729094822236, "Episode": 4348, "Episode Step": 102}
{"Training time": 13.906398252182537, "Episode Reward": 4983.829847914517, "Mean Reward": 47.46504617061445, "Episode": 4349, "Episode Step": 105}
{"Training time": 13.908083315557903, "Episode Reward": -694.1927042641524, "Mean Reward": -6.805810826119141, "Episode": 4350, "Episode Step": 102}
{"Training time": 13.909313214156363, "Episode Reward": -1010.6627750688092, "Mean Reward": -9.908458579105973, "Episode": 4351, "Episode Step": 102}
{"Training time": 13.916304176913368, "Episode Reward": 30458.51195705656, "Mean Reward": 51.01928301014499, "Episode": 4352, "Episode Step": 597}
{"Training time": 13.917971862223414, "Episode Reward": -768.9961867451152, "Mean Reward": -7.539178301422698, "Episode": 4353, "Episode Step": 102}
{"Training time": 13.920228299697241, "Episode Reward": 7537.236425544144, "Mean Reward": 39.46197081436725, "Episode": 4354, "Episode Step": 191}
{"Training time": 13.921461673047807, "Episode Reward": 4326.715510270417, "Mean Reward": 42.418779512455075, "Episode": 4355, "Episode Step": 102}
{"Training time": 13.925955572724343, "Episode Reward": 11417.329745111696, "Mean Reward": 33.09370940612086, "Episode": 4356, "Episode Step": 345}
{"Training time": 13.928177822762066, "Episode Reward": 8265.331518150657, "Mean Reward": 43.273987006024385, "Episode": 4357, "Episode Step": 191}
{"Training time": 13.95218748860889, "Episode Reward": 120757.7888102595, "Mean Reward": 58.84882495626682, "Episode": 4358, "Episode Step": 2052}
{"Training time": 13.9538884702656, "Episode Reward": -189.28454394293647, "Mean Reward": -1.8557308229699654, "Episode": 4359, "Episode Step": 102}
{"Training time": 13.956945277783605, "Episode Reward": 12102.584068227192, "Mean Reward": 47.09176680244043, "Episode": 4360, "Episode Step": 257}
{"Training time": 13.963548363049824, "Episode Reward": 31297.26406847733, "Mean Reward": 56.18898396495032, "Episode": 4361, "Episode Step": 557}
{"Training time": 13.966608061393101, "Episode Reward": 6499.041349071681, "Mean Reward": 29.01357745121286, "Episode": 4362, "Episode Step": 224}
{"Training time": 13.974954286350144, "Episode Reward": 34246.241676260506, "Mean Reward": 48.03119449685906, "Episode": 4363, "Episode Step": 713}
{"Training time": 13.977236600518227, "Episode Reward": 8127.395241298575, "Mean Reward": 41.8937899036009, "Episode": 4364, "Episode Step": 194}
{"Training time": 13.978917125264804, "Episode Reward": -242.28676219439672, "Mean Reward": -2.375360413670556, "Episode": 4365, "Episode Step": 102}
{"Training time": 13.980322422186534, "Episode Reward": 4859.026747452587, "Mean Reward": 41.5301431406204, "Episode": 4366, "Episode Step": 117}
{"Training time": 13.982594321635034, "Episode Reward": 7653.0519544096, "Mean Reward": 39.85964559588333, "Episode": 4367, "Episode Step": 192}
{"Training time": 13.984264166355134, "Episode Reward": -392.0028560973314, "Mean Reward": -3.8431652558561904, "Episode": 4368, "Episode Step": 102}
{"Training time": 13.985463428033723, "Episode Reward": -852.1018358304877, "Mean Reward": -8.353939566965566, "Episode": 4369, "Episode Step": 102}
{"Training time": 13.989223870237668, "Episode Reward": 18760.2534097665, "Mean Reward": 58.26165655206988, "Episode": 4370, "Episode Step": 322}
{"Training time": 13.990890886651146, "Episode Reward": -296.28844237860653, "Mean Reward": -2.9047886507706524, "Episode": 4371, "Episode Step": 102}
{"Training time": 13.992086362772518, "Episode Reward": -1101.5774442275572, "Mean Reward": -10.799778864976052, "Episode": 4372, "Episode Step": 102}
{"Training time": 13.994436286621623, "Episode Reward": 8751.097977843665, "Mean Reward": 43.322267217047845, "Episode": 4373, "Episode Step": 202}
{"Training time": 13.996104856332144, "Episode Reward": -250.84621561118283, "Mean Reward": -2.4592766236390475, "Episode": 4374, "Episode Step": 102}
{"Training time": 13.99721776439084, "Episode Reward": 3874.6566616879454, "Mean Reward": 40.78585959671521, "Episode": 4375, "Episode Step": 95}
{"Training time": 13.99947651717398, "Episode Reward": 8199.711523289054, "Mean Reward": 42.485551934140176, "Episode": 4376, "Episode Step": 193}
{"Training time": 14.00207287384404, "Episode Reward": 4931.704284916815, "Mean Reward": 27.09727629075173, "Episode": 4377, "Episode Step": 182}
{"Training time": 14.003622752494282, "Episode Reward": 4934.871502614022, "Mean Reward": 36.82739927323897, "Episode": 4378, "Episode Step": 134}
{"Training time": 14.005824090507295, "Episode Reward": 8319.527346074286, "Mean Reward": 43.55773479620045, "Episode": 4379, "Episode Step": 191}
{"Training time": 14.007457513875432, "Episode Reward": -278.07611772742166, "Mean Reward": -2.7262364483080557, "Episode": 4380, "Episode Step": 102}
{"Training time": 14.010270052750906, "Episode Reward": 11407.296947572879, "Mean Reward": 48.13205463110919, "Episode": 4381, "Episode Step": 237}
{"Training time": 14.012594829996427, "Episode Reward": 8278.802180170103, "Mean Reward": 41.81213222308133, "Episode": 4382, "Episode Step": 198}
{"Training time": 14.014251942767038, "Episode Reward": -138.21349179924547, "Mean Reward": -1.355034233325936, "Episode": 4383, "Episode Step": 102}
{"Training time": 14.016429005530146, "Episode Reward": 7372.490259979257, "Mean Reward": 39.21537372329392, "Episode": 4384, "Episode Step": 188}
{"Training time": 14.019566651052898, "Episode Reward": 15447.88549414039, "Mean Reward": 57.0032675060531, "Episode": 4385, "Episode Step": 271}
{"Training time": 14.021220679415597, "Episode Reward": -58.084160604466234, "Mean Reward": -0.5694525549457474, "Episode": 4386, "Episode Step": 102}
{"Training time": 14.0235930677255, "Episode Reward": 8585.151377420918, "Mean Reward": 42.92575688710459, "Episode": 4387, "Episode Step": 200}
{"Training time": 14.026007931894727, "Episode Reward": 9109.987276079006, "Mean Reward": 44.22323920426702, "Episode": 4388, "Episode Step": 206}
{"Training time": 14.027678463061651, "Episode Reward": 59.57899149955843, "Mean Reward": 0.5841077597995924, "Episode": 4389, "Episode Step": 102}
{"Training time": 14.029459745221668, "Episode Reward": 5496.483365978783, "Mean Reward": 36.40055209257472, "Episode": 4390, "Episode Step": 151}
{"Training time": 14.037845672170322, "Episode Reward": 44358.91768549086, "Mean Reward": 61.52415767751853, "Episode": 4391, "Episode Step": 721}
{"Training time": 14.040058088037703, "Episode Reward": 4628.476612162779, "Mean Reward": 30.65216299445549, "Episode": 4392, "Episode Step": 151}
{"Training time": 14.04099299636152, "Episode Reward": -658.7724714456863, "Mean Reward": -8.234655893071078, "Episode": 4393, "Episode Step": 80}
{"Training time": 14.043225083880955, "Episode Reward": 8353.322510433882, "Mean Reward": 43.05836345584475, "Episode": 4394, "Episode Step": 194}
{"Training time": 14.045416172213024, "Episode Reward": 4324.0155884019105, "Mean Reward": 28.635864823853712, "Episode": 4395, "Episode Step": 151}
{"Training time": 14.046155600282882, "Episode Reward": -433.3899302851596, "Mean Reward": -7.10475295549442, "Episode": 4396, "Episode Step": 61}
{"Training time": 14.0474083013667, "Episode Reward": 4338.525173135991, "Mean Reward": 42.12160362267953, "Episode": 4397, "Episode Step": 103}
{"Training time": 14.049718201094203, "Episode Reward": 4841.74831123251, "Mean Reward": 31.036848148926346, "Episode": 4398, "Episode Step": 156}
{"Training time": 14.05193564719624, "Episode Reward": -601.7969574107552, "Mean Reward": -7.617683005199433, "Episode": 4399, "Episode Step": 79}
{"Training time": 14.054342391623392, "Episode Reward": 8918.687808445093, "Mean Reward": 49.27451827870217, "Episode": 4400, "Episode Step": 181}
{"Training time": 14.056012376613086, "Episode Reward": 33.641533952729006, "Mean Reward": 0.3298189603208726, "Episode": 4401, "Episode Step": 102}
{"Training time": 14.05721536523766, "Episode Reward": -1052.2835577413662, "Mean Reward": -10.31650546805261, "Episode": 4402, "Episode Step": 102}
{"Training time": 14.064374096923403, "Episode Reward": 34608.2325436311, "Mean Reward": 56.18219568771283, "Episode": 4403, "Episode Step": 616}
{"Training time": 14.066047831906213, "Episode Reward": 115.51878750478882, "Mean Reward": 1.1325371323998903, "Episode": 4404, "Episode Step": 102}
{"Training time": 14.06674085246192, "Episode Reward": -456.5378544567331, "Mean Reward": -7.737929736554798, "Episode": 4405, "Episode Step": 59}
{"Training time": 14.075340174436569, "Episode Reward": 44555.12483717703, "Mean Reward": 60.209628158347336, "Episode": 4406, "Episode Step": 740}
{"Training time": 14.077000454134412, "Episode Reward": -65.4835375804419, "Mean Reward": -0.6419954664749207, "Episode": 4407, "Episode Step": 102}
{"Training time": 14.079336634410753, "Episode Reward": 8415.087512259517, "Mean Reward": 41.86610702616675, "Episode": 4408, "Episode Step": 201}
{"Training time": 14.081543953882324, "Episode Reward": 7726.086345049284, "Mean Reward": 40.87876373041949, "Episode": 4409, "Episode Step": 189}
{"Training time": 14.083220027486483, "Episode Reward": 48.597277908645175, "Mean Reward": 0.4764439010651488, "Episode": 4410, "Episode Step": 102}
{"Training time": 14.083942889968554, "Episode Reward": 2678.9705565868207, "Mean Reward": 43.91755010798067, "Episode": 4411, "Episode Step": 61}
{"Training time": 14.086029764148924, "Episode Reward": 8451.19350102022, "Mean Reward": 48.018144892160336, "Episode": 4412, "Episode Step": 176}
{"Training time": 14.087670533061027, "Episode Reward": -112.20890842373063, "Mean Reward": -1.1000873374875553, "Episode": 4413, "Episode Step": 102}
{"Training time": 14.089870423873265, "Episode Reward": 7823.105803342613, "Mean Reward": 41.834790392206486, "Episode": 4414, "Episode Step": 187}
{"Training time": 14.103416284720103, "Episode Reward": 70529.12700640254, "Mean Reward": 60.12713299778563, "Episode": 4415, "Episode Step": 1173}
{"Training time": 14.105898399419255, "Episode Reward": 3868.0647885319654, "Mean Reward": 22.488748770534684, "Episode": 4416, "Episode Step": 172}
{"Training time": 14.107209485504363, "Episode Reward": 4633.776406706231, "Mean Reward": 41.74573339374982, "Episode": 4417, "Episode Step": 111}
{"Training time": 14.141162718865607, "Episode Reward": 173587.87583440638, "Mean Reward": 59.65219100838707, "Episode": 4418, "Episode Step": 2910}
{"Training time": 14.14282517472903, "Episode Reward": 31.71524290832633, "Mean Reward": 0.31093375400319934, "Episode": 4419, "Episode Step": 102}
{"Training time": 14.14400900218222, "Episode Reward": -426.9042235355767, "Mean Reward": -4.185335524858595, "Episode": 4420, "Episode Step": 102}
{"Training time": 14.15680563138591, "Episode Reward": 61784.585177808745, "Mean Reward": 56.839544781792775, "Episode": 4421, "Episode Step": 1087}
{"Training time": 14.15851586441199, "Episode Reward": -45.70220013105741, "Mean Reward": -0.4480607855986021, "Episode": 4422, "Episode Step": 102}
{"Training time": 14.159727526903152, "Episode Reward": -1155.3713518419347, "Mean Reward": -11.327170116097399, "Episode": 4423, "Episode Step": 102}
{"Training time": 14.161936984724468, "Episode Reward": 7524.199851638325, "Mean Reward": 39.8105812255996, "Episode": 4424, "Episode Step": 189}
{"Training time": 14.16460114578406, "Episode Reward": 5999.364791634183, "Mean Reward": 32.25464941738808, "Episode": 4425, "Episode Step": 186}
{"Training time": 14.167152123583687, "Episode Reward": 7600.272397279542, "Mean Reward": 35.35010417339322, "Episode": 4426, "Episode Step": 215}
{"Training time": 14.168914177748892, "Episode Reward": 6280.360087780124, "Mean Reward": 42.723538012109685, "Episode": 4427, "Episode Step": 147}
{"Training time": 14.170580746332805, "Episode Reward": -115.50940721030211, "Mean Reward": -1.132445168728452, "Episode": 4428, "Episode Step": 102}
{"Training time": 14.171772637168566, "Episode Reward": -1107.000562787534, "Mean Reward": -10.852946693995431, "Episode": 4429, "Episode Step": 102}
{"Training time": 14.201021581093471, "Episode Reward": 143121.0608195988, "Mean Reward": 57.43220739149229, "Episode": 4430, "Episode Step": 2492}
{"Training time": 14.203942786388927, "Episode Reward": 5898.363260877335, "Mean Reward": 27.954328250603485, "Episode": 4431, "Episode Step": 211}
{"Training time": 14.205151738060845, "Episode Reward": -1104.203589760694, "Mean Reward": -10.825525389810727, "Episode": 4432, "Episode Step": 102}
{"Training time": 14.207940793302324, "Episode Reward": 14142.259065552724, "Mean Reward": 59.67197917954736, "Episode": 4433, "Episode Step": 237}
{"Training time": 14.209611810776922, "Episode Reward": -170.30112381650557, "Mean Reward": -1.669618860946133, "Episode": 4434, "Episode Step": 102}
{"Training time": 14.21186256190141, "Episode Reward": 5145.898480809219, "Mean Reward": 26.941876862875493, "Episode": 4435, "Episode Step": 191}
{"Training time": 14.214726176394356, "Episode Reward": 13443.484120814499, "Mean Reward": 55.096246396780735, "Episode": 4436, "Episode Step": 244}
{"Training time": 14.21639321744442, "Episode Reward": -54.284255544666465, "Mean Reward": -0.5321985837712399, "Episode": 4437, "Episode Step": 102}
{"Training time": 14.21762289305528, "Episode Reward": -899.8718348748694, "Mean Reward": -8.822272890930092, "Episode": 4438, "Episode Step": 102}
{"Training time": 14.218838434682953, "Episode Reward": 4452.403622369649, "Mean Reward": 43.6510159055848, "Episode": 4439, "Episode Step": 102}
{"Training time": 14.228319618834389, "Episode Reward": 39807.69811982728, "Mean Reward": 51.83294026019177, "Episode": 4440, "Episode Step": 768}
{"Training time": 14.229538428054916, "Episode Reward": -1102.2185087138287, "Mean Reward": -10.80606381091989, "Episode": 4441, "Episode Step": 102}
{"Training time": 14.231833838290639, "Episode Reward": 9117.61372688557, "Mean Reward": 46.998008901472005, "Episode": 4442, "Episode Step": 194}
{"Training time": 14.23349192414019, "Episode Reward": -43.62891013791773, "Mean Reward": -0.42773441311684046, "Episode": 4443, "Episode Step": 102}
{"Training time": 14.234710841377575, "Episode Reward": -585.5905921105445, "Mean Reward": -5.741084236377888, "Episode": 4444, "Episode Step": 102}
{"Training time": 14.25345027440124, "Episode Reward": 100078.75747316761, "Mean Reward": 62.1607189274333, "Episode": 4445, "Episode Step": 1610}
{"Training time": 14.255112960272365, "Episode Reward": -37.1895302023987, "Mean Reward": -0.36460323727841865, "Episode": 4446, "Episode Step": 102}
{"Training time": 14.256345024440023, "Episode Reward": -535.9612627795101, "Mean Reward": -5.254522184112844, "Episode": 4447, "Episode Step": 102}
{"Training time": 14.258385189970335, "Episode Reward": 8644.080522998036, "Mean Reward": 49.96578336993085, "Episode": 4448, "Episode Step": 173}
{"Training time": 14.261136308577326, "Episode Reward": -25.158522709157577, "Mean Reward": -0.24665218342311349, "Episode": 4449, "Episode Step": 102}
{"Training time": 14.262642999688785, "Episode Reward": 89.67978350048385, "Mean Reward": 0.8792135637302338, "Episode": 4450, "Episode Step": 102}
{"Training time": 14.264704230560197, "Episode Reward": 9103.802633632013, "Mean Reward": 52.929085079255884, "Episode": 4451, "Episode Step": 172}
{"Training time": 14.266405237780678, "Episode Reward": -193.96702688786232, "Mean Reward": -1.9016375185084542, "Episode": 4452, "Episode Step": 102}
{"Training time": 14.267625897725424, "Episode Reward": -684.9127806056781, "Mean Reward": -6.714831182408609, "Episode": 4453, "Episode Step": 102}
{"Training time": 14.269784280525313, "Episode Reward": 7990.4180786071975, "Mean Reward": 44.63920714305697, "Episode": 4454, "Episode Step": 179}
{"Training time": 14.271471123562918, "Episode Reward": -39.58594459253352, "Mean Reward": -0.38809749600523064, "Episode": 4455, "Episode Step": 102}
{"Training time": 14.281113678283162, "Episode Reward": 43265.6496512581, "Mean Reward": 52.6987206470866, "Episode": 4456, "Episode Step": 821}
{"Training time": 14.29983744389481, "Episode Reward": 101449.50200435668, "Mean Reward": 63.129746113476465, "Episode": 4457, "Episode Step": 1607}
{"Training time": 14.302247984409332, "Episode Reward": 6188.903177517966, "Mean Reward": 37.05930046417944, "Episode": 4458, "Episode Step": 167}
{"Training time": 14.303452624943521, "Episode Reward": -555.8498078504696, "Mean Reward": -5.449507920102643, "Episode": 4459, "Episode Step": 102}
{"Training time": 14.30610201133622, "Episode Reward": 12078.847764263322, "Mean Reward": 53.68376784117032, "Episode": 4460, "Episode Step": 225}
{"Training time": 14.307754504415724, "Episode Reward": 22.823829807376896, "Mean Reward": 0.22376303732722447, "Episode": 4461, "Episode Step": 102}
{"Training time": 14.308961921930313, "Episode Reward": -771.2241936167105, "Mean Reward": -7.561021506046181, "Episode": 4462, "Episode Step": 102}
{"Training time": 14.311885852482584, "Episode Reward": 13921.770788158097, "Mean Reward": 55.46522226357808, "Episode": 4463, "Episode Step": 251}
{"Training time": 14.313576484719912, "Episode Reward": -92.94965408445802, "Mean Reward": -0.9112711184750786, "Episode": 4464, "Episode Step": 102}
{"Training time": 14.314816270007027, "Episode Reward": -803.609695301476, "Mean Reward": -7.878526424524274, "Episode": 4465, "Episode Step": 102}
{"Training time": 14.317762565546566, "Episode Reward": 13531.711725311307, "Mean Reward": 55.00695823297279, "Episode": 4466, "Episode Step": 246}
{"Training time": 14.319442186090681, "Episode Reward": -91.74176100561495, "Mean Reward": -0.8994290294668132, "Episode": 4467, "Episode Step": 102}
{"Training time": 14.327362706661225, "Episode Reward": 29239.011022384922, "Mean Reward": 43.51043306902518, "Episode": 4468, "Episode Step": 672}
{"Training time": 14.340188703868124, "Episode Reward": 61562.72316528873, "Mean Reward": 56.068053884598115, "Episode": 4469, "Episode Step": 1098}
{"Training time": 14.341887074112892, "Episode Reward": -49.108587548239974, "Mean Reward": -0.48145674066901933, "Episode": 4470, "Episode Step": 102}
{"Training time": 14.343106625278791, "Episode Reward": -1070.482022756462, "Mean Reward": -10.494921791730018, "Episode": 4471, "Episode Step": 102}
{"Training time": 14.357109861903721, "Episode Reward": 72515.88407514618, "Mean Reward": 61.04030646056076, "Episode": 4472, "Episode Step": 1188}
{"Training time": 14.358810868329472, "Episode Reward": -71.8175084412676, "Mean Reward": -0.7040932200124275, "Episode": 4473, "Episode Step": 102}
{"Training time": 14.360059904721048, "Episode Reward": -761.424533064611, "Mean Reward": -7.464946402594225, "Episode": 4474, "Episode Step": 102}
{"Training time": 14.39263428217835, "Episode Reward": 166899.58695118327, "Mean Reward": 60.16567662263276, "Episode": 4475, "Episode Step": 2774}
{"Training time": 14.395230274134212, "Episode Reward": 6679.989757529489, "Mean Reward": 36.90602075983143, "Episode": 4476, "Episode Step": 181}
{"Training time": 14.396446329156557, "Episode Reward": -667.3061406997917, "Mean Reward": -6.542217065684233, "Episode": 4477, "Episode Step": 102}
{"Training time": 14.408991987506548, "Episode Reward": 61396.29042709494, "Mean Reward": 56.69094222261767, "Episode": 4478, "Episode Step": 1083}
{"Training time": 14.410696045557659, "Episode Reward": 6.012571251395077, "Mean Reward": 0.05894677697446154, "Episode": 4479, "Episode Step": 102}
{"Training time": 14.411894827220175, "Episode Reward": -838.7796008080554, "Mean Reward": -8.223329419686818, "Episode": 4480, "Episode Step": 102}
{"Training time": 14.42012490246031, "Episode Reward": 42106.27308501476, "Mean Reward": 60.324173474233184, "Episode": 4481, "Episode Step": 698}
{"Training time": 14.421810957458284, "Episode Reward": -121.53871025155914, "Mean Reward": -1.191555982858423, "Episode": 4482, "Episode Step": 102}
{"Training time": 14.423035274942716, "Episode Reward": -1480.9493452029617, "Mean Reward": -14.519111227480016, "Episode": 4483, "Episode Step": 102}
{"Training time": 14.428712740275595, "Episode Reward": 27998.73606610207, "Mean Reward": 58.697559887006435, "Episode": 4484, "Episode Step": 477}
{"Training time": 14.430365353557798, "Episode Reward": -119.1818112535612, "Mean Reward": -1.1684491299368744, "Episode": 4485, "Episode Step": 102}
{"Training time": 14.431596222188737, "Episode Reward": -463.73092474672467, "Mean Reward": -4.546381615163967, "Episode": 4486, "Episode Step": 102}
{"Training time": 14.437966659996246, "Episode Reward": 31028.31293374807, "Mean Reward": 58.105454932112494, "Episode": 4487, "Episode Step": 534}
{"Training time": 14.439658140540123, "Episode Reward": -19.150744294166042, "Mean Reward": -0.18775239504084354, "Episode": 4488, "Episode Step": 102}
{"Training time": 14.440908133056428, "Episode Reward": -870.0509351232323, "Mean Reward": -8.52991112865914, "Episode": 4489, "Episode Step": 102}
{"Training time": 14.44682809829712, "Episode Reward": 29508.6581878164, "Mean Reward": 59.61345088447757, "Episode": 4490, "Episode Step": 495}
{"Training time": 14.448521542747816, "Episode Reward": -162.46289783636695, "Mean Reward": -1.592773508199676, "Episode": 4491, "Episode Step": 102}
{"Training time": 14.449764176077313, "Episode Reward": -650.7305363414338, "Mean Reward": -6.379711140602292, "Episode": 4492, "Episode Step": 102}
{"Training time": 14.476895959443516, "Episode Reward": 138380.6163075988, "Mean Reward": 60.03497453691922, "Episode": 4493, "Episode Step": 2305}
{"Training time": 14.478572333322631, "Episode Reward": -167.02108909141634, "Mean Reward": -1.6374616577589838, "Episode": 4494, "Episode Step": 102}
{"Training time": 14.479777306384511, "Episode Reward": -104.95704602329647, "Mean Reward": -1.0289906472872203, "Episode": 4495, "Episode Step": 102}
{"Training time": 14.485387375818359, "Episode Reward": 25975.588254899445, "Mean Reward": 54.57056356071312, "Episode": 4496, "Episode Step": 476}
{"Training time": 14.487074365284707, "Episode Reward": -66.21421736616433, "Mean Reward": -0.6366751669823494, "Episode": 4497, "Episode Step": 104}
{"Training time": 14.488305983874533, "Episode Reward": -738.3365682694911, "Mean Reward": -7.238593806563638, "Episode": 4498, "Episode Step": 102}
{"Training time": 14.502911115818554, "Episode Reward": 63782.56982063589, "Mean Reward": 55.99874435525539, "Episode": 4499, "Episode Step": 1139}
{"Training time": 14.504587710234855, "Episode Reward": -133.29393263274616, "Mean Reward": -1.3068032611053546, "Episode": 4500, "Episode Step": 102}
{"Training time": 14.505830949412452, "Episode Reward": -844.3103366643134, "Mean Reward": -8.277552320238366, "Episode": 4501, "Episode Step": 102}
{"Training time": 14.507634536094136, "Episode Reward": 5394.555802933865, "Mean Reward": 36.44970137117477, "Episode": 4502, "Episode Step": 148}
{"Training time": 14.509326261348194, "Episode Reward": -165.64877582379893, "Mean Reward": -1.6240076061156759, "Episode": 4503, "Episode Step": 102}
{"Training time": 14.510549235542616, "Episode Reward": -408.34104089564937, "Mean Reward": -4.003343538192641, "Episode": 4504, "Episode Step": 102}
{"Training time": 14.516348614692689, "Episode Reward": 25431.238933963938, "Mean Reward": 51.900487620334566, "Episode": 4505, "Episode Step": 490}
{"Training time": 14.51806300693088, "Episode Reward": -125.18645789201186, "Mean Reward": -1.2273182146275672, "Episode": 4506, "Episode Step": 102}
{"Training time": 14.519329146610366, "Episode Reward": -590.3931078510715, "Mean Reward": -5.788167724030113, "Episode": 4507, "Episode Step": 102}
{"Training time": 14.521104335255092, "Episode Reward": 6932.066714205779, "Mean Reward": 48.475991008432025, "Episode": 4508, "Episode Step": 143}
{"Training time": 14.522817575269276, "Episode Reward": -242.22055197647177, "Mean Reward": -2.3747112938869783, "Episode": 4509, "Episode Step": 102}
{"Training time": 14.524035416113005, "Episode Reward": -658.4806220058413, "Mean Reward": -6.455692372606287, "Episode": 4510, "Episode Step": 102}
{"Training time": 14.525520774390962, "Episode Reward": 6078.203302571145, "Mean Reward": 50.651694188092875, "Episode": 4511, "Episode Step": 120}
{"Training time": 14.527222802771462, "Episode Reward": -187.56449387801854, "Mean Reward": -1.8388675870393973, "Episode": 4512, "Episode Step": 102}
{"Training time": 14.528469032181635, "Episode Reward": -831.371256780906, "Mean Reward": -8.150698595891235, "Episode": 4513, "Episode Step": 102}
{"Training time": 14.551525231334898, "Episode Reward": 114441.09396318709, "Mean Reward": 58.29907996086963, "Episode": 4514, "Episode Step": 1963}
{"Training time": 14.553183079428143, "Episode Reward": -131.54749709985902, "Mean Reward": -1.289681344116265, "Episode": 4515, "Episode Step": 102}
{"Training time": 14.554387487504217, "Episode Reward": -723.9221090819337, "Mean Reward": -7.097275579234645, "Episode": 4516, "Episode Step": 102}
{"Training time": 14.561457416945034, "Episode Reward": 34514.4967556114, "Mean Reward": 57.14320654902549, "Episode": 4517, "Episode Step": 604}
{"Training time": 14.563108634418912, "Episode Reward": -194.57443607059514, "Mean Reward": -1.9075925104960307, "Episode": 4518, "Episode Step": 102}
{"Training time": 14.564310791360008, "Episode Reward": -862.6394842319689, "Mean Reward": -8.45724984541146, "Episode": 4519, "Episode Step": 102}
{"Training time": 14.56604534301493, "Episode Reward": 5969.337680533113, "Mean Reward": 40.60773932335451, "Episode": 4520, "Episode Step": 147}
{"Training time": 14.567709159387482, "Episode Reward": -198.64267043097317, "Mean Reward": -1.9474771610879722, "Episode": 4521, "Episode Step": 102}
{"Training time": 14.568926758567493, "Episode Reward": -815.5980875777177, "Mean Reward": -7.996059682134487, "Episode": 4522, "Episode Step": 102}
{"Training time": 14.570414316389297, "Episode Reward": 6147.619385788328, "Mean Reward": 48.40645185660101, "Episode": 4523, "Episode Step": 127}
{"Training time": 14.572066652443674, "Episode Reward": -223.49742311906903, "Mean Reward": -2.191151207049696, "Episode": 4524, "Episode Step": 102}
{"Training time": 14.573302387462721, "Episode Reward": -1001.172846074493, "Mean Reward": -9.815420059553853, "Episode": 4525, "Episode Step": 102}
{"Training time": 14.590058476395077, "Episode Reward": 89469.15519292148, "Mean Reward": 63.095313958336725, "Episode": 4526, "Episode Step": 1418}
{"Training time": 14.591739325258468, "Episode Reward": -184.24060251089335, "Mean Reward": -1.8062804167734643, "Episode": 4527, "Episode Step": 102}
{"Training time": 14.59300383137332, "Episode Reward": -735.9812471694696, "Mean Reward": -7.215502423230094, "Episode": 4528, "Episode Step": 102}
{"Training time": 14.595178633001115, "Episode Reward": 8501.233774350705, "Mean Reward": 45.9526149964903, "Episode": 4529, "Episode Step": 185}
{"Training time": 14.59685032248497, "Episode Reward": -117.14475063654508, "Mean Reward": -1.1484779474171087, "Episode": 4530, "Episode Step": 102}
{"Training time": 14.598076631095674, "Episode Reward": -385.2318298856866, "Mean Reward": -3.7767826459381038, "Episode": 4531, "Episode Step": 102}
{"Training time": 14.606405134134823, "Episode Reward": 41109.405782803165, "Mean Reward": 58.47710637667591, "Episode": 4532, "Episode Step": 703}
{"Training time": 14.613406175838577, "Episode Reward": 31992.777267639198, "Mean Reward": 58.70234361034715, "Episode": 4533, "Episode Step": 545}
{"Training time": 14.614634588294559, "Episode Reward": 168.78908452415422, "Mean Reward": 1.6547949463152374, "Episode": 4534, "Episode Step": 102}
{"Training time": 14.616121974123848, "Episode Reward": 6145.708440262307, "Mean Reward": 49.562164840825055, "Episode": 4535, "Episode Step": 124}
{"Training time": 14.617806027730307, "Episode Reward": -347.87517440897494, "Mean Reward": -3.410540925578186, "Episode": 4536, "Episode Step": 102}
{"Training time": 14.619029298888313, "Episode Reward": 32.66561682387646, "Mean Reward": 0.3202511453321222, "Episode": 4537, "Episode Step": 102}
{"Training time": 14.620532002449036, "Episode Reward": 6354.31833877951, "Mean Reward": 50.43109792682151, "Episode": 4538, "Episode Step": 126}
{"Training time": 14.622227623860041, "Episode Reward": -83.20137400480063, "Mean Reward": -0.8156997451451042, "Episode": 4539, "Episode Step": 102}
{"Training time": 14.62347767525249, "Episode Reward": -396.01234131034283, "Mean Reward": -3.882473934415126, "Episode": 4540, "Episode Step": 102}
{"Training time": 14.624976791938145, "Episode Reward": 6243.327779311691, "Mean Reward": 49.55022047072771, "Episode": 4541, "Episode Step": 126}
{"Training time": 14.626635519398583, "Episode Reward": -271.36898847073354, "Mean Reward": -2.6604802791248385, "Episode": 4542, "Episode Step": 102}
{"Training time": 14.627845974961916, "Episode Reward": 79.47981472930314, "Mean Reward": 0.7792138698951289, "Episode": 4543, "Episode Step": 102}
{"Training time": 14.630521713031662, "Episode Reward": 12519.52150087863, "Mean Reward": 55.15207709638163, "Episode": 4544, "Episode Step": 227}
{"Training time": 14.632195470266872, "Episode Reward": -154.8429320574477, "Mean Reward": -1.5180679613475265, "Episode": 4545, "Episode Step": 102}
{"Training time": 14.633398999174435, "Episode Reward": -175.5689138009387, "Mean Reward": -1.7212638607935167, "Episode": 4546, "Episode Step": 102}
{"Training time": 14.636315451926656, "Episode Reward": 15209.58537238333, "Mean Reward": 61.57726871410255, "Episode": 4547, "Episode Step": 247}
{"Training time": 14.638002471923828, "Episode Reward": -191.8843710630129, "Mean Reward": -1.8812193241471853, "Episode": 4548, "Episode Step": 102}
{"Training time": 14.640376263062159, "Episode Reward": -1054.8862731299141, "Mean Reward": -10.342022285587394, "Episode": 4549, "Episode Step": 102}
{"Training time": 14.642770141892964, "Episode Reward": 7984.265859394249, "Mean Reward": 44.855426176372184, "Episode": 4550, "Episode Step": 178}
{"Training time": 14.644452833003468, "Episode Reward": -313.21176444914124, "Mean Reward": -3.0707035730307966, "Episode": 4551, "Episode Step": 102}
{"Training time": 14.645696644716793, "Episode Reward": 58.598839562025965, "Mean Reward": 0.5744984270786859, "Episode": 4552, "Episode Step": 102}
{"Training time": 14.647205525835355, "Episode Reward": 6305.3097840084965, "Mean Reward": 50.44247827206797, "Episode": 4553, "Episode Step": 125}
{"Training time": 14.648898697164324, "Episode Reward": -298.16841406875284, "Mean Reward": -2.9232197457720868, "Episode": 4554, "Episode Step": 102}
{"Training time": 14.650129536390304, "Episode Reward": 106.8549399953915, "Mean Reward": 1.0475974509352108, "Episode": 4555, "Episode Step": 102}
{"Training time": 14.652968342502913, "Episode Reward": 13719.947574685864, "Mean Reward": 57.40563838780697, "Episode": 4556, "Episode Step": 239}
{"Training time": 14.654641398853727, "Episode Reward": -250.28390379616926, "Mean Reward": -2.453763762707542, "Episode": 4557, "Episode Step": 102}
{"Training time": 14.6558061441448, "Episode Reward": 128.78040600394095, "Mean Reward": 1.262553000038637, "Episode": 4558, "Episode Step": 102}
{"Training time": 14.66410116109583, "Episode Reward": 42105.03807035491, "Mean Reward": 59.63886412231574, "Episode": 4559, "Episode Step": 706}
{"Training time": 14.665780989395248, "Episode Reward": -96.6603599605992, "Mean Reward": -0.9476505878490117, "Episode": 4560, "Episode Step": 102}
{"Training time": 14.66698905772633, "Episode Reward": 219.04172667410128, "Mean Reward": 2.14746790856962, "Episode": 4561, "Episode Step": 102}
{"Training time": 14.678188208606509, "Episode Reward": 59957.21995028226, "Mean Reward": 62.65122251858126, "Episode": 4562, "Episode Step": 957}
{"Training time": 14.679862987465329, "Episode Reward": -150.6146610678789, "Mean Reward": -1.4766143241948912, "Episode": 4563, "Episode Step": 102}
{"Training time": 14.681096364127265, "Episode Reward": -1092.9024468597513, "Mean Reward": -10.714729871174033, "Episode": 4564, "Episode Step": 102}
{"Training time": 14.683329987459713, "Episode Reward": 9112.071056633082, "Mean Reward": 48.989629336736996, "Episode": 4565, "Episode Step": 186}
{"Training time": 14.685012435780632, "Episode Reward": -202.4248153501772, "Mean Reward": -1.9845570132370314, "Episode": 4566, "Episode Step": 102}
{"Training time": 14.68600255800618, "Episode Reward": -471.4696265072279, "Mean Reward": -5.749629591551559, "Episode": 4567, "Episode Step": 82}
{"Training time": 14.697395230796602, "Episode Reward": 61117.93659871571, "Mean Reward": 63.00818206053166, "Episode": 4568, "Episode Step": 970}
{"Training time": 14.699065393010775, "Episode Reward": -258.24579410003037, "Mean Reward": -2.5318215107846114, "Episode": 4569, "Episode Step": 102}
{"Training time": 14.700277159677611, "Episode Reward": 185.2448525892115, "Mean Reward": 1.8161260057765833, "Episode": 4570, "Episode Step": 102}
{"Training time": 14.703246818582217, "Episode Reward": 14658.90922566591, "Mean Reward": 59.58906189295085, "Episode": 4571, "Episode Step": 246}
{"Training time": 14.704940970275137, "Episode Reward": -151.87231727060635, "Mean Reward": -1.4889442869667289, "Episode": 4572, "Episode Step": 102}
{"Training time": 14.706184958285755, "Episode Reward": 60.38843103995039, "Mean Reward": 0.592043441568141, "Episode": 4573, "Episode Step": 102}
{"Training time": 14.70766192469332, "Episode Reward": 5691.608888583938, "Mean Reward": 43.781606835261066, "Episode": 4574, "Episode Step": 130}
{"Training time": 14.70936913245254, "Episode Reward": 110.16800493560709, "Mean Reward": 1.0800784797608538, "Episode": 4575, "Episode Step": 102}
{"Training time": 14.712406204409069, "Episode Reward": 14737.277734140847, "Mean Reward": 57.567491148987685, "Episode": 4576, "Episode Step": 256}
{"Training time": 14.714046186672316, "Episode Reward": 6271.417574705039, "Mean Reward": 45.11811204823769, "Episode": 4577, "Episode Step": 139}
{"Training time": 14.715711187720299, "Episode Reward": 181.91157799894097, "Mean Reward": 1.7834468431268722, "Episode": 4578, "Episode Step": 102}
{"Training time": 14.71629376080301, "Episode Reward": -249.8985328317739, "Mean Reward": -5.206219433995289, "Episode": 4579, "Episode Step": 48}
{"Training time": 14.72761496828662, "Episode Reward": 58753.95413260796, "Mean Reward": 61.265854152875875, "Episode": 4580, "Episode Step": 959}
{"Training time": 14.729297983580166, "Episode Reward": 167.07339271429882, "Mean Reward": 1.6379744383754786, "Episode": 4581, "Episode Step": 102}
{"Training time": 14.730531231628524, "Episode Reward": -902.5815252630126, "Mean Reward": -8.848838482970711, "Episode": 4582, "Episode Step": 102}
{"Training time": 14.736397441095775, "Episode Reward": 32426.189980142637, "Mean Reward": 66.0411201224901, "Episode": 4583, "Episode Step": 491}
{"Training time": 14.738106369972229, "Episode Reward": 200.6094065398085, "Mean Reward": 1.9667588876451814, "Episode": 4584, "Episode Step": 102}
{"Training time": 14.739338902168804, "Episode Reward": -925.487191862753, "Mean Reward": -9.073403841791697, "Episode": 4585, "Episode Step": 102}
{"Training time": 14.741441955500179, "Episode Reward": 8252.47609776371, "Mean Reward": 46.88906873729381, "Episode": 4586, "Episode Step": 176}
{"Training time": 14.743133177227444, "Episode Reward": 136.88223175811615, "Mean Reward": 1.3419826642952564, "Episode": 4587, "Episode Step": 102}
{"Training time": 14.744381408029133, "Episode Reward": -951.1690219135882, "Mean Reward": -9.325186489348903, "Episode": 4588, "Episode Step": 102}
{"Training time": 14.751785095532735, "Episode Reward": 36037.28781450717, "Mean Reward": 57.111391148188865, "Episode": 4589, "Episode Step": 631}
{"Training time": 14.753435513310961, "Episode Reward": -20.886468931352866, "Mean Reward": -0.2047693032485575, "Episode": 4590, "Episode Step": 102}
{"Training time": 14.75465069439676, "Episode Reward": -872.4675354871276, "Mean Reward": -8.553603289089487, "Episode": 4591, "Episode Step": 102}
{"Training time": 14.760468905236985, "Episode Reward": 29287.153135416633, "Mean Reward": 59.52673401507446, "Episode": 4592, "Episode Step": 492}
{"Training time": 14.762142205503253, "Episode Reward": -20.687077472110225, "Mean Reward": -0.20281448502068847, "Episode": 4593, "Episode Step": 102}
{"Training time": 14.763347657455338, "Episode Reward": -1286.6815381111967, "Mean Reward": -12.614524883443105, "Episode": 4594, "Episode Step": 102}
{"Training time": 14.765389931930436, "Episode Reward": 8576.564513847825, "Mean Reward": 49.29060065429785, "Episode": 4595, "Episode Step": 174}
{"Training time": 14.769009309146139, "Episode Reward": 8592.548197964436, "Mean Reward": 32.061747007329984, "Episode": 4596, "Episode Step": 268}
{"Training time": 14.769642422729069, "Episode Reward": -272.4751616978561, "Mean Reward": -5.239906955728002, "Episode": 4597, "Episode Step": 52}
{"Training time": 14.781581325001186, "Episode Reward": 61553.647760280655, "Mean Reward": 59.6450075196518, "Episode": 4598, "Episode Step": 1032}
{"Training time": 14.78534335606628, "Episode Reward": 6631.466701016468, "Mean Reward": 35.273759047959935, "Episode": 4599, "Episode Step": 188}
{"Training time": 14.786675316095351, "Episode Reward": 3340.032286907591, "Mean Reward": 38.3911757115815, "Episode": 4600, "Episode Step": 87}
{"Training time": 14.793930033842722, "Episode Reward": 35495.47334804624, "Mean Reward": 57.999139457591895, "Episode": 4601, "Episode Step": 612}
{"Training time": 14.795844895243645, "Episode Reward": 6253.395285507096, "Mean Reward": 49.63012131354838, "Episode": 4602, "Episode Step": 126}
{"Training time": 14.796913397775755, "Episode Reward": 3794.436172874466, "Mean Reward": 42.160401920827404, "Episode": 4603, "Episode Step": 90}
{"Training time": 14.80395964635743, "Episode Reward": 37193.418381297015, "Mean Reward": 61.783087012121285, "Episode": 4604, "Episode Step": 602}
{"Training time": 14.810223108596272, "Episode Reward": 29265.19818359799, "Mean Reward": 59.36145676186205, "Episode": 4605, "Episode Step": 493}
{"Training time": 14.810811055832438, "Episode Reward": 2010.967852523932, "Mean Reward": 41.04016025559045, "Episode": 4606, "Episode Step": 49}
{"Training time": 14.828870929413371, "Episode Reward": 91537.68893209902, "Mean Reward": 60.02471405383542, "Episode": 4607, "Episode Step": 1525}
{"Training time": 14.830958056648573, "Episode Reward": 6134.960367442247, "Mean Reward": 47.19200282647882, "Episode": 4608, "Episode Step": 130}
{"Training time": 14.831985302766164, "Episode Reward": 3927.2451937001515, "Mean Reward": 47.31620715301387, "Episode": 4609, "Episode Step": 83}
{"Training time": 14.834154917465316, "Episode Reward": 7376.954855634032, "Mean Reward": 41.67771104877984, "Episode": 4610, "Episode Step": 177}
{"Training time": 14.840490904450416, "Episode Reward": 29030.667005481147, "Mean Reward": 58.29451205919909, "Episode": 4611, "Episode Step": 498}
{"Training time": 14.84109429359436, "Episode Reward": 2462.752056294728, "Mean Reward": 48.28925600577898, "Episode": 4612, "Episode Step": 51}
{"Training time": 14.858588136368327, "Episode Reward": 89229.68295955333, "Mean Reward": 60.7004645983356, "Episode": 4613, "Episode Step": 1470}
{"Training time": 14.861391366057926, "Episode Reward": 8791.27641276068, "Mean Reward": 46.26987585663516, "Episode": 4614, "Episode Step": 190}
{"Training time": 14.862057934668329, "Episode Reward": -260.44684374859696, "Mean Reward": -5.00859314901148, "Episode": 4615, "Episode Step": 52}
{"Training time": 14.878526938027806, "Episode Reward": 78145.62670590312, "Mean Reward": 57.08226932498402, "Episode": 4616, "Episode Step": 1369}
{"Training time": 14.881715041067865, "Episode Reward": 9430.72569464339, "Mean Reward": 42.67296694408774, "Episode": 4617, "Episode Step": 221}
{"Training time": 14.882388843297958, "Episode Reward": -274.4109826287679, "Mean Reward": -5.1775657099767525, "Episode": 4618, "Episode Step": 53}
{"Training time": 14.88803088605404, "Episode Reward": 28646.904269225757, "Mean Reward": 61.474043496192614, "Episode": 4619, "Episode Step": 466}
{"Training time": 14.891537850499153, "Episode Reward": 13265.034897441124, "Mean Reward": 52.43096797407559, "Episode": 4620, "Episode Step": 253}
{"Training time": 14.89277740167247, "Episode Reward": -997.4025469251974, "Mean Reward": -9.778456342403896, "Episode": 4621, "Episode Step": 102}
{"Training time": 14.898392388886876, "Episode Reward": 27494.721498111536, "Mean Reward": 58.62413965482204, "Episode": 4622, "Episode Step": 469}
{"Training time": 14.900653649701013, "Episode Reward": 6286.971233520454, "Mean Reward": 42.194437808862105, "Episode": 4623, "Episode Step": 149}
{"Training time": 14.901870705816481, "Episode Reward": -888.9440504299209, "Mean Reward": -8.71513774931295, "Episode": 4624, "Episode Step": 102}
{"Training time": 14.903438730239868, "Episode Reward": 6552.883377088696, "Mean Reward": 48.90211475439325, "Episode": 4625, "Episode Step": 134}
{"Training time": 14.905531917744213, "Episode Reward": 6131.937568715393, "Mean Reward": 45.76072812474174, "Episode": 4626, "Episode Step": 134}
{"Training time": 14.906759357187482, "Episode Reward": -827.3890012813074, "Mean Reward": -8.111656875306934, "Episode": 4627, "Episode Step": 102}
{"Training time": 14.914198419120577, "Episode Reward": 36428.308852670496, "Mean Reward": 58.660722790129626, "Episode": 4628, "Episode Step": 621}
{"Training time": 14.92066035495864, "Episode Reward": 27366.12408738731, "Mean Reward": 54.19034472749962, "Episode": 4629, "Episode Step": 505}
{"Training time": 14.9239674949646, "Episode Reward": 6539.619919002149, "Mean Reward": 23.780436069098723, "Episode": 4630, "Episode Step": 275}
{"Training time": 14.926095290515159, "Episode Reward": 8045.346133171167, "Mean Reward": 45.97340647526381, "Episode": 4631, "Episode Step": 175}
{"Training time": 14.928883335789045, "Episode Reward": 8504.924465015525, "Mean Reward": 44.29648158862253, "Episode": 4632, "Episode Step": 192}
{"Training time": 14.930139193601079, "Episode Reward": -937.3265861758762, "Mean Reward": -9.18947633505761, "Episode": 4633, "Episode Step": 102}
{"Training time": 14.935897802776761, "Episode Reward": 28005.483488631045, "Mean Reward": 59.586135082193714, "Episode": 4634, "Episode Step": 470}
{"Training time": 14.939344666070408, "Episode Reward": 11759.803952097094, "Mean Reward": 48.1959178364635, "Episode": 4635, "Episode Step": 244}
{"Training time": 14.940632510781288, "Episode Reward": 4310.558193904485, "Mean Reward": 41.05293518004272, "Episode": 4636, "Episode Step": 105}
{"Training time": 14.953306677209007, "Episode Reward": 63861.5949471235, "Mean Reward": 59.516863883619294, "Episode": 4637, "Episode Step": 1073}
{"Training time": 14.95679990331332, "Episode Reward": 12797.263509587785, "Mean Reward": 49.989310584327285, "Episode": 4638, "Episode Step": 256}
{"Training time": 14.958031462166044, "Episode Reward": -1006.3187395810249, "Mean Reward": -9.865869995892401, "Episode": 4639, "Episode Step": 102}
{"Training time": 14.979356144997809, "Episode Reward": 117127.22475187133, "Mean Reward": 64.42641625515475, "Episode": 4640, "Episode Step": 1818}
{"Training time": 14.982132316099273, "Episode Reward": 8755.65477336597, "Mean Reward": 45.13224109982459, "Episode": 4641, "Episode Step": 194}
{"Training time": 14.982702887455622, "Episode Reward": -256.78887011597243, "Mean Reward": -5.582366741651574, "Episode": 4642, "Episode Step": 46}
{"Training time": 14.995174356102943, "Episode Reward": 67590.86314217855, "Mean Reward": 63.406062985158115, "Episode": 4643, "Episode Step": 1066}
{"Training time": 15.002435939444435, "Episode Reward": 32459.603002497457, "Mean Reward": 55.29744974871799, "Episode": 4644, "Episode Step": 587}
{"Training time": 15.002980528606308, "Episode Reward": -257.75404387447236, "Mean Reward": -5.8580464516925534, "Episode": 4645, "Episode Step": 44}
{"Training time": 15.01363519748052, "Episode Reward": 57835.365361874035, "Mean Reward": 62.864527567254385, "Episode": 4646, "Episode Step": 920}
{"Training time": 15.017133156061172, "Episode Reward": 11924.497499573741, "Mean Reward": 46.0405308863851, "Episode": 4647, "Episode Step": 259}
{"Training time": 15.01765886273649, "Episode Reward": -252.09579538271078, "Mean Reward": -5.862692915876995, "Episode": 4648, "Episode Step": 43}
{"Training time": 15.031265821059545, "Episode Reward": 67153.31248537324, "Mean Reward": 63.05475350739272, "Episode": 4649, "Episode Step": 1065}
{"Training time": 15.03414459248384, "Episode Reward": 6244.281282367091, "Mean Reward": 30.459908694473615, "Episode": 4650, "Episode Step": 205}
{"Training time": 15.03468858718872, "Episode Reward": -260.0398163726513, "Mean Reward": -5.909995826651166, "Episode": 4651, "Episode Step": 44}
{"Training time": 15.040439456105233, "Episode Reward": 32485.674388222724, "Mean Reward": 66.16226962978152, "Episode": 4652, "Episode Step": 491}
{"Training time": 15.044234402444628, "Episode Reward": 14658.189662765699, "Mean Reward": 51.97939596725425, "Episode": 4653, "Episode Step": 282}
{"Training time": 15.045002898044057, "Episode Reward": 2464.804605577674, "Mean Reward": 38.512571962151156, "Episode": 4654, "Episode Step": 64}
{"Training time": 15.052237522469627, "Episode Reward": 37968.47501529153, "Mean Reward": 61.43766183704131, "Episode": 4655, "Episode Step": 618}
{"Training time": 15.053922546108565, "Episode Reward": -8.541038261413489, "Mean Reward": -0.08373566922954401, "Episode": 4656, "Episode Step": 102}
{"Training time": 15.054732100235091, "Episode Reward": 2489.034651527865, "Mean Reward": 38.292840792736385, "Episode": 4657, "Episode Step": 65}
{"Training time": 15.05684279580911, "Episode Reward": 9117.720059237334, "Mean Reward": 52.10125748135619, "Episode": 4658, "Episode Step": 175}
{"Training time": 15.059174908002218, "Episode Reward": 6607.232978060708, "Mean Reward": 42.62730953587553, "Episode": 4659, "Episode Step": 155}
{"Training time": 15.060397934714953, "Episode Reward": -841.2452898320615, "Mean Reward": -8.2475028414908, "Episode": 4660, "Episode Step": 102}
{"Training time": 15.087613014711273, "Episode Reward": 149694.7000858181, "Mean Reward": 64.3294800540688, "Episode": 4661, "Episode Step": 2327}
{"Training time": 15.096918979949422, "Episode Reward": 43952.06048472161, "Mean Reward": 59.07535011387313, "Episode": 4662, "Episode Step": 744}
{"Training time": 15.09812725994322, "Episode Reward": -680.8931515907432, "Mean Reward": -6.6754230548112075, "Episode": 4663, "Episode Step": 102}
{"Training time": 15.105386836926142, "Episode Reward": 37664.29810294546, "Mean Reward": 61.24276114300075, "Episode": 4664, "Episode Step": 615}
{"Training time": 15.108881652752558, "Episode Reward": 15945.878194578348, "Mean Reward": 60.86213051365782, "Episode": 4665, "Episode Step": 262}
{"Training time": 15.10960899134477, "Episode Reward": 2179.120162653786, "Mean Reward": 36.3186693775631, "Episode": 4666, "Episode Step": 60}
{"Training time": 15.115160830219587, "Episode Reward": 28871.180117047945, "Mean Reward": 60.653739741697365, "Episode": 4667, "Episode Step": 476}
{"Training time": 15.117841208312246, "Episode Reward": 8558.341462196386, "Mean Reward": 45.52309288402333, "Episode": 4668, "Episode Step": 188}
{"Training time": 15.119053427179654, "Episode Reward": -742.0952634598365, "Mean Reward": -7.2754437594101615, "Episode": 4669, "Episode Step": 102}
{"Training time": 15.142213998834292, "Episode Reward": 120013.81717328617, "Mean Reward": 60.95165930588429, "Episode": 4670, "Episode Step": 1969}
{"Training time": 15.1438917711046, "Episode Reward": -108.24922691649404, "Mean Reward": -1.0612669305538631, "Episode": 4671, "Episode Step": 102}
{"Training time": 15.144580686092377, "Episode Reward": 2571.1772826191036, "Mean Reward": 46.74867786580188, "Episode": 4672, "Episode Step": 55}
{"Training time": 15.17272719277276, "Episode Reward": 148888.7299282961, "Mean Reward": 61.24587820991201, "Episode": 4673, "Episode Step": 2431}
{"Training time": 15.174391989707948, "Episode Reward": -76.84001108627054, "Mean Reward": -0.7533334420222602, "Episode": 4674, "Episode Step": 102}
{"Training time": 15.175423502723376, "Episode Reward": 4676.173489025505, "Mean Reward": 55.01380575324123, "Episode": 4675, "Episode Step": 85}
{"Training time": 15.17751582827833, "Episode Reward": 8255.837606023824, "Mean Reward": 46.64315031651878, "Episode": 4676, "Episode Step": 177}
{"Training time": 15.183793055547609, "Episode Reward": 25982.32920443988, "Mean Reward": 52.595808106153605, "Episode": 4677, "Episode Step": 494}
{"Training time": 15.186486837466559, "Episode Reward": 12355.807306305049, "Mean Reward": 54.19213730835548, "Episode": 4678, "Episode Step": 228}
{"Training time": 15.215818146069845, "Episode Reward": 154177.11726849194, "Mean Reward": 61.5477514045876, "Episode": 4679, "Episode Step": 2505}
{"Training time": 15.222105922169156, "Episode Reward": 28095.90296537834, "Mean Reward": 58.65532978158317, "Episode": 4680, "Episode Step": 479}
{"Training time": 15.227741972208023, "Episode Reward": 26464.53269696624, "Mean Reward": 56.66923489714398, "Episode": 4681, "Episode Step": 467}
{"Training time": 15.231410700281462, "Episode Reward": 19123.049909531448, "Mean Reward": 63.11237593904768, "Episode": 4682, "Episode Step": 303}
{"Training time": 15.235259816646575, "Episode Reward": 13498.495069690814, "Mean Reward": 47.697862437070015, "Episode": 4683, "Episode Step": 283}
{"Training time": 15.236543870502048, "Episode Reward": 5231.385157591309, "Mean Reward": 49.82271578658389, "Episode": 4684, "Episode Step": 105}
{"Training time": 15.238652379115422, "Episode Reward": 8925.807669011887, "Mean Reward": 51.59426398272767, "Episode": 4685, "Episode Step": 173}
{"Training time": 15.24473519411352, "Episode Reward": 28727.20369857105, "Mean Reward": 61.12170999695968, "Episode": 4686, "Episode Step": 470}
{"Training time": 15.246911932494905, "Episode Reward": 7666.967423276212, "Mean Reward": 42.358936040200064, "Episode": 4687, "Episode Step": 181}
{"Training time": 15.265213783052232, "Episode Reward": 97175.76355905042, "Mean Reward": 63.47208593014397, "Episode": 4688, "Episode Step": 1531}
{"Training time": 15.271472406917148, "Episode Reward": 31926.585529987748, "Mean Reward": 64.75980837725709, "Episode": 4689, "Episode Step": 493}
{"Training time": 15.273130717476208, "Episode Reward": 6681.389595857056, "Mean Reward": 48.41586663664533, "Episode": 4690, "Episode Step": 138}
{"Training time": 15.276154530776871, "Episode Reward": 14113.945818789376, "Mean Reward": 54.91807711591197, "Episode": 4691, "Episode Step": 257}
{"Training time": 15.281610914667448, "Episode Reward": 25201.661627913203, "Mean Reward": 59.719577317329865, "Episode": 4692, "Episode Step": 422}
{"Training time": 15.282203378611142, "Episode Reward": 2552.5135719685304, "Mean Reward": 52.09211371364348, "Episode": 4693, "Episode Step": 49}
{"Training time": 15.28940563082695, "Episode Reward": 37016.73808793113, "Mean Reward": 59.994713270552886, "Episode": 4694, "Episode Step": 617}
{"Training time": 15.292066191898451, "Episode Reward": 8481.479996374444, "Mean Reward": 44.405654431279814, "Episode": 4695, "Episode Step": 191}
{"Training time": 15.29366428249412, "Episode Reward": 5957.078426867619, "Mean Reward": 43.16723497730159, "Episode": 4696, "Episode Step": 138}
{"Training time": 15.31216463300917, "Episode Reward": 99038.01347863724, "Mean Reward": 61.860095864233124, "Episode": 4697, "Episode Step": 1601}
{"Training time": 15.314942875504494, "Episode Reward": 6058.239027094704, "Mean Reward": 30.291195135473522, "Episode": 4698, "Episode Step": 200}
{"Training time": 15.31854987859726, "Episode Reward": 11827.54140363917, "Mean Reward": 53.7615518347235, "Episode": 4699, "Episode Step": 220}
{"Training time": 15.337136592202716, "Episode Reward": 95391.32654488242, "Mean Reward": 60.18380223651888, "Episode": 4700, "Episode Step": 1585}
{"Training time": 15.339788493315378, "Episode Reward": 8695.732758817767, "Mean Reward": 45.76701452009351, "Episode": 4701, "Episode Step": 190}
{"Training time": 15.34239325635963, "Episode Reward": 11777.483135948667, "Mean Reward": 52.344369493105184, "Episode": 4702, "Episode Step": 225}
{"Training time": 15.343979381653998, "Episode Reward": 5443.422011929598, "Mean Reward": 40.32164453281184, "Episode": 4703, "Episode Step": 135}
{"Training time": 15.34660775244236, "Episode Reward": 8727.832796869496, "Mean Reward": 47.69307539272948, "Episode": 4704, "Episode Step": 183}
{"Training time": 15.348188356624709, "Episode Reward": 6240.699538871782, "Mean Reward": 46.22740399164283, "Episode": 4705, "Episode Step": 135}
{"Training time": 15.359589232736164, "Episode Reward": 57128.20931566483, "Mean Reward": 58.2940911384335, "Episode": 4706, "Episode Step": 980}
{"Training time": 15.362256108853552, "Episode Reward": 8854.779139427395, "Mean Reward": 46.604100733828396, "Episode": 4707, "Episode Step": 190}
{"Training time": 15.364905731942919, "Episode Reward": 11748.488286029047, "Mean Reward": 51.9844614426064, "Episode": 4708, "Episode Step": 226}
{"Training time": 15.367044820255703, "Episode Reward": 7665.304387201092, "Mean Reward": 42.5850243733394, "Episode": 4709, "Episode Step": 180}
{"Training time": 15.3698638488849, "Episode Reward": 8379.211820840403, "Mean Reward": 41.276905521381295, "Episode": 4710, "Episode Step": 203}
{"Training time": 15.372654618885782, "Episode Reward": 11895.547312179206, "Mean Reward": 49.56478046741336, "Episode": 4711, "Episode Step": 240}
{"Training time": 15.374219275514285, "Episode Reward": 5747.148491895873, "Mean Reward": 42.889167849969205, "Episode": 4712, "Episode Step": 134}
{"Training time": 15.37614146967729, "Episode Reward": 5523.91164201928, "Mean Reward": 44.19129313615424, "Episode": 4713, "Episode Step": 125}
{"Training time": 15.378913672765096, "Episode Reward": 11743.658823633623, "Mean Reward": 49.13664779763022, "Episode": 4714, "Episode Step": 239}
{"Training time": 15.380980728334851, "Episode Reward": 7590.634505549673, "Mean Reward": 43.1286051451686, "Episode": 4715, "Episode Step": 176}
{"Training time": 15.390556114448442, "Episode Reward": 41459.687776330706, "Mean Reward": 52.68067061795515, "Episode": 4716, "Episode Step": 787}
{"Training time": 15.393464059432347, "Episode Reward": 12761.017600311232, "Mean Reward": 50.84070757096109, "Episode": 4717, "Episode Step": 251}
{"Training time": 15.394056192768945, "Episode Reward": 1608.242323004909, "Mean Reward": 32.164846460098175, "Episode": 4718, "Episode Step": 50}
{"Training time": 15.39574563384056, "Episode Reward": 5974.899225141091, "Mean Reward": 55.840179674215804, "Episode": 4719, "Episode Step": 107}
{"Training time": 15.398470161888335, "Episode Reward": 10441.973095632538, "Mean Reward": 45.203346734339995, "Episode": 4720, "Episode Step": 231}
{"Training time": 15.40135665330622, "Episode Reward": 15192.940554900786, "Mean Reward": 60.77176221960315, "Episode": 4721, "Episode Step": 250}
{"Training time": 15.40647469745742, "Episode Reward": 25493.75754767238, "Mean Reward": 62.94754950042563, "Episode": 4722, "Episode Step": 405}
{"Training time": 15.409119315279854, "Episode Reward": 11439.2572868639, "Mean Reward": 49.953088588925326, "Episode": 4723, "Episode Step": 229}
{"Training time": 15.416172290245692, "Episode Reward": 34663.94201304361, "Mean Reward": 56.36413335454246, "Episode": 4724, "Episode Step": 615}
{"Training time": 15.419611168834898, "Episode Reward": 16921.118935690145, "Mean Reward": 66.09812084253963, "Episode": 4725, "Episode Step": 256}
{"Training time": 15.421134629117118, "Episode Reward": 6054.500750857798, "Mean Reward": 47.67323425872282, "Episode": 4726, "Episode Step": 127}
{"Training time": 15.435159453286065, "Episode Reward": 72174.16167783042, "Mean Reward": 60.39678801492085, "Episode": 4727, "Episode Step": 1195}
{"Training time": 15.437844093839328, "Episode Reward": 8798.412209022012, "Mean Reward": 46.30743267906322, "Episode": 4728, "Episode Step": 190}
{"Training time": 15.43911385635535, "Episode Reward": 4868.256011410437, "Mean Reward": 45.49771973280782, "Episode": 4729, "Episode Step": 107}
{"Training time": 15.441208910544713, "Episode Reward": 8391.192597610983, "Mean Reward": 47.94967198634848, "Episode": 4730, "Episode Step": 175}
{"Training time": 15.450096359981432, "Episode Reward": 41698.080706415865, "Mean Reward": 58.40067325828552, "Episode": 4731, "Episode Step": 714}
{"Training time": 15.451750992735226, "Episode Reward": 5403.94760583089, "Mean Reward": 38.59962575593493, "Episode": 4732, "Episode Step": 140}
{"Training time": 15.458905411627558, "Episode Reward": 34866.11121495893, "Mean Reward": 56.87783232456596, "Episode": 4733, "Episode Step": 613}
{"Training time": 15.46148522330655, "Episode Reward": 8634.396264379177, "Mean Reward": 48.236850638989814, "Episode": 4734, "Episode Step": 179}
{"Training time": 15.464246426886982, "Episode Reward": 11036.200187604729, "Mean Reward": 46.962553989807354, "Episode": 4735, "Episode Step": 235}
{"Training time": 15.465827292733723, "Episode Reward": 5787.25815641554, "Mean Reward": 43.18849370459358, "Episode": 4736, "Episode Step": 134}
{"Training time": 15.467094061904483, "Episode Reward": 2647.0276831868377, "Mean Reward": 38.926877693924084, "Episode": 4737, "Episode Step": 68}
{"Training time": 15.469803423616622, "Episode Reward": 11849.890873415707, "Mean Reward": 51.52126466702481, "Episode": 4738, "Episode Step": 230}
{"Training time": 15.475546084443728, "Episode Reward": 28967.586980631055, "Mean Reward": 58.87720931022572, "Episode": 4739, "Episode Step": 492}
{"Training time": 15.478252037167548, "Episode Reward": 8926.409514825393, "Mean Reward": 46.98110270960733, "Episode": 4740, "Episode Step": 190}
{"Training time": 15.47992125272751, "Episode Reward": 6125.767267727866, "Mean Reward": 44.070268113150114, "Episode": 4741, "Episode Step": 139}
{"Training time": 15.486092356112268, "Episode Reward": 32073.465420951234, "Mean Reward": 60.86046569440462, "Episode": 4742, "Episode Step": 527}
{"Training time": 15.48818496995502, "Episode Reward": 6851.205594262943, "Mean Reward": 48.590110597609524, "Episode": 4743, "Episode Step": 141}
{"Training time": 15.48958220799764, "Episode Reward": 6450.8152684883835, "Mean Reward": 54.20853166796961, "Episode": 4744, "Episode Step": 119}
{"Training time": 15.495648789405823, "Episode Reward": 31296.515927468346, "Mean Reward": 60.76993383974436, "Episode": 4745, "Episode Step": 515}
{"Training time": 15.49820572025246, "Episode Reward": 8616.5096885967, "Mean Reward": 48.68084569828644, "Episode": 4746, "Episode Step": 177}
{"Training time": 15.500974304146236, "Episode Reward": 12552.8934278121, "Mean Reward": 53.41656777792383, "Episode": 4747, "Episode Step": 235}
{"Training time": 15.50258027361499, "Episode Reward": 6263.98629222562, "Mean Reward": 46.399898460930515, "Episode": 4748, "Episode Step": 135}
{"Training time": 15.506206751929389, "Episode Reward": 8695.820828936152, "Mean Reward": 49.128931236927414, "Episode": 4749, "Episode Step": 177}
{"Training time": 15.50923098941644, "Episode Reward": 13443.919483838155, "Mean Reward": 57.94792880964722, "Episode": 4750, "Episode Step": 232}
{"Training time": 15.511289903322856, "Episode Reward": 8717.059433522554, "Mean Reward": 49.811768191557455, "Episode": 4751, "Episode Step": 175}
{"Training time": 15.517768472764228, "Episode Reward": 30372.90955693572, "Mean Reward": 60.26370943836452, "Episode": 4752, "Episode Step": 504}
{"Training time": 15.520438431633844, "Episode Reward": 13825.988083006669, "Mean Reward": 61.44883592447408, "Episode": 4753, "Episode Step": 225}
{"Training time": 15.522088415821393, "Episode Reward": 5689.036662607493, "Mean Reward": 42.45549748214547, "Episode": 4754, "Episode Step": 134}
{"Training time": 15.524665364424388, "Episode Reward": 8886.765510858395, "Mean Reward": 49.09815199369279, "Episode": 4755, "Episode Step": 181}
{"Training time": 15.52742903219329, "Episode Reward": 12328.689575192691, "Mean Reward": 53.14090334134781, "Episode": 4756, "Episode Step": 232}
{"Training time": 15.529043773611386, "Episode Reward": 5621.666245746382, "Mean Reward": 42.26816726125099, "Episode": 4757, "Episode Step": 133}
{"Training time": 15.532550913559065, "Episode Reward": 16138.70723213804, "Mean Reward": 62.071950892838615, "Episode": 4758, "Episode Step": 260}
{"Training time": 15.5331973966625, "Episode Reward": 2111.5224053825723, "Mean Reward": 39.84004538457683, "Episode": 4759, "Episode Step": 53}
{"Training time": 15.540104796621534, "Episode Reward": 33554.74847267553, "Mean Reward": 57.65420699772427, "Episode": 4760, "Episode Step": 582}
{"Training time": 15.543618358837234, "Episode Reward": 15799.546986319981, "Mean Reward": 61.71698041531243, "Episode": 4761, "Episode Step": 256}
{"Training time": 15.545813906656372, "Episode Reward": 8318.91359021918, "Mean Reward": 44.72534188289881, "Episode": 4762, "Episode Step": 186}
{"Training time": 15.547869067456988, "Episode Reward": 8086.0856317713005, "Mean Reward": 45.943668362336936, "Episode": 4763, "Episode Step": 176}
{"Training time": 15.550484881930881, "Episode Reward": 9117.16005343, "Mean Reward": 49.820546740054645, "Episode": 4764, "Episode Step": 183}
{"Training time": 15.55199083301756, "Episode Reward": 6018.273454410805, "Mean Reward": 47.76407503500639, "Episode": 4765, "Episode Step": 126}
{"Training time": 15.554081739981969, "Episode Reward": 7894.054060298056, "Mean Reward": 45.63037029074021, "Episode": 4766, "Episode Step": 173}
{"Training time": 15.556678061617745, "Episode Reward": 8875.66627356445, "Mean Reward": 49.86329367171039, "Episode": 4767, "Episode Step": 178}
{"Training time": 15.559490760498576, "Episode Reward": 12985.30838024874, "Mean Reward": 55.492770855763844, "Episode": 4768, "Episode Step": 234}
{"Training time": 15.561851033568383, "Episode Reward": 8961.448006658451, "Mean Reward": 45.956143623889496, "Episode": 4769, "Episode Step": 195}
{"Training time": 15.564411876069174, "Episode Reward": 9410.752364423435, "Mean Reward": 53.16809245436969, "Episode": 4770, "Episode Step": 177}
{"Training time": 15.571170071628359, "Episode Reward": 33604.36713853642, "Mean Reward": 59.05864171974766, "Episode": 4771, "Episode Step": 569}
{"Training time": 15.57471874276797, "Episode Reward": 17148.88333533899, "Mean Reward": 57.54658837362077, "Episode": 4772, "Episode Step": 298}
{"Training time": 15.58116845998499, "Episode Reward": 31115.876296956532, "Mean Reward": 61.86058905955573, "Episode": 4773, "Episode Step": 503}
{"Training time": 15.58498408165243, "Episode Reward": 18164.28935341458, "Mean Reward": 57.300597329383535, "Episode": 4774, "Episode Step": 317}
{"Training time": 15.586563110550244, "Episode Reward": 6323.016600117391, "Mean Reward": 48.63858923167224, "Episode": 4775, "Episode Step": 130}
{"Training time": 15.59315380944146, "Episode Reward": 31848.966618335424, "Mean Reward": 61.962970074582536, "Episode": 4776, "Episode Step": 514}
{"Training time": 15.59445102499591, "Episode Reward": 6088.4868766235495, "Mean Reward": 55.85767776718853, "Episode": 4777, "Episode Step": 109}
{"Training time": 15.59719728105598, "Episode Reward": 13750.490931728722, "Mean Reward": 59.78474318142923, "Episode": 4778, "Episode Step": 230}
{"Training time": 15.60299735804399, "Episode Reward": 26231.133334126567, "Mean Reward": 57.77782672715103, "Episode": 4779, "Episode Step": 454}
{"Training time": 15.606022103561296, "Episode Reward": 15861.545598484394, "Mean Reward": 61.24148879723704, "Episode": 4780, "Episode Step": 259}
{"Training time": 15.607610669136047, "Episode Reward": 6147.566931109663, "Mean Reward": 45.53753282303454, "Episode": 4781, "Episode Step": 135}
{"Training time": 15.61324090745714, "Episode Reward": 27025.521093429565, "Mean Reward": 61.00569095582294, "Episode": 4782, "Episode Step": 443}
{"Training time": 15.615506898562113, "Episode Reward": 9501.25805053665, "Mean Reward": 48.72440025916231, "Episode": 4783, "Episode Step": 195}
{"Training time": 15.62421597606606, "Episode Reward": 47349.37212517666, "Mean Reward": 63.641629200506266, "Episode": 4784, "Episode Step": 744}
{"Training time": 15.626734139985508, "Episode Reward": 8686.988233364522, "Mean Reward": 49.35788768957115, "Episode": 4785, "Episode Step": 176}
{"Training time": 15.630255979432, "Episode Reward": 18446.51566195607, "Mean Reward": 61.081177688596256, "Episode": 4786, "Episode Step": 302}
{"Training time": 15.636560597221056, "Episode Reward": 30863.06167893541, "Mean Reward": 57.687965755019455, "Episode": 4787, "Episode Step": 535}
{"Training time": 15.643745871053802, "Episode Reward": 34309.966517534755, "Mean Reward": 60.833273967260205, "Episode": 4788, "Episode Step": 564}
{"Training time": 15.648029923041662, "Episode Reward": 21214.530782967035, "Mean Reward": 58.28167797518416, "Episode": 4789, "Episode Step": 364}
{"Training time": 15.651532593833076, "Episode Reward": 16507.506373941134, "Mean Reward": 55.20905141786333, "Episode": 4790, "Episode Step": 299}
{"Training time": 15.659397914409638, "Episode Reward": 37178.67047822005, "Mean Reward": 58.920238475784544, "Episode": 4791, "Episode Step": 631}
{"Training time": 15.663742345505291, "Episode Reward": 20799.359280388475, "Mean Reward": 56.21448454159047, "Episode": 4792, "Episode Step": 370}
{"Training time": 15.670088069968754, "Episode Reward": 31164.535516627308, "Mean Reward": 57.81917535552376, "Episode": 4793, "Episode Step": 539}
{"Training time": 15.67259434554312, "Episode Reward": 8761.625783449146, "Mean Reward": 51.53897519675969, "Episode": 4794, "Episode Step": 170}
{"Training time": 15.676886688603295, "Episode Reward": 20014.44969590943, "Mean Reward": 56.22036431435233, "Episode": 4795, "Episode Step": 356}
{"Training time": 15.685177189442847, "Episode Reward": 42153.73125195416, "Mean Reward": 60.13371077311577, "Episode": 4796, "Episode Step": 701}
{"Training time": 15.687705655230417, "Episode Reward": 8958.096229614639, "Mean Reward": 51.18912131208365, "Episode": 4797, "Episode Step": 175}
{"Training time": 15.688914707501729, "Episode Reward": 5659.563250304733, "Mean Reward": 55.48591421867385, "Episode": 4798, "Episode Step": 102}
{"Training time": 15.694592971934213, "Episode Reward": 21543.749669037872, "Mean Reward": 55.24038376676378, "Episode": 4799, "Episode Step": 390}
{"Training time": 15.705418126914235, "Episode Reward": 52494.05322259677, "Mean Reward": 59.181570713186886, "Episode": 4800, "Episode Step": 887}
{"Training time": 15.706642592748006, "Episode Reward": 5609.220473668507, "Mean Reward": 54.99235758498536, "Episode": 4801, "Episode Step": 102}
{"Training time": 15.707916301356422, "Episode Reward": 5375.806090984915, "Mean Reward": 50.715151801744476, "Episode": 4802, "Episode Step": 106}
{"Training time": 15.713549253278309, "Episode Reward": 25344.47906104781, "Mean Reward": 57.60108877510866, "Episode": 4803, "Episode Step": 440}
{"Training time": 15.715036064386368, "Episode Reward": 6311.715610607433, "Mean Reward": 52.16293893063994, "Episode": 4804, "Episode Step": 121}
{"Training time": 15.720617276098993, "Episode Reward": 28361.00457173712, "Mean Reward": 61.12285468046793, "Episode": 4805, "Episode Step": 464}
{"Training time": 15.724040196935336, "Episode Reward": 15869.117673096924, "Mean Reward": 65.03736751269231, "Episode": 4806, "Episode Step": 244}
{"Training time": 15.727203452454672, "Episode Reward": 15959.472204842525, "Mean Reward": 61.61958380248079, "Episode": 4807, "Episode Step": 259}
{"Training time": 15.730727528002527, "Episode Reward": 17300.121403680605, "Mean Reward": 60.0698659850021, "Episode": 4808, "Episode Step": 288}
{"Training time": 15.733295671608714, "Episode Reward": 9133.13180399013, "Mean Reward": 52.48926324132259, "Episode": 4809, "Episode Step": 174}
{"Training time": 15.736870698862605, "Episode Reward": 18186.789642751428, "Mean Reward": 61.44185690118726, "Episode": 4810, "Episode Step": 296}
{"Training time": 15.740440328054959, "Episode Reward": 17908.411657785146, "Mean Reward": 59.49638424513337, "Episode": 4811, "Episode Step": 301}
{"Training time": 15.742355957229933, "Episode Reward": 6491.513245238414, "Mean Reward": 53.209124960970605, "Episode": 4812, "Episode Step": 122}
{"Training time": 15.74540048552884, "Episode Reward": 16331.431124815872, "Mean Reward": 63.794652831312, "Episode": 4813, "Episode Step": 256}
{"Training time": 15.751018918024169, "Episode Reward": 26363.571487524678, "Mean Reward": 55.9736125000524, "Episode": 4814, "Episode Step": 471}
{"Training time": 15.753587966892454, "Episode Reward": 8600.940472588763, "Mean Reward": 49.14823127193579, "Episode": 4815, "Episode Step": 175}
{"Training time": 15.762687379717827, "Episode Reward": 48896.34761601317, "Mean Reward": 63.09206144001699, "Episode": 4816, "Episode Step": 775}
{"Training time": 15.765992956360181, "Episode Reward": 16283.217613373828, "Mean Reward": 58.36278714470906, "Episode": 4817, "Episode Step": 279}
{"Training time": 15.769239178564813, "Episode Reward": 16023.244498510898, "Mean Reward": 67.60862657599534, "Episode": 4818, "Episode Step": 237}
{"Training time": 15.772732096115748, "Episode Reward": 19097.393314761124, "Mean Reward": 64.3009875917883, "Episode": 4819, "Episode Step": 297}
{"Training time": 15.781972488562266, "Episode Reward": 43807.852259185376, "Mean Reward": 54.89705796890398, "Episode": 4820, "Episode Step": 798}
{"Training time": 15.787519014676413, "Episode Reward": 25371.1900549742, "Mean Reward": 58.324574839021146, "Episode": 4821, "Episode Step": 435}
{"Training time": 15.796292129953702, "Episode Reward": 48969.77715440147, "Mean Reward": 65.20609474620701, "Episode": 4822, "Episode Step": 751}
{"Training time": 15.799943814410105, "Episode Reward": 17504.394237047934, "Mean Reward": 57.96157032135078, "Episode": 4823, "Episode Step": 302}
{"Training time": 15.803302642173238, "Episode Reward": 14756.232490586039, "Mean Reward": 59.98468492108146, "Episode": 4824, "Episode Step": 246}
{"Training time": 15.807003816101286, "Episode Reward": 18810.09130184024, "Mean Reward": 60.48260868758919, "Episode": 4825, "Episode Step": 311}
{"Training time": 15.812666540278329, "Episode Reward": 28347.62333721573, "Mean Reward": 59.3046513330873, "Episode": 4826, "Episode Step": 478}
{"Training time": 15.815196187165048, "Episode Reward": 8402.067660940187, "Mean Reward": 47.73902080079652, "Episode": 4827, "Episode Step": 176}
{"Training time": 15.818763545817799, "Episode Reward": 19461.376619110517, "Mean Reward": 63.80779219380497, "Episode": 4828, "Episode Step": 305}
{"Training time": 15.824982928567463, "Episode Reward": 31773.43773460001, "Mean Reward": 58.83969950851854, "Episode": 4829, "Episode Step": 540}
{"Training time": 15.82836767633756, "Episode Reward": 16096.097565641876, "Mean Reward": 65.1663869054327, "Episode": 4830, "Episode Step": 247}
{"Training time": 15.83044321583377, "Episode Reward": 8979.448741231368, "Mean Reward": 51.31113566417925, "Episode": 4831, "Episode Step": 175}
{"Training time": 15.836635163293945, "Episode Reward": 30084.479922675215, "Mean Reward": 56.23267275266395, "Episode": 4832, "Episode Step": 535}
{"Training time": 15.85033645272255, "Episode Reward": 71851.46388259484, "Mean Reward": 62.75237020313959, "Episode": 4833, "Episode Step": 1145}
{"Training time": 15.859359997444683, "Episode Reward": 48667.647032351284, "Mean Reward": 62.63532436596047, "Episode": 4834, "Episode Step": 777}
{"Training time": 15.889594408869744, "Episode Reward": 156648.03895935608, "Mean Reward": 59.74372195246227, "Episode": 4835, "Episode Step": 2622}
{"Training time": 15.910303349428707, "Episode Reward": 113602.25424734259, "Mean Reward": 64.5834304987735, "Episode": 4836, "Episode Step": 1759}
{"Training time": 15.916401730775833, "Episode Reward": 32832.056281009056, "Mean Reward": 62.53725005906487, "Episode": 4837, "Episode Step": 525}
{"Training time": 15.918495438893636, "Episode Reward": 7626.091934859267, "Mean Reward": 42.133104612482136, "Episode": 4838, "Episode Step": 181}
{"Training time": 15.93726732412974, "Episode Reward": 101661.67511900615, "Mean Reward": 65.04265842546778, "Episode": 4839, "Episode Step": 1563}
{"Training time": 15.945874852736791, "Episode Reward": 46477.04428233439, "Mean Reward": 63.06247528132211, "Episode": 4840, "Episode Step": 737}
{"Training time": 15.980623279147679, "Episode Reward": 172202.51630202937, "Mean Reward": 57.72796389608762, "Episode": 4841, "Episode Step": 2983}
{"Training time": 15.988156103889148, "Episode Reward": 36566.78878798, "Mean Reward": 60.04398815760262, "Episode": 4842, "Episode Step": 609}
{"Training time": 15.997225306100315, "Episode Reward": 48991.952548547866, "Mean Reward": 63.70865090838474, "Episode": 4843, "Episode Step": 769}
{"Training time": 16.021868279973667, "Episode Reward": 124556.75964361592, "Mean Reward": 59.143760514537476, "Episode": 4844, "Episode Step": 2106}
{"Training time": 16.055165189438394, "Episode Reward": 181703.89538766508, "Mean Reward": 64.77857233071839, "Episode": 4845, "Episode Step": 2805}
{"Training time": 16.059006223877272, "Episode Reward": 19586.832472986658, "Mean Reward": 59.89857025378183, "Episode": 4846, "Episode Step": 327}
{"Training time": 16.071697145501773, "Episode Reward": 62782.074854858976, "Mean Reward": 57.97052156496674, "Episode": 4847, "Episode Step": 1083}
{"Training time": 16.079581491351128, "Episode Reward": 36009.5391057849, "Mean Reward": 57.43148182740813, "Episode": 4848, "Episode Step": 627}
{"Training time": 16.095466672182084, "Episode Reward": 81385.74353154065, "Mean Reward": 64.59185994566718, "Episode": 4849, "Episode Step": 1260}
{"Training time": 16.09784299082226, "Episode Reward": 7831.091868437512, "Mean Reward": 43.74911658344979, "Episode": 4850, "Episode Step": 179}
{"Training time": 16.101219425532552, "Episode Reward": 16493.11554254032, "Mean Reward": 66.50449815540452, "Episode": 4851, "Episode Step": 248}
{"Training time": 16.105120835238033, "Episode Reward": 19487.823915904693, "Mean Reward": 58.17260870419312, "Episode": 4852, "Episode Step": 335}
{"Training time": 16.113639091054598, "Episode Reward": 42544.378548354995, "Mean Reward": 58.12073572179644, "Episode": 4853, "Episode Step": 732}
{"Training time": 16.12640211164951, "Episode Reward": 65910.01870553217, "Mean Reward": 62.29680406950111, "Episode": 4854, "Episode Step": 1058}
{"Training time": 16.139103169441224, "Episode Reward": 65860.65326629096, "Mean Reward": 60.20169402768826, "Episode": 4855, "Episode Step": 1094}
{"Training time": 16.152962510784466, "Episode Reward": 69432.0542482545, "Mean Reward": 58.102137446238075, "Episode": 4856, "Episode Step": 1195}
{"Training time": 16.154899132185513, "Episode Reward": 6097.513971892222, "Mean Reward": 48.01192103852143, "Episode": 4857, "Episode Step": 127}
{"Training time": 16.162020441624854, "Episode Reward": 39099.58723982432, "Mean Reward": 64.41447650712409, "Episode": 4858, "Episode Step": 607}
{"Training time": 16.196948302785554, "Episode Reward": 174820.91174650282, "Mean Reward": 58.080037125084, "Episode": 4859, "Episode Step": 3010}
{"Training time": 16.204532763295703, "Episode Reward": 34432.384535787256, "Mean Reward": 56.262066234946495, "Episode": 4860, "Episode Step": 612}
{"Training time": 16.225618957479796, "Episode Reward": 111747.16416592411, "Mean Reward": 61.97846043589801, "Episode": 4861, "Episode Step": 1803}
{"Training time": 16.250863485270077, "Episode Reward": 126610.24107453863, "Mean Reward": 58.39955769120785, "Episode": 4862, "Episode Step": 2168}
{"Training time": 16.258015415271124, "Episode Reward": 34262.082384924, "Mean Reward": 60.964559403779354, "Episode": 4863, "Episode Step": 562}
{"Training time": 16.275346007479563, "Episode Reward": 87986.2926701373, "Mean Reward": 59.36996806352045, "Episode": 4864, "Episode Step": 1482}
{"Training time": 16.28227869523896, "Episode Reward": 34964.97144096891, "Mean Reward": 59.1623882249897, "Episode": 4865, "Episode Step": 591}
{"Training time": 16.28826020359993, "Episode Reward": 29719.920128145302, "Mean Reward": 62.436806991901896, "Episode": 4866, "Episode Step": 476}
{"Training time": 16.299575330813727, "Episode Reward": 57577.17987597782, "Mean Reward": 59.851538332617274, "Episode": 4867, "Episode Step": 962}
{"Training time": 16.301647274957762, "Episode Reward": 7639.394388118325, "Mean Reward": 43.90456544895589, "Episode": 4868, "Episode Step": 174}
{"Training time": 16.307480976117983, "Episode Reward": 27228.179419242715, "Mean Reward": 59.320652329504824, "Episode": 4869, "Episode Step": 459}
{"Training time": 16.312114691668086, "Episode Reward": 19351.935261546456, "Mean Reward": 49.36718178965933, "Episode": 4870, "Episode Step": 392}
{"Training time": 16.32594187332524, "Episode Reward": 70540.04353950993, "Mean Reward": 60.13643950512356, "Episode": 4871, "Episode Step": 1173}
{"Training time": 16.349422675503625, "Episode Reward": 126445.50571283165, "Mean Reward": 64.15297093497294, "Episode": 4872, "Episode Step": 1971}
{"Training time": 16.355642555819617, "Episode Reward": 36072.803240379566, "Mean Reward": 67.80602112853302, "Episode": 4873, "Episode Step": 532}
{"Training time": 16.363017471896278, "Episode Reward": 35330.86614201221, "Mean Reward": 55.81495441076178, "Episode": 4874, "Episode Step": 633}
{"Training time": 16.368872652782333, "Episode Reward": 28234.019979492423, "Mean Reward": 61.91671048134303, "Episode": 4875, "Episode Step": 456}
{"Training time": 16.38442858139674, "Episode Reward": 77504.14833370873, "Mean Reward": 58.05554182300279, "Episode": 4876, "Episode Step": 1335}
{"Training time": 16.417665481103793, "Episode Reward": 173948.0171137135, "Mean Reward": 60.60906519641585, "Episode": 4877, "Episode Step": 2870}
{"Training time": 16.424575856394238, "Episode Reward": 33034.538098978424, "Mean Reward": 59.20168118096492, "Episode": 4878, "Episode Step": 558}
{"Training time": 16.426948605246015, "Episode Reward": 9587.643448126031, "Mean Reward": 46.99825219669623, "Episode": 4879, "Episode Step": 204}
{"Training time": 16.434057379166287, "Episode Reward": 33509.342591169, "Mean Reward": 54.753827763348035, "Episode": 4880, "Episode Step": 612}
{"Training time": 16.436514484153854, "Episode Reward": 8439.120201348016, "Mean Reward": 49.3515801248422, "Episode": 4881, "Episode Step": 171}
{"Training time": 16.444450476898087, "Episode Reward": 36013.59179378656, "Mean Reward": 52.421530995322506, "Episode": 4882, "Episode Step": 687}
{"Training time": 16.482875143024657, "Episode Reward": 192204.4249069904, "Mean Reward": 57.98021867480857, "Episode": 4883, "Episode Step": 3315}
{"Training time": 16.484846005837124, "Episode Reward": 5856.99787974913, "Mean Reward": 46.85598303799304, "Episode": 4884, "Episode Step": 125}
{"Training time": 16.4860674683253, "Episode Reward": -237.9633643082356, "Mean Reward": -2.332974159884663, "Episode": 4885, "Episode Step": 102}
{"Training time": 16.492492235832746, "Episode Reward": 31537.11839176204, "Mean Reward": 57.444660094284224, "Episode": 4886, "Episode Step": 549}
{"Training time": 16.500670665502547, "Episode Reward": 44517.82962491457, "Mean Reward": 66.94410469911966, "Episode": 4887, "Episode Step": 665}
{"Training time": 16.503812701370983, "Episode Reward": 8612.506154227522, "Mean Reward": 31.898170941583412, "Episode": 4888, "Episode Step": 270}
{"Training time": 16.561599396069845, "Episode Reward": 285097.29659516126, "Mean Reward": 57.01945931903225, "Episode": 4889, "Episode Step": 5000}
{"Training time": 16.589126053320037, "Episode Reward": 146932.6118232831, "Mean Reward": 62.73809215340867, "Episode": 4890, "Episode Step": 2342}
{"Training time": 16.59034605940183, "Episode Reward": 57.22913085777727, "Mean Reward": 0.5610699103703654, "Episode": 4891, "Episode Step": 102}
{"Training time": 16.60181060579088, "Episode Reward": 51834.81837095388, "Mean Reward": 52.2528410997519, "Episode": 4892, "Episode Step": 992}
{"Training time": 16.604304223590425, "Episode Reward": 8709.057226254155, "Mean Reward": 50.34137125002402, "Episode": 4893, "Episode Step": 173}
{"Training time": 16.605524611340627, "Episode Reward": 46.05514646296895, "Mean Reward": 0.45152104375459756, "Episode": 4894, "Episode Step": 102}
{"Training time": 16.663666719132, "Episode Reward": 293409.35671527573, "Mean Reward": 58.68187134305515, "Episode": 4895, "Episode Step": 5000}
{"Training time": 16.689906264675987, "Episode Reward": 139725.89443905308, "Mean Reward": 63.51177019956958, "Episode": 4896, "Episode Step": 2200}
{"Training time": 16.691639149718814, "Episode Reward": 4367.419431322013, "Mean Reward": 30.120134009117333, "Episode": 4897, "Episode Step": 145}
{"Training time": 16.713840908871756, "Episode Reward": 108675.38393794796, "Mean Reward": 57.077407530434854, "Episode": 4898, "Episode Step": 1904}
{"Training time": 16.72236380663183, "Episode Reward": 35149.77072098062, "Mean Reward": 58.582951201634366, "Episode": 4899, "Episode Step": 600}
{"Training time": 16.725115094449784, "Episode Reward": 8407.390608033733, "Mean Reward": 39.65750286808365, "Episode": 4900, "Episode Step": 212}
{"Training time": 16.7277555138535, "Episode Reward": 9063.408263378142, "Mean Reward": 39.92690864924292, "Episode": 4901, "Episode Step": 227}
{"Training time": 16.740223276350232, "Episode Reward": 64802.0542332411, "Mean Reward": 62.24981194355533, "Episode": 4902, "Episode Step": 1041}
{"Training time": 16.742543221116065, "Episode Reward": 7947.466510389231, "Mean Reward": 40.13871974944056, "Episode": 4903, "Episode Step": 198}
{"Training time": 16.75516657133897, "Episode Reward": 58860.37384773864, "Mean Reward": 53.60689785768547, "Episode": 4904, "Episode Step": 1098}
{"Training time": 16.807691189116902, "Episode Reward": 282128.3110585072, "Mean Reward": 62.225035522388, "Episode": 4905, "Episode Step": 4534}
{"Training time": 16.81011384440793, "Episode Reward": 8461.061415065917, "Mean Reward": 40.290768643171035, "Episode": 4906, "Episode Step": 210}
{"Training time": 16.82404867635833, "Episode Reward": 73130.08117631599, "Mean Reward": 61.09447048982121, "Episode": 4907, "Episode Step": 1197}
{"Training time": 16.82918235136403, "Episode Reward": 24338.32242219941, "Mean Reward": 60.69407087830277, "Episode": 4908, "Episode Step": 401}
{"Training time": 16.83233420358764, "Episode Reward": 16171.135671022797, "Mean Reward": 59.67208734694759, "Episode": 4909, "Episode Step": 271}
{"Training time": 16.83573268605603, "Episode Reward": 18023.662097981505, "Mean Reward": 60.8907503310186, "Episode": 4910, "Episode Step": 296}
{"Training time": 16.838158079716894, "Episode Reward": 8880.90906412234, "Mean Reward": 52.54975777587183, "Episode": 4911, "Episode Step": 169}
{"Training time": 16.84151566081577, "Episode Reward": 15302.154262574077, "Mean Reward": 54.45606499136682, "Episode": 4912, "Episode Step": 281}
{"Training time": 16.859599935809772, "Episode Reward": 89021.31418707401, "Mean Reward": 57.101548548475954, "Episode": 4913, "Episode Step": 1559}
{"Training time": 16.8671573583285, "Episode Reward": 36041.054348600315, "Mean Reward": 59.18071321609247, "Episode": 4914, "Episode Step": 609}
{"Training time": 16.869454569684134, "Episode Reward": 8346.137615392343, "Mean Reward": 41.9403900270972, "Episode": 4915, "Episode Step": 199}
{"Training time": 16.884895882209143, "Episode Reward": 72726.22765152535, "Mean Reward": 55.13739776461361, "Episode": 4916, "Episode Step": 1319}
{"Training time": 16.888070086638134, "Episode Reward": 13882.122792532802, "Mean Reward": 61.154725958294286, "Episode": 4917, "Episode Step": 227}
{"Training time": 16.890878630280493, "Episode Reward": 7979.683528654405, "Mean Reward": 33.52808205316977, "Episode": 4918, "Episode Step": 238}
{"Training time": 16.89301461941666, "Episode Reward": 8070.48907763923, "Mean Reward": 45.33982627887208, "Episode": 4919, "Episode Step": 178}
{"Training time": 16.90580165439182, "Episode Reward": 64805.84409298252, "Mean Reward": 61.544011484313884, "Episode": 4920, "Episode Step": 1053}
{"Training time": 16.90700439578957, "Episode Reward": -148.41048442204448, "Mean Reward": -1.45500474923573, "Episode": 4921, "Episode Step": 102}
{"Training time": 16.925656972726188, "Episode Reward": 93714.67340348501, "Mean Reward": 58.244048106578624, "Episode": 4922, "Episode Step": 1609}
{"Training time": 16.929587256113688, "Episode Reward": 17847.4680318658, "Mean Reward": 60.0924849557771, "Episode": 4923, "Episode Step": 297}
{"Training time": 16.93081208805243, "Episode Reward": -136.67307154764012, "Mean Reward": -1.3399320739964717, "Episode": 4924, "Episode Step": 102}
{"Training time": 16.93207455886735, "Episode Reward": 5545.691219880085, "Mean Reward": 52.81610685600081, "Episode": 4925, "Episode Step": 105}
{"Training time": 16.934583889974487, "Episode Reward": 9206.070260061839, "Mean Reward": 53.83666818749613, "Episode": 4926, "Episode Step": 171}
{"Training time": 16.93636061999533, "Episode Reward": 3420.755375719867, "Mean Reward": 22.805035838132447, "Episode": 4927, "Episode Step": 150}
{"Training time": 16.94724871582455, "Episode Reward": 56585.63826640779, "Mean Reward": 60.5193992154094, "Episode": 4928, "Episode Step": 935}
{"Training time": 16.949202175272834, "Episode Reward": 5932.7188141310235, "Mean Reward": 48.23348629374816, "Episode": 4929, "Episode Step": 123}
{"Training time": 16.95041887773408, "Episode Reward": 67.35126998033061, "Mean Reward": 0.6603065684346139, "Episode": 4930, "Episode Step": 102}
{"Training time": 16.95352935247951, "Episode Reward": 14445.456018309176, "Mean Reward": 54.7176364329893, "Episode": 4931, "Episode Step": 264}
{"Training time": 16.956066778302194, "Episode Reward": 8853.690418679666, "Mean Reward": 50.59251667816952, "Episode": 4932, "Episode Step": 175}
{"Training time": 16.95727870305379, "Episode Reward": -56.01617932097396, "Mean Reward": -0.5491782286369996, "Episode": 4933, "Episode Step": 102}
{"Training time": 16.970753799941804, "Episode Reward": 68921.64620697535, "Mean Reward": 59.41521224739254, "Episode": 4934, "Episode Step": 1160}
{"Training time": 16.994183855520355, "Episode Reward": 117737.38700767652, "Mean Reward": 60.25454811037693, "Episode": 4935, "Episode Step": 1954}
{"Training time": 16.995417439142862, "Episode Reward": 2.1376125697411936, "Mean Reward": 0.02095698597785484, "Episode": 4936, "Episode Step": 102}
{"Training time": 17.007719703581596, "Episode Reward": 63693.97302701807, "Mean Reward": 60.718754077233626, "Episode": 4937, "Episode Step": 1049}
{"Training time": 17.025944182210498, "Episode Reward": 86862.98851021718, "Mean Reward": 57.52515795378621, "Episode": 4938, "Episode Step": 1510}
{"Training time": 17.027164921628103, "Episode Reward": -154.55158887482474, "Mean Reward": -1.5152116556355366, "Episode": 4939, "Episode Step": 102}
{"Training time": 17.044028424951765, "Episode Reward": 87241.9194768411, "Mean Reward": 60.29158222311064, "Episode": 4940, "Episode Step": 1447}
{"Training time": 17.048097302450074, "Episode Reward": 15097.396632768305, "Mean Reward": 48.85888877918545, "Episode": 4941, "Episode Step": 309}
{"Training time": 17.049290097753207, "Episode Reward": -82.66455202371914, "Mean Reward": -0.8104367845462661, "Episode": 4942, "Episode Step": 102}
{"Training time": 17.067112481660313, "Episode Reward": 90511.79306309929, "Mean Reward": 58.39470520199954, "Episode": 4943, "Episode Step": 1550}
{"Training time": 17.069613882170785, "Episode Reward": 7544.888836750185, "Mean Reward": 43.61207420086812, "Episode": 4944, "Episode Step": 173}
{"Training time": 17.070817658834986, "Episode Reward": -110.19696172538697, "Mean Reward": -1.080362369856735, "Episode": 4945, "Episode Step": 102}
{"Training time": 17.08309666633606, "Episode Reward": 65223.723555103265, "Mean Reward": 61.07090220515287, "Episode": 4946, "Episode Step": 1068}
{"Training time": 17.085560469163788, "Episode Reward": 8692.464870121532, "Mean Reward": 49.671227829265895, "Episode": 4947, "Episode Step": 175}
{"Training time": 17.086879694726733, "Episode Reward": 3310.9854000152004, "Mean Reward": 29.043731579080706, "Episode": 4948, "Episode Step": 114}
{"Training time": 17.094374855558076, "Episode Reward": 31943.08700892814, "Mean Reward": 58.078340016232985, "Episode": 4949, "Episode Step": 550}
{"Training time": 17.111378770536845, "Episode Reward": 91046.64423835515, "Mean Reward": 63.358833847150414, "Episode": 4950, "Episode Step": 1437}
{"Training time": 17.112607987721763, "Episode Reward": 89.93025082316413, "Mean Reward": 0.8483985926713598, "Episode": 4951, "Episode Step": 106}
{"Training time": 17.120908726387555, "Episode Reward": 42844.330385215006, "Mean Reward": 59.838450258680176, "Episode": 4952, "Episode Step": 716}
{"Training time": 17.126915755271913, "Episode Reward": 28142.71306254655, "Mean Reward": 59.75098314765722, "Episode": 4953, "Episode Step": 471}
{"Training time": 17.128133854667347, "Episode Reward": 222.94231486440842, "Mean Reward": 2.185708969258906, "Episode": 4954, "Episode Step": 102}
{"Training time": 17.13124031609959, "Episode Reward": 15059.588102191738, "Mean Reward": 57.04389432648385, "Episode": 4955, "Episode Step": 264}
{"Training time": 17.132925437490144, "Episode Reward": 5622.795646337183, "Mean Reward": 55.125447513109634, "Episode": 4956, "Episode Step": 102}
{"Training time": 17.134135088589456, "Episode Reward": 171.22397721572378, "Mean Reward": 1.6786664432914096, "Episode": 4957, "Episode Step": 102}
{"Training time": 17.140448266334005, "Episode Reward": 29106.397245997687, "Mean Reward": 54.81430743125741, "Episode": 4958, "Episode Step": 531}
{"Training time": 17.143019939396115, "Episode Reward": 8050.618125580737, "Mean Reward": 46.00353214617564, "Episode": 4959, "Episode Step": 175}
{"Training time": 17.144088441663317, "Episode Reward": -28.26655077610718, "Mean Reward": -0.3212108042739452, "Episode": 4960, "Episode Step": 88}
{"Training time": 17.150267292459805, "Episode Reward": 32507.470478952528, "Mean Reward": 61.684004703894736, "Episode": 4961, "Episode Step": 527}
{"Training time": 17.153551951116984, "Episode Reward": 15037.589948197457, "Mean Reward": 61.8830862065739, "Episode": 4962, "Episode Step": 243}
{"Training time": 17.154742063615057, "Episode Reward": -14.119127807365624, "Mean Reward": -0.13842282164083944, "Episode": 4963, "Episode Step": 102}
{"Training time": 17.188592449691562, "Episode Reward": 171495.15418368354, "Mean Reward": 59.05480515967064, "Episode": 4964, "Episode Step": 2904}
{"Training time": 17.195521911647585, "Episode Reward": 32809.12188273811, "Mean Reward": 58.7977094672726, "Episode": 4965, "Episode Step": 558}
{"Training time": 17.196729706658257, "Episode Reward": 207.3350561138751, "Mean Reward": 2.032696628567403, "Episode": 4966, "Episode Step": 102}
{"Training time": 17.19773670805825, "Episode Reward": -534.3714018757971, "Mean Reward": -6.2867223750093775, "Episode": 4967, "Episode Step": 85}
{"Training time": 17.20531392302778, "Episode Reward": 35786.20934842345, "Mean Reward": 58.85889695464383, "Episode": 4968, "Episode Step": 608}
{"Training time": 17.20653424607383, "Episode Reward": -4.052303458483525, "Mean Reward": -0.039728465279250245, "Episode": 4969, "Episode Step": 102}
{"Training time": 17.207418942451476, "Episode Reward": -481.8672663121869, "Mean Reward": -6.6926009210025965, "Episode": 4970, "Episode Step": 72}
{"Training time": 17.215095337761774, "Episode Reward": 36900.02564906206, "Mean Reward": 59.70877936741434, "Episode": 4971, "Episode Step": 618}
{"Training time": 17.216298184129926, "Episode Reward": -4.113120669862599, "Mean Reward": -0.04032471244963332, "Episode": 4972, "Episode Step": 102}
{"Training time": 17.23534519188934, "Episode Reward": 89845.10794898275, "Mean Reward": 55.11969812821028, "Episode": 4973, "Episode Step": 1630}
{"Training time": 17.243127920561367, "Episode Reward": 33143.25444896963, "Mean Reward": 53.3707801110622, "Episode": 4974, "Episode Step": 621}
{"Training time": 17.244328742490875, "Episode Reward": -84.52412070172629, "Mean Reward": -0.8286678500169244, "Episode": 4975, "Episode Step": 102}
{"Training time": 17.245668591923184, "Episode Reward": 5377.848394974006, "Mean Reward": 47.591578716584124, "Episode": 4976, "Episode Step": 113}
{"Training time": 17.25788161383735, "Episode Reward": 62527.49149994273, "Mean Reward": 62.34047008967371, "Episode": 4977, "Episode Step": 1003}
{"Training time": 17.25909981250763, "Episode Reward": 0.1846029235261646, "Mean Reward": 0.001809832583589849, "Episode": 4978, "Episode Step": 102}
{"Training time": 17.262255936662356, "Episode Reward": 14809.623235293937, "Mean Reward": 54.85045642701458, "Episode": 4979, "Episode Step": 270}
{"Training time": 17.270038673281668, "Episode Reward": 36733.464040153995, "Mean Reward": 59.924084894215326, "Episode": 4980, "Episode Step": 613}
{"Training time": 17.271285405225225, "Episode Reward": 65.11073803011416, "Mean Reward": 0.6383405689226879, "Episode": 4981, "Episode Step": 102}
{"Training time": 17.274067390826012, "Episode Reward": 10686.68867728434, "Mean Reward": 46.871441567036584, "Episode": 4982, "Episode Step": 228}
{"Training time": 17.28468094388644, "Episode Reward": 49979.61136996945, "Mean Reward": 58.592744865145896, "Episode": 4983, "Episode Step": 853}
{"Training time": 17.285891238848368, "Episode Reward": -1.1708953473796235, "Mean Reward": -0.011479366150780624, "Episode": 4984, "Episode Step": 102}
{"Training time": 17.292381835778553, "Episode Reward": 31306.284774121243, "Mean Reward": 56.40772031373197, "Episode": 4985, "Episode Step": 555}
{"Training time": 17.294885620276133, "Episode Reward": 8386.031017952138, "Mean Reward": 47.92017724544079, "Episode": 4986, "Episode Step": 175}
{"Training time": 17.296111294693418, "Episode Reward": 2.1728048996067177, "Mean Reward": 0.021302008819673705, "Episode": 4987, "Episode Step": 102}
{"Training time": 17.29827410161495, "Episode Reward": 9173.48448805734, "Mean Reward": 50.68223474064829, "Episode": 4988, "Episode Step": 181}
{"Training time": 17.29995739996433, "Episode Reward": 5216.555210185162, "Mean Reward": 50.64616708917633, "Episode": 4989, "Episode Step": 103}
{"Training time": 17.301299852728842, "Episode Reward": 1621.2779316534097, "Mean Reward": 14.3475923155169, "Episode": 4990, "Episode Step": 113}
{"Training time": 17.308791354166136, "Episode Reward": 34899.87239054775, "Mean Reward": 54.108329287670934, "Episode": 4991, "Episode Step": 645}
{"Training time": 17.36703310860528, "Episode Reward": 304378.50235207187, "Mean Reward": 61.6775080753945, "Episode": 4992, "Episode Step": 4935}
{"Training time": 17.368639489677218, "Episode Reward": 3376.4664876883585, "Mean Reward": 25.010862871765617, "Episode": 4993, "Episode Step": 135}
{"Training time": 17.370771611332895, "Episode Reward": 8665.78309112284, "Mean Reward": 48.684174669229435, "Episode": 4994, "Episode Step": 178}
{"Training time": 17.373325034976006, "Episode Reward": 7638.158142275066, "Mean Reward": 43.398625808381055, "Episode": 4995, "Episode Step": 176}
{"Training time": 17.375429413318635, "Episode Reward": 7863.398271779867, "Mean Reward": 44.17639478528015, "Episode": 4996, "Episode Step": 178}
{"Training time": 17.377548321353064, "Episode Reward": 8674.687071584814, "Mean Reward": 48.19270595324897, "Episode": 4997, "Episode Step": 180}
{"Training time": 17.38011668026447, "Episode Reward": 7655.7880521319485, "Mean Reward": 42.76976565436843, "Episode": 4998, "Episode Step": 179}
{"Training time": 17.38335656914446, "Episode Reward": 7803.492618577022, "Mean Reward": 42.642036167087554, "Episode": 4999, "Episode Step": 183}
{"Training time": 17.38496645443969, "Episode Reward": 6167.993149916944, "Mean Reward": 54.58401017625614, "Episode": 5000, "Episode Step": 113}
{"Training time": 17.4080383919345, "Episode Reward": 114284.3305968658, "Mean Reward": 58.13038178884323, "Episode": 5001, "Episode Step": 1966}
{"Training time": 17.41010029527876, "Episode Reward": 8013.669980319339, "Mean Reward": 45.53221579726897, "Episode": 5002, "Episode Step": 176}
{"Training time": 17.412179338335992, "Episode Reward": 8956.474367671986, "Mean Reward": 50.317271728494305, "Episode": 5003, "Episode Step": 178}
{"Training time": 17.424950284428068, "Episode Reward": 64947.5595106389, "Mean Reward": 60.75543452819355, "Episode": 5004, "Episode Step": 1069}
{"Training time": 17.42699290745788, "Episode Reward": 7166.980542888132, "Mean Reward": 41.18954334993179, "Episode": 5005, "Episode Step": 174}
{"Training time": 17.429098925259378, "Episode Reward": 8827.14497308704, "Mean Reward": 48.5007965554233, "Episode": 5006, "Episode Step": 182}
{"Training time": 17.432674533857238, "Episode Reward": 14982.701928538787, "Mean Reward": 56.538497843542594, "Episode": 5007, "Episode Step": 265}
{"Training time": 17.434652328557437, "Episode Reward": 7885.496790479098, "Mean Reward": 46.659744322361526, "Episode": 5008, "Episode Step": 169}
{"Training time": 17.45668946027756, "Episode Reward": 119803.36920183497, "Mean Reward": 62.790025787125245, "Episode": 5009, "Episode Step": 1908}
{"Training time": 17.472749799158837, "Episode Reward": 82855.92998340784, "Mean Reward": 61.51145507305704, "Episode": 5010, "Episode Step": 1347}
{"Training time": 17.474775538047155, "Episode Reward": 7795.65672016691, "Mean Reward": 45.32358558236576, "Episode": 5011, "Episode Step": 172}
{"Training time": 17.476881385776732, "Episode Reward": 8849.415237582414, "Mean Reward": 49.43807395297438, "Episode": 5012, "Episode Step": 179}
{"Training time": 17.479385471079084, "Episode Reward": 8582.972322393203, "Mean Reward": 49.61255677683933, "Episode": 5013, "Episode Step": 173}
{"Training time": 17.481418585512372, "Episode Reward": 7388.352956344414, "Mean Reward": 43.46089974320244, "Episode": 5014, "Episode Step": 170}
{"Training time": 17.483532660802204, "Episode Reward": 9079.781863073697, "Mean Reward": 50.72503834119384, "Episode": 5015, "Episode Step": 179}
{"Training time": 17.486002019974922, "Episode Reward": 8223.362081159024, "Mean Reward": 48.372718124464846, "Episode": 5016, "Episode Step": 170}
{"Training time": 17.486990214122667, "Episode Reward": 3639.6589889144307, "Mean Reward": 44.38608523066379, "Episode": 5017, "Episode Step": 82}
{"Training time": 17.48916547689173, "Episode Reward": 9358.163740119347, "Mean Reward": 51.702562100106896, "Episode": 5018, "Episode Step": 181}
{"Training time": 17.49259211467372, "Episode Reward": 15715.218565367746, "Mean Reward": 63.36781679583768, "Episode": 5019, "Episode Step": 248}
{"Training time": 17.494133016665778, "Episode Reward": 5519.562805734137, "Mean Reward": 42.45817542872413, "Episode": 5020, "Episode Step": 130}
{"Training time": 17.49630031194952, "Episode Reward": 8599.925824107397, "Mean Reward": 46.7387273049315, "Episode": 5021, "Episode Step": 184}
{"Training time": 17.49736198498143, "Episode Reward": 2131.141284971547, "Mean Reward": 43.49267928513361, "Episode": 5022, "Episode Step": 49}
{"Training time": 17.49892274412844, "Episode Reward": 5805.623324211647, "Mean Reward": 43.98199488039126, "Episode": 5023, "Episode Step": 132}
{"Training time": 17.522245298027993, "Episode Reward": 121113.13920101081, "Mean Reward": 60.16549389021898, "Episode": 5024, "Episode Step": 2013}
{"Training time": 17.52326204856237, "Episode Reward": 2732.2172630633677, "Mean Reward": 58.13228219283761, "Episode": 5025, "Episode Step": 47}
{"Training time": 17.524206475549274, "Episode Reward": 4226.3350489730165, "Mean Reward": 52.17697591324712, "Episode": 5026, "Episode Step": 81}
{"Training time": 17.52639795773559, "Episode Reward": 8854.086402300936, "Mean Reward": 47.34805562727773, "Episode": 5027, "Episode Step": 187}
{"Training time": 17.52888664583365, "Episode Reward": 8547.309352529495, "Mean Reward": 49.40641244236703, "Episode": 5028, "Episode Step": 173}
{"Training time": 17.530884679423437, "Episode Reward": 8332.82265661995, "Mean Reward": 49.0166038624703, "Episode": 5029, "Episode Step": 170}
{"Training time": 17.554237056639458, "Episode Reward": 121236.41644738025, "Mean Reward": 59.84028452486686, "Episode": 5030, "Episode Step": 2026}
{"Training time": 17.56279414329264, "Episode Reward": 41807.92649425733, "Mean Reward": 59.55545084652041, "Episode": 5031, "Episode Step": 702}
{"Training time": 17.56336192720466, "Episode Reward": 1809.6345336501859, "Mean Reward": 37.700719451045536, "Episode": 5032, "Episode Step": 48}
{"Training time": 17.575051971938876, "Episode Reward": 59112.47026976608, "Mean Reward": 58.18156522614772, "Episode": 5033, "Episode Step": 1016}
{"Training time": 17.577571800814734, "Episode Reward": 9067.211844566204, "Mean Reward": 50.37339913647891, "Episode": 5034, "Episode Step": 180}
{"Training time": 17.57854962249597, "Episode Reward": 4197.028918261427, "Mean Reward": 51.18327949099301, "Episode": 5035, "Episode Step": 82}
{"Training time": 17.627807842757967, "Episode Reward": 250314.58893992618, "Mean Reward": 58.307614474709105, "Episode": 5036, "Episode Step": 4293}
{"Training time": 17.630314761333995, "Episode Reward": 9152.3659356725, "Mean Reward": 52.002079179957384, "Episode": 5037, "Episode Step": 176}
{"Training time": 17.630899115535946, "Episode Reward": 1756.168852555963, "Mean Reward": 35.840180664407406, "Episode": 5038, "Episode Step": 49}
{"Training time": 17.671566799150572, "Episode Reward": 202411.08384678408, "Mean Reward": 57.2753491360453, "Episode": 5039, "Episode Step": 3534}
{"Training time": 17.674959095252884, "Episode Reward": 15780.639137216393, "Mean Reward": 62.37406773603317, "Episode": 5040, "Episode Step": 253}
{"Training time": 17.67590767416689, "Episode Reward": 4038.4047731697456, "Mean Reward": 50.48005966462182, "Episode": 5041, "Episode Step": 80}
{"Training time": 17.67709602607621, "Episode Reward": -683.6221982014852, "Mean Reward": -6.70217841374005, "Episode": 5042, "Episode Step": 102}
{"Training time": 17.67960136665238, "Episode Reward": 9013.632109017186, "Mean Reward": 52.101919705301654, "Episode": 5043, "Episode Step": 173}
{"Training time": 17.680560835003853, "Episode Reward": 3979.0289411792146, "Mean Reward": 49.73786176474018, "Episode": 5044, "Episode Step": 80}
{"Training time": 17.688551345003976, "Episode Reward": 32810.30667839829, "Mean Reward": 48.038516366615355, "Episode": 5045, "Episode Step": 683}
{"Training time": 17.69041138192018, "Episode Reward": 6204.7756594195025, "Mean Reward": 53.03227059332908, "Episode": 5046, "Episode Step": 117}
{"Training time": 17.69241512470775, "Episode Reward": 7962.79455273153, "Mean Reward": 46.83996795724429, "Episode": 5047, "Episode Step": 170}
{"Training time": 17.694587495525678, "Episode Reward": 8525.090895827278, "Mean Reward": 46.081572409877175, "Episode": 5048, "Episode Step": 185}
{"Training time": 17.70187499139044, "Episode Reward": 28669.028662469813, "Mean Reward": 58.62787047539839, "Episode": 5049, "Episode Step": 489}
{"Training time": 17.7042409602801, "Episode Reward": 8313.366073767482, "Mean Reward": 47.23503451004251, "Episode": 5050, "Episode Step": 176}
{"Training time": 17.71163139442603, "Episode Reward": 35561.625042746986, "Mean Reward": 55.65199537206101, "Episode": 5051, "Episode Step": 639}
{"Training time": 17.714945759442116, "Episode Reward": 15291.899717621982, "Mean Reward": 62.1621939740731, "Episode": 5052, "Episode Step": 246}
{"Training time": 17.71591598133246, "Episode Reward": 3959.690797583091, "Mean Reward": 48.885071575099886, "Episode": 5053, "Episode Step": 81}
{"Training time": 17.71712654027674, "Episode Reward": -364.81564596086787, "Mean Reward": -3.5766239800085087, "Episode": 5054, "Episode Step": 102}
{"Training time": 17.72058612803618, "Episode Reward": 15816.204674732662, "Mean Reward": 62.02433205777515, "Episode": 5055, "Episode Step": 255}
{"Training time": 17.721553518043624, "Episode Reward": 4242.869212657146, "Mean Reward": 53.03586515821432, "Episode": 5056, "Episode Step": 80}
{"Training time": 17.722781642741626, "Episode Reward": -560.8142001741348, "Mean Reward": -5.498178433079754, "Episode": 5057, "Episode Step": 102}
{"Training time": 17.72614472415712, "Episode Reward": 15715.653292299576, "Mean Reward": 63.11507346305051, "Episode": 5058, "Episode Step": 249}
{"Training time": 17.727072940005197, "Episode Reward": 4129.371819764338, "Mean Reward": 52.27052936410555, "Episode": 5059, "Episode Step": 79}
{"Training time": 17.72827784385946, "Episode Reward": -314.0548257702741, "Mean Reward": -3.0789688801007262, "Episode": 5060, "Episode Step": 102}
{"Training time": 17.73879289329052, "Episode Reward": 50878.25208542494, "Mean Reward": 60.13977787875288, "Episode": 5061, "Episode Step": 846}
{"Training time": 17.739745667444335, "Episode Reward": 4094.4781797784453, "Mean Reward": 51.828837718714496, "Episode": 5062, "Episode Step": 79}
{"Training time": 17.77811961942249, "Episode Reward": 174681.13737317943, "Mean Reward": 53.76458521796843, "Episode": 5063, "Episode Step": 3249}
{"Training time": 17.78065649304125, "Episode Reward": 8477.846620524197, "Mean Reward": 48.444837831566836, "Episode": 5064, "Episode Step": 175}
{"Training time": 17.782700567444166, "Episode Reward": 7599.48976926651, "Mean Reward": 44.44146063898544, "Episode": 5065, "Episode Step": 171}
{"Training time": 17.783922574387656, "Episode Reward": -202.1828389460376, "Mean Reward": -1.9821846955493883, "Episode": 5066, "Episode Step": 102}
{"Training time": 17.786552682452733, "Episode Reward": 8551.60193900318, "Mean Reward": 47.50889966112878, "Episode": 5067, "Episode Step": 180}
{"Training time": 17.790064789387916, "Episode Reward": 17369.898522801104, "Mean Reward": 57.51622027417584, "Episode": 5068, "Episode Step": 302}
{"Training time": 17.791289897759757, "Episode Reward": -201.42233026155148, "Mean Reward": -1.9747287280544263, "Episode": 5069, "Episode Step": 102}
{"Training time": 17.79377795636654, "Episode Reward": 8243.06765059002, "Mean Reward": 47.647789887803576, "Episode": 5070, "Episode Step": 173}
{"Training time": 17.795785250531303, "Episode Reward": 7860.4770543634495, "Mean Reward": 45.967702072300874, "Episode": 5071, "Episode Step": 171}
{"Training time": 17.815749221907723, "Episode Reward": 91717.57312726887, "Mean Reward": 54.238659448414474, "Episode": 5072, "Episode Step": 1691}
{"Training time": 17.81832302722666, "Episode Reward": 8351.051161134777, "Mean Reward": 47.18108000641117, "Episode": 5073, "Episode Step": 177}
{"Training time": 17.819258343312477, "Episode Reward": 4531.467084468106, "Mean Reward": 58.095731852155204, "Episode": 5074, "Episode Step": 78}
{"Training time": 17.832157854437828, "Episode Reward": 61456.87707904227, "Mean Reward": 55.768490997316036, "Episode": 5075, "Episode Step": 1102}
{"Training time": 17.834020827743743, "Episode Reward": 5946.9378057155045, "Mean Reward": 49.557815047629205, "Episode": 5076, "Episode Step": 120}
{"Training time": 17.836052802469997, "Episode Reward": 8200.662179191017, "Mean Reward": 47.6782684836687, "Episode": 5077, "Episode Step": 172}
{"Training time": 17.837240538001062, "Episode Reward": -217.05450865278831, "Mean Reward": -2.127985378948905, "Episode": 5078, "Episode Step": 102}
{"Training time": 17.84404565665457, "Episode Reward": 31247.625838292286, "Mean Reward": 58.40677726783605, "Episode": 5079, "Episode Step": 535}
{"Training time": 17.846051232483653, "Episode Reward": 8088.6230650569105, "Mean Reward": 48.14656586343399, "Episode": 5080, "Episode Step": 168}
{"Training time": 17.84726795050833, "Episode Reward": -184.39532124336614, "Mean Reward": -1.807797267091825, "Episode": 5081, "Episode Step": 102}
{"Training time": 17.85069495525625, "Episode Reward": 15533.162425423176, "Mean Reward": 60.91436245263991, "Episode": 5082, "Episode Step": 255}
{"Training time": 17.852657282749814, "Episode Reward": 8270.459046345946, "Mean Reward": 49.228922894916344, "Episode": 5083, "Episode Step": 168}
{"Training time": 17.853879516389636, "Episode Reward": -235.32830679561206, "Mean Reward": -2.307140262702079, "Episode": 5084, "Episode Step": 102}
{"Training time": 17.85733916607168, "Episode Reward": 15020.297952544264, "Mean Reward": 58.444739114958224, "Episode": 5085, "Episode Step": 257}
{"Training time": 17.859365309145716, "Episode Reward": 8240.300036119963, "Mean Reward": 48.47235315364684, "Episode": 5086, "Episode Step": 170}
{"Training time": 17.860608901381493, "Episode Reward": -220.4095345108183, "Mean Reward": -2.160877789321748, "Episode": 5087, "Episode Step": 102}
{"Training time": 17.868333906928697, "Episode Reward": 36464.82971685771, "Mean Reward": 58.90925640849388, "Episode": 5088, "Episode Step": 619}
{"Training time": 17.87185035970476, "Episode Reward": 18447.77368187338, "Mean Reward": 61.905280811655636, "Episode": 5089, "Episode Step": 298}
{"Training time": 17.873068324393696, "Episode Reward": -212.2936886254565, "Mean Reward": -2.081310672798593, "Episode": 5090, "Episode Step": 102}
{"Training time": 17.876637734439637, "Episode Reward": 16869.923546977447, "Mean Reward": 64.88432133452864, "Episode": 5091, "Episode Step": 260}
{"Training time": 17.878640563289323, "Episode Reward": 8347.746537876812, "Mean Reward": 49.68896748736198, "Episode": 5092, "Episode Step": 168}
{"Training time": 17.879882244997553, "Episode Reward": -217.0478369483396, "Mean Reward": -2.127919970081761, "Episode": 5093, "Episode Step": 102}
{"Training time": 17.883369558321107, "Episode Reward": 15801.92775662103, "Mean Reward": 62.706062526273925, "Episode": 5094, "Episode Step": 252}
{"Training time": 17.884334980514314, "Episode Reward": 4461.020565466966, "Mean Reward": 55.07432796872798, "Episode": 5095, "Episode Step": 81}
{"Training time": 17.88554392748409, "Episode Reward": -214.21248755025363, "Mean Reward": -2.100122426963271, "Episode": 5096, "Episode Step": 102}
{"Training time": 17.889083753294415, "Episode Reward": 15769.133953027327, "Mean Reward": 60.88468707732559, "Episode": 5097, "Episode Step": 259}
{"Training time": 17.892063878311053, "Episode Reward": 15757.015874295535, "Mean Reward": 62.28069515531832, "Episode": 5098, "Episode Step": 253}
{"Training time": 17.910670134954984, "Episode Reward": 75391.19768285839, "Mean Reward": 48.73380587127239, "Episode": 5099, "Episode Step": 1547}
{"Training time": 17.919198698335222, "Episode Reward": 42193.258979188984, "Mean Reward": 60.276084255984266, "Episode": 5100, "Episode Step": 700}
{"Training time": 17.921223913563622, "Episode Reward": 9072.102469102567, "Mean Reward": 53.053230813465305, "Episode": 5101, "Episode Step": 171}
{"Training time": 17.96686312470171, "Episode Reward": 232104.28517088984, "Mean Reward": 58.894769137500596, "Episode": 5102, "Episode Step": 3941}
{"Training time": 17.969438160790336, "Episode Reward": 8670.382805792102, "Mean Reward": 47.90266743531548, "Episode": 5103, "Episode Step": 181}
{"Training time": 17.970915384160147, "Episode Reward": 6126.25511429735, "Mean Reward": 48.62107233569325, "Episode": 5104, "Episode Step": 126}
{"Training time": 17.972131563557518, "Episode Reward": -223.6986306122769, "Mean Reward": -2.1931238295321265, "Episode": 5105, "Episode Step": 102}
{"Training time": 17.97397331972917, "Episode Reward": 6133.032853103356, "Mean Reward": 52.870972871580655, "Episode": 5106, "Episode Step": 116}
{"Training time": 17.975962238576678, "Episode Reward": 8804.023080883144, "Mean Reward": 53.036283619777976, "Episode": 5107, "Episode Step": 166}
{"Training time": 17.993015991912948, "Episode Reward": 79754.21328621737, "Mean Reward": 54.21768408308455, "Episode": 5108, "Episode Step": 1471}
{"Training time": 17.99691884080569, "Episode Reward": 18169.62330516801, "Mean Reward": 61.17718284568353, "Episode": 5109, "Episode Step": 297}
{"Training time": 18.000311324132813, "Episode Reward": 18361.579144160514, "Mean Reward": 62.88212035671409, "Episode": 5110, "Episode Step": 292}
{"Training time": 18.001511288881304, "Episode Reward": -233.0170462612363, "Mean Reward": -2.284480845698395, "Episode": 5111, "Episode Step": 102}
{"Training time": 18.003307272195816, "Episode Reward": 6244.693782327892, "Mean Reward": 53.37345113100763, "Episode": 5112, "Episode Step": 117}
{"Training time": 18.005291102727256, "Episode Reward": 7916.353200923273, "Mean Reward": 47.12115000549567, "Episode": 5113, "Episode Step": 168}
{"Training time": 18.006923952500024, "Episode Reward": 5063.523310268849, "Mean Reward": 36.42822525373273, "Episode": 5114, "Episode Step": 139}
{"Training time": 18.008612976074218, "Episode Reward": 5331.413845585417, "Mean Reward": 52.26876319201389, "Episode": 5115, "Episode Step": 102}
{"Training time": 18.01633382525709, "Episode Reward": 44803.99439884502, "Mean Reward": 66.47476913775225, "Episode": 5116, "Episode Step": 674}
{"Training time": 18.017464849948883, "Episode Reward": -444.7743181215049, "Mean Reward": -4.585302248675308, "Episode": 5117, "Episode Step": 97}
{"Training time": 18.020902053846253, "Episode Reward": 15001.721180652157, "Mean Reward": 58.37245595584497, "Episode": 5118, "Episode Step": 257}
{"Training time": 18.02287855386734, "Episode Reward": 7971.484738875679, "Mean Reward": 47.16854875074366, "Episode": 5119, "Episode Step": 169}
{"Training time": 18.02410866300265, "Episode Reward": -453.14152442573027, "Mean Reward": -4.671562107481756, "Episode": 5120, "Episode Step": 97}
{"Training time": 18.028070848319267, "Episode Reward": 17488.675532052308, "Mean Reward": 58.101912066618965, "Episode": 5121, "Episode Step": 301}
{"Training time": 18.03640402721034, "Episode Reward": 47412.73651876165, "Mean Reward": 65.30679961261936, "Episode": 5122, "Episode Step": 726}
{"Training time": 18.0375908627775, "Episode Reward": -250.98686308481888, "Mean Reward": -2.460655520439401, "Episode": 5123, "Episode Step": 102}
{"Training time": 18.040974706610044, "Episode Reward": 15931.211375900784, "Mean Reward": 63.21909276151105, "Episode": 5124, "Episode Step": 252}
{"Training time": 18.059434232181975, "Episode Reward": 103190.70013463292, "Mean Reward": 64.696363720773, "Episode": 5125, "Episode Step": 1595}
{"Training time": 18.060538524720403, "Episode Reward": -450.858232305713, "Mean Reward": -4.796364173465032, "Episode": 5126, "Episode Step": 94}
{"Training time": 18.063942611349955, "Episode Reward": 16663.379040688804, "Mean Reward": 66.38796430553309, "Episode": 5127, "Episode Step": 251}
{"Training time": 18.075602685544226, "Episode Reward": 65886.19527678115, "Mean Reward": 66.55171240078903, "Episode": 5128, "Episode Step": 990}
{"Training time": 18.07679509414567, "Episode Reward": -463.91943126029315, "Mean Reward": -4.733871747554012, "Episode": 5129, "Episode Step": 98}
{"Training time": 18.080415291918648, "Episode Reward": 16276.09434423343, "Mean Reward": 61.88629028225639, "Episode": 5130, "Episode Step": 263}
{"Training time": 18.09673454384009, "Episode Reward": 91023.36225447619, "Mean Reward": 65.62607228152574, "Episode": 5131, "Episode Step": 1387}
{"Training time": 18.097951104111143, "Episode Reward": -230.480145516627, "Mean Reward": -2.259609269770853, "Episode": 5132, "Episode Step": 102}
{"Training time": 18.10139926440186, "Episode Reward": 16280.716822923046, "Mean Reward": 64.60601913858352, "Episode": 5133, "Episode Step": 252}
{"Training time": 18.123286036650338, "Episode Reward": 124242.7409375758, "Mean Reward": 66.76127938612348, "Episode": 5134, "Episode Step": 1861}
{"Training time": 18.12671577135722, "Episode Reward": 14306.662291496807, "Mean Reward": 49.16378794328799, "Episode": 5135, "Episode Step": 291}
{"Training time": 18.1283952824937, "Episode Reward": 6003.193922228198, "Mean Reward": 58.85484237478626, "Episode": 5136, "Episode Step": 102}
{"Training time": 18.14502732389503, "Episode Reward": 96006.72411378026, "Mean Reward": 67.70572927629074, "Episode": 5137, "Episode Step": 1418}
{"Training time": 18.1462488202254, "Episode Reward": -257.47225333707945, "Mean Reward": -2.524237777814504, "Episode": 5138, "Episode Step": 102}
{"Training time": 18.148742378618984, "Episode Reward": 9047.335587583202, "Mean Reward": 52.29673750048094, "Episode": 5139, "Episode Step": 173}
{"Training time": 18.155967526634534, "Episode Reward": 40388.008144973945, "Mean Reward": 65.458684189585, "Episode": 5140, "Episode Step": 617}
{"Training time": 18.15718383219507, "Episode Reward": -237.3975232323054, "Mean Reward": -2.3274266983559353, "Episode": 5141, "Episode Step": 102}
{"Training time": 18.159662021332316, "Episode Reward": 7605.862215757413, "Mean Reward": 43.71185181469777, "Episode": 5142, "Episode Step": 174}
{"Training time": 18.166792816917102, "Episode Reward": 39037.828936650534, "Mean Reward": 63.476144612439896, "Episode": 5143, "Episode Step": 615}
{"Training time": 18.167966008318796, "Episode Reward": -464.0574803744052, "Mean Reward": -4.640574803744052, "Episode": 5144, "Episode Step": 100}
{"Training time": 18.1704519241386, "Episode Reward": 8220.974971869126, "Mean Reward": 47.520086542596104, "Episode": 5145, "Episode Step": 173}
{"Training time": 18.172413186629612, "Episode Reward": 8449.613751055085, "Mean Reward": 49.99771450328453, "Episode": 5146, "Episode Step": 169}
{"Training time": 18.173643648293282, "Episode Reward": -215.40431614157026, "Mean Reward": -2.111807020995787, "Episode": 5147, "Episode Step": 102}
{"Training time": 18.176063026388487, "Episode Reward": 8480.247018184251, "Mean Reward": 50.17897643896006, "Episode": 5148, "Episode Step": 169}
{"Training time": 18.18823265996244, "Episode Reward": 67110.16782001739, "Mean Reward": 68.34029309574072, "Episode": 5149, "Episode Step": 982}
{"Training time": 18.207634923325646, "Episode Reward": 93412.76390696586, "Mean Reward": 56.959002382296255, "Episode": 5150, "Episode Step": 1640}
{"Training time": 18.210088129705852, "Episode Reward": 8866.097623318426, "Mean Reward": 51.54707920533969, "Episode": 5151, "Episode Step": 172}
{"Training time": 18.212132684985797, "Episode Reward": 9120.890292794757, "Mean Reward": 53.652295839969156, "Episode": 5152, "Episode Step": 170}
{"Training time": 18.21316644191742, "Episode Reward": -418.18751518143733, "Mean Reward": -4.978422799779016, "Episode": 5153, "Episode Step": 84}
{"Training time": 18.215779117478263, "Episode Reward": 9057.09384135015, "Mean Reward": 50.88254967050646, "Episode": 5154, "Episode Step": 178}
{"Training time": 18.217036181357173, "Episode Reward": 5974.441165528198, "Mean Reward": 58.00428316046794, "Episode": 5155, "Episode Step": 103}
{"Training time": 18.219259105523427, "Episode Reward": 8794.544819897526, "Mean Reward": 47.28249903170713, "Episode": 5156, "Episode Step": 186}
{"Training time": 18.22279347638289, "Episode Reward": 16307.671322408918, "Mean Reward": 62.96398193980277, "Episode": 5157, "Episode Step": 259}
{"Training time": 18.230000538892217, "Episode Reward": 40771.5700052075, "Mean Reward": 66.51153345058319, "Episode": 5158, "Episode Step": 613}
{"Training time": 18.25340507162942, "Episode Reward": 114937.10434514271, "Mean Reward": 57.35384448360415, "Episode": 5159, "Episode Step": 2004}
{"Training time": 18.257042045262125, "Episode Reward": 14977.259220747794, "Mean Reward": 56.73204250283255, "Episode": 5160, "Episode Step": 264}
{"Training time": 18.25905060244931, "Episode Reward": 8548.817226972258, "Mean Reward": 50.584717319362476, "Episode": 5161, "Episode Step": 169}
{"Training time": 18.261859681341384, "Episode Reward": 13746.171524134053, "Mean Reward": 57.03805611673881, "Episode": 5162, "Episode Step": 241}
{"Training time": 18.264652668303913, "Episode Reward": 8298.859302208788, "Mean Reward": 42.34111888882035, "Episode": 5163, "Episode Step": 196}
{"Training time": 18.266675842735502, "Episode Reward": 8510.532438983446, "Mean Reward": 50.358180112328085, "Episode": 5164, "Episode Step": 169}
{"Training time": 18.267780174414316, "Episode Reward": -445.75193816376765, "Mean Reward": -4.89837294685459, "Episode": 5165, "Episode Step": 91}
{"Training time": 18.269699441923034, "Episode Reward": 6132.601330836669, "Mean Reward": 49.858547405176175, "Episode": 5166, "Episode Step": 123}
{"Training time": 18.274694515268006, "Episode Reward": 26094.3347150856, "Mean Reward": 62.27764848469117, "Episode": 5167, "Episode Step": 419}
{"Training time": 18.277391073571312, "Episode Reward": 12797.919880936584, "Mean Reward": 55.886113017190326, "Episode": 5168, "Episode Step": 229}
{"Training time": 18.283783550262452, "Episode Reward": 28728.72644627706, "Mean Reward": 57.00144136166084, "Episode": 5169, "Episode Step": 504}
{"Training time": 18.33736639413569, "Episode Reward": 306183.25645588565, "Mean Reward": 66.4748711367533, "Episode": 5170, "Episode Step": 4606}
{"Training time": 18.350591186086337, "Episode Reward": 70415.60218015559, "Mean Reward": 61.44467904027538, "Episode": 5171, "Episode Step": 1146}
{"Training time": 18.352433896925714, "Episode Reward": 5940.918660884544, "Mean Reward": 49.09850132962433, "Episode": 5172, "Episode Step": 121}
{"Training time": 18.368917837474083, "Episode Reward": 91767.10724591342, "Mean Reward": 65.407774230872, "Episode": 5173, "Episode Step": 1403}
{"Training time": 18.369894139170647, "Episode Reward": -408.3894706205331, "Mean Reward": -4.980359397811379, "Episode": 5174, "Episode Step": 82}
{"Training time": 18.372455666661264, "Episode Reward": 8785.222382778556, "Mean Reward": 49.63402476146077, "Episode": 5175, "Episode Step": 177}
{"Training time": 18.379509668019082, "Episode Reward": 37188.76669930316, "Mean Reward": 61.46903586661679, "Episode": 5176, "Episode Step": 605}
{"Training time": 18.380554108023645, "Episode Reward": -452.9693854617077, "Mean Reward": -5.1473793802466785, "Episode": 5177, "Episode Step": 88}
{"Training time": 18.38246178554164, "Episode Reward": 6551.106134657832, "Mean Reward": 53.697591267687145, "Episode": 5178, "Episode Step": 122}
{"Training time": 18.384502891103427, "Episode Reward": 8961.969122478871, "Mean Reward": 51.5055696694188, "Episode": 5179, "Episode Step": 174}
{"Training time": 18.38547880080011, "Episode Reward": -424.2323176393206, "Mean Reward": -5.37002933720659, "Episode": 5180, "Episode Step": 79}
{"Training time": 18.38734763801098, "Episode Reward": 7070.603556657271, "Mean Reward": 59.92036912421416, "Episode": 5181, "Episode Step": 118}
{"Training time": 18.38935289190875, "Episode Reward": 8581.8365499362, "Mean Reward": 50.48139147021295, "Episode": 5182, "Episode Step": 170}
{"Training time": 18.390506470004716, "Episode Reward": -542.1399926044326, "Mean Reward": -5.829462286069167, "Episode": 5183, "Episode Step": 93}
{"Training time": 18.39310611300998, "Episode Reward": 8573.194856856175, "Mean Reward": 48.71133441395554, "Episode": 5184, "Episode Step": 176}
{"Training time": 18.400371925499705, "Episode Reward": 35515.60236216573, "Mean Reward": 58.03203000353877, "Episode": 5185, "Episode Step": 612}
{"Training time": 18.402138402197096, "Episode Reward": 6229.5577961671515, "Mean Reward": 42.091606730859134, "Episode": 5186, "Episode Step": 148}
{"Training time": 18.405775150524246, "Episode Reward": 15964.132933707533, "Mean Reward": 59.12641827299086, "Episode": 5187, "Episode Step": 270}
{"Training time": 18.407002658049265, "Episode Reward": 4386.953927014292, "Mean Reward": 42.591785699167886, "Episode": 5188, "Episode Step": 103}
{"Training time": 18.408045801387892, "Episode Reward": -490.261164942227, "Mean Reward": -5.700711220258454, "Episode": 5189, "Episode Step": 86}
{"Training time": 18.411686328583293, "Episode Reward": 16412.09371301956, "Mean Reward": 61.93242910573419, "Episode": 5190, "Episode Step": 265}
{"Training time": 18.413708684113292, "Episode Reward": 7467.668494261039, "Mean Reward": 43.927461730947286, "Episode": 5191, "Episode Step": 170}
{"Training time": 18.414795099960433, "Episode Reward": -446.23290184812873, "Mean Reward": -4.850357628784008, "Episode": 5192, "Episode Step": 92}
{"Training time": 18.418255580531227, "Episode Reward": 15857.607974815377, "Mean Reward": 61.94378115162257, "Episode": 5193, "Episode Step": 256}
{"Training time": 18.41982148077753, "Episode Reward": 6229.996579030645, "Mean Reward": 47.19694378053519, "Episode": 5194, "Episode Step": 132}
{"Training time": 18.423477210799852, "Episode Reward": 13812.489985155937, "Mean Reward": 44.41315107767182, "Episode": 5195, "Episode Step": 311}
{"Training time": 18.425898675256306, "Episode Reward": 8548.575629620711, "Mean Reward": 50.884378747742325, "Episode": 5196, "Episode Step": 168}
{"Training time": 18.43459654384189, "Episode Reward": 45973.233003713896, "Mean Reward": 61.95853504543652, "Episode": 5197, "Episode Step": 742}
{"Training time": 18.43571181555589, "Episode Reward": -455.6102242935975, "Mean Reward": -4.952285046669538, "Episode": 5198, "Episode Step": 92}
{"Training time": 18.442309574683506, "Episode Reward": 24735.705140485246, "Mean Reward": 57.39142724010498, "Episode": 5199, "Episode Step": 431}
{"Training time": 18.444576810532148, "Episode Reward": 8040.998823977422, "Mean Reward": 47.299993082220126, "Episode": 5200, "Episode Step": 170}
{"Training time": 18.446177596648536, "Episode Reward": 5782.360030723148, "Mean Reward": 42.20700752352663, "Episode": 5201, "Episode Step": 137}
{"Training time": 18.448699928058517, "Episode Reward": 8677.120680053706, "Mean Reward": 48.4755345254397, "Episode": 5202, "Episode Step": 179}
{"Training time": 18.454234137733778, "Episode Reward": 28008.96974873926, "Mean Reward": 59.59355265689204, "Episode": 5203, "Episode Step": 470}
{"Training time": 18.455231355230012, "Episode Reward": -423.4108870824049, "Mean Reward": -5.040605798600058, "Episode": 5204, "Episode Step": 84}
{"Training time": 18.45710512055291, "Episode Reward": 6136.264656402911, "Mean Reward": 50.71293104465216, "Episode": 5205, "Episode Step": 121}
{"Training time": 18.47315958665477, "Episode Reward": 86324.51286184911, "Mean Reward": 62.73583783564616, "Episode": 5206, "Episode Step": 1376}
{"Training time": 18.47517571773794, "Episode Reward": 6038.603588731062, "Mean Reward": 35.1081603995992, "Episode": 5207, "Episode Step": 172}
{"Training time": 18.478648473554188, "Episode Reward": 15669.24654788489, "Mean Reward": 60.26633287648035, "Episode": 5208, "Episode Step": 260}
{"Training time": 18.512623691889974, "Episode Reward": 176686.49938794828, "Mean Reward": 60.8215144192593, "Episode": 5209, "Episode Step": 2905}
{"Training time": 18.51431267970138, "Episode Reward": 5894.333625577932, "Mean Reward": 42.10238303984237, "Episode": 5210, "Episode Step": 140}
{"Training time": 18.51969531721539, "Episode Reward": 24149.180469429524, "Mean Reward": 57.63527558336402, "Episode": 5211, "Episode Step": 419}
{"Training time": 18.52648560471005, "Episode Reward": 33090.12759291586, "Mean Reward": 56.56432067165104, "Episode": 5212, "Episode Step": 585}
{"Training time": 18.527692141069306, "Episode Reward": -179.86546979087495, "Mean Reward": -1.7633869587340683, "Episode": 5213, "Episode Step": 102}
{"Training time": 18.53135378804472, "Episode Reward": 17435.85670127623, "Mean Reward": 63.86760696438179, "Episode": 5214, "Episode Step": 273}
{"Training time": 18.54033090273539, "Episode Reward": 44811.95734535242, "Mean Reward": 57.89658571750959, "Episode": 5215, "Episode Step": 774}
{"Training time": 18.541556214690207, "Episode Reward": -50.274552194406404, "Mean Reward": -0.4928877666118275, "Episode": 5216, "Episode Step": 102}
{"Training time": 18.54491788884004, "Episode Reward": 15220.010504804239, "Mean Reward": 60.637492051012906, "Episode": 5217, "Episode Step": 251}
{"Training time": 18.54549975136916, "Episode Reward": 1833.2306984815543, "Mean Reward": 38.192306218365715, "Episode": 5218, "Episode Step": 48}
{"Training time": 18.546691641608874, "Episode Reward": -250.91204807351187, "Mean Reward": -2.459922039936391, "Episode": 5219, "Episode Step": 102}
{"Training time": 18.548728311657907, "Episode Reward": 6426.6686009205805, "Mean Reward": 47.60495259941171, "Episode": 5220, "Episode Step": 135}
{"Training time": 18.5545718069209, "Episode Reward": 27925.76775079368, "Mean Reward": 56.18866750662712, "Episode": 5221, "Episode Step": 497}
{"Training time": 18.555524092780217, "Episode Reward": -482.2917661494614, "Mean Reward": -6.263529430512486, "Episode": 5222, "Episode Step": 77}
{"Training time": 18.562181469135815, "Episode Reward": 33709.95329765405, "Mean Reward": 63.603685467271795, "Episode": 5223, "Episode Step": 530}
{"Training time": 18.564428730275896, "Episode Reward": 7321.538087327772, "Mean Reward": 38.33266014307734, "Episode": 5224, "Episode Step": 191}
{"Training time": 18.565236630837123, "Episode Reward": -455.2952982996327, "Mean Reward": -6.898413610600495, "Episode": 5225, "Episode Step": 66}
{"Training time": 18.568819301393297, "Episode Reward": 16218.854339319847, "Mean Reward": 60.293138807880474, "Episode": 5226, "Episode Step": 269}
{"Training time": 18.570073513057498, "Episode Reward": 5013.472462122197, "Mean Reward": 47.296910020020725, "Episode": 5227, "Episode Step": 106}
{"Training time": 18.571292075514794, "Episode Reward": -60.69785998094095, "Mean Reward": -0.5950770586366759, "Episode": 5228, "Episode Step": 102}
{"Training time": 18.57734356217914, "Episode Reward": 27993.063596832257, "Mean Reward": 58.31888249340054, "Episode": 5229, "Episode Step": 480}
{"Training time": 18.584721804393663, "Episode Reward": 35088.77963179219, "Mean Reward": 55.60820860822851, "Episode": 5230, "Episode Step": 631}
{"Training time": 18.586460739440387, "Episode Reward": 4351.621773130095, "Mean Reward": 29.402849818446587, "Episode": 5231, "Episode Step": 148}
{"Training time": 18.59007824467288, "Episode Reward": 17321.81215426803, "Mean Reward": 64.87570095231472, "Episode": 5232, "Episode Step": 267}
{"Training time": 18.591527707444296, "Episode Reward": 4941.793158825968, "Mean Reward": 40.5065013018522, "Episode": 5233, "Episode Step": 122}
{"Training time": 18.59362259666125, "Episode Reward": 7573.2156039953015, "Mean Reward": 43.02963411360967, "Episode": 5234, "Episode Step": 176}
{"Training time": 18.599641960263252, "Episode Reward": 29445.006591908197, "Mean Reward": 61.98948756191199, "Episode": 5235, "Episode Step": 475}
{"Training time": 18.60327750470903, "Episode Reward": 16165.56148605783, "Mean Reward": 51.9792973828226, "Episode": 5236, "Episode Step": 311}
{"Training time": 18.604165011644362, "Episode Reward": -437.50862818925486, "Mean Reward": -5.993268879304861, "Episode": 5237, "Episode Step": 73}
{"Training time": 18.60623951084084, "Episode Reward": 6243.558484072965, "Mean Reward": 45.90851826524239, "Episode": 5238, "Episode Step": 136}
{"Training time": 18.607770852446556, "Episode Reward": 5379.895951863839, "Mean Reward": 41.70461978189023, "Episode": 5239, "Episode Step": 129}
{"Training time": 18.60881539636188, "Episode Reward": -477.69561604172236, "Mean Reward": -5.490754207376119, "Episode": 5240, "Episode Step": 87}
{"Training time": 18.652504805790052, "Episode Reward": 228079.4441684793, "Mean Reward": 61.96127252607425, "Episode": 5241, "Episode Step": 3681}
{"Training time": 18.653757019705242, "Episode Reward": 4933.197579889833, "Mean Reward": 46.539599810281445, "Episode": 5242, "Episode Step": 106}
{"Training time": 18.65494402249654, "Episode Reward": -459.5618253668295, "Mean Reward": -4.595618253668295, "Episode": 5243, "Episode Step": 100}
{"Training time": 18.68693096664217, "Episode Reward": 157592.764104502, "Mean Reward": 58.346080749537954, "Episode": 5244, "Episode Step": 2701}
{"Training time": 18.69187559299999, "Episode Reward": 23696.22175097646, "Mean Reward": 56.554228522616846, "Episode": 5245, "Episode Step": 419}
{"Training time": 18.693082526922225, "Episode Reward": -20.375342666347304, "Mean Reward": -0.19975826143477748, "Episode": 5246, "Episode Step": 102}
{"Training time": 18.69889202164279, "Episode Reward": 28191.42464699027, "Mean Reward": 60.757380704720404, "Episode": 5247, "Episode Step": 464}
{"Training time": 18.69948717666997, "Episode Reward": 1632.7120239046048, "Mean Reward": 32.6542404780921, "Episode": 5248, "Episode Step": 50}
{"Training time": 18.749033852219583, "Episode Reward": 251409.10969652102, "Mean Reward": 60.20333086602515, "Episode": 5249, "Episode Step": 4176}
{"Training time": 18.76059681190385, "Episode Reward": 54159.65521541693, "Mean Reward": 57.49432613101585, "Episode": 5250, "Episode Step": 942}
{"Training time": 18.761141278280153, "Episode Reward": 1506.941043302327, "Mean Reward": 34.24866007505289, "Episode": 5251, "Episode Step": 44}
{"Training time": 18.762028232216835, "Episode Reward": -468.2816059690524, "Mean Reward": -6.3281298103926, "Episode": 5252, "Episode Step": 74}
{"Training time": 18.775022234982913, "Episode Reward": 62439.46615382325, "Mean Reward": 58.628606717204924, "Episode": 5253, "Episode Step": 1065}
{"Training time": 18.780575538012716, "Episode Reward": 28658.896993518258, "Mean Reward": 60.58963423576799, "Episode": 5254, "Episode Step": 473}
{"Training time": 18.781593578855198, "Episode Reward": -498.4932672688435, "Mean Reward": -5.934443657962423, "Episode": 5255, "Episode Step": 84}
{"Training time": 18.78928823583656, "Episode Reward": 33538.0956580374, "Mean Reward": 54.00659526254009, "Episode": 5256, "Episode Step": 621}
{"Training time": 18.78983254439301, "Episode Reward": 1538.7074249554882, "Mean Reward": 33.45016141207583, "Episode": 5257, "Episode Step": 46}
{"Training time": 18.790649548835226, "Episode Reward": -449.93350628600194, "Mean Reward": -6.715425466955253, "Episode": 5258, "Episode Step": 67}
{"Training time": 18.81453774915801, "Episode Reward": 114910.58074173998, "Mean Reward": 57.744010422984914, "Episode": 5259, "Episode Step": 1990}
{"Training time": 18.81509978969892, "Episode Reward": 1559.7210539604919, "Mean Reward": 34.66046786578871, "Episode": 5260, "Episode Step": 45}
{"Training time": 18.815820501910316, "Episode Reward": -444.37774329762647, "Mean Reward": -7.4062957216271075, "Episode": 5261, "Episode Step": 60}
{"Training time": 18.818324066334302, "Episode Reward": 8440.667741092677, "Mean Reward": 48.23238709195815, "Episode": 5262, "Episode Step": 175}
{"Training time": 18.819528163340358, "Episode Reward": 4074.0830252011815, "Mean Reward": 39.94199044314884, "Episode": 5263, "Episode Step": 102}
{"Training time": 18.820545823838977, "Episode Reward": -522.9549511637013, "Mean Reward": -6.1524111901611915, "Episode": 5264, "Episode Step": 85}
{"Training time": 18.825891859994993, "Episode Reward": 24439.531946998548, "Mean Reward": 59.46358137955851, "Episode": 5265, "Episode Step": 411}
{"Training time": 18.8271243666278, "Episode Reward": 4553.166820871889, "Mean Reward": 44.638890400704796, "Episode": 5266, "Episode Step": 102}
{"Training time": 18.827970666355558, "Episode Reward": -437.4011959107995, "Mean Reward": -6.3391477668231815, "Episode": 5267, "Episode Step": 69}
{"Training time": 18.841395257777638, "Episode Reward": 63106.54596244574, "Mean Reward": 57.57896529420232, "Episode": 5268, "Episode Step": 1096}
{"Training time": 18.84692773083846, "Episode Reward": 27553.44757673208, "Mean Reward": 58.62435654623847, "Episode": 5269, "Episode Step": 470}
{"Training time": 18.847635310557152, "Episode Reward": -425.174152509916, "Mean Reward": -7.459195658068701, "Episode": 5270, "Episode Step": 57}
{"Training time": 18.855602219435905, "Episode Reward": 34230.14525684455, "Mean Reward": 54.16162224184265, "Episode": 5271, "Episode Step": 632}
{"Training time": 18.856899884409376, "Episode Reward": 5060.516049002424, "Mean Reward": 47.29454251404134, "Episode": 5272, "Episode Step": 107}
{"Training time": 18.85811765829722, "Episode Reward": -253.87583474739645, "Mean Reward": -2.4889787720332985, "Episode": 5273, "Episode Step": 102}
{"Training time": 18.859807329442766, "Episode Reward": 5797.929730688271, "Mean Reward": 55.21837838750734, "Episode": 5274, "Episode Step": 105}
{"Training time": 18.86106640941567, "Episode Reward": 5146.46776940765, "Mean Reward": 49.48526701353509, "Episode": 5275, "Episode Step": 104}
{"Training time": 18.86191499359078, "Episode Reward": -471.83464651548223, "Mean Reward": -6.740494950221175, "Episode": 5276, "Episode Step": 70}
{"Training time": 18.864466907779377, "Episode Reward": 8227.724240807689, "Mean Reward": 46.22316989217803, "Episode": 5277, "Episode Step": 178}
{"Training time": 18.865735183027056, "Episode Reward": 5048.726195902297, "Mean Reward": 47.1843569710495, "Episode": 5278, "Episode Step": 107}
{"Training time": 18.86655120578077, "Episode Reward": -490.4946385334138, "Mean Reward": -7.431736947475967, "Episode": 5279, "Episode Step": 66}
{"Training time": 18.8745459310876, "Episode Reward": 35137.61486629622, "Mean Reward": 55.50966013632895, "Episode": 5280, "Episode Step": 633}
{"Training time": 18.880426305267545, "Episode Reward": 29750.05362199193, "Mean Reward": 59.859262820909315, "Episode": 5281, "Episode Step": 497}
{"Training time": 18.881150232487254, "Episode Reward": -440.0318439418785, "Mean Reward": -7.333864065697975, "Episode": 5282, "Episode Step": 60}
{"Training time": 18.883698458340433, "Episode Reward": 8478.972881661219, "Mean Reward": 48.45127360949268, "Episode": 5283, "Episode Step": 175}
{"Training time": 18.88963928361734, "Episode Reward": 31663.391298933442, "Mean Reward": 63.45368997782253, "Episode": 5284, "Episode Step": 499}
{"Training time": 18.890359928276805, "Episode Reward": -440.6685282431248, "Mean Reward": -7.468958105815674, "Episode": 5285, "Episode Step": 59}
{"Training time": 18.892910398311084, "Episode Reward": 8255.8699462784, "Mean Reward": 46.381291833024726, "Episode": 5286, "Episode Step": 178}
{"Training time": 18.89880572689904, "Episode Reward": 30688.679876710947, "Mean Reward": 60.890237850616955, "Episode": 5287, "Episode Step": 504}
{"Training time": 18.899512066377532, "Episode Reward": -456.26118877952524, "Mean Reward": -7.733240487788564, "Episode": 5288, "Episode Step": 59}
{"Training time": 18.901452570557595, "Episode Reward": 6203.711477535794, "Mean Reward": 49.23580537726821, "Episode": 5289, "Episode Step": 126}
{"Training time": 18.928699136641292, "Episode Reward": 142392.23675145, "Mean Reward": 60.92949796810012, "Episode": 5290, "Episode Step": 2337}
{"Training time": 18.929450600544612, "Episode Reward": -467.5961452331651, "Mean Reward": -7.665510577592871, "Episode": 5291, "Episode Step": 61}
{"Training time": 18.931149241924285, "Episode Reward": 5661.30001616865, "Mean Reward": 54.96407782688009, "Episode": 5292, "Episode Step": 103}
{"Training time": 18.95839441637198, "Episode Reward": 149830.14194409852, "Mean Reward": 64.16708434436768, "Episode": 5293, "Episode Step": 2335}
{"Training time": 18.959288211663566, "Episode Reward": -471.83829572436485, "Mean Reward": -6.291177276324865, "Episode": 5294, "Episode Step": 75}
{"Training time": 18.960953867170545, "Episode Reward": 5515.094603779262, "Mean Reward": 53.544607803682155, "Episode": 5295, "Episode Step": 103}
{"Training time": 18.964565684729152, "Episode Reward": 18940.17789068269, "Mean Reward": 62.098943903877675, "Episode": 5296, "Episode Step": 305}
{"Training time": 18.965307233598498, "Episode Reward": -448.16187737911923, "Mean Reward": -7.469364622985321, "Episode": 5297, "Episode Step": 60}
{"Training time": 18.967031063305008, "Episode Reward": 5607.87136151486, "Mean Reward": 53.4082986810939, "Episode": 5298, "Episode Step": 105}
{"Training time": 18.974585319691233, "Episode Reward": 33970.44014449207, "Mean Reward": 62.103181251356624, "Episode": 5299, "Episode Step": 547}
{"Training time": 18.975634636614057, "Episode Reward": -452.3171931769972, "Mean Reward": -7.179637986936464, "Episode": 5300, "Episode Step": 63}
{"Training time": 18.97811296555731, "Episode Reward": 8417.073448993033, "Mean Reward": 48.653603751404816, "Episode": 5301, "Episode Step": 173}
{"Training time": 18.996399643553627, "Episode Reward": 97717.2633225752, "Mean Reward": 62.161108983826466, "Episode": 5302, "Episode Step": 1572}
{"Training time": 18.997140946653154, "Episode Reward": -456.3347179654337, "Mean Reward": -7.360237386539253, "Episode": 5303, "Episode Step": 62}
{"Training time": 18.998831282721625, "Episode Reward": 5686.014813864762, "Mean Reward": 54.152522036807255, "Episode": 5304, "Episode Step": 105}
{"Training time": 19.002227320538626, "Episode Reward": 18336.715500845166, "Mean Reward": 62.15835762998361, "Episode": 5305, "Episode Step": 295}
{"Training time": 19.002937007745107, "Episode Reward": -446.9514493107263, "Mean Reward": -7.449190821845438, "Episode": 5306, "Episode Step": 60}
{"Training time": 19.00459332578712, "Episode Reward": 5670.329339841729, "Mean Reward": 55.051741163511934, "Episode": 5307, "Episode Step": 103}
{"Training time": 19.016332229706975, "Episode Reward": 65025.62725182691, "Mean Reward": 64.96066658524167, "Episode": 5308, "Episode Step": 1001}
{"Training time": 19.017112521396744, "Episode Reward": -455.79564087182143, "Mean Reward": -7.12180688862221, "Episode": 5309, "Episode Step": 64}
{"Training time": 19.01961022555828, "Episode Reward": 8286.18341079848, "Mean Reward": 47.62174374022115, "Episode": 5310, "Episode Step": 174}
{"Training time": 19.020816716618008, "Episode Reward": 6193.563744926969, "Mean Reward": 59.553497547374704, "Episode": 5311, "Episode Step": 104}
{"Training time": 19.02159689360195, "Episode Reward": -457.0823317950439, "Mean Reward": -7.141911434297561, "Episode": 5312, "Episode Step": 64}
{"Training time": 19.024130495521757, "Episode Reward": 8611.134365400498, "Mean Reward": 48.92689980341192, "Episode": 5313, "Episode Step": 176}
{"Training time": 19.030580486390324, "Episode Reward": 34370.53993804569, "Mean Reward": 61.81751787418289, "Episode": 5314, "Episode Step": 556}
{"Training time": 19.031310395797092, "Episode Reward": -450.49684960148375, "Mean Reward": -7.2660782193787705, "Episode": 5315, "Episode Step": 62}
{"Training time": 19.033813036349084, "Episode Reward": 8881.530036892203, "Mean Reward": 51.04327607409312, "Episode": 5316, "Episode Step": 174}
{"Training time": 19.03731164554755, "Episode Reward": 18968.363474872036, "Mean Reward": 63.22787824957345, "Episode": 5317, "Episode Step": 300}
{"Training time": 19.03851963135931, "Episode Reward": -262.86620284122006, "Mean Reward": -2.577119635698236, "Episode": 5318, "Episode Step": 102}
{"Training time": 19.04039772497283, "Episode Reward": 6046.216609508722, "Mean Reward": 49.55915253695674, "Episode": 5319, "Episode Step": 122}
{"Training time": 19.043956895271936, "Episode Reward": 18553.480040235158, "Mean Reward": 61.844933467450524, "Episode": 5320, "Episode Step": 300}
{"Training time": 19.044737386107446, "Episode Reward": -454.2463783289733, "Mean Reward": -6.9884058204457435, "Episode": 5321, "Episode Step": 65}
{"Training time": 19.060330162445705, "Episode Reward": 79751.78734202022, "Mean Reward": 61.394755459599864, "Episode": 5322, "Episode Step": 1299}
{"Training time": 19.063880207472376, "Episode Reward": 18569.250180672283, "Mean Reward": 61.08305980484304, "Episode": 5323, "Episode Step": 304}
{"Training time": 19.064662736058235, "Episode Reward": -273.3061102802894, "Mean Reward": -4.141001670913475, "Episode": 5324, "Episode Step": 66}
{"Training time": 19.06714113526874, "Episode Reward": 8457.10584652914, "Mean Reward": 48.88500489323203, "Episode": 5325, "Episode Step": 173}
{"Training time": 19.070568731890784, "Episode Reward": 18500.92153752403, "Mean Reward": 62.71498826279333, "Episode": 5326, "Episode Step": 295}
{"Training time": 19.071499390006064, "Episode Reward": -481.04162670071844, "Mean Reward": -6.2472938532560836, "Episode": 5327, "Episode Step": 77}
{"Training time": 19.090083384447627, "Episode Reward": 98232.7537056455, "Mean Reward": 62.92937457120148, "Episode": 5328, "Episode Step": 1561}
{"Training time": 19.098880660004085, "Episode Reward": 47298.24544021594, "Mean Reward": 63.23294844948656, "Episode": 5329, "Episode Step": 748}
{"Training time": 19.099698483281664, "Episode Reward": -276.8215552850204, "Mean Reward": -4.070905224779712, "Episode": 5330, "Episode Step": 68}
{"Training time": 19.102247144712344, "Episode Reward": 9012.235724829958, "Mean Reward": 50.916586015988464, "Episode": 5331, "Episode Step": 177}
{"Training time": 19.105229328340954, "Episode Reward": 16545.6043860104, "Mean Reward": 65.14017474807244, "Episode": 5332, "Episode Step": 254}
{"Training time": 19.106059235003258, "Episode Reward": -501.44795667716505, "Mean Reward": -7.267361690973407, "Episode": 5333, "Episode Step": 69}
{"Training time": 19.11333014772998, "Episode Reward": 34956.28844620435, "Mean Reward": 59.75433922428094, "Episode": 5334, "Episode Step": 585}
{"Training time": 19.116241366664568, "Episode Reward": 15425.89847408592, "Mean Reward": 61.703593896343676, "Episode": 5335, "Episode Step": 250}
{"Training time": 19.11743756082323, "Episode Reward": -267.3868025629778, "Mean Reward": -2.6214392408135074, "Episode": 5336, "Episode Step": 102}
{"Training time": 19.11935047050317, "Episode Reward": 6721.5518093882465, "Mean Reward": 54.64676267795323, "Episode": 5337, "Episode Step": 123}
{"Training time": 19.122821864684422, "Episode Reward": 17760.005039587442, "Mean Reward": 59.59733234760887, "Episode": 5338, "Episode Step": 298}
{"Training time": 19.123616308305, "Episode Reward": -294.7529382460445, "Mean Reward": -4.465953609788553, "Episode": 5339, "Episode Step": 66}
{"Training time": 19.130799606111314, "Episode Reward": 36624.37133545208, "Mean Reward": 62.92847308496921, "Episode": 5340, "Episode Step": 582}
{"Training time": 19.13869344525867, "Episode Reward": 44584.470088274975, "Mean Reward": 65.27740862119323, "Episode": 5341, "Episode Step": 683}
{"Training time": 19.15280046555731, "Episode Reward": 70178.93748105182, "Mean Reward": 57.903413763244075, "Episode": 5342, "Episode Step": 1212}
{"Training time": 19.155306612186962, "Episode Reward": 8877.362571313568, "Mean Reward": 50.439560064281636, "Episode": 5343, "Episode Step": 176}
{"Training time": 19.156967364947, "Episode Reward": 6915.409432860918, "Mean Reward": 49.75114699899941, "Episode": 5344, "Episode Step": 139}
{"Training time": 19.157776261104477, "Episode Reward": -514.9165764123453, "Mean Reward": -7.921793483266851, "Episode": 5345, "Episode Step": 65}
{"Training time": 19.16236594994863, "Episode Reward": 20070.231683620343, "Mean Reward": 59.37938367935013, "Episode": 5346, "Episode Step": 338}
{"Training time": 19.19088744746314, "Episode Reward": 159836.812101531, "Mean Reward": 65.0536475789707, "Episode": 5347, "Episode Step": 2457}
{"Training time": 19.191666342218717, "Episode Reward": -306.06605852302005, "Mean Reward": -4.708708592661847, "Episode": 5348, "Episode Step": 65}
{"Training time": 19.19388880027665, "Episode Reward": 2357.8217947379167, "Mean Reward": 44.48720367430032, "Episode": 5349, "Episode Step": 53}
{"Training time": 19.213008844984902, "Episode Reward": 104842.84714550324, "Mean Reward": 65.24134856596343, "Episode": 5350, "Episode Step": 1607}
{"Training time": 19.213727724419698, "Episode Reward": -481.581170574433, "Mean Reward": -8.026352842907217, "Episode": 5351, "Episode Step": 60}
{"Training time": 19.216334051357375, "Episode Reward": 8537.610244312955, "Mean Reward": 46.90994639732393, "Episode": 5352, "Episode Step": 182}
{"Training time": 19.21841676361031, "Episode Reward": 8350.151588740153, "Mean Reward": 46.91096398168625, "Episode": 5353, "Episode Step": 178}
{"Training time": 19.226770991947916, "Episode Reward": 37100.956361897646, "Mean Reward": 52.03500191009488, "Episode": 5354, "Episode Step": 713}
{"Training time": 19.229392892453404, "Episode Reward": 9046.692414725403, "Mean Reward": 49.16680660176849, "Episode": 5355, "Episode Step": 184}
{"Training time": 19.230604060226018, "Episode Reward": 4454.4107893345345, "Mean Reward": 43.67069401308367, "Episode": 5356, "Episode Step": 102}
{"Training time": 19.231986110806464, "Episode Reward": -73.69904970143831, "Mean Reward": -0.6464828921178799, "Episode": 5357, "Episode Step": 114}
{"Training time": 19.23454764690664, "Episode Reward": 8897.157110010843, "Mean Reward": 49.70478832408292, "Episode": 5358, "Episode Step": 179}
{"Training time": 19.24246623383628, "Episode Reward": 43531.50375023158, "Mean Reward": 64.01691727975233, "Episode": 5359, "Episode Step": 680}
{"Training time": 19.243668257196745, "Episode Reward": -236.6320204414919, "Mean Reward": -2.3199217690342344, "Episode": 5360, "Episode Step": 102}
{"Training time": 19.246210680272846, "Episode Reward": 8511.16988287412, "Mean Reward": 47.28427712707844, "Episode": 5361, "Episode Step": 180}
{"Training time": 19.252369075814883, "Episode Reward": 34672.645860235025, "Mean Reward": 65.66788988680877, "Episode": 5362, "Episode Step": 528}
{"Training time": 19.255562603871027, "Episode Reward": 7389.287792209021, "Mean Reward": 27.066988249849896, "Episode": 5363, "Episode Step": 273}
{"Training time": 19.259053611622917, "Episode Reward": 16818.035219681493, "Mean Reward": 64.93449891768917, "Episode": 5364, "Episode Step": 259}
{"Training time": 19.262531523307164, "Episode Reward": 17942.205875803444, "Mean Reward": 59.41127773444849, "Episode": 5365, "Episode Step": 302}
{"Training time": 19.263745918605064, "Episode Reward": 36.25948523067446, "Mean Reward": 0.3554851493203378, "Episode": 5366, "Episode Step": 102}
{"Training time": 19.266219270825385, "Episode Reward": 8751.845116432629, "Mean Reward": 50.882820444375746, "Episode": 5367, "Episode Step": 172}
{"Training time": 19.279482892751695, "Episode Reward": 71514.80318901667, "Mean Reward": 62.56763183641004, "Episode": 5368, "Episode Step": 1143}
{"Training time": 19.292164000272752, "Episode Reward": 62755.733548876335, "Mean Reward": 58.161013483666665, "Episode": 5369, "Episode Step": 1079}
{"Training time": 19.294705786903698, "Episode Reward": 8424.663766404476, "Mean Reward": 48.140935808025574, "Episode": 5370, "Episode Step": 175}
{"Training time": 19.29777350412475, "Episode Reward": 15343.493885282187, "Mean Reward": 58.787332893801484, "Episode": 5371, "Episode Step": 261}
{"Training time": 19.300939019123714, "Episode Reward": 12671.927871620024, "Mean Reward": 46.41731821106236, "Episode": 5372, "Episode Step": 273}
{"Training time": 19.303500086334015, "Episode Reward": 8649.689059138153, "Mean Reward": 48.868299769142105, "Episode": 5373, "Episode Step": 177}
{"Training time": 19.306470481620895, "Episode Reward": 15527.458097939147, "Mean Reward": 61.86238286031533, "Episode": 5374, "Episode Step": 251}
{"Training time": 19.30898232665327, "Episode Reward": 7669.536985221893, "Mean Reward": 35.3434884111608, "Episode": 5375, "Episode Step": 217}
{"Training time": 19.314297799401814, "Episode Reward": 26044.5331930018, "Mean Reward": 62.15879043675847, "Episode": 5376, "Episode Step": 419}
{"Training time": 19.34780256582631, "Episode Reward": 187800.6283222718, "Mean Reward": 65.29924489647837, "Episode": 5377, "Episode Step": 2876}
{"Training time": 19.361999016337926, "Episode Reward": 72628.87997215586, "Mean Reward": 59.92481845887447, "Episode": 5378, "Episode Step": 1212}
{"Training time": 19.36453992055522, "Episode Reward": 8738.505227126858, "Mean Reward": 49.3700860289653, "Episode": 5379, "Episode Step": 177}
{"Training time": 19.372655002209875, "Episode Reward": 43740.86696078794, "Mean Reward": 63.76219673584248, "Episode": 5380, "Episode Step": 686}
{"Training time": 19.3895527780056, "Episode Reward": 84138.84683004646, "Mean Reward": 58.06683701176429, "Episode": 5381, "Episode Step": 1449}
{"Training time": 19.397322861353555, "Episode Reward": 38933.9763496177, "Mean Reward": 62.394192867977075, "Episode": 5382, "Episode Step": 624}
{"Training time": 19.40022501051426, "Episode Reward": 16233.449708147069, "Mean Reward": 65.45745850059302, "Episode": 5383, "Episode Step": 248}
{"Training time": 19.403792974948882, "Episode Reward": 13591.880639886705, "Mean Reward": 44.41791058786505, "Episode": 5384, "Episode Step": 306}
{"Training time": 19.406307470268672, "Episode Reward": 9110.441140237086, "Mean Reward": 51.76387011498344, "Episode": 5385, "Episode Step": 176}
{"Training time": 19.434312651356063, "Episode Reward": 155395.07618419206, "Mean Reward": 64.31915404974836, "Episode": 5386, "Episode Step": 2416}
{"Training time": 19.437610731654697, "Episode Reward": 14278.551351280816, "Mean Reward": 49.9250047247581, "Episode": 5387, "Episode Step": 286}
{"Training time": 19.440134090251394, "Episode Reward": 8889.793566480199, "Mean Reward": 50.510190718637496, "Episode": 5388, "Episode Step": 176}
{"Training time": 19.442246737215253, "Episode Reward": 9003.315467292794, "Mean Reward": 50.58042397355502, "Episode": 5389, "Episode Step": 178}
{"Training time": 19.451190836628278, "Episode Reward": 41115.67538915723, "Mean Reward": 53.8868615847408, "Episode": 5390, "Episode Step": 763}
{"Training time": 19.453692231376966, "Episode Reward": 9118.649049176905, "Mean Reward": 52.406029018258074, "Episode": 5391, "Episode Step": 174}
{"Training time": 19.45654203719563, "Episode Reward": 15967.695817118698, "Mean Reward": 65.9822141203252, "Episode": 5392, "Episode Step": 242}
{"Training time": 19.46003593272633, "Episode Reward": 12018.206453491062, "Mean Reward": 40.73968289319004, "Episode": 5393, "Episode Step": 295}
{"Training time": 19.46334695915381, "Episode Reward": 14759.062509664804, "Mean Reward": 60.98786161018514, "Episode": 5394, "Episode Step": 242}
{"Training time": 19.466164101362228, "Episode Reward": 16273.762158226946, "Mean Reward": 67.80734232594561, "Episode": 5395, "Episode Step": 240}
{"Training time": 19.47031851940685, "Episode Reward": 15462.183323977075, "Mean Reward": 44.559606120971395, "Episode": 5396, "Episode Step": 347}
{"Training time": 19.472913257744576, "Episode Reward": 8941.70662510802, "Mean Reward": 50.80515127902284, "Episode": 5397, "Episode Step": 176}
{"Training time": 19.475849881900682, "Episode Reward": 16089.480614288628, "Mean Reward": 66.21185437978859, "Episode": 5398, "Episode Step": 243}
{"Training time": 19.489530301094057, "Episode Reward": 56132.95064779731, "Mean Reward": 52.95561381867671, "Episode": 5399, "Episode Step": 1060}
{"Training time": 19.49734197749032, "Episode Reward": 38243.63702559887, "Mean Reward": 61.48494698649336, "Episode": 5400, "Episode Step": 622}
{"Training time": 19.500246956944466, "Episode Reward": 16634.393786762274, "Mean Reward": 67.89548484392765, "Episode": 5401, "Episode Step": 245}
{"Training time": 19.53049634191725, "Episode Reward": 139004.37524038443, "Mean Reward": 53.856790097010624, "Episode": 5402, "Episode Step": 2581}
{"Training time": 19.532999719712468, "Episode Reward": 8945.388391070708, "Mean Reward": 51.11650509183262, "Episode": 5403, "Episode Step": 175}
{"Training time": 19.535786687201924, "Episode Reward": 16490.540140574114, "Mean Reward": 68.99807590198374, "Episode": 5404, "Episode Step": 239}
{"Training time": 19.538405158321062, "Episode Reward": 7227.5202402305695, "Mean Reward": 32.41040466471107, "Episode": 5405, "Episode Step": 223}
{"Training time": 19.540434694422615, "Episode Reward": 6618.899161670831, "Mean Reward": 49.39476986321515, "Episode": 5406, "Episode Step": 134}
{"Training time": 19.543308487733206, "Episode Reward": 16382.84300955142, "Mean Reward": 67.41910703519103, "Episode": 5407, "Episode Step": 243}
{"Training time": 19.546544593042796, "Episode Reward": 10701.70537435964, "Mean Reward": 38.22037633699872, "Episode": 5408, "Episode Step": 280}
{"Training time": 19.54916743444072, "Episode Reward": 8387.521027868792, "Mean Reward": 46.08528037290545, "Episode": 5409, "Episode Step": 182}
{"Training time": 19.551987809406388, "Episode Reward": 16425.743134688648, "Mean Reward": 68.15661051738029, "Episode": 5410, "Episode Step": 241}
{"Training time": 19.554566879140005, "Episode Reward": 7178.415192153837, "Mean Reward": 32.77815156234629, "Episode": 5411, "Episode Step": 219}
{"Training time": 19.556459288597107, "Episode Reward": 6671.896755394135, "Mean Reward": 54.68767832290274, "Episode": 5412, "Episode Step": 122}
{"Training time": 19.559392064412435, "Episode Reward": 15435.918006983971, "Mean Reward": 63.52229632503692, "Episode": 5413, "Episode Step": 243}
{"Training time": 19.572141674160957, "Episode Reward": 55738.6009757095, "Mean Reward": 51.46685223980563, "Episode": 5414, "Episode Step": 1083}
{"Training time": 19.57997104552057, "Episode Reward": 37286.51985154789, "Mean Reward": 59.75403822363444, "Episode": 5415, "Episode Step": 624}
{"Training time": 19.58282191442119, "Episode Reward": 15736.298400273943, "Mean Reward": 65.56791000114143, "Episode": 5416, "Episode Step": 240}
{"Training time": 19.58902159611384, "Episode Reward": 24475.34451965523, "Mean Reward": 46.3548191660137, "Episode": 5417, "Episode Step": 528}
{"Training time": 19.595393629140325, "Episode Reward": 31847.886373115605, "Mean Reward": 64.73147636812115, "Episode": 5418, "Episode Step": 492}
{"Training time": 19.598365896079276, "Episode Reward": 16633.74980167163, "Mean Reward": 68.17110574455586, "Episode": 5419, "Episode Step": 244}
{"Training time": 19.60711027774546, "Episode Reward": 39770.72215803736, "Mean Reward": 53.9629880027644, "Episode": 5420, "Episode Step": 737}
{"Training time": 19.60967380444209, "Episode Reward": 8631.69943785156, "Mean Reward": 48.766663490686774, "Episode": 5421, "Episode Step": 177}
{"Training time": 19.612557674712605, "Episode Reward": 15812.878233969275, "Mean Reward": 65.6136026305779, "Episode": 5422, "Episode Step": 241}
{"Training time": 19.616114550232886, "Episode Reward": 11084.098760061455, "Mean Reward": 36.94699586687152, "Episode": 5423, "Episode Step": 300}
{"Training time": 19.619528227183554, "Episode Reward": 16680.76455594769, "Mean Reward": 66.72305822379077, "Episode": 5424, "Episode Step": 250}
{"Training time": 19.622416284150546, "Episode Reward": 16994.69617905146, "Mean Reward": 69.93702131296898, "Episode": 5425, "Episode Step": 243}
{"Training time": 19.626103655497232, "Episode Reward": 11804.547576661444, "Mean Reward": 38.326453170978716, "Episode": 5426, "Episode Step": 308}
{"Training time": 19.628645573059718, "Episode Reward": 8690.102947945259, "Mean Reward": 49.375584931507156, "Episode": 5427, "Episode Step": 176}
{"Training time": 19.631456663012504, "Episode Reward": 14321.878431289184, "Mean Reward": 60.17595979533271, "Episode": 5428, "Episode Step": 238}
{"Training time": 19.63537172800965, "Episode Reward": 12936.27953270287, "Mean Reward": 38.96469738765925, "Episode": 5429, "Episode Step": 332}
{"Training time": 19.64144766079055, "Episode Reward": 32145.39758866811, "Mean Reward": 66.83034841718943, "Episode": 5430, "Episode Step": 481}
{"Training time": 19.644233259956042, "Episode Reward": 14456.122511561738, "Mean Reward": 60.485868249212295, "Episode": 5431, "Episode Step": 239}
{"Training time": 19.645737434162033, "Episode Reward": 2372.1619716733535, "Mean Reward": 18.67844072183743, "Episode": 5432, "Episode Step": 127}
{"Training time": 19.652681475811534, "Episode Reward": 36701.305830418474, "Mean Reward": 65.65528771094539, "Episode": 5433, "Episode Step": 559}
{"Training time": 19.655471489959293, "Episode Reward": 15261.127006321041, "Mean Reward": 63.854087892556656, "Episode": 5434, "Episode Step": 239}
{"Training time": 19.656666087441973, "Episode Reward": -623.2464877218606, "Mean Reward": -6.110259683547653, "Episode": 5435, "Episode Step": 102}
{"Training time": 19.66300319665008, "Episode Reward": 31525.011579503513, "Mean Reward": 63.30323610342071, "Episode": 5436, "Episode Step": 498}
{"Training time": 19.665798088312147, "Episode Reward": 15405.39320023617, "Mean Reward": 64.18913833431738, "Episode": 5437, "Episode Step": 240}
{"Training time": 19.667028852767416, "Episode Reward": -674.131734578388, "Mean Reward": -6.609134652729294, "Episode": 5438, "Episode Step": 102}
{"Training time": 19.669568626615735, "Episode Reward": 8730.153910906343, "Mean Reward": 50.1732983385422, "Episode": 5439, "Episode Step": 174}
{"Training time": 19.67237188027965, "Episode Reward": 15402.908529369904, "Mean Reward": 64.44731602246821, "Episode": 5440, "Episode Step": 239}
{"Training time": 19.673592652479808, "Episode Reward": -618.2076422149485, "Mean Reward": -6.060859237401456, "Episode": 5441, "Episode Step": 102}
{"Training time": 19.676882044672965, "Episode Reward": 15908.935460377941, "Mean Reward": 66.28723108490809, "Episode": 5442, "Episode Step": 240}
{"Training time": 19.67830941968494, "Episode Reward": 6774.69902989172, "Mean Reward": 55.53031991714524, "Episode": 5443, "Episode Step": 122}
{"Training time": 19.682083009680113, "Episode Reward": 11317.221808455335, "Mean Reward": 34.92969693967696, "Episode": 5444, "Episode Step": 324}
{"Training time": 19.700165375007522, "Episode Reward": 96019.08674155374, "Mean Reward": 63.71538602624667, "Episode": 5445, "Episode Step": 1507}
{"Training time": 19.702168770498698, "Episode Reward": 8517.216664953748, "Mean Reward": 49.51870154042877, "Episode": 5446, "Episode Step": 172}
{"Training time": 19.703113815254635, "Episode Reward": -781.038369338714, "Mean Reward": -9.762979616733926, "Episode": 5447, "Episode Step": 80}
{"Training time": 19.711500364144644, "Episode Reward": 46073.24491327129, "Mean Reward": 67.55607758544178, "Episode": 5448, "Episode Step": 682}
{"Training time": 19.715395042498905, "Episode Reward": 15435.354515246814, "Mean Reward": 64.58307328555152, "Episode": 5449, "Episode Step": 239}
{"Training time": 19.71667515999741, "Episode Reward": -812.7458499179958, "Mean Reward": -9.561715881388185, "Episode": 5450, "Episode Step": 85}
{"Training time": 19.723860374689103, "Episode Reward": 35593.102237834944, "Mean Reward": 62.885339642817925, "Episode": 5451, "Episode Step": 566}
{"Training time": 19.726729096637833, "Episode Reward": 16065.542968588334, "Mean Reward": 66.38654119251377, "Episode": 5452, "Episode Step": 242}
{"Training time": 19.727669660780165, "Episode Reward": -789.0745610441877, "Mean Reward": -10.116340526207535, "Episode": 5453, "Episode Step": 78}
{"Training time": 19.745809952484237, "Episode Reward": 98168.94039230439, "Mean Reward": 64.75523772579444, "Episode": 5454, "Episode Step": 1516}
{"Training time": 19.748654423885874, "Episode Reward": 16326.731884870316, "Mean Reward": 67.46583423500131, "Episode": 5455, "Episode Step": 242}
{"Training time": 19.74952300634649, "Episode Reward": -782.7766650131451, "Mean Reward": -10.578063040718177, "Episode": 5456, "Episode Step": 74}
{"Training time": 19.757170695000223, "Episode Reward": 38583.85309442958, "Mean Reward": 62.84015161959215, "Episode": 5457, "Episode Step": 614}
{"Training time": 19.75986056857639, "Episode Reward": 14965.366145958636, "Mean Reward": 66.21843427415325, "Episode": 5458, "Episode Step": 226}
{"Training time": 19.761081083284484, "Episode Reward": -771.4218191352863, "Mean Reward": -7.562959011130258, "Episode": 5459, "Episode Step": 102}
{"Training time": 19.76365069495307, "Episode Reward": 8900.071371301541, "Mean Reward": 49.44484095167523, "Episode": 5460, "Episode Step": 180}
{"Training time": 19.76652317914698, "Episode Reward": 15120.713366335734, "Mean Reward": 62.48228663775097, "Episode": 5461, "Episode Step": 242}
{"Training time": 19.767683712773852, "Episode Reward": -940.433832521584, "Mean Reward": -9.796185755433166, "Episode": 5462, "Episode Step": 96}
{"Training time": 19.791184573835796, "Episode Reward": 128815.28147912811, "Mean Reward": 65.72208238731027, "Episode": 5463, "Episode Step": 1960}
{"Training time": 19.794056008855502, "Episode Reward": 15878.374310851963, "Mean Reward": 66.43671259770696, "Episode": 5464, "Episode Step": 239}
{"Training time": 19.795294567743937, "Episode Reward": -854.8802382562554, "Mean Reward": -8.381178806433876, "Episode": 5465, "Episode Step": 102}
{"Training time": 19.803074750502905, "Episode Reward": 37221.18022827277, "Mean Reward": 59.841125768927284, "Episode": 5466, "Episode Step": 622}
{"Training time": 19.805809147755305, "Episode Reward": 14405.13800260919, "Mean Reward": 62.09111208021203, "Episode": 5467, "Episode Step": 232}
{"Training time": 19.807026164134342, "Episode Reward": -880.3450473497134, "Mean Reward": -8.63083379754621, "Episode": 5468, "Episode Step": 102}
{"Training time": 19.819953433010312, "Episode Reward": 66219.4165051284, "Mean Reward": 62.294841491183824, "Episode": 5469, "Episode Step": 1063}
{"Training time": 19.826432124442526, "Episode Reward": 34094.35120795, "Mean Reward": 60.77424457745098, "Episode": 5470, "Episode Step": 561}
{"Training time": 19.827648653586706, "Episode Reward": -959.9643884341925, "Mean Reward": -9.411415572884241, "Episode": 5471, "Episode Step": 102}
{"Training time": 19.830144450267156, "Episode Reward": 8536.59212619947, "Mean Reward": 49.34446315722237, "Episode": 5472, "Episode Step": 173}
{"Training time": 19.832970514959758, "Episode Reward": 15136.220616777762, "Mean Reward": 62.54636618503208, "Episode": 5473, "Episode Step": 242}
{"Training time": 19.83416970749696, "Episode Reward": -966.601810596151, "Mean Reward": -9.476488339177951, "Episode": 5474, "Episode Step": 102}
{"Training time": 19.83680145720641, "Episode Reward": 8796.254789175522, "Mean Reward": 48.33107027019518, "Episode": 5475, "Episode Step": 182}
{"Training time": 19.849495996899076, "Episode Reward": 71912.7052675726, "Mean Reward": 65.49426709250692, "Episode": 5476, "Episode Step": 1098}
{"Training time": 19.85070776442687, "Episode Reward": -1005.5476631638253, "Mean Reward": -9.858310423174757, "Episode": 5477, "Episode Step": 102}
{"Training time": 19.85316582666503, "Episode Reward": 8668.65812596809, "Mean Reward": 50.399175150977264, "Episode": 5478, "Episode Step": 172}
{"Training time": 19.8559700936079, "Episode Reward": 14743.026538540462, "Mean Reward": 60.67089110510478, "Episode": 5479, "Episode Step": 243}
{"Training time": 19.857180478572847, "Episode Reward": -1045.6432200678817, "Mean Reward": -10.251404118312566, "Episode": 5480, "Episode Step": 102}
{"Training time": 19.875180960231358, "Episode Reward": 90811.48755228058, "Mean Reward": 60.06050764039721, "Episode": 5481, "Episode Step": 1512}
{"Training time": 19.877999024987222, "Episode Reward": 14928.643161474898, "Mean Reward": 61.18296377653647, "Episode": 5482, "Episode Step": 244}
{"Training time": 19.879206261369916, "Episode Reward": -1197.3208152107159, "Mean Reward": -11.73843936481094, "Episode": 5483, "Episode Step": 102}
{"Training time": 19.889630303051735, "Episode Reward": 52359.83606760293, "Mean Reward": 61.31128345152568, "Episode": 5484, "Episode Step": 854}
{"Training time": 19.891218668023747, "Episode Reward": 6518.419998081118, "Mean Reward": 49.01067667730164, "Episode": 5485, "Episode Step": 133}
{"Training time": 19.892454246083897, "Episode Reward": -1047.06032896976, "Mean Reward": -10.265297342840784, "Episode": 5486, "Episode Step": 102}
{"Training time": 19.922141595284145, "Episode Reward": 157075.43645261793, "Mean Reward": 63.260344926547695, "Episode": 5487, "Episode Step": 2483}
{"Training time": 19.924997784958947, "Episode Reward": 15593.27507967232, "Mean Reward": 64.16985629494782, "Episode": 5488, "Episode Step": 243}
{"Training time": 19.92618817137347, "Episode Reward": -1125.3375750231621, "Mean Reward": -11.03272132375649, "Episode": 5489, "Episode Step": 102}
{"Training time": 19.928121031920114, "Episode Reward": 5498.9165700078465, "Mean Reward": 45.07308663940858, "Episode": 5490, "Episode Step": 122}
{"Training time": 19.9302095183399, "Episode Reward": 8741.204014263363, "Mean Reward": 49.949737224362075, "Episode": 5491, "Episode Step": 175}
{"Training time": 19.931435554954742, "Episode Reward": -1166.0601184697373, "Mean Reward": -11.431961945781739, "Episode": 5492, "Episode Step": 102}
{"Training time": 19.936698872447014, "Episode Reward": 22604.39870033098, "Mean Reward": 55.53906314577637, "Episode": 5493, "Episode Step": 407}
{"Training time": 19.939613262216252, "Episode Reward": 13452.591116431662, "Mean Reward": 54.68532974159212, "Episode": 5494, "Episode Step": 246}
{"Training time": 19.940825154980022, "Episode Reward": -1266.4297619608637, "Mean Reward": -12.41597805843984, "Episode": 5495, "Episode Step": 102}
{"Training time": 19.946012516087954, "Episode Reward": 24878.43206638849, "Mean Reward": 61.42822732441603, "Episode": 5496, "Episode Step": 405}
{"Training time": 19.954005661341878, "Episode Reward": 42152.17282291527, "Mean Reward": 63.19666090392095, "Episode": 5497, "Episode Step": 667}
{"Training time": 19.955239550007715, "Episode Reward": -1326.6007732539495, "Mean Reward": -13.00588993386225, "Episode": 5498, "Episode Step": 102}
{"Training time": 19.958241908020444, "Episode Reward": 6330.127601498122, "Mean Reward": 53.1943495924212, "Episode": 5499, "Episode Step": 119}
{"Training time": 19.966325989166897, "Episode Reward": 41649.14657613452, "Mean Reward": 62.81922560502944, "Episode": 5500, "Episode Step": 663}
{"Training time": 19.967521216074626, "Episode Reward": -1282.8386619200057, "Mean Reward": -12.576849626666723, "Episode": 5501, "Episode Step": 102}
{"Training time": 19.972822415828706, "Episode Reward": 23662.464504911182, "Mean Reward": 58.1387334273002, "Episode": 5502, "Episode Step": 407}
{"Training time": 19.980739799141883, "Episode Reward": 41428.66567329339, "Mean Reward": 61.01423515948953, "Episode": 5503, "Episode Step": 679}
{"Training time": 19.981957849992646, "Episode Reward": -1212.2754618781307, "Mean Reward": -11.88505354782481, "Episode": 5504, "Episode Step": 102}
{"Training time": 19.989637064403958, "Episode Reward": 35869.45163977835, "Mean Reward": 58.419302344915884, "Episode": 5505, "Episode Step": 614}
{"Training time": 19.99253833777375, "Episode Reward": 14466.108284599723, "Mean Reward": 58.33108179274082, "Episode": 5506, "Episode Step": 248}
{"Training time": 19.99374347580804, "Episode Reward": -1299.9212481311279, "Mean Reward": -12.744325962069881, "Episode": 5507, "Episode Step": 102}
{"Training time": 19.995459449688592, "Episode Reward": 5816.778655924944, "Mean Reward": 54.362417345092936, "Episode": 5508, "Episode Step": 107}
{"Training time": 20.01230016330878, "Episode Reward": 85049.1574719258, "Mean Reward": 59.144059438056885, "Episode": 5509, "Episode Step": 1438}
{"Training time": 20.013494562771584, "Episode Reward": -1305.4904444613862, "Mean Reward": -12.798925926092021, "Episode": 5510, "Episode Step": 102}
{"Training time": 20.01605155467987, "Episode Reward": 8340.489128541749, "Mean Reward": 46.59491133263547, "Episode": 5511, "Episode Step": 179}
{"Training time": 20.05296481496758, "Episode Reward": 191077.57538356038, "Mean Reward": 60.44845788787105, "Episode": 5512, "Episode Step": 3161}
{"Training time": 20.054172091947663, "Episode Reward": -1285.212780798014, "Mean Reward": -12.600125301941313, "Episode": 5513, "Episode Step": 102}
{"Training time": 20.056739011075763, "Episode Reward": 8073.412663859089, "Mean Reward": 45.871662862835734, "Episode": 5514, "Episode Step": 176}
{"Training time": 20.063937807480496, "Episode Reward": 31138.433801759445, "Mean Reward": 50.22328032541846, "Episode": 5515, "Episode Step": 620}
{"Training time": 20.06514235695203, "Episode Reward": -1235.9705622946674, "Mean Reward": -12.117358453869288, "Episode": 5516, "Episode Step": 102}
{"Training time": 20.067708854145472, "Episode Reward": 8739.477042915076, "Mean Reward": 47.7567051525414, "Episode": 5517, "Episode Step": 183}
{"Training time": 20.085870825780763, "Episode Reward": 90521.02545230795, "Mean Reward": 57.95200092977461, "Episode": 5518, "Episode Step": 1562}
{"Training time": 20.08706161995729, "Episode Reward": -1160.0136478774705, "Mean Reward": -11.372682822328143, "Episode": 5519, "Episode Step": 102}
{"Training time": 20.09504399995009, "Episode Reward": 36155.28620318283, "Mean Reward": 56.141748762706264, "Episode": 5520, "Episode Step": 644}
{"Training time": 20.104129517740674, "Episode Reward": 44346.04496664176, "Mean Reward": 56.70849739979765, "Episode": 5521, "Episode Step": 782}
{"Training time": 20.105359908276135, "Episode Reward": -1087.3282789333189, "Mean Reward": -10.66008116601293, "Episode": 5522, "Episode Step": 102}
{"Training time": 20.107848343584273, "Episode Reward": 8413.909240029585, "Mean Reward": 48.91807697691619, "Episode": 5523, "Episode Step": 172}
{"Training time": 20.11095676806238, "Episode Reward": 15381.660342236331, "Mean Reward": 57.825790760286964, "Episode": 5524, "Episode Step": 266}
{"Training time": 20.11215633385711, "Episode Reward": -1207.4674828880786, "Mean Reward": -11.837916498902732, "Episode": 5525, "Episode Step": 102}
{"Training time": 20.114674138559234, "Episode Reward": 7880.405649773482, "Mean Reward": 45.289687642376336, "Episode": 5526, "Episode Step": 174}
{"Training time": 20.117540451089543, "Episode Reward": 10491.342714694181, "Mean Reward": 42.47507171940964, "Episode": 5527, "Episode Step": 247}
{"Training time": 20.11874292333921, "Episode Reward": -1107.841184293686, "Mean Reward": -10.861188081310647, "Episode": 5528, "Episode Step": 102}
{"Training time": 20.121230346096887, "Episode Reward": 8148.895971494652, "Mean Reward": 47.37730215985263, "Episode": 5529, "Episode Step": 172}
{"Training time": 20.12334835025999, "Episode Reward": 7680.555653867987, "Mean Reward": 44.396275455884314, "Episode": 5530, "Episode Step": 173}
{"Training time": 20.124575573603313, "Episode Reward": -1186.9336357046625, "Mean Reward": -11.636604271614338, "Episode": 5531, "Episode Step": 102}
{"Training time": 20.13770992524094, "Episode Reward": 62180.06616348042, "Mean Reward": 57.89577855072665, "Episode": 5532, "Episode Step": 1074}
{"Training time": 20.152609317766295, "Episode Reward": 72776.96138344907, "Mean Reward": 57.66795672222589, "Episode": 5533, "Episode Step": 1262}
{"Training time": 20.15383706861072, "Episode Reward": -1179.9608482659976, "Mean Reward": -11.568243610450956, "Episode": 5534, "Episode Step": 102}
{"Training time": 20.156405716074836, "Episode Reward": 7706.83061884947, "Mean Reward": 43.2968012294914, "Episode": 5535, "Episode Step": 178}
{"Training time": 20.164654020004804, "Episode Reward": 38343.116331814585, "Mean Reward": 54.85424367927695, "Episode": 5536, "Episode Step": 699}
{"Training time": 20.165895146926243, "Episode Reward": -1265.9732295948588, "Mean Reward": -12.411502250929988, "Episode": 5537, "Episode Step": 102}
{"Training time": 20.1678783866432, "Episode Reward": 5611.227389084802, "Mean Reward": 43.837713977225015, "Episode": 5538, "Episode Step": 128}
{"Training time": 20.169459794163703, "Episode Reward": 5896.588995583729, "Mean Reward": 44.3352556058927, "Episode": 5539, "Episode Step": 133}
{"Training time": 20.17066332856814, "Episode Reward": -1230.9875762741433, "Mean Reward": -12.068505649746504, "Episode": 5540, "Episode Step": 102}
{"Training time": 20.173216945793893, "Episode Reward": 7489.17616164424, "Mean Reward": 42.07402338002382, "Episode": 5541, "Episode Step": 178}
{"Training time": 20.175288538866575, "Episode Reward": 8091.5514831475475, "Mean Reward": 45.97472433606561, "Episode": 5542, "Episode Step": 176}
{"Training time": 20.17653934220473, "Episode Reward": -1204.6121124884892, "Mean Reward": -11.809922671455777, "Episode": 5543, "Episode Step": 102}
{"Training time": 20.18964750415749, "Episode Reward": 61405.891914707085, "Mean Reward": 57.44236848896827, "Episode": 5544, "Episode Step": 1069}
{"Training time": 20.19169355299738, "Episode Reward": 8235.676370398023, "Mean Reward": 47.33147339309209, "Episode": 5545, "Episode Step": 174}
{"Training time": 20.192929742733636, "Episode Reward": -1036.4855299696935, "Mean Reward": -10.161622842840133, "Episode": 5546, "Episode Step": 102}
{"Training time": 20.195493133862815, "Episode Reward": 8322.672819818603, "Mean Reward": 47.28791374896934, "Episode": 5547, "Episode Step": 176}
{"Training time": 20.197567631933424, "Episode Reward": 8729.18373471366, "Mean Reward": 49.88104991264949, "Episode": 5548, "Episode Step": 175}
{"Training time": 20.199889395501877, "Episode Reward": -1158.3643220788604, "Mean Reward": -11.356512961557454, "Episode": 5549, "Episode Step": 102}
{"Training time": 20.207654862735005, "Episode Reward": 36963.923385169415, "Mean Reward": 58.67289426217368, "Episode": 5550, "Episode Step": 630}
{"Training time": 20.20971095442772, "Episode Reward": 8297.758793586456, "Mean Reward": 47.146356781741225, "Episode": 5551, "Episode Step": 176}
{"Training time": 20.210929985509978, "Episode Reward": -1291.219677108764, "Mean Reward": -12.659016442242784, "Episode": 5552, "Episode Step": 102}
{"Training time": 20.213432444400258, "Episode Reward": 8865.779994098595, "Mean Reward": 50.952758586773534, "Episode": 5553, "Episode Step": 174}
{"Training time": 20.21622941467497, "Episode Reward": 15126.631421898803, "Mean Reward": 62.24951202427491, "Episode": 5554, "Episode Step": 243}
{"Training time": 20.21743830250369, "Episode Reward": -1202.1077316629962, "Mean Reward": -11.785369918264669, "Episode": 5555, "Episode Step": 102}
{"Training time": 20.22471546133359, "Episode Reward": 33674.54803018668, "Mean Reward": 57.367202777149366, "Episode": 5556, "Episode Step": 587}
{"Training time": 20.242667141622967, "Episode Reward": 92053.36685244774, "Mean Reward": 58.933013349838504, "Episode": 5557, "Episode Step": 1562}
{"Training time": 20.243898574709892, "Episode Reward": -1323.8698191840615, "Mean Reward": -12.979115874353544, "Episode": 5558, "Episode Step": 102}
{"Training time": 20.24646002219783, "Episode Reward": 8205.837052318588, "Mean Reward": 45.336116311152416, "Episode": 5559, "Episode Step": 181}
{"Training time": 20.248519875274763, "Episode Reward": 8030.669949423235, "Mean Reward": 45.11612331136649, "Episode": 5560, "Episode Step": 178}
{"Training time": 20.249732981059285, "Episode Reward": -1321.3174451650211, "Mean Reward": -12.95409259965707, "Episode": 5561, "Episode Step": 102}
{"Training time": 20.251802419424056, "Episode Reward": 6554.834995723431, "Mean Reward": 47.498804316836456, "Episode": 5562, "Episode Step": 138}
{"Training time": 20.259071334997813, "Episode Reward": 36342.21068750769, "Mean Reward": 58.61646885081886, "Episode": 5563, "Episode Step": 620}
{"Training time": 20.260279941360157, "Episode Reward": -1229.5877713717482, "Mean Reward": -12.054782072272042, "Episode": 5564, "Episode Step": 102}
{"Training time": 20.268184105820126, "Episode Reward": 36315.87926869553, "Mean Reward": 57.010799479898786, "Episode": 5565, "Episode Step": 637}
{"Training time": 20.27031585805946, "Episode Reward": 8357.413302141567, "Mean Reward": 46.68945978850038, "Episode": 5566, "Episode Step": 179}
{"Training time": 20.271529400282436, "Episode Reward": -1303.0655813710869, "Mean Reward": -12.775152758540067, "Episode": 5567, "Episode Step": 102}
{"Training time": 20.273618465264637, "Episode Reward": 5966.39414365324, "Mean Reward": 42.923698875203165, "Episode": 5568, "Episode Step": 139}
{"Training time": 20.286241951915954, "Episode Reward": 63431.97401963373, "Mean Reward": 58.24791002721187, "Episode": 5569, "Episode Step": 1089}
{"Training time": 20.2874487700065, "Episode Reward": -1200.5540328898053, "Mean Reward": -11.770137577351033, "Episode": 5570, "Episode Step": 102}
{"Training time": 20.289969108038477, "Episode Reward": 8365.427588506935, "Mean Reward": 47.262302759926186, "Episode": 5571, "Episode Step": 177}
{"Training time": 20.303431867228614, "Episode Reward": 73680.09802690239, "Mean Reward": 63.40800174432219, "Episode": 5572, "Episode Step": 1162}
{"Training time": 20.304663594961166, "Episode Reward": -1200.6937724096915, "Mean Reward": -11.771507572644035, "Episode": 5573, "Episode Step": 102}
{"Training time": 20.308158501386643, "Episode Reward": 16334.988068471115, "Mean Reward": 63.06945200181898, "Episode": 5574, "Episode Step": 259}
{"Training time": 20.309436254435116, "Episode Reward": 2433.538732140951, "Mean Reward": 23.858222864126972, "Episode": 5575, "Episode Step": 102}
{"Training time": 20.31066125472387, "Episode Reward": -1235.9248499657629, "Mean Reward": -12.11691029378199, "Episode": 5576, "Episode Step": 102}
{"Training time": 20.314122641086577, "Episode Reward": 14006.851649422322, "Mean Reward": 55.363049997716686, "Episode": 5577, "Episode Step": 253}
{"Training time": 20.327222438322174, "Episode Reward": 72045.8885965871, "Mean Reward": 64.67314954810332, "Episode": 5578, "Episode Step": 1114}
{"Training time": 20.328427296347087, "Episode Reward": -1144.0838925785843, "Mean Reward": -11.216508750770434, "Episode": 5579, "Episode Step": 102}
{"Training time": 20.330498098333678, "Episode Reward": 5881.020982837499, "Mean Reward": 42.616094078532605, "Episode": 5580, "Episode Step": 138}
{"Training time": 20.353004663321705, "Episode Reward": 119857.74836731619, "Mean Reward": 61.62352101147362, "Episode": 5581, "Episode Step": 1945}
{"Training time": 20.354214361376233, "Episode Reward": -1269.168972734031, "Mean Reward": -12.442833066019912, "Episode": 5582, "Episode Step": 102}
{"Training time": 20.356266888048914, "Episode Reward": 6304.947062287204, "Mean Reward": 46.35990486975885, "Episode": 5583, "Episode Step": 136}
{"Training time": 20.369436964392662, "Episode Reward": 75972.55210798173, "Mean Reward": 66.70109930463715, "Episode": 5584, "Episode Step": 1139}
{"Training time": 20.37062701470322, "Episode Reward": -1258.1235774221586, "Mean Reward": -12.33454487668783, "Episode": 5585, "Episode Step": 102}
{"Training time": 20.37266436636448, "Episode Reward": 6531.2165210041185, "Mean Reward": 48.379381637067546, "Episode": 5586, "Episode Step": 135}
{"Training time": 20.376145552463, "Episode Reward": 19177.17229086009, "Mean Reward": 64.13769996943174, "Episode": 5587, "Episode Step": 299}
{"Training time": 20.377352803614404, "Episode Reward": -846.105430283088, "Mean Reward": -8.295151277285177, "Episode": 5588, "Episode Step": 102}
{"Training time": 20.378388454119364, "Episode Reward": 2033.0108884577585, "Mean Reward": 41.49001813179099, "Episode": 5589, "Episode Step": 49}
{"Training time": 20.399310197763974, "Episode Reward": 115781.4919798676, "Mean Reward": 63.51151507398113, "Episode": 5590, "Episode Step": 1823}
{"Training time": 20.400523556669555, "Episode Reward": -935.373741175313, "Mean Reward": -9.170330795836401, "Episode": 5591, "Episode Step": 102}
{"Training time": 20.41014652384652, "Episode Reward": 46318.10878427487, "Mean Reward": 58.48246058620564, "Episode": 5592, "Episode Step": 792}
{"Training time": 20.41383319583204, "Episode Reward": 19176.908959007265, "Mean Reward": 61.66208668491082, "Episode": 5593, "Episode Step": 311}
{"Training time": 20.415050547785228, "Episode Reward": -995.7589324210672, "Mean Reward": -9.762342474716345, "Episode": 5594, "Episode Step": 102}
{"Training time": 20.422529659668605, "Episode Reward": 34307.62106400019, "Mean Reward": 57.17936844000031, "Episode": 5595, "Episode Step": 600}
{"Training time": 20.424147845837805, "Episode Reward": 5674.123955739863, "Mean Reward": 40.82103565280477, "Episode": 5596, "Episode Step": 139}
{"Training time": 20.425374001926848, "Episode Reward": -907.7112470851174, "Mean Reward": -8.899129873383504, "Episode": 5597, "Episode Step": 102}
{"Training time": 20.43322743025091, "Episode Reward": 35683.03288798384, "Mean Reward": 56.371299981017124, "Episode": 5598, "Episode Step": 633}
{"Training time": 20.4435312057866, "Episode Reward": 47391.20765225774, "Mean Reward": 59.46199203545513, "Episode": 5599, "Episode Step": 797}
{"Training time": 20.445037216941515, "Episode Reward": -1005.9613110541067, "Mean Reward": -9.862365794648104, "Episode": 5600, "Episode Step": 102}
{"Training time": 20.447050952447785, "Episode Reward": 6207.9588203703415, "Mean Reward": 45.98488015089142, "Episode": 5601, "Episode Step": 135}
{"Training time": 20.457869152757855, "Episode Reward": 56255.45838798182, "Mean Reward": 61.01459695008874, "Episode": 5602, "Episode Step": 922}
{"Training time": 20.459106624987392, "Episode Reward": -955.1453014489371, "Mean Reward": -9.364169622048403, "Episode": 5603, "Episode Step": 102}
{"Training time": 20.463211008310317, "Episode Reward": 17781.25750007926, "Mean Reward": 57.174461415045855, "Episode": 5604, "Episode Step": 311}
{"Training time": 20.474349902735817, "Episode Reward": 54900.368650204204, "Mean Reward": 57.78986173705706, "Episode": 5605, "Episode Step": 950}
{"Training time": 20.47556184609731, "Episode Reward": -894.2063836922199, "Mean Reward": -8.76672925188451, "Episode": 5606, "Episode Step": 102}
{"Training time": 20.482279809117315, "Episode Reward": 32039.953318701562, "Mean Reward": 59.443327121895294, "Episode": 5607, "Episode Step": 539}
{"Training time": 20.4852790408002, "Episode Reward": 15015.053932437506, "Mean Reward": 58.65255442358401, "Episode": 5608, "Episode Step": 256}
{"Training time": 20.486470413009325, "Episode Reward": -1153.0653600667538, "Mean Reward": -11.304562353595625, "Episode": 5609, "Episode Step": 102}
{"Training time": 20.48837418138981, "Episode Reward": 6469.055095342413, "Mean Reward": 52.59394386457246, "Episode": 5610, "Episode Step": 123}
{"Training time": 20.501242461336982, "Episode Reward": 64826.637763261926, "Mean Reward": 58.2973361180413, "Episode": 5611, "Episode Step": 1112}
{"Training time": 20.502443973885644, "Episode Reward": -965.5392461307689, "Mean Reward": -9.466071040497734, "Episode": 5612, "Episode Step": 102}
{"Training time": 20.50643409470717, "Episode Reward": 17970.074447344596, "Mean Reward": 60.1005834359351, "Episode": 5613, "Episode Step": 299}
{"Training time": 20.509389667775896, "Episode Reward": 15194.529015968536, "Mean Reward": 60.778116063874144, "Episode": 5614, "Episode Step": 250}
{"Training time": 20.510608236657248, "Episode Reward": -1057.8624759249326, "Mean Reward": -10.371200744362085, "Episode": 5615, "Episode Step": 102}
{"Training time": 20.513204579949377, "Episode Reward": 8560.280470952854, "Mean Reward": 46.271786329474885, "Episode": 5616, "Episode Step": 185}
{"Training time": 20.515655342472925, "Episode Reward": 10163.055703600778, "Mean Reward": 47.938941998116874, "Episode": 5617, "Episode Step": 212}
{"Training time": 20.516883641613855, "Episode Reward": -862.410649487318, "Mean Reward": -8.455006367522726, "Episode": 5618, "Episode Step": 102}
{"Training time": 20.520780058304467, "Episode Reward": 15563.20256196653, "Mean Reward": 52.75661885412383, "Episode": 5619, "Episode Step": 295}
{"Training time": 20.523721334139506, "Episode Reward": 15393.045354780359, "Mean Reward": 61.083513312620475, "Episode": 5620, "Episode Step": 252}
{"Training time": 20.52492208328512, "Episode Reward": -865.4567078149742, "Mean Reward": -8.48486968446053, "Episode": 5621, "Episode Step": 102}
{"Training time": 20.526983662777475, "Episode Reward": 6239.718951409838, "Mean Reward": 44.89006439863193, "Episode": 5622, "Episode Step": 139}
{"Training time": 20.546202839944097, "Episode Reward": 105800.41007750567, "Mean Reward": 63.429502444547765, "Episode": 5623, "Episode Step": 1668}
{"Training time": 20.547385776638986, "Episode Reward": -1073.5830514107165, "Mean Reward": -10.525324033438396, "Episode": 5624, "Episode Step": 102}
{"Training time": 20.549939425256518, "Episode Reward": 7687.317321052605, "Mean Reward": 42.70731845029225, "Episode": 5625, "Episode Step": 180}
{"Training time": 20.598002831935883, "Episode Reward": 266316.9262036494, "Mean Reward": 64.3433018129136, "Episode": 5626, "Episode Step": 4139}
{"Training time": 20.599220326344174, "Episode Reward": -831.0007937530565, "Mean Reward": -8.147066605422124, "Episode": 5627, "Episode Step": 102}
{"Training time": 20.602702513602043, "Episode Reward": 16265.649990663409, "Mean Reward": 63.045155002571356, "Episode": 5628, "Episode Step": 258}
{"Training time": 20.60395465195179, "Episode Reward": 5120.07701073352, "Mean Reward": 49.23150971859154, "Episode": 5629, "Episode Step": 104}
{"Training time": 20.605160932474668, "Episode Reward": -954.6160212970585, "Mean Reward": -9.358980600951554, "Episode": 5630, "Episode Step": 102}
{"Training time": 20.608560237752066, "Episode Reward": 15666.993434681188, "Mean Reward": 62.17060886778249, "Episode": 5631, "Episode Step": 252}
{"Training time": 20.611975416673555, "Episode Reward": 19177.927322393596, "Mean Reward": 65.45367686823752, "Episode": 5632, "Episode Step": 293}
{"Training time": 20.613190595242713, "Episode Reward": -1052.6328274465773, "Mean Reward": -10.319929680848796, "Episode": 5633, "Episode Step": 102}
{"Training time": 20.617126239670647, "Episode Reward": 18305.233874020076, "Mean Reward": 61.8420063311489, "Episode": 5634, "Episode Step": 296}
{"Training time": 20.622749461068047, "Episode Reward": 29405.19753319748, "Mean Reward": 60.6292732643247, "Episode": 5635, "Episode Step": 485}
{"Training time": 20.623986216055023, "Episode Reward": -816.3187120983434, "Mean Reward": -8.003124628415131, "Episode": 5636, "Episode Step": 102}
{"Training time": 20.631165656646093, "Episode Reward": 33838.68282629879, "Mean Reward": 59.0552928905738, "Episode": 5637, "Episode Step": 573}
{"Training time": 20.63670898192459, "Episode Reward": 28289.38004906892, "Mean Reward": 59.93512722260365, "Episode": 5638, "Episode Step": 472}
{"Training time": 20.63792852110333, "Episode Reward": -884.309576131566, "Mean Reward": -8.669701726780058, "Episode": 5639, "Episode Step": 102}
{"Training time": 20.640040431353782, "Episode Reward": 5658.43226012408, "Mean Reward": 41.00313231973971, "Episode": 5640, "Episode Step": 138}
{"Training time": 20.64563547803296, "Episode Reward": 29981.140988156578, "Mean Reward": 62.33085444523197, "Episode": 5641, "Episode Step": 481}
{"Training time": 20.6468310379982, "Episode Reward": -949.3525457005726, "Mean Reward": -9.307377899025221, "Episode": 5642, "Episode Step": 102}
{"Training time": 20.65086745666133, "Episode Reward": 17836.845607288713, "Mean Reward": 59.062402673141435, "Episode": 5643, "Episode Step": 302}
{"Training time": 20.657560441891352, "Episode Reward": 32348.63554618373, "Mean Reward": 56.45486133714438, "Episode": 5644, "Episode Step": 573}
{"Training time": 20.658783742454318, "Episode Reward": -1077.2049636029328, "Mean Reward": -10.560832976499341, "Episode": 5645, "Episode Step": 102}
{"Training time": 20.66077203578419, "Episode Reward": 6009.291335653692, "Mean Reward": 45.52493436101282, "Episode": 5646, "Episode Step": 132}
{"Training time": 20.662843641638755, "Episode Reward": 8250.95945018091, "Mean Reward": 46.88045142148244, "Episode": 5647, "Episode Step": 176}
{"Training time": 20.66404342300362, "Episode Reward": -984.2214902669224, "Mean Reward": -9.649230296734533, "Episode": 5648, "Episode Step": 102}
{"Training time": 20.667200378312003, "Episode Reward": 6083.793445501093, "Mean Reward": 44.407251427015275, "Episode": 5649, "Episode Step": 137}
{"Training time": 20.6688945202695, "Episode Reward": 6500.438387002115, "Mean Reward": 53.28228186067307, "Episode": 5650, "Episode Step": 122}
{"Training time": 20.670082720253202, "Episode Reward": -1025.7573465432158, "Mean Reward": -10.056444573953096, "Episode": 5651, "Episode Step": 102}
{"Training time": 20.672651473879814, "Episode Reward": 8297.798962450328, "Mean Reward": 46.61684810365353, "Episode": 5652, "Episode Step": 178}
{"Training time": 20.678167765802808, "Episode Reward": 29872.042689265967, "Mean Reward": 62.756392204340266, "Episode": 5653, "Episode Step": 476}
{"Training time": 20.679354731374318, "Episode Reward": -979.7179927938282, "Mean Reward": -9.605078360723805, "Episode": 5654, "Episode Step": 102}
{"Training time": 20.683261401388382, "Episode Reward": 16610.5057334991, "Mean Reward": 56.116573423983446, "Episode": 5655, "Episode Step": 296}
{"Training time": 20.704233717719713, "Episode Reward": 112819.68811371565, "Mean Reward": 62.1253789172443, "Episode": 5656, "Episode Step": 1816}
{"Training time": 20.70545527107186, "Episode Reward": -957.0777524828165, "Mean Reward": -9.38311522041977, "Episode": 5657, "Episode Step": 102}
{"Training time": 20.70756044778559, "Episode Reward": 5161.558790884135, "Mean Reward": 37.40259993394301, "Episode": 5658, "Episode Step": 138}
{"Training time": 20.709190647469626, "Episode Reward": 5883.859051955704, "Mean Reward": 42.947876291647475, "Episode": 5659, "Episode Step": 137}
{"Training time": 20.710405070251888, "Episode Reward": -1040.2122872872612, "Mean Reward": -10.198159679286874, "Episode": 5660, "Episode Step": 102}
{"Training time": 20.712458357214928, "Episode Reward": 5428.170205069334, "Mean Reward": 39.9130162137451, "Episode": 5661, "Episode Step": 136}
{"Training time": 20.71402515583568, "Episode Reward": 6085.930282897419, "Mean Reward": 45.75887430749939, "Episode": 5662, "Episode Step": 133}
{"Training time": 20.715267567767036, "Episode Reward": -850.3938389991148, "Mean Reward": -8.337194499991321, "Episode": 5663, "Episode Step": 102}
{"Training time": 20.71734892944495, "Episode Reward": 6239.801400058754, "Mean Reward": 46.5656820899907, "Episode": 5664, "Episode Step": 134}
{"Training time": 20.720016472736994, "Episode Reward": 12315.423693149576, "Mean Reward": 54.979570058703466, "Episode": 5665, "Episode Step": 224}
{"Training time": 20.721231499976582, "Episode Reward": -909.1618660718711, "Mean Reward": -8.9133516281556, "Episode": 5666, "Episode Step": 102}
{"Training time": 20.72590285917123, "Episode Reward": 18540.49307298166, "Mean Reward": 51.789086796038156, "Episode": 5667, "Episode Step": 358}
{"Training time": 20.728008829686377, "Episode Reward": 8775.404318455525, "Mean Reward": 49.02460513103645, "Episode": 5668, "Episode Step": 179}
{"Training time": 20.729231329427826, "Episode Reward": -730.8531527072467, "Mean Reward": -7.165226987325949, "Episode": 5669, "Episode Step": 102}
{"Training time": 20.74593278944492, "Episode Reward": 83408.05105481784, "Mean Reward": 60.97079755469141, "Episode": 5670, "Episode Step": 1368}
{"Training time": 20.76485798411899, "Episode Reward": 103450.16161759535, "Mean Reward": 64.41479552776796, "Episode": 5671, "Episode Step": 1606}
{"Training time": 20.766069193283716, "Episode Reward": -867.3098588961279, "Mean Reward": -8.50303783231498, "Episode": 5672, "Episode Step": 102}
{"Training time": 20.772050399714047, "Episode Reward": 28521.396087647707, "Mean Reward": 61.46852605096488, "Episode": 5673, "Episode Step": 464}
{"Training time": 20.78395146277216, "Episode Reward": 62821.655382562334, "Mean Reward": 62.44697354131445, "Episode": 5674, "Episode Step": 1006}
{"Training time": 20.78517540971438, "Episode Reward": -914.5798340283898, "Mean Reward": -8.966468961062645, "Episode": 5675, "Episode Step": 102}
{"Training time": 20.790771407485007, "Episode Reward": 25632.063656218408, "Mean Reward": 58.52069327903746, "Episode": 5676, "Episode Step": 438}
{"Training time": 20.796897496382396, "Episode Reward": 34429.29855196331, "Mean Reward": 66.08310662564934, "Episode": 5677, "Episode Step": 521}
{"Training time": 20.79810139271948, "Episode Reward": -842.7341088972761, "Mean Reward": -8.26209910683604, "Episode": 5678, "Episode Step": 102}
{"Training time": 20.804029727776847, "Episode Reward": 27135.409427892977, "Mean Reward": 58.60779574058958, "Episode": 5679, "Episode Step": 463}
{"Training time": 20.821022203564645, "Episode Reward": 91174.64039058196, "Mean Reward": 62.57696663732461, "Episode": 5680, "Episode Step": 1457}
{"Training time": 20.822238121893673, "Episode Reward": -858.3825943860327, "Mean Reward": -8.415515631235614, "Episode": 5681, "Episode Step": 102}
{"Training time": 20.826803011099496, "Episode Reward": 21506.510431258746, "Mean Reward": 61.978416228411376, "Episode": 5682, "Episode Step": 347}
{"Training time": 20.830946323606703, "Episode Reward": 20910.51820634685, "Mean Reward": 59.91552494655258, "Episode": 5683, "Episode Step": 349}
{"Training time": 20.832139308055243, "Episode Reward": -778.8078637740575, "Mean Reward": -7.635371213471152, "Episode": 5684, "Episode Step": 102}
{"Training time": 20.834067308306693, "Episode Reward": 5738.07364860997, "Mean Reward": 45.90458918887976, "Episode": 5685, "Episode Step": 125}
{"Training time": 20.849379944668875, "Episode Reward": 85598.90088838154, "Mean Reward": 64.94605530226217, "Episode": 5686, "Episode Step": 1318}
{"Training time": 20.85060152053833, "Episode Reward": -783.5667155889686, "Mean Reward": -7.682026623421261, "Episode": 5687, "Episode Step": 102}
{"Training time": 20.864745798574553, "Episode Reward": 72789.55358410403, "Mean Reward": 61.58168661937735, "Episode": 5688, "Episode Step": 1182}
{"Training time": 20.87022313442495, "Episode Reward": 31100.266747202575, "Mean Reward": 65.75109248880037, "Episode": 5689, "Episode Step": 473}
{"Training time": 20.8714214605093, "Episode Reward": -1017.289594799732, "Mean Reward": -9.973427399997371, "Episode": 5690, "Episode Step": 102}
{"Training time": 20.879096883601612, "Episode Reward": 37272.86214159643, "Mean Reward": 59.732150867943, "Episode": 5691, "Episode Step": 624}
{"Training time": 20.882539621392887, "Episode Reward": 19832.955877728426, "Mean Reward": 67.45903359771573, "Episode": 5692, "Episode Step": 294}
{"Training time": 20.88373778111405, "Episode Reward": -768.7329738149153, "Mean Reward": -7.53659778249917, "Episode": 5693, "Episode Step": 102}
{"Training time": 20.886326273878414, "Episode Reward": 8029.007113839473, "Mean Reward": 44.85478834547192, "Episode": 5694, "Episode Step": 179}
{"Training time": 20.889174293014737, "Episode Reward": 15472.892536245785, "Mean Reward": 63.1546634132481, "Episode": 5695, "Episode Step": 245}
{"Training time": 20.89037257273992, "Episode Reward": -937.7912452169662, "Mean Reward": -9.19403181585261, "Episode": 5696, "Episode Step": 102}
{"Training time": 20.89570915579796, "Episode Reward": 23899.31429837747, "Mean Reward": 56.90312928185112, "Episode": 5697, "Episode Step": 420}
{"Training time": 20.89862644467089, "Episode Reward": 16995.456247383667, "Mean Reward": 67.71098106527357, "Episode": 5698, "Episode Step": 251}
{"Training time": 20.900911741654078, "Episode Reward": -783.5600580950058, "Mean Reward": -7.681961353872606, "Episode": 5699, "Episode Step": 102}
{"Training time": 20.919801036053233, "Episode Reward": 102381.72358893583, "Mean Reward": 64.35054908166929, "Episode": 5700, "Episode Step": 1591}
{"Training time": 20.94035261498557, "Episode Reward": 115941.3219235039, "Mean Reward": 65.20884247666136, "Episode": 5701, "Episode Step": 1778}
{"Training time": 20.941537950237592, "Episode Reward": -1131.8646325324755, "Mean Reward": -11.09671208365172, "Episode": 5702, "Episode Step": 102}
{"Training time": 20.9476898460918, "Episode Reward": 31239.126939389364, "Mean Reward": 63.36536904541453, "Episode": 5703, "Episode Step": 493}
{"Training time": 21.002328729165924, "Episode Reward": 316626.4291768723, "Mean Reward": 67.49657411572635, "Episode": 5704, "Episode Step": 4691}
{"Training time": 21.003529040283627, "Episode Reward": -1079.9619154048055, "Mean Reward": -10.587861915733388, "Episode": 5705, "Episode Step": 102}
{"Training time": 21.008739851382042, "Episode Reward": 24262.94934137512, "Mean Reward": 59.760958968904234, "Episode": 5706, "Episode Step": 406}
{"Training time": 21.045128600531154, "Episode Reward": 209992.63274930723, "Mean Reward": 66.72787821712971, "Episode": 5707, "Episode Step": 3147}
{"Training time": 21.04632595969571, "Episode Reward": -916.4815567895918, "Mean Reward": -8.985113301858743, "Episode": 5708, "Episode Step": 102}
{"Training time": 21.05740769022041, "Episode Reward": 60956.82157807059, "Mean Reward": 65.97058612345302, "Episode": 5709, "Episode Step": 924}
{"Training time": 21.060058388312658, "Episode Reward": 13578.864250183113, "Mean Reward": 59.818785243097416, "Episode": 5710, "Episode Step": 227}
{"Training time": 21.061254141661855, "Episode Reward": -1037.4089134187172, "Mean Reward": -10.17067562175213, "Episode": 5711, "Episode Step": 102}
{"Training time": 21.06728849305047, "Episode Reward": 30808.024672792704, "Mean Reward": 63.784730171413464, "Episode": 5712, "Episode Step": 483}
{"Training time": 21.084875491658845, "Episode Reward": 95894.94391351743, "Mean Reward": 63.21354246111894, "Episode": 5713, "Episode Step": 1517}
{"Training time": 21.08607865691185, "Episode Reward": -954.7598972730962, "Mean Reward": -9.360391149736238, "Episode": 5714, "Episode Step": 102}
{"Training time": 21.08866005665726, "Episode Reward": 8746.293702009425, "Mean Reward": 49.13648147196306, "Episode": 5715, "Episode Step": 178}
{"Training time": 21.094176446331872, "Episode Reward": 30653.939561078976, "Mean Reward": 65.0826742273439, "Episode": 5716, "Episode Step": 471}
{"Training time": 21.095380604399576, "Episode Reward": -783.0303646131822, "Mean Reward": -7.676768280521394, "Episode": 5717, "Episode Step": 102}
{"Training time": 21.108266166117456, "Episode Reward": 67637.50985543514, "Mean Reward": 62.74351563583965, "Episode": 5718, "Episode Step": 1078}
{"Training time": 21.165794579717847, "Episode Reward": 332351.9286896825, "Mean Reward": 66.4703857379365, "Episode": 5719, "Episode Step": 5000}
{"Training time": 21.167277786069445, "Episode Reward": -1118.0503046031413, "Mean Reward": -10.961277496109227, "Episode": 5720, "Episode Step": 102}
{"Training time": 21.16978486445215, "Episode Reward": 8857.739449053528, "Mean Reward": 49.76258117445802, "Episode": 5721, "Episode Step": 178}
{"Training time": 21.20116709775395, "Episode Reward": 183277.05044252437, "Mean Reward": 67.2576331899172, "Episode": 5722, "Episode Step": 2725}
{"Training time": 21.202382668322986, "Episode Reward": -1124.7613253258435, "Mean Reward": -11.027071816920033, "Episode": 5723, "Episode Step": 102}
{"Training time": 21.204889780547884, "Episode Reward": 8838.140333645486, "Mean Reward": 50.50365904940278, "Episode": 5724, "Episode Step": 175}
{"Training time": 21.206337885525492, "Episode Reward": 6645.61571300282, "Mean Reward": 53.16492570402256, "Episode": 5725, "Episode Step": 125}
{"Training time": 21.207584859993723, "Episode Reward": -925.0166135765894, "Mean Reward": -9.06879032918225, "Episode": 5726, "Episode Step": 102}
{"Training time": 21.232098641660478, "Episode Reward": 127979.46540542072, "Mean Reward": 63.86200868533968, "Episode": 5727, "Episode Step": 2004}
{"Training time": 21.23620869775613, "Episode Reward": 21526.57335069519, "Mean Reward": 62.03623444004378, "Episode": 5728, "Episode Step": 347}
{"Training time": 21.237421314451428, "Episode Reward": -948.6207669528039, "Mean Reward": -9.300203597576509, "Episode": 5729, "Episode Step": 102}
{"Training time": 21.24342297050688, "Episode Reward": 30491.649356639697, "Mean Reward": 64.73810903745158, "Episode": 5730, "Episode Step": 471}
{"Training time": 21.247622290253638, "Episode Reward": 22053.362284212515, "Mean Reward": 62.122147279471875, "Episode": 5731, "Episode Step": 355}
{"Training time": 21.24887433886528, "Episode Reward": -1051.5516816965358, "Mean Reward": -10.309330212711135, "Episode": 5732, "Episode Step": 102}
{"Training time": 21.25227999077903, "Episode Reward": 16748.699760768628, "Mean Reward": 66.99479904307451, "Episode": 5733, "Episode Step": 250}
{"Training time": 21.253688141372468, "Episode Reward": 6805.379778827058, "Mean Reward": 56.71149815689215, "Episode": 5734, "Episode Step": 120}
{"Training time": 21.25494905915525, "Episode Reward": -1165.9419712814556, "Mean Reward": -11.43080364001427, "Episode": 5735, "Episode Step": 102}
{"Training time": 21.25755312581857, "Episode Reward": 8873.632268750061, "Mean Reward": 49.85186667837113, "Episode": 5736, "Episode Step": 178}
{"Training time": 21.262459658583005, "Episode Reward": 26197.20219109325, "Mean Reward": 62.823026837154075, "Episode": 5737, "Episode Step": 417}
{"Training time": 21.26369842330615, "Episode Reward": -1119.9802740747155, "Mean Reward": -10.980198765438386, "Episode": 5738, "Episode Step": 102}
{"Training time": 21.26630920774407, "Episode Reward": 9028.360494136854, "Mean Reward": 50.1575583007603, "Episode": 5739, "Episode Step": 180}
{"Training time": 21.27639590528276, "Episode Reward": 57442.56934841765, "Mean Reward": 67.10580531357202, "Episode": 5740, "Episode Step": 856}
{"Training time": 21.277604733837975, "Episode Reward": -892.0570613211129, "Mean Reward": -8.74565746393248, "Episode": 5741, "Episode Step": 102}
{"Training time": 21.28899132523272, "Episode Reward": 58249.983389861525, "Mean Reward": 62.70181204506085, "Episode": 5742, "Episode Step": 929}
{"Training time": 21.295684088865915, "Episode Reward": 35899.472376919926, "Mean Reward": 63.65154676758852, "Episode": 5743, "Episode Step": 564}
{"Training time": 21.296906266609827, "Episode Reward": -612.2451392010697, "Mean Reward": -6.0024033255006835, "Episode": 5744, "Episode Step": 102}
{"Training time": 21.310095516112117, "Episode Reward": 69584.68588114121, "Mean Reward": 64.0742963914744, "Episode": 5745, "Episode Step": 1086}
{"Training time": 21.318382371664047, "Episode Reward": 47478.425374438564, "Mean Reward": 68.02066672555668, "Episode": 5746, "Episode Step": 698}
{"Training time": 21.3213815844059, "Episode Reward": 15563.077532883543, "Mean Reward": 62.00429295969539, "Episode": 5747, "Episode Step": 251}
{"Training time": 21.323946919971043, "Episode Reward": 8994.10420979517, "Mean Reward": 50.24639223349257, "Episode": 5748, "Episode Step": 179}
{"Training time": 21.329087506333988, "Episode Reward": 22422.628915926573, "Mean Reward": 64.61852713523508, "Episode": 5749, "Episode Step": 347}
{"Training time": 21.33256559550762, "Episode Reward": 14790.323895128991, "Mean Reward": 54.982616710516695, "Episode": 5750, "Episode Step": 269}
{"Training time": 21.33592803246445, "Episode Reward": 15508.411986566894, "Mean Reward": 63.55906551871678, "Episode": 5751, "Episode Step": 244}
{"Training time": 21.33653859078884, "Episode Reward": 2483.131277326596, "Mean Reward": 49.66262554653192, "Episode": 5752, "Episode Step": 50}
{"Training time": 21.337238561643495, "Episode Reward": 2312.4552257907285, "Mean Reward": 39.869917686047046, "Episode": 5753, "Episode Step": 58}
{"Training time": 21.34962002416452, "Episode Reward": 66590.01971724835, "Mean Reward": 64.96587289487644, "Episode": 5754, "Episode Step": 1025}
{"Training time": 21.3537922605541, "Episode Reward": 22788.239281741156, "Mean Reward": 65.48344621189987, "Episode": 5755, "Episode Step": 348}
{"Training time": 21.35541422916783, "Episode Reward": 5558.421505738973, "Mean Reward": 40.87074636572774, "Episode": 5756, "Episode Step": 136}
{"Training time": 21.358058562477428, "Episode Reward": 9172.04878816811, "Mean Reward": 49.84809124004407, "Episode": 5757, "Episode Step": 184}
{"Training time": 21.358671646912892, "Episode Reward": 2183.5383388140394, "Mean Reward": 44.56200691457224, "Episode": 5758, "Episode Step": 49}
{"Training time": 21.360347723894648, "Episode Reward": 5625.7846769526, "Mean Reward": 39.89918210604681, "Episode": 5759, "Episode Step": 141}
{"Training time": 21.362925412721104, "Episode Reward": 8596.316552975375, "Mean Reward": 48.56676018630156, "Episode": 5760, "Episode Step": 177}
{"Training time": 21.372987878057693, "Episode Reward": 55890.91677465148, "Mean Reward": 64.98943811005987, "Episode": 5761, "Episode Step": 860}
{"Training time": 21.374738075534502, "Episode Reward": 5593.999034217666, "Mean Reward": 37.046351219984544, "Episode": 5762, "Episode Step": 151}
{"Training time": 21.37738757133484, "Episode Reward": 9598.92225406416, "Mean Reward": 51.60710889281807, "Episode": 5763, "Episode Step": 186}
{"Training time": 21.380399795505735, "Episode Reward": 16296.445867846716, "Mean Reward": 63.16451886762293, "Episode": 5764, "Episode Step": 258}
{"Training time": 21.3876020430194, "Episode Reward": 34096.21938431214, "Mean Reward": 54.641377218448945, "Episode": 5765, "Episode Step": 624}
{"Training time": 21.403372403052117, "Episode Reward": 88991.07656532215, "Mean Reward": 67.16307665307332, "Episode": 5766, "Episode Step": 1325}
{"Training time": 21.4081206013759, "Episode Reward": 26999.830480421206, "Mean Reward": 65.53356912723594, "Episode": 5767, "Episode Step": 412}
{"Training time": 21.416677978568607, "Episode Reward": 44399.03599275913, "Mean Reward": 60.16129538314245, "Episode": 5768, "Episode Step": 738}
{"Training time": 21.424454193843737, "Episode Reward": 40194.6324821195, "Mean Reward": 63.39847394656073, "Episode": 5769, "Episode Step": 634}
{"Training time": 21.425037818021245, "Episode Reward": 2601.7762595627146, "Mean Reward": 54.20367207422322, "Episode": 5770, "Episode Step": 48}
{"Training time": 21.433454317185614, "Episode Reward": 42107.423332423765, "Mean Reward": 57.83986721486781, "Episode": 5771, "Episode Step": 728}
{"Training time": 21.439877845512495, "Episode Reward": 33685.23187024482, "Mean Reward": 65.92021892415815, "Episode": 5772, "Episode Step": 511}
{"Training time": 21.445570435788895, "Episode Reward": 33743.3323993832, "Mean Reward": 68.72369124110632, "Episode": 5773, "Episode Step": 491}
{"Training time": 21.447222540246116, "Episode Reward": 6052.936978664749, "Mean Reward": 42.03428457406076, "Episode": 5774, "Episode Step": 144}
{"Training time": 21.469169023566774, "Episode Reward": 120489.93252104957, "Mean Reward": 65.16491753436969, "Episode": 5775, "Episode Step": 1849}
{"Training time": 21.469754399723477, "Episode Reward": 2585.5231377216724, "Mean Reward": 52.76577832085046, "Episode": 5776, "Episode Step": 49}
{"Training time": 21.472967227167555, "Episode Reward": 13768.451776485184, "Mean Reward": 49.88569484233763, "Episode": 5777, "Episode Step": 276}
{"Training time": 21.480642154680357, "Episode Reward": 39594.67683146554, "Mean Reward": 63.65703670653624, "Episode": 5778, "Episode Step": 622}
{"Training time": 21.484657646086482, "Episode Reward": 22408.212061097907, "Mean Reward": 64.39141396867215, "Episode": 5779, "Episode Step": 348}
{"Training time": 21.486384892198775, "Episode Reward": 6441.850311872813, "Mean Reward": 42.66126034352856, "Episode": 5780, "Episode Step": 151}
{"Training time": 21.507259512742362, "Episode Reward": 117706.18779931974, "Mean Reward": 66.500671073062, "Episode": 5781, "Episode Step": 1770}
{"Training time": 21.518202936384412, "Episode Reward": 62477.79991935041, "Mean Reward": 66.18411008405764, "Episode": 5782, "Episode Step": 944}
{"Training time": 21.521249662505255, "Episode Reward": 14766.554966751539, "Mean Reward": 56.1465968317549, "Episode": 5783, "Episode Step": 263}
{"Training time": 21.56058535443412, "Episode Reward": 229003.97042968855, "Mean Reward": 68.07490203022846, "Episode": 5784, "Episode Step": 3364}
{"Training time": 21.561158684690792, "Episode Reward": 2637.071127762409, "Mean Reward": 56.107896335370405, "Episode": 5785, "Episode Step": 47}
{"Training time": 21.564051181938915, "Episode Reward": 14300.466265522022, "Mean Reward": 57.89662455676932, "Episode": 5786, "Episode Step": 247}
{"Training time": 21.56607522189617, "Episode Reward": 6943.226455019993, "Mean Reward": 51.05313569867642, "Episode": 5787, "Episode Step": 136}
{"Training time": 21.566641379992166, "Episode Reward": 2702.893922866517, "Mean Reward": 57.50838133758547, "Episode": 5788, "Episode Step": 47}
{"Training time": 21.567984772721925, "Episode Reward": 5469.292415761867, "Mean Reward": 47.5590644848858, "Episode": 5789, "Episode Step": 115}
{"Training time": 21.577121565540633, "Episode Reward": 50455.18293249123, "Mean Reward": 68.64650739114454, "Episode": 5790, "Episode Step": 735}
{"Training time": 21.580536270274056, "Episode Reward": 19540.594257727444, "Mean Reward": 66.46460631880083, "Episode": 5791, "Episode Step": 294}
{"Training time": 21.583590471347172, "Episode Reward": 13454.166462691062, "Mean Reward": 51.746794087273315, "Episode": 5792, "Episode Step": 260}
{"Training time": 21.58559485303031, "Episode Reward": 6975.542077811974, "Mean Reward": 52.845015740999806, "Episode": 5793, "Episode Step": 132}
{"Training time": 21.586185382207233, "Episode Reward": 2657.216358612692, "Mean Reward": 54.22890527781004, "Episode": 5794, "Episode Step": 49}
{"Training time": 21.58772789246506, "Episode Reward": 4555.719537715604, "Mean Reward": 35.043996443966186, "Episode": 5795, "Episode Step": 130}
{"Training time": 21.59433153000143, "Episode Reward": 36045.143845618666, "Mean Reward": 68.78844245347074, "Episode": 5796, "Episode Step": 524}
{"Training time": 21.600125758051874, "Episode Reward": 31256.490624182232, "Mean Reward": 64.05018570529145, "Episode": 5797, "Episode Step": 488}
{"Training time": 21.601799859139653, "Episode Reward": 5610.861502120295, "Mean Reward": 40.36591008719637, "Episode": 5798, "Episode Step": 139}
{"Training time": 21.604948101904657, "Episode Reward": 7050.9328027299625, "Mean Reward": 52.61890151291017, "Episode": 5799, "Episode Step": 134}
{"Training time": 21.60579071799914, "Episode Reward": 2485.2516179124596, "Mean Reward": 54.02720908505347, "Episode": 5800, "Episode Step": 46}
{"Training time": 21.60719226161639, "Episode Reward": 4880.682542050746, "Mean Reward": 41.36171645805717, "Episode": 5801, "Episode Step": 118}
{"Training time": 21.61034286134773, "Episode Reward": 14631.475029383044, "Mean Reward": 63.89290405844124, "Episode": 5802, "Episode Step": 229}
{"Training time": 21.610922226376005, "Episode Reward": 1984.1294927008703, "Mean Reward": 41.3360310979348, "Episode": 5803, "Episode Step": 48}
{"Training time": 21.61305241498682, "Episode Reward": 6019.791329909256, "Mean Reward": 33.258515634857766, "Episode": 5804, "Episode Step": 181}
{"Training time": 21.61695137222608, "Episode Reward": 18905.791292136593, "Mean Reward": 64.5248849560976, "Episode": 5805, "Episode Step": 293}
{"Training time": 21.617504155238468, "Episode Reward": 2259.4949188057776, "Mean Reward": 50.21099819568395, "Episode": 5806, "Episode Step": 45}
{"Training time": 21.618844594690536, "Episode Reward": 4968.498948769775, "Mean Reward": 43.58332411201557, "Episode": 5807, "Episode Step": 114}
{"Training time": 21.620903649992414, "Episode Reward": 7184.2456900829975, "Mean Reward": 52.43974956264962, "Episode": 5808, "Episode Step": 137}
{"Training time": 21.621493383314874, "Episode Reward": 2541.6360972074103, "Mean Reward": 52.95075202515438, "Episode": 5809, "Episode Step": 48}
{"Training time": 21.62891473359532, "Episode Reward": 33834.16758669779, "Mean Reward": 54.04819103306356, "Episode": 5810, "Episode Step": 626}
{"Training time": 21.636212695505883, "Episode Reward": 36729.68490945116, "Mean Reward": 63.001174801803025, "Episode": 5811, "Episode Step": 583}
{"Training time": 21.636788782477378, "Episode Reward": 2676.1194577608903, "Mean Reward": 56.938711867252984, "Episode": 5812, "Episode Step": 47}
{"Training time": 21.643995990819402, "Episode Reward": 32084.572916262827, "Mean Reward": 52.511575967696935, "Episode": 5813, "Episode Step": 611}
{"Training time": 21.64867277801037, "Episode Reward": 23160.17937890538, "Mean Reward": 63.97839607432426, "Episode": 5814, "Episode Step": 362}
{"Training time": 21.649265485538375, "Episode Reward": 2671.148039899291, "Mean Reward": 53.422960797985816, "Episode": 5815, "Episode Step": 50}
{"Training time": 21.653035698864194, "Episode Reward": 18425.926684209782, "Mean Reward": 57.04621264461233, "Episode": 5816, "Episode Step": 323}
{"Training time": 21.65774167385366, "Episode Reward": 22761.982026923168, "Mean Reward": 63.93815176102014, "Episode": 5817, "Episode Step": 356}
{"Training time": 21.65898133635521, "Episode Reward": 5673.102320157073, "Mean Reward": 55.618650197618365, "Episode": 5818, "Episode Step": 102}
{"Training time": 21.660216472744942, "Episode Reward": 4666.963265853928, "Mean Reward": 44.874646787056996, "Episode": 5819, "Episode Step": 104}
{"Training time": 21.66229171468152, "Episode Reward": 6775.307358384756, "Mean Reward": 49.096430133222874, "Episode": 5820, "Episode Step": 138}
{"Training time": 21.662850567499795, "Episode Reward": 2617.9193584278073, "Mean Reward": 55.70041188144271, "Episode": 5821, "Episode Step": 47}
{"Training time": 21.664509741067885, "Episode Reward": 5602.923829686723, "Mean Reward": 39.45721006821636, "Episode": 5822, "Episode Step": 142}
{"Training time": 21.66624833583832, "Episode Reward": 5759.018266699279, "Mean Reward": 52.35471151544799, "Episode": 5823, "Episode Step": 110}
{"Training time": 21.666809917489687, "Episode Reward": 2420.4617533093924, "Mean Reward": 51.49918624062537, "Episode": 5824, "Episode Step": 47}
{"Training time": 21.668040115833282, "Episode Reward": 4468.122553844814, "Mean Reward": 42.962716863892446, "Episode": 5825, "Episode Step": 104}
{"Training time": 21.672739695244367, "Episode Reward": 23298.53905200353, "Mean Reward": 66.1890313977373, "Episode": 5826, "Episode Step": 352}
{"Training time": 21.67332031607628, "Episode Reward": 2413.8962622911095, "Mean Reward": 51.35949494236403, "Episode": 5827, "Episode Step": 47}
{"Training time": 21.674617014394865, "Episode Reward": 4206.237355912262, "Mean Reward": 39.68148448973832, "Episode": 5828, "Episode Step": 106}
{"Training time": 21.679246992998653, "Episode Reward": 22947.23390636389, "Mean Reward": 64.6400955108842, "Episode": 5829, "Episode Step": 355}
{"Training time": 21.67983825749821, "Episode Reward": 2673.9212882336246, "Mean Reward": 55.70669350486718, "Episode": 5830, "Episode Step": 48}
{"Training time": 21.689485295547378, "Episode Reward": 44862.161300754095, "Mean Reward": 54.4443705106239, "Episode": 5831, "Episode Step": 824}
{"Training time": 21.728722413844533, "Episode Reward": 230907.2591824162, "Mean Reward": 69.46668447124435, "Episode": 5832, "Episode Step": 3324}
{"Training time": 21.729273047778342, "Episode Reward": 2562.242469233076, "Mean Reward": 55.700923244197305, "Episode": 5833, "Episode Step": 46}
{"Training time": 21.73226829720868, "Episode Reward": 13589.96699925736, "Mean Reward": 53.5038070836904, "Episode": 5834, "Episode Step": 254}
{"Training time": 21.75592694805728, "Episode Reward": 129249.74014968786, "Mean Reward": 65.67568097036985, "Episode": 5835, "Episode Step": 1968}
{"Training time": 21.757133627997504, "Episode Reward": 5683.745805185, "Mean Reward": 55.72299809004902, "Episode": 5836, "Episode Step": 102}
{"Training time": 21.760537672506437, "Episode Reward": 15377.661142449935, "Mean Reward": 53.02641773258598, "Episode": 5837, "Episode Step": 290}
{"Training time": 21.768868733313347, "Episode Reward": 45208.59044951737, "Mean Reward": 66.77782931981886, "Episode": 5838, "Episode Step": 677}
{"Training time": 21.774960742195447, "Episode Reward": 33789.60648545967, "Mean Reward": 64.23879559973321, "Episode": 5839, "Episode Step": 526}
{"Training time": 21.776835088862313, "Episode Reward": 5885.791906810119, "Mean Reward": 36.55771370689515, "Episode": 5840, "Episode Step": 161}
{"Training time": 21.7800064113405, "Episode Reward": 14136.43299028862, "Mean Reward": 61.19667961163905, "Episode": 5841, "Episode Step": 231}
{"Training time": 21.783467771344714, "Episode Reward": 19719.213260845965, "Mean Reward": 66.17185658002002, "Episode": 5842, "Episode Step": 298}
{"Training time": 21.786661778291066, "Episode Reward": 13456.870438540333, "Mean Reward": 48.93407432196484, "Episode": 5843, "Episode Step": 275}
{"Training time": 21.789220590790112, "Episode Reward": 9415.409300145071, "Mean Reward": 52.60005195611772, "Episode": 5844, "Episode Step": 179}
{"Training time": 21.79220543689198, "Episode Reward": 17832.266883498214, "Mean Reward": 69.3862524649736, "Episode": 5845, "Episode Step": 257}
{"Training time": 21.79340636829535, "Episode Reward": 4462.40792474857, "Mean Reward": 44.18225668067891, "Episode": 5846, "Episode Step": 101}
{"Training time": 21.82720263388422, "Episode Reward": 195088.64780538846, "Mean Reward": 68.04626711035523, "Episode": 5847, "Episode Step": 2867}
{"Training time": 21.828531220224168, "Episode Reward": 5750.798529278552, "Mean Reward": 52.27998662980502, "Episode": 5848, "Episode Step": 110}
{"Training time": 21.8309184091621, "Episode Reward": 4576.260155743606, "Mean Reward": 44.00250149753468, "Episode": 5849, "Episode Step": 104}
{"Training time": 21.835518588556184, "Episode Reward": 23342.17289766494, "Mean Reward": 66.31299118654812, "Episode": 5850, "Episode Step": 352}
{"Training time": 21.836800522208215, "Episode Reward": 5865.319072457479, "Mean Reward": 54.30850993016184, "Episode": 5851, "Episode Step": 108}
{"Training time": 21.840655139419766, "Episode Reward": 18355.6969630788, "Mean Reward": 55.9624907410939, "Episode": 5852, "Episode Step": 328}
{"Training time": 21.844631376332707, "Episode Reward": 18906.138225486684, "Mean Reward": 63.65703106224473, "Episode": 5853, "Episode Step": 297}
{"Training time": 21.845936172737016, "Episode Reward": 6084.425929176823, "Mean Reward": 55.312962992516574, "Episode": 5854, "Episode Step": 110}
{"Training time": 21.84978353526857, "Episode Reward": 16055.443858207225, "Mean Reward": 48.505872683405514, "Episode": 5855, "Episode Step": 331}
{"Training time": 21.857108928296302, "Episode Reward": 36803.4117256621, "Mean Reward": 63.56375082152349, "Episode": 5856, "Episode Step": 579}
{"Training time": 21.86071796192063, "Episode Reward": 19280.924721553463, "Mean Reward": 63.63341492261869, "Episode": 5857, "Episode Step": 303}
{"Training time": 21.862426623834505, "Episode Reward": 5976.40999536456, "Mean Reward": 41.21662065768662, "Episode": 5858, "Episode Step": 145}
{"Training time": 21.866903556386628, "Episode Reward": 22761.249345575794, "Mean Reward": 65.78395764617281, "Episode": 5859, "Episode Step": 346}
{"Training time": 21.869082299139766, "Episode Reward": 9097.355463322683, "Mean Reward": 49.17489439633883, "Episode": 5860, "Episode Step": 185}
{"Training time": 21.870284451378716, "Episode Reward": 4554.109367009558, "Mean Reward": 44.64813104911331, "Episode": 5861, "Episode Step": 102}
{"Training time": 21.883814223011335, "Episode Reward": 78101.38472739098, "Mean Reward": 69.48521772899554, "Episode": 5862, "Episode Step": 1124}
{"Training time": 21.885904904405276, "Episode Reward": 9040.577470331089, "Mean Reward": 50.50601938732452, "Episode": 5863, "Episode Step": 179}
{"Training time": 21.887531682451566, "Episode Reward": 6224.165613066901, "Mean Reward": 44.77816987817914, "Episode": 5864, "Episode Step": 139}
{"Training time": 21.890042959981493, "Episode Reward": 9635.65474407019, "Mean Reward": 54.748038318580626, "Episode": 5865, "Episode Step": 176}
{"Training time": 21.898337840835254, "Episode Reward": 45826.47713349901, "Mean Reward": 63.91419404951047, "Episode": 5866, "Episode Step": 717}
{"Training time": 21.900133306648996, "Episode Reward": 4374.191171648794, "Mean Reward": 28.40383877694022, "Episode": 5867, "Episode Step": 154}
{"Training time": 21.905394516388576, "Episode Reward": 26769.00634129738, "Mean Reward": 64.348572935811, "Episode": 5868, "Episode Step": 416}
{"Training time": 21.906869287225934, "Episode Reward": 6276.606362350719, "Mean Reward": 50.61779324476386, "Episode": 5869, "Episode Step": 124}
{"Training time": 21.920858860810597, "Episode Reward": 60584.49027815176, "Mean Reward": 50.99704568867993, "Episode": 5870, "Episode Step": 1188}
{"Training time": 21.92291146470441, "Episode Reward": 7022.206121424949, "Mean Reward": 51.63386853988933, "Episode": 5871, "Episode Step": 136}
{"Training time": 21.929236048327553, "Episode Reward": 34398.81614642038, "Mean Reward": 63.46645045465015, "Episode": 5872, "Episode Step": 542}
{"Training time": 21.944070986376868, "Episode Reward": 72021.48520518994, "Mean Reward": 56.844108291389055, "Episode": 5873, "Episode Step": 1267}
{"Training time": 21.946167121065987, "Episode Reward": 6880.030100233906, "Mean Reward": 49.1430721445279, "Episode": 5874, "Episode Step": 140}
{"Training time": 21.947468888892068, "Episode Reward": 5935.885182266574, "Mean Reward": 53.96259256605976, "Episode": 5875, "Episode Step": 110}
{"Training time": 21.955948289169207, "Episode Reward": 42935.14639365867, "Mean Reward": 59.38471147117382, "Episode": 5876, "Episode Step": 723}
{"Training time": 21.964620889690188, "Episode Reward": 47127.14842937706, "Mean Reward": 67.8088466609742, "Episode": 5877, "Episode Step": 695}
{"Training time": 21.968386536637944, "Episode Reward": 18447.224334307415, "Mean Reward": 58.74912208378158, "Episode": 5878, "Episode Step": 314}
{"Training time": 21.97146254579226, "Episode Reward": 13470.317388874468, "Mean Reward": 52.21053251501732, "Episode": 5879, "Episode Step": 258}
{"Training time": 21.976844194730123, "Episode Reward": 27294.371928286666, "Mean Reward": 65.29754049829346, "Episode": 5880, "Episode Step": 418}
{"Training time": 21.98050059027142, "Episode Reward": 18469.795823344422, "Mean Reward": 59.77280201729587, "Episode": 5881, "Episode Step": 309}
{"Training time": 22.0026783274942, "Episode Reward": 115800.05049415669, "Mean Reward": 60.88330730502455, "Episode": 5882, "Episode Step": 1902}
{"Training time": 22.006665480004415, "Episode Reward": 19545.596106194684, "Mean Reward": 64.93553523652719, "Episode": 5883, "Episode Step": 301}
{"Training time": 22.01020436194208, "Episode Reward": 20100.85628677913, "Mean Reward": 67.00285428926377, "Episode": 5884, "Episode Step": 300}
{"Training time": 22.023451969424883, "Episode Reward": 71129.30709270244, "Mean Reward": 63.39510436069736, "Episode": 5885, "Episode Step": 1122}
{"Training time": 22.031390703585412, "Episode Reward": 39304.715326921876, "Mean Reward": 62.38843702686012, "Episode": 5886, "Episode Step": 630}
{"Training time": 22.040260536935595, "Episode Reward": 49242.74010576379, "Mean Reward": 64.87844546213938, "Episode": 5887, "Episode Step": 759}
{"Training time": 22.057918618586328, "Episode Reward": 93494.38174495415, "Mean Reward": 61.79403948774233, "Episode": 5888, "Episode Step": 1513}
{"Training time": 22.069170977738167, "Episode Reward": 63710.400917033185, "Mean Reward": 68.35879926720298, "Episode": 5889, "Episode Step": 932}
{"Training time": 22.071341115236283, "Episode Reward": 8463.311905217477, "Mean Reward": 45.01761651711424, "Episode": 5890, "Episode Step": 188}
{"Training time": 22.07419071720706, "Episode Reward": 14957.57524902707, "Mean Reward": 61.05132754704926, "Episode": 5891, "Episode Step": 245}
{"Training time": 22.085631879170737, "Episode Reward": 63128.493516793074, "Mean Reward": 67.88010055569148, "Episode": 5892, "Episode Step": 930}
{"Training time": 22.091962906387117, "Episode Reward": 33425.11945038685, "Mean Reward": 61.783954621787146, "Episode": 5893, "Episode Step": 541}
{"Training time": 22.099855912195313, "Episode Reward": 42744.1051424498, "Mean Reward": 62.76667421798796, "Episode": 5894, "Episode Step": 681}
{"Training time": 22.121754915780492, "Episode Reward": 124740.62123510604, "Mean Reward": 68.20154250142484, "Episode": 5895, "Episode Step": 1829}
{"Training time": 22.124004015790092, "Episode Reward": 8455.159758387423, "Mean Reward": 44.500840833618014, "Episode": 5896, "Episode Step": 190}
{"Training time": 22.126725054979325, "Episode Reward": 13480.962566879816, "Mean Reward": 58.612880725564416, "Episode": 5897, "Episode Step": 230}
{"Training time": 22.140459873014027, "Episode Reward": 69569.0528167552, "Mean Reward": 61.18650203760352, "Episode": 5898, "Episode Step": 1137}
{"Training time": 22.15978735831049, "Episode Reward": 94634.22691857486, "Mean Reward": 60.779850300947246, "Episode": 5899, "Episode Step": 1557}
{"Training time": 22.172249254981676, "Episode Reward": 67193.61984918574, "Mean Reward": 64.23864230323684, "Episode": 5900, "Episode Step": 1046}
{"Training time": 22.190014024972914, "Episode Reward": 95584.32029009171, "Mean Reward": 65.28983626372384, "Episode": 5901, "Episode Step": 1464}
{"Training time": 22.218669886920186, "Episode Reward": 159597.81985372963, "Mean Reward": 65.00929525610168, "Episode": 5902, "Episode Step": 2455}
{"Training time": 22.219851656092537, "Episode Reward": 4942.4990126764615, "Mean Reward": 48.45587267329864, "Episode": 5903, "Episode Step": 102}
{"Training time": 22.226181756390467, "Episode Reward": 33113.68600328497, "Mean Reward": 65.70175794302574, "Episode": 5904, "Episode Step": 504}
{"Training time": 22.238680484957165, "Episode Reward": 65296.34275758624, "Mean Reward": 59.57695507079036, "Episode": 5905, "Episode Step": 1096}
{"Training time": 22.241446924143368, "Episode Reward": 13959.492671508307, "Mean Reward": 58.40791912764982, "Episode": 5906, "Episode Step": 239}
{"Training time": 22.254632764988475, "Episode Reward": 69829.72209101797, "Mean Reward": 63.02321488359023, "Episode": 5907, "Episode Step": 1108}
{"Training time": 22.272142007748286, "Episode Reward": 97766.39907049472, "Mean Reward": 64.02514673902732, "Episode": 5908, "Episode Step": 1527}
{"Training time": 22.274315993587177, "Episode Reward": 8491.002740015503, "Mean Reward": 45.65055236567475, "Episode": 5909, "Episode Step": 186}
{"Training time": 22.280761461059253, "Episode Reward": 33357.26380162339, "Mean Reward": 64.27218458886973, "Episode": 5910, "Episode Step": 519}
{"Training time": 22.293407126930024, "Episode Reward": 69019.56003687184, "Mean Reward": 63.2047253084907, "Episode": 5911, "Episode Step": 1092}
{"Training time": 22.310014659431246, "Episode Reward": 89497.18089878141, "Mean Reward": 62.19401035356596, "Episode": 5912, "Episode Step": 1439}
{"Training time": 22.316606315837966, "Episode Reward": 32219.751146505394, "Mean Reward": 60.67749745104594, "Episode": 5913, "Episode Step": 531}
{"Training time": 22.322342012723286, "Episode Reward": 33349.603558050134, "Mean Reward": 67.37293648090936, "Episode": 5914, "Episode Step": 495}
{"Training time": 22.32356148329046, "Episode Reward": 5635.234430969337, "Mean Reward": 54.18494645162824, "Episode": 5915, "Episode Step": 104}
{"Training time": 22.326101088855, "Episode Reward": 9344.375317463815, "Mean Reward": 52.49649054754952, "Episode": 5916, "Episode Step": 178}
{"Training time": 22.33067743745115, "Episode Reward": 21642.201422637074, "Mean Reward": 54.79038334844829, "Episode": 5917, "Episode Step": 395}
{"Training time": 22.33358104719056, "Episode Reward": 14654.982820559782, "Mean Reward": 58.15469373238009, "Episode": 5918, "Episode Step": 252}
{"Training time": 22.34528821806113, "Episode Reward": 64750.83710179307, "Mean Reward": 66.41111497619802, "Episode": 5919, "Episode Step": 975}
{"Training time": 22.347422457204924, "Episode Reward": 8999.362058786737, "Mean Reward": 48.90957640644966, "Episode": 5920, "Episode Step": 184}
{"Training time": 22.35463517718845, "Episode Reward": 36797.14714595117, "Mean Reward": 58.78138521717439, "Episode": 5921, "Episode Step": 626}
{"Training time": 22.372433296110895, "Episode Reward": 92218.03141795579, "Mean Reward": 61.76693330070716, "Episode": 5922, "Episode Step": 1493}
{"Training time": 22.385968385802375, "Episode Reward": 77020.91846875135, "Mean Reward": 67.03300127828663, "Episode": 5923, "Episode Step": 1149}
{"Training time": 22.387459525532194, "Episode Reward": 6417.175050672127, "Mean Reward": 51.33740040537702, "Episode": 5924, "Episode Step": 125}
{"Training time": 22.39373717135853, "Episode Reward": 31989.38930680705, "Mean Reward": 65.0190839569249, "Episode": 5925, "Episode Step": 492}
{"Training time": 22.394726708332698, "Episode Reward": 4358.205132712845, "Mean Reward": 52.50849557485355, "Episode": 5926, "Episode Step": 83}
{"Training time": 22.397767804728613, "Episode Reward": 14835.597214355847, "Mean Reward": 57.28029812492605, "Episode": 5927, "Episode Step": 259}
{"Training time": 22.40552629272143, "Episode Reward": 38740.730114590006, "Mean Reward": 61.98516818334401, "Episode": 5928, "Episode Step": 625}
{"Training time": 22.412376210822, "Episode Reward": 35265.09834053587, "Mean Reward": 60.07682851880046, "Episode": 5929, "Episode Step": 587}
{"Training time": 22.413849481940268, "Episode Reward": 6255.798808598581, "Mean Reward": 49.25825833542189, "Episode": 5930, "Episode Step": 127}
{"Training time": 22.420251977443694, "Episode Reward": 32409.149981122235, "Mean Reward": 63.547352904161244, "Episode": 5931, "Episode Step": 510}
{"Training time": 22.423889928327668, "Episode Reward": 19016.798375104143, "Mean Reward": 61.34451088743272, "Episode": 5932, "Episode Step": 310}
{"Training time": 22.425374227762223, "Episode Reward": 6041.066218058574, "Mean Reward": 48.71827595208528, "Episode": 5933, "Episode Step": 124}
{"Training time": 22.43200898024771, "Episode Reward": 31688.11401026149, "Mean Reward": 60.12924859632162, "Episode": 5934, "Episode Step": 527}
{"Training time": 22.438717022207047, "Episode Reward": 35507.66952409107, "Mean Reward": 61.220119869122534, "Episode": 5935, "Episode Step": 580}
{"Training time": 22.445054356919396, "Episode Reward": 34422.097246629244, "Mean Reward": 62.585631357507715, "Episode": 5936, "Episode Step": 550}
{"Training time": 22.46754761331611, "Episode Reward": 119298.3374141721, "Mean Reward": 63.221164501416055, "Episode": 5937, "Episode Step": 1887}
{"Training time": 22.469218504163955, "Episode Reward": 6821.649434769689, "Mean Reward": 48.3804924451751, "Episode": 5938, "Episode Step": 141}
{"Training time": 22.472635948061942, "Episode Reward": 17158.86583059592, "Mean Reward": 58.165646883376006, "Episode": 5939, "Episode Step": 295}
{"Training time": 22.47405367248588, "Episode Reward": -1138.3466569127954, "Mean Reward": -14.409451353326524, "Episode": 5940, "Episode Step": 79}
{"Training time": 22.47681422220336, "Episode Reward": 15018.20911516067, "Mean Reward": 63.90727283047093, "Episode": 5941, "Episode Step": 235}
{"Training time": 22.479928594695195, "Episode Reward": 16048.102853827953, "Mean Reward": 59.218091711542264, "Episode": 5942, "Episode Step": 271}
{"Training time": 22.48129080110126, "Episode Reward": -991.4515944604703, "Mean Reward": -13.21935459280627, "Episode": 5943, "Episode Step": 75}
{"Training time": 22.484776374432776, "Episode Reward": 19371.982009807787, "Mean Reward": 64.57327336602596, "Episode": 5944, "Episode Step": 300}
{"Training time": 22.48780938916736, "Episode Reward": 15309.252537647206, "Mean Reward": 59.338188130415524, "Episode": 5945, "Episode Step": 258}
{"Training time": 22.489181638558705, "Episode Reward": -1062.292485111423, "Mean Reward": -13.79600630014835, "Episode": 5946, "Episode Step": 77}
{"Training time": 22.49739143272241, "Episode Reward": 46226.87003079381, "Mean Reward": 65.10826764900537, "Episode": 5947, "Episode Step": 710}
{"Training time": 22.49807446334097, "Episode Reward": 2611.505571946765, "Mean Reward": 46.634028070477946, "Episode": 5948, "Episode Step": 56}
{"Training time": 22.50057875527276, "Episode Reward": -1196.9302605620187, "Mean Reward": -15.345259750795112, "Episode": 5949, "Episode Step": 78}
{"Training time": 22.50771568470531, "Episode Reward": 35570.22955902295, "Mean Reward": 60.084847228079305, "Episode": 5950, "Episode Step": 592}
{"Training time": 22.509202329715094, "Episode Reward": 6416.297820749759, "Mean Reward": 50.92299857737904, "Episode": 5951, "Episode Step": 126}
{"Training time": 22.510544110536575, "Episode Reward": -924.0987276762988, "Mean Reward": -12.487820644274308, "Episode": 5952, "Episode Step": 74}
{"Training time": 22.512738249699275, "Episode Reward": 8723.685937236403, "Mean Reward": 46.90153729696991, "Episode": 5953, "Episode Step": 186}
{"Training time": 22.513957420786223, "Episode Reward": 5877.119386372366, "Mean Reward": 57.05941151817831, "Episode": 5954, "Episode Step": 103}
{"Training time": 22.527069111333955, "Episode Reward": 60699.51828884937, "Mean Reward": 55.99586558011935, "Episode": 5955, "Episode Step": 1084}
{"Training time": 22.529939986069998, "Episode Reward": 15866.903540034327, "Mean Reward": 65.56571710757987, "Episode": 5956, "Episode Step": 242}
{"Training time": 22.5321084849702, "Episode Reward": 8725.477368824468, "Mean Reward": 48.20705728632303, "Episode": 5957, "Episode Step": 181}
{"Training time": 22.539960806104872, "Episode Reward": 37345.171959523206, "Mean Reward": 59.27805072940191, "Episode": 5958, "Episode Step": 630}
{"Training time": 22.541150151093802, "Episode Reward": 6099.237577269073, "Mean Reward": 59.7964468359713, "Episode": 5959, "Episode Step": 102}
{"Training time": 22.542421185506715, "Episode Reward": 5529.048469206869, "Mean Reward": 51.67335017950345, "Episode": 5960, "Episode Step": 107}
{"Training time": 22.54408284942309, "Episode Reward": 5121.397177766044, "Mean Reward": 50.20977625260827, "Episode": 5961, "Episode Step": 102}
{"Training time": 22.545280988282627, "Episode Reward": 2678.3024690812326, "Mean Reward": 26.257867343933654, "Episode": 5962, "Episode Step": 102}
{"Training time": 22.546766573058235, "Episode Reward": 5722.282731109363, "Mean Reward": 45.41494231039177, "Episode": 5963, "Episode Step": 126}
{"Training time": 22.550828407208126, "Episode Reward": 19496.197919944385, "Mean Reward": 62.68873929242567, "Episode": 5964, "Episode Step": 311}
{"Training time": 22.553079047732883, "Episode Reward": 9022.329580951468, "Mean Reward": 46.50685351005911, "Episode": 5965, "Episode Step": 194}
{"Training time": 22.55607645915614, "Episode Reward": 16352.44365473894, "Mean Reward": 63.38156455325171, "Episode": 5966, "Episode Step": 258}
{"Training time": 22.56559586385886, "Episode Reward": 49048.335070326546, "Mean Reward": 62.561651875416516, "Episode": 5967, "Episode Step": 784}
{"Training time": 22.567196969389915, "Episode Reward": 6756.397672536293, "Mean Reward": 49.3167713323817, "Episode": 5968, "Episode Step": 137}
{"Training time": 22.570375940799714, "Episode Reward": 16190.270839725255, "Mean Reward": 58.660401593207446, "Episode": 5969, "Episode Step": 276}
{"Training time": 22.575928434729576, "Episode Reward": 25637.92614246254, "Mean Reward": 60.041981598272926, "Episode": 5970, "Episode Step": 427}
{"Training time": 22.58900128106276, "Episode Reward": 67177.71209742926, "Mean Reward": 60.5750334512437, "Episode": 5971, "Episode Step": 1109}
{"Training time": 22.591172881391312, "Episode Reward": 8666.57183043572, "Mean Reward": 46.84633421857146, "Episode": 5972, "Episode Step": 185}
{"Training time": 22.63681272579564, "Episode Reward": 244274.56370585668, "Mean Reward": 62.44237313544394, "Episode": 5973, "Episode Step": 3912}
{"Training time": 22.652384516663023, "Episode Reward": 83946.74160827382, "Mean Reward": 62.275030866671976, "Episode": 5974, "Episode Step": 1348}
{"Training time": 22.65459029277166, "Episode Reward": 8925.694536470115, "Mean Reward": 47.2258970183604, "Episode": 5975, "Episode Step": 189}
{"Training time": 22.71343208471934, "Episode Reward": 323318.188807212, "Mean Reward": 64.6636377614424, "Episode": 5976, "Episode Step": 5000}
{"Training time": 22.71733039577802, "Episode Reward": 19257.92757002316, "Mean Reward": 63.14074613122347, "Episode": 5977, "Episode Step": 305}
{"Training time": 22.71947606166204, "Episode Reward": 8605.563470212102, "Mean Reward": 46.26647026995754, "Episode": 5978, "Episode Step": 186}
{"Training time": 22.720632212493154, "Episode Reward": -560.9216449009093, "Mean Reward": -9.671062843119126, "Episode": 5979, "Episode Step": 58}
{"Training time": 22.72747475134002, "Episode Reward": 36087.79905036789, "Mean Reward": 61.58327482997933, "Episode": 5980, "Episode Step": 586}
{"Training time": 22.730677392482757, "Episode Reward": 15985.65461365822, "Mean Reward": 58.12965314057534, "Episode": 5981, "Episode Step": 275}
{"Training time": 22.731772788299455, "Episode Reward": -440.10446602433393, "Mean Reward": -8.303857849515735, "Episode": 5982, "Episode Step": 53}
{"Training time": 22.73976784745852, "Episode Reward": 41921.214530758414, "Mean Reward": 60.843562453930936, "Episode": 5983, "Episode Step": 689}
{"Training time": 22.741924578282568, "Episode Reward": 8336.95666707825, "Mean Reward": 45.064630632855405, "Episode": 5984, "Episode Step": 185}
{"Training time": 22.74308268997404, "Episode Reward": -622.3266529839664, "Mean Reward": -10.547909372609599, "Episode": 5985, "Episode Step": 59}
{"Training time": 22.752622282769945, "Episode Reward": 50869.21319350108, "Mean Reward": 61.436247818238016, "Episode": 5986, "Episode Step": 828}
{"Training time": 22.75383969300323, "Episode Reward": 5350.957447755039, "Mean Reward": 51.451513920721524, "Episode": 5987, "Episode Step": 104}
{"Training time": 22.754913468294674, "Episode Reward": -398.479661380764, "Mean Reward": -7.663070411168539, "Episode": 5988, "Episode Step": 52}
{"Training time": 22.762112588882445, "Episode Reward": 38331.42873137166, "Mean Reward": 61.725328069841645, "Episode": 5989, "Episode Step": 621}
{"Training time": 22.77076753106382, "Episode Reward": 43333.81714358247, "Mean Reward": 58.40137081345346, "Episode": 5990, "Episode Step": 742}
{"Training time": 22.771847274435892, "Episode Reward": -407.5162800023902, "Mean Reward": -7.836851538507504, "Episode": 5991, "Episode Step": 52}
{"Training time": 22.782471827467283, "Episode Reward": 55740.481457005386, "Mean Reward": 61.3881954372306, "Episode": 5992, "Episode Step": 908}
{"Training time": 22.785550402998926, "Episode Reward": 16079.80475587715, "Mean Reward": 61.373300594950955, "Episode": 5993, "Episode Step": 262}
{"Training time": 22.786643236080806, "Episode Reward": -404.1321411000197, "Mean Reward": -7.92415962941215, "Episode": 5994, "Episode Step": 51}
{"Training time": 22.788834823038844, "Episode Reward": 9397.652894605744, "Mean Reward": 51.07420051416165, "Episode": 5995, "Episode Step": 184}
{"Training time": 22.807584053609105, "Episode Reward": 101556.21663655629, "Mean Reward": 62.92206730889485, "Episode": 5996, "Episode Step": 1614}
{"Training time": 22.80875692639086, "Episode Reward": -362.7116178913186, "Mean Reward": -5.946092096578994, "Episode": 5997, "Episode Step": 61}
{"Training time": 22.811709386110305, "Episode Reward": 16982.886402438486, "Mean Reward": 68.47938065499389, "Episode": 5998, "Episode Step": 248}
{"Training time": 22.841210725506148, "Episode Reward": 161848.41508358304, "Mean Reward": 66.30414382776856, "Episode": 5999, "Episode Step": 2441}
