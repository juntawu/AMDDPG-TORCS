{"Training Time": 0.0008409730593363444, "Episode Reward": -0.3316130421296252, "Mean Reward": -0.3316130421296252, "Episode": 0, "Episode Step": 1}
{"Training Time": 0.001841494705941942, "Episode Reward": -180.51897119617118, "Mean Reward": -10.618763011539482, "Episode": 1, "Episode Step": 17}
{"Training Time": 0.002685958610640632, "Episode Reward": -159.98915314564738, "Mean Reward": -8.888286285869299, "Episode": 2, "Episode Step": 18}
{"Training Time": 0.003971716099315219, "Episode Reward": 1582.3838222265945, "Mean Reward": 22.933098872849197, "Episode": 3, "Episode Step": 69}
{"Training Time": 0.004793843362066481, "Episode Reward": 2187.073692255656, "Mean Reward": 31.696720177618204, "Episode": 4, "Episode Step": 69}
{"Training Time": 0.005473109152581957, "Episode Reward": 977.8188519572061, "Mean Reward": 16.858945723400105, "Episode": 5, "Episode Step": 58}
{"Training Time": 0.006745432217915853, "Episode Reward": 1121.3546988121795, "Mean Reward": 16.25151737408956, "Episode": 6, "Episode Step": 69}
{"Training Time": 0.007663151688045926, "Episode Reward": 1082.2708847843714, "Mean Reward": 14.055466036160668, "Episode": 7, "Episode Step": 77}
{"Training Time": 0.0080245221985711, "Episode Reward": -56.57765413933956, "Mean Reward": -1.9509535910117088, "Episode": 8, "Episode Step": 29}
{"Training Time": 0.008807475831773546, "Episode Reward": -101.24544867976304, "Mean Reward": -3.7498314325838162, "Episode": 9, "Episode Step": 27}
{"Training Time": 0.009634771082136366, "Episode Reward": 705.0562908343175, "Mean Reward": 10.072232726204534, "Episode": 10, "Episode Step": 70}
{"Training Time": 0.01048309220208062, "Episode Reward": 1164.637221768498, "Mean Reward": 16.175516969006917, "Episode": 11, "Episode Step": 72}
{"Training Time": 0.011768834988276163, "Episode Reward": 862.5309154117695, "Mean Reward": 12.148322752278442, "Episode": 12, "Episode Step": 71}
{"Training Time": 0.01261118663681878, "Episode Reward": 1575.1391971789078, "Mean Reward": 22.501988531127253, "Episode": 13, "Episode Step": 70}
{"Training Time": 0.013430051671134102, "Episode Reward": 2107.9753526756685, "Mean Reward": 30.550367430082154, "Episode": 14, "Episode Step": 69}
{"Training Time": 0.014705641137229072, "Episode Reward": 1363.3352005468762, "Mean Reward": 19.75848116734603, "Episode": 15, "Episode Step": 69}
{"Training Time": 0.015539215803146362, "Episode Reward": 1940.105053111506, "Mean Reward": 27.715786473021517, "Episode": 16, "Episode Step": 70}
{"Training Time": 0.016341960827509563, "Episode Reward": 2123.498105282131, "Mean Reward": 32.17421371639592, "Episode": 17, "Episode Step": 66}
{"Training Time": 0.017206061085065207, "Episode Reward": 170.7916958714962, "Mean Reward": 5.175505935499885, "Episode": 18, "Episode Step": 33}
{"Training Time": 0.01808282110426161, "Episode Reward": 1777.8805951687557, "Mean Reward": 24.692786044010496, "Episode": 19, "Episode Step": 72}
{"Training Time": 0.018934515251053705, "Episode Reward": 2065.4308077326305, "Mean Reward": 29.09057475679761, "Episode": 20, "Episode Step": 71}
{"Training Time": 0.020258980525864494, "Episode Reward": 1203.0451586734698, "Mean Reward": 16.48007066675986, "Episode": 21, "Episode Step": 73}
{"Training Time": 0.02110638724433051, "Episode Reward": 1918.115966423643, "Mean Reward": 27.015717836952717, "Episode": 22, "Episode Step": 71}
{"Training Time": 0.02180330693721771, "Episode Reward": 1162.176064187899, "Mean Reward": 20.037518348067227, "Episode": 23, "Episode Step": 58}
{"Training Time": 0.023023648858070372, "Episode Reward": 1186.1624920338495, "Mean Reward": 18.248653723597684, "Episode": 24, "Episode Step": 65}
{"Training Time": 0.023849670555856493, "Episode Reward": 2257.121329329457, "Mean Reward": 32.24459041899224, "Episode": 25, "Episode Step": 70}
{"Training Time": 0.02466825975312127, "Episode Reward": 1468.1872364276521, "Mean Reward": 21.278075890255828, "Episode": 26, "Episode Step": 69}
{"Training Time": 0.025963366097874113, "Episode Reward": 1965.9753383121224, "Mean Reward": 27.689793497353836, "Episode": 27, "Episode Step": 71}
{"Training Time": 0.026822363336881, "Episode Reward": 1955.8916470359027, "Mean Reward": 27.54776967656201, "Episode": 28, "Episode Step": 71}
{"Training Time": 0.027664795253011916, "Episode Reward": 2026.9256430443902, "Mean Reward": 28.151745042283196, "Episode": 29, "Episode Step": 72}
{"Training Time": 0.028948076963424683, "Episode Reward": 1711.428788688157, "Mean Reward": 24.104630826593763, "Episode": 30, "Episode Step": 71}
{"Training Time": 0.029777385857370164, "Episode Reward": 1772.532109372692, "Mean Reward": 25.321887276752744, "Episode": 31, "Episode Step": 70}
{"Training Time": 0.030614332755406697, "Episode Reward": 2326.079443913636, "Mean Reward": 33.71129628860342, "Episode": 32, "Episode Step": 69}
{"Training Time": 0.03190238581763374, "Episode Reward": 1459.9808648241333, "Mean Reward": 20.85686949748762, "Episode": 33, "Episode Step": 70}
{"Training Time": 0.03273242109351688, "Episode Reward": 2107.9734108512907, "Mean Reward": 30.550339287699867, "Episode": 34, "Episode Step": 69}
{"Training Time": 0.03359711779488458, "Episode Reward": 2113.0811866502904, "Mean Reward": 29.76170685422944, "Episode": 35, "Episode Step": 71}
{"Training Time": 0.03436041196187337, "Episode Reward": -104.59546174988184, "Mean Reward": -4.022902374995455, "Episode": 36, "Episode Step": 26}
{"Training Time": 0.035203777220514085, "Episode Reward": 1783.9997921608724, "Mean Reward": 25.48571131658389, "Episode": 37, "Episode Step": 70}
{"Training Time": 0.03602670556969113, "Episode Reward": 2205.8816258394468, "Mean Reward": 31.969298925209372, "Episode": 38, "Episode Step": 69}
{"Training Time": 0.03734276029798719, "Episode Reward": 1433.2205910077096, "Mean Reward": 20.186205507150838, "Episode": 39, "Episode Step": 71}
{"Training Time": 0.03819435583220588, "Episode Reward": 1453.412963098803, "Mean Reward": 20.7630423299829, "Episode": 40, "Episode Step": 70}
{"Training Time": 0.0390129013856252, "Episode Reward": 2261.467627370929, "Mean Reward": 31.851656723534216, "Episode": 41, "Episode Step": 71}
{"Training Time": 0.039885973069402905, "Episode Reward": 153.63172799091603, "Mean Reward": 4.389477942597601, "Episode": 42, "Episode Step": 35}
{"Training Time": 0.04071240663528442, "Episode Reward": 2113.384947098705, "Mean Reward": 30.191213529981503, "Episode": 43, "Episode Step": 70}
{"Training Time": 0.04152900139490763, "Episode Reward": 1640.0081427871203, "Mean Reward": 23.768233953436525, "Episode": 44, "Episode Step": 69}
{"Training Time": 0.04262346890237596, "Episode Reward": 714.7235549701211, "Mean Reward": 13.235621388335575, "Episode": 45, "Episode Step": 54}
{"Training Time": 0.04324789497587416, "Episode Reward": 1437.1201536243882, "Mean Reward": 27.11547459668657, "Episode": 46, "Episode Step": 53}
{"Training Time": 0.04406638834211561, "Episode Reward": 1258.8346402700388, "Mean Reward": 18.51227412161822, "Episode": 47, "Episode Step": 68}
{"Training Time": 0.04536055637730493, "Episode Reward": 1464.2486101194845, "Mean Reward": 20.336786251659507, "Episode": 48, "Episode Step": 72}
{"Training Time": 0.04681450055705177, "Episode Reward": 1614.237979952494, "Mean Reward": 23.39475333264484, "Episode": 49, "Episode Step": 69}
{"Training Time": 0.04764903889762031, "Episode Reward": 587.2538443295573, "Mean Reward": 12.766387920207768, "Episode": 50, "Episode Step": 46}
{"Training Time": 0.04890061053964827, "Episode Reward": 1452.4292758799581, "Mean Reward": 21.049699650434174, "Episode": 51, "Episode Step": 69}
{"Training Time": 0.04962833139631483, "Episode Reward": 1082.57677501041, "Mean Reward": 18.0429462501735, "Episode": 52, "Episode Step": 60}
{"Training Time": 0.05043898085753123, "Episode Reward": 1786.5224700832646, "Mean Reward": 25.89163000120673, "Episode": 53, "Episode Step": 69}
{"Training Time": 0.051699193053775364, "Episode Reward": 1516.6174385280806, "Mean Reward": 22.30319762541295, "Episode": 54, "Episode Step": 68}
{"Training Time": 0.0525199074877633, "Episode Reward": 2525.910946626176, "Mean Reward": 36.60740502356777, "Episode": 55, "Episode Step": 69}
{"Training Time": 0.05336675306161245, "Episode Reward": 1921.106005634998, "Mean Reward": 27.4443715090714, "Episode": 56, "Episode Step": 70}
{"Training Time": 0.05466818941964043, "Episode Reward": 1397.853599972108, "Mean Reward": 19.688078872846592, "Episode": 57, "Episode Step": 71}
{"Training Time": 0.055484153628349304, "Episode Reward": 1770.4569773834653, "Mean Reward": 26.03613202034508, "Episode": 58, "Episode Step": 68}
{"Training Time": 0.05606016973654429, "Episode Reward": 1031.501835083288, "Mean Reward": 21.489621564235165, "Episode": 59, "Episode Step": 48}
{"Training Time": 0.05735508528020647, "Episode Reward": 1348.2291756611862, "Mean Reward": 19.260416795159802, "Episode": 60, "Episode Step": 70}
{"Training Time": 0.05818543136119843, "Episode Reward": 1928.7014947333323, "Mean Reward": 27.552878496190463, "Episode": 61, "Episode Step": 70}
{"Training Time": 0.05907092306349013, "Episode Reward": 1486.5562368776166, "Mean Reward": 20.088597795643466, "Episode": 62, "Episode Step": 74}
{"Training Time": 0.06035397834248013, "Episode Reward": 1498.3794908532516, "Mean Reward": 21.71564479497466, "Episode": 63, "Episode Step": 69}
{"Training Time": 0.061186713642544216, "Episode Reward": 1627.386343862654, "Mean Reward": 23.248376340895057, "Episode": 64, "Episode Step": 70}
{"Training Time": 0.0620169327656428, "Episode Reward": 2386.775367673658, "Mean Reward": 34.59094735758924, "Episode": 65, "Episode Step": 69}
{"Training Time": 0.06330713861518436, "Episode Reward": 1017.9743309525313, "Mean Reward": 14.337666633134244, "Episode": 66, "Episode Step": 71}
{"Training Time": 0.06416990472210778, "Episode Reward": 1553.1258410982211, "Mean Reward": 21.571192237475294, "Episode": 67, "Episode Step": 72}
{"Training Time": 0.0650210780567593, "Episode Reward": 1896.0391587097488, "Mean Reward": 26.704776883235898, "Episode": 68, "Episode Step": 71}
{"Training Time": 0.0662890480624305, "Episode Reward": 1058.7283381585783, "Mean Reward": 15.343888958819974, "Episode": 69, "Episode Step": 69}
{"Training Time": 0.06711502525541517, "Episode Reward": 1910.3663695273785, "Mean Reward": 27.290948136105406, "Episode": 70, "Episode Step": 70}
{"Training Time": 0.06794744220044878, "Episode Reward": 1685.2517588878195, "Mean Reward": 23.735940266025626, "Episode": 71, "Episode Step": 71}
{"Training Time": 0.06923840277724796, "Episode Reward": 954.9696396199572, "Mean Reward": 13.450276614365594, "Episode": 72, "Episode Step": 71}
{"Training Time": 0.07006662805875143, "Episode Reward": 1666.5433514698423, "Mean Reward": 23.80776216385489, "Episode": 73, "Episode Step": 70}
{"Training Time": 0.07091586358017392, "Episode Reward": 2554.332264246536, "Mean Reward": 35.976510764035716, "Episode": 74, "Episode Step": 71}
{"Training Time": 0.07218636691570282, "Episode Reward": 1169.25921357082, "Mean Reward": 16.703703051011715, "Episode": 75, "Episode Step": 70}
{"Training Time": 0.07299576527542538, "Episode Reward": 2076.308008580915, "Mean Reward": 30.533941302660516, "Episode": 76, "Episode Step": 68}
{"Training Time": 0.07382605585787032, "Episode Reward": 1824.2924563808763, "Mean Reward": 26.43902110696922, "Episode": 77, "Episode Step": 69}
{"Training Time": 0.07511349141597748, "Episode Reward": 1083.0673802908927, "Mean Reward": 15.042602504040177, "Episode": 78, "Episode Step": 72}
{"Training Time": 0.07595572279559241, "Episode Reward": 1618.0478971987025, "Mean Reward": 22.47288746109309, "Episode": 79, "Episode Step": 72}
{"Training Time": 0.07679896586471134, "Episode Reward": 1986.8466282969198, "Mean Reward": 28.383523261384568, "Episode": 80, "Episode Step": 70}
{"Training Time": 0.07807978941334619, "Episode Reward": 1019.0522975185897, "Mean Reward": 14.557889964551283, "Episode": 81, "Episode Step": 70}
{"Training Time": 0.07895649916595883, "Episode Reward": 2309.5264958484086, "Mean Reward": 31.63734925819738, "Episode": 82, "Episode Step": 73}
{"Training Time": 0.07976677278677623, "Episode Reward": 2118.2287010936857, "Mean Reward": 30.698966682517185, "Episode": 83, "Episode Step": 69}
{"Training Time": 0.08109870360957251, "Episode Reward": 1232.8650984179649, "Mean Reward": 16.660339167810335, "Episode": 84, "Episode Step": 74}
{"Training Time": 0.08195744110478295, "Episode Reward": 2213.492910479364, "Mean Reward": 30.74295708999117, "Episode": 85, "Episode Step": 72}
{"Training Time": 0.08283702082104154, "Episode Reward": 2378.848332448597, "Mean Reward": 32.58696345819996, "Episode": 86, "Episode Step": 73}
{"Training Time": 0.08412246611383226, "Episode Reward": 1225.2407836399818, "Mean Reward": 17.256912445633546, "Episode": 87, "Episode Step": 71}
{"Training Time": 0.08490165220366584, "Episode Reward": 1668.020322002268, "Mean Reward": 25.273035181852546, "Episode": 88, "Episode Step": 66}
{"Training Time": 0.08577659580442641, "Episode Reward": 2408.9633093473954, "Mean Reward": 32.999497388320485, "Episode": 89, "Episode Step": 73}
{"Training Time": 0.0870663947529263, "Episode Reward": 1736.5688285943843, "Mean Reward": 24.80812612277692, "Episode": 90, "Episode Step": 70}
{"Training Time": 0.08790295918782552, "Episode Reward": 1869.6694453707478, "Mean Reward": 26.33337247001053, "Episode": 91, "Episode Step": 71}
{"Training Time": 0.08875352084636688, "Episode Reward": 1982.4426718803848, "Mean Reward": 27.921727772963166, "Episode": 92, "Episode Step": 71}
{"Training Time": 0.09003164225154453, "Episode Reward": 1570.6586832116277, "Mean Reward": 22.121953284670813, "Episode": 93, "Episode Step": 71}
{"Training Time": 0.09084948221842448, "Episode Reward": 2147.55861250853, "Mean Reward": 30.67940875012186, "Episode": 94, "Episode Step": 70}
{"Training Time": 0.09163059360451169, "Episode Reward": 2039.9409604310717, "Mean Reward": 30.908196370167754, "Episode": 95, "Episode Step": 66}
{"Training Time": 0.09289777252409193, "Episode Reward": 1358.8298558608528, "Mean Reward": 19.693186316823954, "Episode": 96, "Episode Step": 69}
{"Training Time": 0.09376015113459693, "Episode Reward": 2471.1782730936807, "Mean Reward": 34.321920459634455, "Episode": 97, "Episode Step": 72}
{"Training Time": 0.09465018471082051, "Episode Reward": 2095.2761961327155, "Mean Reward": 28.314543190982643, "Episode": 98, "Episode Step": 74}
{"Training Time": 0.09772664666175843, "Episode Reward": 1471.8306814272046, "Mean Reward": 20.730009597566262, "Episode": 99, "Episode Step": 71}
{"Training Time": 0.09887615415785048, "Episode Reward": 2426.6072562357963, "Mean Reward": 33.702878558830506, "Episode": 100, "Episode Step": 72}
{"Training Time": 0.09976006335682339, "Episode Reward": 2505.224589850398, "Mean Reward": 34.318145066443805, "Episode": 101, "Episode Step": 73}
{"Training Time": 0.10084223833349015, "Episode Reward": 559.1863448787377, "Mean Reward": 10.550685752429013, "Episode": 102, "Episode Step": 53}
{"Training Time": 0.10167000830173492, "Episode Reward": 1953.5640460783056, "Mean Reward": 27.90805780111865, "Episode": 103, "Episode Step": 70}
{"Training Time": 0.10256135000122918, "Episode Reward": 2053.7783182357043, "Mean Reward": 27.38371090980939, "Episode": 104, "Episode Step": 75}
{"Training Time": 0.10384887860880958, "Episode Reward": 1106.026574767004, "Mean Reward": 15.800379639528627, "Episode": 105, "Episode Step": 70}
{"Training Time": 0.10471535722414653, "Episode Reward": 1674.8026527116895, "Mean Reward": 22.942502091940952, "Episode": 106, "Episode Step": 73}
{"Training Time": 0.10555128614107767, "Episode Reward": 2610.7090427004846, "Mean Reward": 37.29584346714978, "Episode": 107, "Episode Step": 70}
{"Training Time": 0.10685958193408118, "Episode Reward": 1188.857087016272, "Mean Reward": 16.98367267166103, "Episode": 108, "Episode Step": 70}
{"Training Time": 0.10772209915849898, "Episode Reward": 2377.8504203837406, "Mean Reward": 32.57329342991425, "Episode": 109, "Episode Step": 73}
{"Training Time": 0.10862583696842193, "Episode Reward": 2155.0196570960757, "Mean Reward": 28.733595427947677, "Episode": 110, "Episode Step": 75}
{"Training Time": 0.10982898447248671, "Episode Reward": 1254.2134779095657, "Mean Reward": 20.229249643702673, "Episode": 111, "Episode Step": 62}
{"Training Time": 0.1106973033481174, "Episode Reward": 2378.9122031626443, "Mean Reward": 33.04044726614784, "Episode": 112, "Episode Step": 72}
{"Training Time": 0.1115845266977946, "Episode Reward": 1906.0910896745318, "Mean Reward": 25.757987698304483, "Episode": 113, "Episode Step": 74}
{"Training Time": 0.11289037863413492, "Episode Reward": 1804.0157387670824, "Mean Reward": 25.055774149542813, "Episode": 114, "Episode Step": 72}
{"Training Time": 0.11373168753253089, "Episode Reward": 2692.2351691813687, "Mean Reward": 37.39215512751901, "Episode": 115, "Episode Step": 72}
{"Training Time": 0.1145932380358378, "Episode Reward": 2556.193466110624, "Mean Reward": 36.00272487479752, "Episode": 116, "Episode Step": 71}
{"Training Time": 0.11589709586567348, "Episode Reward": 1742.4758266251024, "Mean Reward": 24.201053147570867, "Episode": 117, "Episode Step": 72}
{"Training Time": 0.11702054891321394, "Episode Reward": 3284.9181215705116, "Mean Reward": 34.21789709969283, "Episode": 118, "Episode Step": 96}
{"Training Time": 0.11783288333151076, "Episode Reward": 2115.1247470682033, "Mean Reward": 30.653981841568164, "Episode": 119, "Episode Step": 69}
{"Training Time": 0.11909308003054725, "Episode Reward": 2383.3180488000908, "Mean Reward": 34.047400697144155, "Episode": 120, "Episode Step": 70}
{"Training Time": 0.11994638807243771, "Episode Reward": 1795.8267400251152, "Mean Reward": 24.942038055904376, "Episode": 121, "Episode Step": 72}
{"Training Time": 0.12084600501590305, "Episode Reward": 2501.1017252597144, "Mean Reward": 33.348023003462856, "Episode": 122, "Episode Step": 75}
{"Training Time": 0.12213245941532982, "Episode Reward": 1374.241875379174, "Mean Reward": 19.91654891853875, "Episode": 123, "Episode Step": 69}
{"Training Time": 0.12301350083616044, "Episode Reward": 2139.2275631206385, "Mean Reward": 29.304487166036143, "Episode": 124, "Episode Step": 73}
{"Training Time": 0.12386688305271996, "Episode Reward": 2374.247058884199, "Mean Reward": 32.97565359561387, "Episode": 125, "Episode Step": 72}
{"Training Time": 0.1251833752791087, "Episode Reward": 1911.8370330476137, "Mean Reward": 25.83563558172451, "Episode": 126, "Episode Step": 74}
{"Training Time": 0.12600440720717113, "Episode Reward": 2079.0698329417505, "Mean Reward": 29.70099761345358, "Episode": 127, "Episode Step": 70}
{"Training Time": 0.1269110600153605, "Episode Reward": 2344.23436760478, "Mean Reward": 31.2564582347304, "Episode": 128, "Episode Step": 75}
{"Training Time": 0.1282451644208696, "Episode Reward": 1648.5378253197425, "Mean Reward": 21.69128717525977, "Episode": 129, "Episode Step": 76}
{"Training Time": 0.12911005165841843, "Episode Reward": 2119.939506996135, "Mean Reward": 29.040267219125138, "Episode": 130, "Episode Step": 73}
{"Training Time": 0.12995458053217993, "Episode Reward": 2295.2446449540507, "Mean Reward": 31.878397846584036, "Episode": 131, "Episode Step": 72}
{"Training Time": 0.13160774224334293, "Episode Reward": 3151.5409070016585, "Mean Reward": 30.89745987256528, "Episode": 132, "Episode Step": 102}
{"Training Time": 0.13241600864463382, "Episode Reward": 1956.055646288281, "Mean Reward": 28.76552421012178, "Episode": 133, "Episode Step": 68}
{"Training Time": 0.13326195471816593, "Episode Reward": 2447.167571442989, "Mean Reward": 33.98843849226373, "Episode": 134, "Episode Step": 72}
{"Training Time": 0.1345476155810886, "Episode Reward": 2253.323350023333, "Mean Reward": 31.736948591877933, "Episode": 135, "Episode Step": 71}
{"Training Time": 0.13535021278593276, "Episode Reward": 2134.0677913308264, "Mean Reward": 30.928518714939514, "Episode": 136, "Episode Step": 69}
{"Training Time": 0.13622982501983644, "Episode Reward": 1907.1739119624203, "Mean Reward": 25.428985492832272, "Episode": 137, "Episode Step": 75}
{"Training Time": 0.137496749692493, "Episode Reward": 2092.260786811609, "Mean Reward": 29.88943981159441, "Episode": 138, "Episode Step": 70}
{"Training Time": 0.1383468144469791, "Episode Reward": 2237.1799857449346, "Mean Reward": 31.071944246457424, "Episode": 139, "Episode Step": 72}
{"Training Time": 0.13923090193006726, "Episode Reward": 2159.172122981735, "Mean Reward": 28.410159512917563, "Episode": 140, "Episode Step": 76}
{"Training Time": 0.14052306003040738, "Episode Reward": 2404.0463675240785, "Mean Reward": 33.85980799329688, "Episode": 141, "Episode Step": 71}
{"Training Time": 0.14138168275356292, "Episode Reward": 2447.329293060441, "Mean Reward": 33.990684625839464, "Episode": 142, "Episode Step": 72}
{"Training Time": 0.14221409334076776, "Episode Reward": 2110.1223790799136, "Mean Reward": 30.144605415427336, "Episode": 143, "Episode Step": 70}
{"Training Time": 0.1435134514172872, "Episode Reward": 1383.3642507219445, "Mean Reward": 18.694111496242492, "Episode": 144, "Episode Step": 74}
{"Training Time": 0.14434353636370764, "Episode Reward": 2067.1416103663664, "Mean Reward": 29.114670568540372, "Episode": 145, "Episode Step": 71}
{"Training Time": 0.1451933005783293, "Episode Reward": 2540.4654285086895, "Mean Reward": 34.800896280940954, "Episode": 146, "Episode Step": 73}
{"Training Time": 0.14645340502262116, "Episode Reward": 2209.109733868617, "Mean Reward": 31.558710483837384, "Episode": 147, "Episode Step": 70}
{"Training Time": 0.1473026774989234, "Episode Reward": 2552.741993723257, "Mean Reward": 35.45474991282302, "Episode": 148, "Episode Step": 72}
{"Training Time": 0.15078548192977906, "Episode Reward": 2360.631245866147, "Mean Reward": 30.6575486476123, "Episode": 149, "Episode Step": 77}
{"Training Time": 0.1520911916759279, "Episode Reward": 2264.5094060951333, "Mean Reward": 31.020676795823743, "Episode": 150, "Episode Step": 73}
{"Training Time": 0.15295044667190977, "Episode Reward": 2151.6633686556547, "Mean Reward": 29.88421345355076, "Episode": 151, "Episode Step": 72}
{"Training Time": 0.15386211415131887, "Episode Reward": 1995.2675968055337, "Mean Reward": 26.253521010599126, "Episode": 152, "Episode Step": 76}
{"Training Time": 0.15512915750344594, "Episode Reward": 2177.224979928996, "Mean Reward": 31.10321399898566, "Episode": 153, "Episode Step": 70}
{"Training Time": 0.15603537334336176, "Episode Reward": 2335.8735319697835, "Mean Reward": 30.336019895711473, "Episode": 154, "Episode Step": 77}
{"Training Time": 0.15690076861116622, "Episode Reward": 2200.15759960741, "Mean Reward": 29.731859454154186, "Episode": 155, "Episode Step": 74}
{"Training Time": 0.1581780344247818, "Episode Reward": 2054.626333908747, "Mean Reward": 29.351804770124954, "Episode": 156, "Episode Step": 70}
{"Training Time": 0.1590683141681883, "Episode Reward": 2475.843097110292, "Mean Reward": 32.57688285671437, "Episode": 157, "Episode Step": 76}
{"Training Time": 0.15995510306623248, "Episode Reward": 2015.8131581975035, "Mean Reward": 27.240718354020316, "Episode": 158, "Episode Step": 74}
{"Training Time": 0.16125724302397834, "Episode Reward": 2280.4325228380103, "Mean Reward": 31.23880168271247, "Episode": 159, "Episode Step": 73}
{"Training Time": 0.16219076805644564, "Episode Reward": 2246.1534307993975, "Mean Reward": 28.432321908853133, "Episode": 160, "Episode Step": 79}
{"Training Time": 0.16308460831642152, "Episode Reward": 1997.9268973219323, "Mean Reward": 26.28851180686753, "Episode": 161, "Episode Step": 76}
{"Training Time": 0.1643467116355896, "Episode Reward": 1907.8304766021392, "Mean Reward": 27.649717052204917, "Episode": 162, "Episode Step": 69}
{"Training Time": 0.16525024943881564, "Episode Reward": 2513.504923793841, "Mean Reward": 32.6429210882317, "Episode": 163, "Episode Step": 77}
{"Training Time": 0.16613300528791217, "Episode Reward": 1857.8278801742076, "Mean Reward": 24.77103840232277, "Episode": 164, "Episode Step": 75}
{"Training Time": 0.1674370861053467, "Episode Reward": 2238.7890917696996, "Mean Reward": 30.668343722872596, "Episode": 165, "Episode Step": 73}
{"Training Time": 0.16836341751946343, "Episode Reward": 2228.529822552742, "Mean Reward": 28.570895160932594, "Episode": 166, "Episode Step": 78}
{"Training Time": 0.1692452749941084, "Episode Reward": 2139.9151318489858, "Mean Reward": 28.917772052013323, "Episode": 167, "Episode Step": 74}
{"Training Time": 0.1705862714184655, "Episode Reward": 2378.4612274035107, "Mean Reward": 31.295542465835666, "Episode": 168, "Episode Step": 76}
{"Training Time": 0.17160466306739383, "Episode Reward": 2205.3822684621514, "Mean Reward": 25.349221476576453, "Episode": 169, "Episode Step": 87}
{"Training Time": 0.17249395138687557, "Episode Reward": 2052.7783105091494, "Mean Reward": 27.010240927751966, "Episode": 170, "Episode Step": 76}
{"Training Time": 0.1739005602730645, "Episode Reward": 2273.1039402336373, "Mean Reward": 28.413799252920466, "Episode": 171, "Episode Step": 80}
{"Training Time": 0.1748843358622657, "Episode Reward": 2162.501015654382, "Mean Reward": 26.054229104269666, "Episode": 172, "Episode Step": 83}
{"Training Time": 0.17576664917998844, "Episode Reward": 1772.714592715826, "Mean Reward": 23.95560260426792, "Episode": 173, "Episode Step": 74}
{"Training Time": 0.17721388863192664, "Episode Reward": 2172.044997381781, "Mean Reward": 25.553470557432714, "Episode": 174, "Episode Step": 85}
{"Training Time": 0.1781731269756953, "Episode Reward": 2536.1610097936446, "Mean Reward": 30.55615674450174, "Episode": 175, "Episode Step": 83}
{"Training Time": 0.17905173030164506, "Episode Reward": 2216.705839279271, "Mean Reward": 29.955484314584744, "Episode": 176, "Episode Step": 74}
{"Training Time": 0.1804575088951323, "Episode Reward": 1708.4448892314895, "Mean Reward": 20.834693771115724, "Episode": 177, "Episode Step": 82}
{"Training Time": 0.1815691508187188, "Episode Reward": 2377.50190886854, "Mean Reward": 25.026335882826736, "Episode": 178, "Episode Step": 95}
{"Training Time": 0.1824361136224535, "Episode Reward": 2075.3496033861775, "Mean Reward": 28.42944662172846, "Episode": 179, "Episode Step": 73}
{"Training Time": 0.1837825314203898, "Episode Reward": 1678.0507979157685, "Mean Reward": 22.079615762049585, "Episode": 180, "Episode Step": 76}
{"Training Time": 0.1846903028090795, "Episode Reward": 1832.2085812931975, "Mean Reward": 23.794916640171397, "Episode": 181, "Episode Step": 77}
{"Training Time": 0.18558070056968265, "Episode Reward": 1996.7292980624165, "Mean Reward": 26.623057307498886, "Episode": 182, "Episode Step": 75}
{"Training Time": 0.186892285545667, "Episode Reward": 1497.3164253544994, "Mean Reward": 20.511183908965744, "Episode": 183, "Episode Step": 73}
{"Training Time": 0.1880894002649519, "Episode Reward": 2130.755680860066, "Mean Reward": 21.096590899604614, "Episode": 184, "Episode Step": 101}
{"Training Time": 0.1889812527762519, "Episode Reward": 2048.3794809067203, "Mean Reward": 27.680803796036763, "Episode": 185, "Episode Step": 74}
{"Training Time": 0.19066010302967495, "Episode Reward": 2539.7730631725617, "Mean Reward": 24.89973591345649, "Episode": 186, "Episode Step": 102}
{"Training Time": 0.19177293280760446, "Episode Reward": 2325.803275938443, "Mean Reward": 25.008637375682184, "Episode": 187, "Episode Step": 93}
{"Training Time": 0.19270350608560774, "Episode Reward": 1685.7217929659062, "Mean Reward": 22.180549907446135, "Episode": 188, "Episode Step": 76}
{"Training Time": 0.1941742338736852, "Episode Reward": 1329.6345170058235, "Mean Reward": 15.642759023597923, "Episode": 189, "Episode Step": 85}
{"Training Time": 0.19545731080902948, "Episode Reward": 2804.8579130250573, "Mean Reward": 26.21362535537437, "Episode": 190, "Episode Step": 107}
{"Training Time": 0.19630923165215386, "Episode Reward": 1742.407496381784, "Mean Reward": 24.20010411641367, "Episode": 191, "Episode Step": 72}
{"Training Time": 0.1977299905485577, "Episode Reward": 1409.34296634268, "Mean Reward": 17.399295880773828, "Episode": 192, "Episode Step": 81}
{"Training Time": 0.19891829636361863, "Episode Reward": 2346.7902463989844, "Mean Reward": 23.007747513715533, "Episode": 193, "Episode Step": 102}
{"Training Time": 0.19986111832989586, "Episode Reward": 1878.4825958839551, "Mean Reward": 24.08311020364045, "Episode": 194, "Episode Step": 78}
{"Training Time": 0.2013524438937505, "Episode Reward": 1227.2461803703675, "Mean Reward": 13.94597932239054, "Episode": 195, "Episode Step": 88}
{"Training Time": 0.20240259501669142, "Episode Reward": 1932.9999447371538, "Mean Reward": 21.71910050266465, "Episode": 196, "Episode Step": 89}
{"Training Time": 0.20337641775608062, "Episode Reward": 1802.731310204289, "Mean Reward": 22.534141377553613, "Episode": 197, "Episode Step": 80}
{"Training Time": 0.2046965922249688, "Episode Reward": 1050.7060777446286, "Mean Reward": 14.593139968675397, "Episode": 198, "Episode Step": 72}
{"Training Time": 0.20597042275799646, "Episode Reward": 2019.3977503321084, "Mean Reward": 23.75762059214245, "Episode": 199, "Episode Step": 85}
{"Training Time": 0.2071557558245129, "Episode Reward": 1875.9260589777118, "Mean Reward": 25.012347453036156, "Episode": 200, "Episode Step": 75}
{"Training Time": 0.20866926974720426, "Episode Reward": 1348.7413593866333, "Mean Reward": 15.683039062635272, "Episode": 201, "Episode Step": 86}
{"Training Time": 0.20964177277353074, "Episode Reward": 2465.3539301552046, "Mean Reward": 30.436468273521044, "Episode": 202, "Episode Step": 81}
{"Training Time": 0.21065979222456613, "Episode Reward": 1554.4263506652292, "Mean Reward": 18.07472500773522, "Episode": 203, "Episode Step": 86}
{"Training Time": 0.21197320222854615, "Episode Reward": 854.9382928540317, "Mean Reward": 11.874142956305995, "Episode": 204, "Episode Step": 72}
{"Training Time": 0.21319128195444742, "Episode Reward": 2980.2776953708844, "Mean Reward": 28.93473490651344, "Episode": 205, "Episode Step": 103}
{"Training Time": 0.21408514248000252, "Episode Reward": 1898.6432714279563, "Mean Reward": 25.315243619039418, "Episode": 206, "Episode Step": 75}
{"Training Time": 0.21571582165029313, "Episode Reward": 1939.7449522597171, "Mean Reward": 19.59338335615876, "Episode": 207, "Episode Step": 99}
{"Training Time": 0.21665623386700947, "Episode Reward": 2224.497599575747, "Mean Reward": 27.806219994696836, "Episode": 208, "Episode Step": 80}
{"Training Time": 0.21758434388372633, "Episode Reward": 1884.6003773414586, "Mean Reward": 24.16154329924947, "Episode": 209, "Episode Step": 78}
{"Training Time": 0.2187999991575877, "Episode Reward": 442.125268797599, "Mean Reward": 7.017861409485699, "Episode": 210, "Episode Step": 63}
{"Training Time": 0.21994165387418535, "Episode Reward": 2272.7106572312755, "Mean Reward": 23.190925073788524, "Episode": 211, "Episode Step": 98}
{"Training Time": 0.2208606649769677, "Episode Reward": 1917.3052719954753, "Mean Reward": 24.900068467473705, "Episode": 212, "Episode Step": 77}
{"Training Time": 0.22230350553989411, "Episode Reward": 1178.9344603979428, "Mean Reward": 14.034934052356462, "Episode": 213, "Episode Step": 84}
{"Training Time": 0.22336736612849764, "Episode Reward": 2344.573406737738, "Mean Reward": 26.343521424019528, "Episode": 214, "Episode Step": 89}
{"Training Time": 0.224328196644783, "Episode Reward": 1872.4482010430524, "Mean Reward": 23.116644457321634, "Episode": 215, "Episode Step": 81}
{"Training Time": 0.22593655970361498, "Episode Reward": 1073.0560717805804, "Mean Reward": 11.062433729696705, "Episode": 216, "Episode Step": 97}
{"Training Time": 0.2269534491830402, "Episode Reward": 2339.1817067629504, "Mean Reward": 27.519784785446475, "Episode": 217, "Episode Step": 85}
{"Training Time": 0.22788914614253575, "Episode Reward": 1781.833233191085, "Mean Reward": 22.844015810142114, "Episode": 218, "Episode Step": 78}
{"Training Time": 0.22955834163559807, "Episode Reward": 1159.7887436136643, "Mean Reward": 11.15181484243908, "Episode": 219, "Episode Step": 104}
{"Training Time": 0.23059855083624523, "Episode Reward": 2360.0044104434915, "Mean Reward": 26.818231936857856, "Episode": 220, "Episode Step": 88}
{"Training Time": 0.23157386945353614, "Episode Reward": 1843.1143935860616, "Mean Reward": 22.47700479983002, "Episode": 221, "Episode Step": 82}
{"Training Time": 0.23307886362075805, "Episode Reward": 282.51690242573864, "Mean Reward": 3.174347218266726, "Episode": 222, "Episode Step": 89}
{"Training Time": 0.2346006460984548, "Episode Reward": 3604.344796575934, "Mean Reward": 27.514082416610183, "Episode": 223, "Episode Step": 131}
{"Training Time": 0.2355239236354828, "Episode Reward": 1592.4680337551122, "Mean Reward": 20.68140303578068, "Episode": 224, "Episode Step": 77}
{"Training Time": 0.23717353641986846, "Episode Reward": 921.4341931309319, "Mean Reward": 9.033668560107175, "Episode": 225, "Episode Step": 102}
{"Training Time": 0.23835477219687567, "Episode Reward": 2449.557707765316, "Mean Reward": 24.015271644758002, "Episode": 226, "Episode Step": 102}
{"Training Time": 0.23932774470912085, "Episode Reward": 1870.3194630486496, "Mean Reward": 22.53396943432108, "Episode": 227, "Episode Step": 83}
{"Training Time": 0.24113162332110935, "Episode Reward": 763.4796470807016, "Mean Reward": 6.638953452875667, "Episode": 228, "Episode Step": 115}
{"Training Time": 0.24227973441282907, "Episode Reward": 2069.2414736824167, "Mean Reward": 21.332386326622853, "Episode": 229, "Episode Step": 97}
{"Training Time": 0.24326008558273315, "Episode Reward": 2031.4526969674944, "Mean Reward": 23.899443493735227, "Episode": 230, "Episode Step": 85}
{"Training Time": 0.2449326627784305, "Episode Reward": 468.7915188389481, "Mean Reward": 4.507610758066809, "Episode": 231, "Episode Step": 104}
{"Training Time": 0.24604833443959553, "Episode Reward": 2095.1211606917045, "Mean Reward": 21.824178757205257, "Episode": 232, "Episode Step": 96}
{"Training Time": 0.24700053195158642, "Episode Reward": 2173.640732535283, "Mean Reward": 27.170509156691036, "Episode": 233, "Episode Step": 80}
{"Training Time": 0.24830506556563908, "Episode Reward": 47.09691267706489, "Mean Reward": 0.6541237871814568, "Episode": 234, "Episode Step": 72}
{"Training Time": 0.2494224841727151, "Episode Reward": 2115.6370532912983, "Mean Reward": 22.26986371885577, "Episode": 235, "Episode Step": 95}
{"Training Time": 0.25036739971902633, "Episode Reward": 1750.137077096706, "Mean Reward": 21.606630581440815, "Episode": 236, "Episode Step": 81}
{"Training Time": 0.2520544519689348, "Episode Reward": 283.4561162534405, "Mean Reward": 2.7789815318964752, "Episode": 237, "Episode Step": 102}
{"Training Time": 0.25310292469130624, "Episode Reward": 1790.3516473116329, "Mean Reward": 20.344905083086736, "Episode": 238, "Episode Step": 88}
{"Training Time": 0.2540409421920776, "Episode Reward": 1824.5220881619728, "Mean Reward": 23.391308822589394, "Episode": 239, "Episode Step": 78}
{"Training Time": 0.2552089830239614, "Episode Reward": -56.0995286107339, "Mean Reward": -0.9508394679785407, "Episode": 240, "Episode Step": 59}
{"Training Time": 0.2562181552913454, "Episode Reward": 1945.1822216664991, "Mean Reward": 22.884496725488226, "Episode": 241, "Episode Step": 85}
{"Training Time": 0.25712984303633374, "Episode Reward": 1758.8781917770825, "Mean Reward": 22.84257391918289, "Episode": 242, "Episode Step": 77}
{"Training Time": 0.25864912860923345, "Episode Reward": -2.260061514065171, "Mean Reward": -0.025111794600724123, "Episode": 243, "Episode Step": 90}
{"Training Time": 0.26020880414379965, "Episode Reward": 3806.04100653573, "Mean Reward": 28.616849673200978, "Episode": 244, "Episode Step": 133}
{"Training Time": 0.26107589443524676, "Episode Reward": 1847.6034738906494, "Mean Reward": 24.9676145120358, "Episode": 245, "Episode Step": 74}
{"Training Time": 0.26274225638972387, "Episode Reward": 247.88451204848317, "Mean Reward": 2.406645748043526, "Episode": 246, "Episode Step": 103}
{"Training Time": 0.2638109946913189, "Episode Reward": 2216.985340347243, "Mean Reward": 24.909947644351046, "Episode": 247, "Episode Step": 89}
{"Training Time": 0.26471830474005803, "Episode Reward": 1644.544688561892, "Mean Reward": 21.638745902130157, "Episode": 248, "Episode Step": 76}
{"Training Time": 0.2666704736153285, "Episode Reward": 316.1141568446666, "Mean Reward": 3.0395592004294865, "Episode": 249, "Episode Step": 104}
{"Training Time": 0.26799380057387884, "Episode Reward": 2112.3282594976636, "Mean Reward": 24.003730221564357, "Episode": 250, "Episode Step": 88}
{"Training Time": 0.2689301022556093, "Episode Reward": 1867.7617399619508, "Mean Reward": 23.945663332845523, "Episode": 251, "Episode Step": 78}
{"Training Time": 0.2705764658583535, "Episode Reward": 208.10421842147662, "Mean Reward": 2.060437806153234, "Episode": 252, "Episode Step": 101}
{"Training Time": 0.271767026119762, "Episode Reward": 2187.9025895300515, "Mean Reward": 21.450025387549523, "Episode": 253, "Episode Step": 102}
{"Training Time": 0.273003483083513, "Episode Reward": 2536.798836183149, "Mean Reward": 24.15998891602999, "Episode": 254, "Episode Step": 105}
{"Training Time": 0.27449277751975587, "Episode Reward": 157.31025026911595, "Mean Reward": 1.7876164803308632, "Episode": 255, "Episode Step": 88}
{"Training Time": 0.2755649799770779, "Episode Reward": 2077.2910204961863, "Mean Reward": 22.579250222784633, "Episode": 256, "Episode Step": 92}
{"Training Time": 0.27648539556397334, "Episode Reward": 1980.2182067834447, "Mean Reward": 25.717119568616166, "Episode": 257, "Episode Step": 77}
{"Training Time": 0.27775342888302273, "Episode Reward": -24.110934233073863, "Mean Reward": -0.3494338294648386, "Episode": 258, "Episode Step": 69}
{"Training Time": 0.27889268113507165, "Episode Reward": 2027.7900917605448, "Mean Reward": 20.90505249237675, "Episode": 259, "Episode Step": 97}
{"Training Time": 0.2798197525077396, "Episode Reward": 2048.5336943110005, "Mean Reward": 26.263252491166675, "Episode": 260, "Episode Step": 78}
{"Training Time": 0.28167583776844873, "Episode Reward": 871.441167970972, "Mean Reward": 7.323035024966151, "Episode": 261, "Episode Step": 119}
{"Training Time": 0.28334784362051224, "Episode Reward": 3493.811186114422, "Mean Reward": 24.955794186531588, "Episode": 262, "Episode Step": 140}
{"Training Time": 0.2842286172178056, "Episode Reward": 2280.9754088014, "Mean Reward": 30.413005450685336, "Episode": 263, "Episode Step": 75}
{"Training Time": 0.28616363611486223, "Episode Reward": 938.8507679755721, "Mean Reward": 7.277912930043195, "Episode": 264, "Episode Step": 129}
{"Training Time": 0.28735809750027125, "Episode Reward": 2209.507931176325, "Mean Reward": 21.661842462512993, "Episode": 265, "Episode Step": 102}
{"Training Time": 0.288310809135437, "Episode Reward": 2260.1715620266496, "Mean Reward": 27.903352617612956, "Episode": 266, "Episode Step": 81}
{"Training Time": 0.29002195835113526, "Episode Reward": 394.6054088656908, "Mean Reward": 3.7581467511018167, "Episode": 267, "Episode Step": 105}
{"Training Time": 0.2916579986280865, "Episode Reward": 3514.875764412831, "Mean Reward": 25.286876002970008, "Episode": 268, "Episode Step": 139}
{"Training Time": 0.2925897569126553, "Episode Reward": 1920.025420607542, "Mean Reward": 24.61571052060951, "Episode": 269, "Episode Step": 78}
{"Training Time": 0.2942356816927592, "Episode Reward": 256.2267658554854, "Mean Reward": 2.5120271162302488, "Episode": 270, "Episode Step": 102}
{"Training Time": 0.2959397863679462, "Episode Reward": 3490.1127678464836, "Mean Reward": 23.581843025989755, "Episode": 271, "Episode Step": 148}
{"Training Time": 0.29684005697568255, "Episode Reward": 1665.126200367631, "Mean Reward": 21.625015589190014, "Episode": 272, "Episode Step": 77}
{"Training Time": 0.29858381304475995, "Episode Reward": 292.7662194627246, "Mean Reward": 2.685928618924079, "Episode": 273, "Episode Step": 109}
{"Training Time": 0.29977429389953614, "Episode Reward": 1930.0823383436007, "Mean Reward": 18.922375866113732, "Episode": 274, "Episode Step": 102}
{"Training Time": 0.3006835194428762, "Episode Reward": 2040.4928619538646, "Mean Reward": 26.499907298102137, "Episode": 275, "Episode Step": 77}
{"Training Time": 0.30238064169883727, "Episode Reward": 306.59788496033246, "Mean Reward": 2.919979856765071, "Episode": 276, "Episode Step": 105}
{"Training Time": 0.3035396750105752, "Episode Reward": 1646.8600120306796, "Mean Reward": 16.977938268357523, "Episode": 277, "Episode Step": 97}
{"Training Time": 0.30447864724530116, "Episode Reward": 2254.115553351729, "Mean Reward": 28.898917350663194, "Episode": 278, "Episode Step": 78}
{"Training Time": 0.3062306008074019, "Episode Reward": 514.1813323969828, "Mean Reward": 4.805433013055914, "Episode": 279, "Episode Step": 107}
{"Training Time": 0.30804947276910144, "Episode Reward": 3479.6038047445454, "Mean Reward": 22.594829900938606, "Episode": 280, "Episode Step": 154}
{"Training Time": 0.30895141859849296, "Episode Reward": 2166.0496301507546, "Mean Reward": 28.880661735343395, "Episode": 281, "Episode Step": 75}
{"Training Time": 0.31059809969531166, "Episode Reward": 549.9482420005338, "Mean Reward": 5.3916494313777825, "Episode": 282, "Episode Step": 102}
{"Training Time": 0.3118128055334091, "Episode Reward": 2026.097463912358, "Mean Reward": 19.863700626591747, "Episode": 283, "Episode Step": 102}
{"Training Time": 0.31274802141719393, "Episode Reward": 1952.256045819448, "Mean Reward": 25.353974621031792, "Episode": 284, "Episode Step": 77}
{"Training Time": 0.3146563438574473, "Episode Reward": 666.033081554567, "Mean Reward": 5.371234528665863, "Episode": 285, "Episode Step": 124}
{"Training Time": 0.3163866474893358, "Episode Reward": 3756.803545025035, "Mean Reward": 25.556486700850577, "Episode": 286, "Episode Step": 147}
{"Training Time": 0.317299154135916, "Episode Reward": 1891.3320493566252, "Mean Reward": 24.56275388774838, "Episode": 287, "Episode Step": 77}
{"Training Time": 0.3190361789200041, "Episode Reward": 607.615478464542, "Mean Reward": 5.678649331444317, "Episode": 288, "Episode Step": 107}
{"Training Time": 0.3206311730543772, "Episode Reward": 2286.945632092666, "Mean Reward": 16.94033801550123, "Episode": 289, "Episode Step": 135}
{"Training Time": 0.32155439886781906, "Episode Reward": 2095.164946124411, "Mean Reward": 27.209934365252092, "Episode": 290, "Episode Step": 77}
{"Training Time": 0.3232586363951365, "Episode Reward": 577.7455983356181, "Mean Reward": 5.502339031767791, "Episode": 291, "Episode Step": 105}
{"Training Time": 0.32507367193698883, "Episode Reward": 3242.275971233161, "Mean Reward": 21.330762968639217, "Episode": 292, "Episode Step": 152}
{"Training Time": 0.32600807613796656, "Episode Reward": 2189.5119657553355, "Mean Reward": 27.715341338675135, "Episode": 293, "Episode Step": 79}
{"Training Time": 0.3278330628077189, "Episode Reward": 660.5666545890775, "Mean Reward": 5.744057865991978, "Episode": 294, "Episode Step": 115}
{"Training Time": 0.3289361944463518, "Episode Reward": 1436.0769202787096, "Mean Reward": 15.441687314824835, "Episode": 295, "Episode Step": 93}
{"Training Time": 0.32998416668838926, "Episode Reward": 2021.5657168846283, "Mean Reward": 22.972337691870777, "Episode": 296, "Episode Step": 88}
{"Training Time": 0.3319500286049313, "Episode Reward": 1145.655709040742, "Mean Reward": 8.950435226880797, "Episode": 297, "Episode Step": 128}
{"Training Time": 0.33299415972497726, "Episode Reward": 1587.1643364378099, "Mean Reward": 18.455399260904766, "Episode": 298, "Episode Step": 86}
{"Training Time": 0.3342455191744698, "Episode Reward": 1887.1597198340478, "Mean Reward": 22.736864094386117, "Episode": 299, "Episode Step": 83}
{"Training Time": 0.33640229807959665, "Episode Reward": 1038.093554318882, "Mean Reward": 7.208983016103348, "Episode": 300, "Episode Step": 144}
{"Training Time": 0.33801469140582613, "Episode Reward": 2836.8726503307444, "Mean Reward": 20.859357723020178, "Episode": 301, "Episode Step": 136}
{"Training Time": 0.33898247639338175, "Episode Reward": 2264.9468447060326, "Mean Reward": 27.962306724765835, "Episode": 302, "Episode Step": 81}
{"Training Time": 0.3410280578003989, "Episode Reward": 1375.6307736911954, "Mean Reward": 10.189857582897744, "Episode": 303, "Episode Step": 135}
{"Training Time": 0.34233552389674715, "Episode Reward": 2473.7552594067693, "Mean Reward": 22.488684176425174, "Episode": 304, "Episode Step": 110}
{"Training Time": 0.34328824083010356, "Episode Reward": 2318.1004325655485, "Mean Reward": 29.343043450196816, "Episode": 305, "Episode Step": 79}
{"Training Time": 0.3461101000176536, "Episode Reward": 2834.635347337695, "Mean Reward": 14.102663419590522, "Episode": 306, "Episode Step": 201}
{"Training Time": 0.3477618138657676, "Episode Reward": 2816.519638821735, "Mean Reward": 20.117997420155252, "Episode": 307, "Episode Step": 140}
{"Training Time": 0.3486613674958547, "Episode Reward": 2281.7872683544565, "Mean Reward": 30.423830244726087, "Episode": 308, "Episode Step": 75}
{"Training Time": 0.3506218852599462, "Episode Reward": 1837.6857883038015, "Mean Reward": 14.356920221123449, "Episode": 309, "Episode Step": 128}
{"Training Time": 0.3516911444399092, "Episode Reward": 1374.7595349778053, "Mean Reward": 15.275105944197836, "Episode": 310, "Episode Step": 90}
{"Training Time": 0.3526261280642615, "Episode Reward": 2015.666063468917, "Mean Reward": 25.514760297074897, "Episode": 311, "Episode Step": 79}
{"Training Time": 0.35460366136497923, "Episode Reward": 2014.569721857698, "Mean Reward": 15.496690168136137, "Episode": 312, "Episode Step": 130}
{"Training Time": 0.3560725935962465, "Episode Reward": 3092.667953006009, "Mean Reward": 24.741343624048074, "Episode": 313, "Episode Step": 125}
{"Training Time": 0.357374449968338, "Episode Reward": 3711.8695689432448, "Mean Reward": 33.74426880857495, "Episode": 314, "Episode Step": 110}
{"Training Time": 0.35946599165598553, "Episode Reward": 2463.7850531212644, "Mean Reward": 17.598464665151887, "Episode": 315, "Episode Step": 140}
{"Training Time": 0.3611679361263911, "Episode Reward": 3435.2715887750987, "Mean Reward": 23.856052699827075, "Episode": 316, "Episode Step": 144}
{"Training Time": 0.3620610586139891, "Episode Reward": 2464.811708004979, "Mean Reward": 32.864156106733056, "Episode": 317, "Episode Step": 75}
{"Training Time": 0.3637303391430113, "Episode Reward": 344.65557599738537, "Mean Reward": 3.378976235268484, "Episode": 318, "Episode Step": 102}
{"Training Time": 0.36513168474038443, "Episode Reward": 3269.455089549213, "Mean Reward": 27.474412517220276, "Episode": 319, "Episode Step": 119}
{"Training Time": 0.3661110227637821, "Episode Reward": 2133.827429647341, "Mean Reward": 26.343548514164702, "Episode": 320, "Episode Step": 81}
{"Training Time": 0.3677894758515888, "Episode Reward": 403.40211318318643, "Mean Reward": 3.916525370710548, "Episode": 321, "Episode Step": 103}
{"Training Time": 0.36917680945661335, "Episode Reward": 2741.952644605584, "Mean Reward": 23.041618862231797, "Episode": 322, "Episode Step": 119}
{"Training Time": 0.3705492385890749, "Episode Reward": 3971.3279425305514, "Mean Reward": 33.37250371874413, "Episode": 323, "Episode Step": 119}
{"Training Time": 0.37387085139751436, "Episode Reward": 5764.232710744211, "Mean Reward": 23.527480452017187, "Episode": 324, "Episode Step": 245}
{"Training Time": 0.37526438501146103, "Episode Reward": 2340.15419931537, "Mean Reward": 19.83181524843534, "Episode": 325, "Episode Step": 118}
{"Training Time": 0.37624209695392186, "Episode Reward": 1854.2330957842487, "Mean Reward": 22.612598729076204, "Episode": 326, "Episode Step": 82}
{"Training Time": 0.37790417419539557, "Episode Reward": 317.17493329971614, "Mean Reward": 3.10955816960506, "Episode": 327, "Episode Step": 102}
{"Training Time": 0.37884095973438686, "Episode Reward": 1049.1018561705703, "Mean Reward": 13.450023797058593, "Episode": 328, "Episode Step": 78}
{"Training Time": 0.3802548708518346, "Episode Reward": 4081.499383422413, "Mean Reward": 33.73139986299515, "Episode": 329, "Episode Step": 121}
{"Training Time": 0.3819190019369125, "Episode Reward": 336.3337126954655, "Mean Reward": 3.2973893401516228, "Episode": 330, "Episode Step": 102}
{"Training Time": 0.3837741086218092, "Episode Reward": 2845.585958035494, "Mean Reward": 18.010037709085406, "Episode": 331, "Episode Step": 158}
{"Training Time": 0.3852874677711063, "Episode Reward": 3835.5150702666187, "Mean Reward": 29.96496148645796, "Episode": 332, "Episode Step": 128}
{"Training Time": 0.3869461986091402, "Episode Reward": 262.5572692725881, "Mean Reward": 2.5740908752214517, "Episode": 333, "Episode Step": 102}
{"Training Time": 0.38848655303319296, "Episode Reward": 2744.191151017792, "Mean Reward": 21.607804338722772, "Episode": 334, "Episode Step": 127}
{"Training Time": 0.39030122333102757, "Episode Reward": 4187.00231404658, "Mean Reward": 27.188326714588182, "Episode": 335, "Episode Step": 154}
{"Training Time": 0.3919736583365334, "Episode Reward": 298.29213394143534, "Mean Reward": 2.840877466108908, "Episode": 336, "Episode Step": 105}
{"Training Time": 0.3934099091423882, "Episode Reward": 2540.666252197111, "Mean Reward": 20.489243969331543, "Episode": 337, "Episode Step": 124}
{"Training Time": 0.3952552691433165, "Episode Reward": 3617.019984117567, "Mean Reward": 22.748553359229984, "Episode": 338, "Episode Step": 159}
{"Training Time": 0.3968948080804613, "Episode Reward": 314.1330877121541, "Mean Reward": 3.079736154040727, "Episode": 339, "Episode Step": 102}
{"Training Time": 0.3984000125196245, "Episode Reward": 2715.3755207159456, "Mean Reward": 21.550599370761475, "Episode": 340, "Episode Step": 126}
{"Training Time": 0.40031565335061814, "Episode Reward": 3592.367347790458, "Mean Reward": 21.904678949941818, "Episode": 341, "Episode Step": 164}
{"Training Time": 0.4025306969218784, "Episode Reward": 1670.2538970525334, "Mean Reward": 10.988512480608772, "Episode": 342, "Episode Step": 152}
{"Training Time": 0.40406354275014666, "Episode Reward": 2313.1354341018214, "Mean Reward": 17.93128243489784, "Episode": 343, "Episode Step": 129}
{"Training Time": 0.406321309738689, "Episode Reward": 4605.955739835707, "Mean Reward": 23.742039896060348, "Episode": 344, "Episode Step": 194}
{"Training Time": 0.40796130306190914, "Episode Reward": 297.9495702773141, "Mean Reward": 2.9210742184050402, "Episode": 345, "Episode Step": 102}
{"Training Time": 0.40950945721732246, "Episode Reward": 2143.3110124065297, "Mean Reward": 16.237204639443405, "Episode": 346, "Episode Step": 132}
{"Training Time": 0.4111545755465825, "Episode Reward": 3833.899760475618, "Mean Reward": 27.190778443089492, "Episode": 347, "Episode Step": 141}
{"Training Time": 0.4133713280492359, "Episode Reward": 2604.7653485084024, "Mean Reward": 17.25010164575101, "Episode": 348, "Episode Step": 151}
{"Training Time": 0.4152020686202579, "Episode Reward": 1921.071111165907, "Mean Reward": 14.230156379006718, "Episode": 349, "Episode Step": 135}
{"Training Time": 0.4170049203104443, "Episode Reward": 3899.995970518283, "Mean Reward": 29.77096160700979, "Episode": 350, "Episode Step": 131}
{"Training Time": 0.4191371561421288, "Episode Reward": 2693.966052353977, "Mean Reward": 18.708097585791506, "Episode": 351, "Episode Step": 144}
{"Training Time": 0.4203888455364439, "Episode Reward": 1917.5782715361886, "Mean Reward": 17.921292257347556, "Episode": 352, "Episode Step": 107}
{"Training Time": 0.4219623855749766, "Episode Reward": 3587.429882651679, "Mean Reward": 27.384960936272357, "Episode": 353, "Episode Step": 131}
{"Training Time": 0.4242432210842768, "Episode Reward": 2553.2261371699974, "Mean Reward": 16.2625868609554, "Episode": 354, "Episode Step": 157}
{"Training Time": 0.4259306089083354, "Episode Reward": 2271.958273459327, "Mean Reward": 15.887820094121167, "Episode": 355, "Episode Step": 143}
{"Training Time": 0.42727544864018757, "Episode Reward": 3657.314132287257, "Mean Reward": 32.36561179015272, "Episode": 356, "Episode Step": 113}
{"Training Time": 0.43034204747941757, "Episode Reward": 4927.9968169791055, "Mean Reward": 21.999985790085294, "Episode": 357, "Episode Step": 224}
{"Training Time": 0.4322021863857905, "Episode Reward": 3060.6155117675976, "Mean Reward": 19.128846948547483, "Episode": 358, "Episode Step": 160}
{"Training Time": 0.433816760579745, "Episode Reward": 3862.6441642511973, "Mean Reward": 28.612178994453313, "Episode": 359, "Episode Step": 135}
{"Training Time": 0.43609887613190546, "Episode Reward": 2714.843677098575, "Mean Reward": 17.18255491834541, "Episode": 360, "Episode Step": 158}
{"Training Time": 0.4373417752981186, "Episode Reward": 1939.849125997882, "Mean Reward": 18.30046345281021, "Episode": 361, "Episode Step": 106}
{"Training Time": 0.4391594833135605, "Episode Reward": 3313.4664806363294, "Mean Reward": 21.240169747668777, "Episode": 362, "Episode Step": 156}
{"Training Time": 0.44143945025073156, "Episode Reward": 2677.236105127338, "Mean Reward": 16.83796292532917, "Episode": 363, "Episode Step": 159}
{"Training Time": 0.44321868280569715, "Episode Reward": 2794.114200342361, "Mean Reward": 18.262184315963143, "Episode": 364, "Episode Step": 153}
{"Training Time": 0.44440071086088817, "Episode Reward": 1902.5622451222646, "Mean Reward": 18.65257103061044, "Episode": 365, "Episode Step": 102}
{"Training Time": 0.4465610025326411, "Episode Reward": 2569.560219182189, "Mean Reward": 17.4800014910353, "Episode": 366, "Episode Step": 147}
{"Training Time": 0.4479380130767822, "Episode Reward": 2526.1075077336777, "Mean Reward": 21.407690743505743, "Episode": 367, "Episode Step": 118}
{"Training Time": 0.44958225667476653, "Episode Reward": 3653.3273755681103, "Mean Reward": 25.72765757442331, "Episode": 368, "Episode Step": 142}
{"Training Time": 0.4522640280591117, "Episode Reward": 4494.2552087178965, "Mean Reward": 23.407579212072378, "Episode": 369, "Episode Step": 192}
{"Training Time": 0.4538180124759674, "Episode Reward": 2280.5657758914654, "Mean Reward": 17.14711109692831, "Episode": 370, "Episode Step": 133}
{"Training Time": 0.4554156544473436, "Episode Reward": 3293.8910417173033, "Mean Reward": 24.21978707145076, "Episode": 371, "Episode Step": 136}
{"Training Time": 0.4575796427991655, "Episode Reward": 2473.10040620089, "Mean Reward": 16.59798930336168, "Episode": 372, "Episode Step": 149}
{"Training Time": 0.45893088082472483, "Episode Reward": 2337.001443176656, "Mean Reward": 20.321751679797007, "Episode": 373, "Episode Step": 115}
{"Training Time": 0.4606795013613171, "Episode Reward": 3629.8766121825, "Mean Reward": 24.19917741455, "Episode": 374, "Episode Step": 150}
{"Training Time": 0.4629235394133462, "Episode Reward": 2662.629724017452, "Mean Reward": 17.289803402710728, "Episode": 375, "Episode Step": 154}
{"Training Time": 0.46430373224947186, "Episode Reward": 1997.650835476844, "Mean Reward": 17.07393876475935, "Episode": 376, "Episode Step": 117}
{"Training Time": 0.466007033056683, "Episode Reward": 3643.9219611375015, "Mean Reward": 25.130496283706908, "Episode": 377, "Episode Step": 145}
{"Training Time": 0.46799865166346233, "Episode Reward": 2454.514638736583, "Mean Reward": 18.594807869216538, "Episode": 378, "Episode Step": 132}
{"Training Time": 0.46938130497932434, "Episode Reward": 2131.584573461858, "Mean Reward": 18.06427604628693, "Episode": 379, "Episode Step": 118}
{"Training Time": 0.4705807489156723, "Episode Reward": 1797.1318899493465, "Mean Reward": 17.618940097542612, "Episode": 380, "Episode Step": 102}
{"Training Time": 0.4728233300315009, "Episode Reward": 2443.799419727041, "Mean Reward": 15.972545226974123, "Episode": 381, "Episode Step": 153}
{"Training Time": 0.47416595028506386, "Episode Reward": 2118.184344629512, "Mean Reward": 18.580564426574668, "Episode": 382, "Episode Step": 114}
{"Training Time": 0.47601505862341986, "Episode Reward": 3015.77073201913, "Mean Reward": 19.20873077719191, "Episode": 383, "Episode Step": 157}
{"Training Time": 0.4776638827721278, "Episode Reward": 41.887592995089655, "Mean Reward": 0.4106626764224476, "Episode": 384, "Episode Step": 102}
{"Training Time": 0.4790161194403966, "Episode Reward": 2310.4392495922534, "Mean Reward": 19.917579737864255, "Episode": 385, "Episode Step": 116}
{"Training Time": 0.4805867922306061, "Episode Reward": 3432.3119275453782, "Mean Reward": 26.002363087464985, "Episode": 386, "Episode Step": 132}
{"Training Time": 0.4822723686032825, "Episode Reward": 55.8664990548, "Mean Reward": 0.5477107750470589, "Episode": 387, "Episode Step": 102}
{"Training Time": 0.4837894830438826, "Episode Reward": 2046.078051812473, "Mean Reward": 16.368624414499784, "Episode": 388, "Episode Step": 125}
{"Training Time": 0.48542931808365714, "Episode Reward": 3212.08046632913, "Mean Reward": 23.275945408182103, "Episode": 389, "Episode Step": 138}
{"Training Time": 0.4874537847439448, "Episode Reward": 1221.2166757578402, "Mean Reward": 9.251641483013941, "Episode": 390, "Episode Step": 132}
{"Training Time": 0.48888538082440697, "Episode Reward": 1867.5186237604669, "Mean Reward": 15.693433813113167, "Episode": 391, "Episode Step": 119}
{"Training Time": 0.4904353791475296, "Episode Reward": 3190.5792762212695, "Mean Reward": 24.92640059547867, "Episode": 392, "Episode Step": 128}
{"Training Time": 0.49269268029265934, "Episode Reward": 2256.3388151568715, "Mean Reward": 15.245532534843727, "Episode": 393, "Episode Step": 148}
{"Training Time": 0.4942023033565945, "Episode Reward": 1922.3241249704706, "Mean Reward": 15.378592999763764, "Episode": 394, "Episode Step": 125}
{"Training Time": 0.4957656844456991, "Episode Reward": 3652.093129356953, "Mean Reward": 28.31079945237948, "Episode": 395, "Episode Step": 129}
{"Training Time": 0.49777446971999273, "Episode Reward": 1179.7411474378032, "Mean Reward": 9.145280212696148, "Episode": 396, "Episode Step": 129}
{"Training Time": 0.4992463774813546, "Episode Reward": 2154.96940453164, "Mean Reward": 17.378785520416454, "Episode": 397, "Episode Step": 124}
{"Training Time": 0.5011573241816627, "Episode Reward": 4417.850255325654, "Mean Reward": 27.785221731607887, "Episode": 398, "Episode Step": 159}
{"Training Time": 0.5035136197010676, "Episode Reward": 2133.984765432438, "Mean Reward": 15.925259443525658, "Episode": 399, "Episode Step": 134}
{"Training Time": 0.5050492511192958, "Episode Reward": 1509.6136909646634, "Mean Reward": 14.51551625927561, "Episode": 400, "Episode Step": 104}
{"Training Time": 0.5066195436318716, "Episode Reward": 3055.540506571028, "Mean Reward": 22.633633382007613, "Episode": 401, "Episode Step": 135}
{"Training Time": 0.5084598841932085, "Episode Reward": 2176.705587800243, "Mean Reward": 19.093908664914412, "Episode": 402, "Episode Step": 114}
{"Training Time": 0.5099083661370807, "Episode Reward": 2128.3055224459085, "Mean Reward": 17.735879353715905, "Episode": 403, "Episode Step": 120}
{"Training Time": 0.5118012741539213, "Episode Reward": 2682.940828017526, "Mean Reward": 16.87384168564482, "Episode": 404, "Episode Step": 159}
{"Training Time": 0.514223271144761, "Episode Reward": 2276.593761345583, "Mean Reward": 13.797537947548989, "Episode": 405, "Episode Step": 165}
{"Training Time": 0.5155249722136391, "Episode Reward": 2988.473449951045, "Mean Reward": 27.92965841075743, "Episode": 406, "Episode Step": 107}
{"Training Time": 0.5167685891522301, "Episode Reward": 1346.101894592599, "Mean Reward": 13.197077397966655, "Episode": 407, "Episode Step": 102}
{"Training Time": 0.5192803319295247, "Episode Reward": 2212.308640498879, "Mean Reward": 13.0135802382287, "Episode": 408, "Episode Step": 170}
{"Training Time": 0.520765826370981, "Episode Reward": 2340.1448750111813, "Mean Reward": 19.18151536894411, "Episode": 409, "Episode Step": 122}
{"Training Time": 0.5212095799711015, "Episode Reward": 213.83518412105883, "Mean Reward": 5.939866225584968, "Episode": 410, "Episode Step": 36}
{"Training Time": 0.522887261112531, "Episode Reward": 41.44113584264791, "Mean Reward": 0.406285645516156, "Episode": 411, "Episode Step": 102}
{"Training Time": 0.5242302378018697, "Episode Reward": 2303.49011262463, "Mean Reward": 20.38486825331531, "Episode": 412, "Episode Step": 113}
{"Training Time": 0.5254497522115708, "Episode Reward": 899.6094902361389, "Mean Reward": 8.819700884668029, "Episode": 413, "Episode Step": 102}
{"Training Time": 0.527136208348804, "Episode Reward": 39.711285902723084, "Mean Reward": 0.3893263323796381, "Episode": 414, "Episode Step": 102}
{"Training Time": 0.5285348197486666, "Episode Reward": 2382.032686870306, "Mean Reward": 20.186717685341577, "Episode": 415, "Episode Step": 118}
{"Training Time": 0.5290356889035966, "Episode Reward": 261.0612051471528, "Mean Reward": 6.52653012867882, "Episode": 416, "Episode Step": 40}
{"Training Time": 0.5307097558180491, "Episode Reward": 60.33742536828384, "Mean Reward": 0.591543385963567, "Episode": 417, "Episode Step": 102}
{"Training Time": 0.5319233544667562, "Episode Reward": 2790.813857192609, "Mean Reward": 27.631820368243652, "Episode": 418, "Episode Step": 101}
{"Training Time": 0.5324220355351766, "Episode Reward": 150.81714183615088, "Mean Reward": 3.770428545903772, "Episode": 419, "Episode Step": 40}
{"Training Time": 0.534859317474895, "Episode Reward": 2225.051421376815, "Mean Reward": 13.165984741874645, "Episode": 420, "Episode Step": 169}
{"Training Time": 0.5362049927976397, "Episode Reward": 2506.06082103216, "Mean Reward": 21.982989658176844, "Episode": 421, "Episode Step": 114}
{"Training Time": 0.5366211911042531, "Episode Reward": 207.38422049067378, "Mean Reward": 5.92526344259068, "Episode": 422, "Episode Step": 35}
{"Training Time": 0.538265034755071, "Episode Reward": 63.81275769102082, "Mean Reward": 0.6256152714805963, "Episode": 423, "Episode Step": 102}
{"Training Time": 0.5395514433251487, "Episode Reward": 2247.2074373477103, "Mean Reward": 20.61658199401569, "Episode": 424, "Episode Step": 109}
{"Training Time": 0.5407668702469932, "Episode Reward": 1217.3945365253119, "Mean Reward": 11.935240554169724, "Episode": 425, "Episode Step": 102}
{"Training Time": 0.5424231647120582, "Episode Reward": 43.34322743317059, "Mean Reward": 0.4249336022859862, "Episode": 426, "Episode Step": 102}
{"Training Time": 0.5436678136057324, "Episode Reward": 3111.71729897863, "Mean Reward": 29.635402847415524, "Episode": 427, "Episode Step": 105}
{"Training Time": 0.5448946461412641, "Episode Reward": 1280.5765455881026, "Mean Reward": 12.554672015569633, "Episode": 428, "Episode Step": 102}
{"Training Time": 0.5465539408392376, "Episode Reward": 37.34914258777051, "Mean Reward": 0.3661680645859854, "Episode": 429, "Episode Step": 102}
{"Training Time": 0.5478818641768561, "Episode Reward": 2143.246004373491, "Mean Reward": 18.966778799765407, "Episode": 430, "Episode Step": 113}
{"Training Time": 0.5484033905797534, "Episode Reward": 526.7362537394018, "Mean Reward": 12.249680319520973, "Episode": 431, "Episode Step": 43}
{"Training Time": 0.5500770799981223, "Episode Reward": 51.93367705883064, "Mean Reward": 0.5091536966552024, "Episode": 432, "Episode Step": 102}
{"Training Time": 0.5513301261266073, "Episode Reward": 3019.2250911951023, "Mean Reward": 28.21705692705703, "Episode": 433, "Episode Step": 107}
{"Training Time": 0.5525079939100478, "Episode Reward": 1321.1150520345398, "Mean Reward": 12.952108353279801, "Episode": 434, "Episode Step": 102}
{"Training Time": 0.5541650927729077, "Episode Reward": 28.3241567481084, "Mean Reward": 0.2776878112559647, "Episode": 435, "Episode Step": 102}
{"Training Time": 0.555718202193578, "Episode Reward": 3105.817369020409, "Mean Reward": 23.89090283861853, "Episode": 436, "Episode Step": 130}
{"Training Time": 0.5570443744129605, "Episode Reward": 2086.961100520617, "Mean Reward": 18.633581254648366, "Episode": 437, "Episode Step": 112}
{"Training Time": 0.5593648413817088, "Episode Reward": 1675.277262828271, "Mean Reward": 10.34121767177945, "Episode": 438, "Episode Step": 162}
{"Training Time": 0.5608367066913181, "Episode Reward": 3338.164435185661, "Mean Reward": 26.70531548148529, "Episode": 439, "Episode Step": 125}
{"Training Time": 0.56204091363483, "Episode Reward": 1657.2040952686416, "Mean Reward": 16.247098973221977, "Episode": 440, "Episode Step": 102}
{"Training Time": 0.5636908519268036, "Episode Reward": 31.067723018341, "Mean Reward": 0.30458551978765686, "Episode": 441, "Episode Step": 102}
{"Training Time": 0.5650247527493371, "Episode Reward": 2882.711690573741, "Mean Reward": 26.206469914306737, "Episode": 442, "Episode Step": 110}
{"Training Time": 0.5663766008615494, "Episode Reward": 1897.5096285844834, "Mean Reward": 16.79212060694233, "Episode": 443, "Episode Step": 113}
{"Training Time": 0.5680343644486533, "Episode Reward": 47.6451998312227, "Mean Reward": 0.4671098022668892, "Episode": 444, "Episode Step": 102}
{"Training Time": 0.5693775049845378, "Episode Reward": 2098.8479913440033, "Mean Reward": 18.7397142084286, "Episode": 445, "Episode Step": 112}
{"Training Time": 0.5711643716361787, "Episode Reward": 2530.8692394289437, "Mean Reward": 16.760723439926778, "Episode": 446, "Episode Step": 151}
{"Training Time": 0.5728245041767757, "Episode Reward": 38.76230812610783, "Mean Reward": 0.38002262868733167, "Episode": 447, "Episode Step": 102}
{"Training Time": 0.5742087816529804, "Episode Reward": 2381.7960049558073, "Mean Reward": 20.357230811588096, "Episode": 448, "Episode Step": 117}
{"Training Time": 0.5759308941496744, "Episode Reward": 1871.9463795590498, "Mean Reward": 16.864381797829278, "Episode": 449, "Episode Step": 111}
{"Training Time": 0.5776074900229772, "Episode Reward": 41.43685067484112, "Mean Reward": 0.40624363406706976, "Episode": 450, "Episode Step": 102}
{"Training Time": 0.5788917277918921, "Episode Reward": 2652.639460430573, "Mean Reward": 24.336141838812594, "Episode": 451, "Episode Step": 109}
{"Training Time": 0.580442134141922, "Episode Reward": 2477.7517966578457, "Mean Reward": 18.91413585234997, "Episode": 452, "Episode Step": 131}
{"Training Time": 0.5821026953061422, "Episode Reward": 30.108543701710317, "Mean Reward": 0.29518180099715996, "Episode": 453, "Episode Step": 102}
{"Training Time": 0.5834819208251105, "Episode Reward": 2515.5497272423554, "Mean Reward": 22.06622567756452, "Episode": 454, "Episode Step": 114}
{"Training Time": 0.5852794688940048, "Episode Reward": 2340.933810136812, "Mean Reward": 15.502872914813326, "Episode": 455, "Episode Step": 151}
{"Training Time": 0.5873499066962136, "Episode Reward": 641.4466614099648, "Mean Reward": 4.822907228646352, "Episode": 456, "Episode Step": 133}
{"Training Time": 0.5887566277715894, "Episode Reward": 2535.9350467973086, "Mean Reward": 21.49097497285855, "Episode": 457, "Episode Step": 118}
{"Training Time": 0.5892664900090959, "Episode Reward": 315.38701313634454, "Mean Reward": 7.692366174057184, "Episode": 458, "Episode Step": 41}
{"Training Time": 0.5909294264184104, "Episode Reward": 42.0193046731504, "Mean Reward": 0.41195396738382745, "Episode": 459, "Episode Step": 102}
{"Training Time": 0.59222482919693, "Episode Reward": 2783.815601875522, "Mean Reward": 25.539592677757085, "Episode": 460, "Episode Step": 109}
{"Training Time": 0.5926835052834617, "Episode Reward": 317.6230081563824, "Mean Reward": 8.584405625848174, "Episode": 461, "Episode Step": 37}
{"Training Time": 0.5943431925111347, "Episode Reward": 40.160383551330106, "Mean Reward": 0.3937292505032363, "Episode": 462, "Episode Step": 102}
{"Training Time": 0.5958700727754169, "Episode Reward": 3345.560383188064, "Mean Reward": 25.934576613860962, "Episode": 463, "Episode Step": 129}
{"Training Time": 0.5963419366545147, "Episode Reward": 383.7955392964624, "Mean Reward": 9.840911264011856, "Episode": 464, "Episode Step": 39}
{"Training Time": 0.5981189513868755, "Episode Reward": 619.3939710694183, "Mean Reward": 5.5303033131198065, "Episode": 465, "Episode Step": 112}
{"Training Time": 0.5993774380286535, "Episode Reward": 3150.3155915769266, "Mean Reward": 29.442201790438567, "Episode": 466, "Episode Step": 107}
{"Training Time": 0.6009097219175763, "Episode Reward": 2050.511931025768, "Mean Reward": 15.534181295649756, "Episode": 467, "Episode Step": 132}
{"Training Time": 0.6025648044215308, "Episode Reward": 366.47487845538615, "Mean Reward": 3.5928909652488836, "Episode": 468, "Episode Step": 102}
{"Training Time": 0.603850190308359, "Episode Reward": 2953.7669367168364, "Mean Reward": 27.09877923593428, "Episode": 469, "Episode Step": 109}
{"Training Time": 0.6043032044172287, "Episode Reward": 495.2162501196906, "Mean Reward": 13.384222976207854, "Episode": 470, "Episode Step": 37}
{"Training Time": 0.6059924730327394, "Episode Reward": 670.3095890869065, "Mean Reward": 6.383900848446729, "Episode": 471, "Episode Step": 105}
{"Training Time": 0.6075397080845303, "Episode Reward": 2997.164052259427, "Mean Reward": 22.87911490274372, "Episode": 472, "Episode Step": 131}
{"Training Time": 0.6095369055536058, "Episode Reward": 3174.648796273625, "Mean Reward": 18.457260443451307, "Episode": 473, "Episode Step": 172}
{"Training Time": 0.6108926841947767, "Episode Reward": 307.02081687309146, "Mean Reward": 3.987283336014175, "Episode": 474, "Episode Step": 77}
{"Training Time": 0.6123154136207368, "Episode Reward": 2561.1203106718685, "Mean Reward": 21.16628355927164, "Episode": 475, "Episode Step": 121}
{"Training Time": 0.6138881669441859, "Episode Reward": 2765.9666516637153, "Mean Reward": 20.64154217659489, "Episode": 476, "Episode Step": 134}
{"Training Time": 0.6150494913922416, "Episode Reward": 65.59969164044242, "Mean Reward": 1.0754047809908593, "Episode": 477, "Episode Step": 61}
{"Training Time": 0.6163171780771679, "Episode Reward": 2676.0890757349616, "Mean Reward": 24.55127592417396, "Episode": 478, "Episode Step": 109}
{"Training Time": 0.6170890594191022, "Episode Reward": 1361.6617094203002, "Mean Reward": 20.6312380215197, "Episode": 479, "Episode Step": 66}
{"Training Time": 0.6184501486354405, "Episode Reward": 438.6099248263871, "Mean Reward": 5.927161146302528, "Episode": 480, "Episode Step": 74}
{"Training Time": 0.6198015764024523, "Episode Reward": 2663.5286615687914, "Mean Reward": 22.961453979041305, "Episode": 481, "Episode Step": 116}
{"Training Time": 0.621029346121682, "Episode Reward": 2584.491557553028, "Mean Reward": 25.092151044204154, "Episode": 482, "Episode Step": 103}
{"Training Time": 0.6226793652772904, "Episode Reward": 34.003081352190776, "Mean Reward": 0.333363542668537, "Episode": 483, "Episode Step": 102}
{"Training Time": 0.6242978083425098, "Episode Reward": 3168.249503684945, "Mean Reward": 23.125908786021498, "Episode": 484, "Episode Step": 137}
{"Training Time": 0.6250844811068641, "Episode Reward": 1484.6711642913044, "Mean Reward": 22.15927110882544, "Episode": 485, "Episode Step": 67}
{"Training Time": 0.6267666186226739, "Episode Reward": 488.2354884302453, "Mean Reward": 4.78662243559064, "Episode": 486, "Episode Step": 102}
{"Training Time": 0.6283368597428004, "Episode Reward": 2844.105643133793, "Mean Reward": 21.38425295589318, "Episode": 487, "Episode Step": 133}
{"Training Time": 0.6291686680581835, "Episode Reward": 1281.823097461165, "Mean Reward": 18.053846443115, "Episode": 488, "Episode Step": 71}
{"Training Time": 0.630678229994244, "Episode Reward": 105.29048034070337, "Mean Reward": 1.1964827311443564, "Episode": 489, "Episode Step": 88}
{"Training Time": 0.6321646641360389, "Episode Reward": 3509.177691495962, "Mean Reward": 27.415450714812202, "Episode": 490, "Episode Step": 128}
{"Training Time": 0.6329396186272304, "Episode Reward": 1473.2039845039494, "Mean Reward": 23.01881225787421, "Episode": 491, "Episode Step": 64}
{"Training Time": 0.6342923652463489, "Episode Reward": 140.24132929670606, "Mean Reward": 1.845280648640869, "Episode": 492, "Episode Step": 76}
{"Training Time": 0.6356155311399035, "Episode Reward": 2812.426301647608, "Mean Reward": 25.33717388871719, "Episode": 493, "Episode Step": 111}
{"Training Time": 0.6365047266748216, "Episode Reward": 1707.8613192269968, "Mean Reward": 23.079207016581037, "Episode": 494, "Episode Step": 74}
{"Training Time": 0.6377772683567471, "Episode Reward": 302.8374434051429, "Mean Reward": 4.265316104297788, "Episode": 495, "Episode Step": 71}
{"Training Time": 0.6390699950191709, "Episode Reward": 2681.082369204298, "Mean Reward": 24.15389521805674, "Episode": 496, "Episode Step": 111}
{"Training Time": 0.639817352493604, "Episode Reward": 1374.109230157568, "Mean Reward": 22.16305209931561, "Episode": 497, "Episode Step": 62}
{"Training Time": 0.6409351072046492, "Episode Reward": 136.27530337431836, "Mean Reward": 2.47773278862397, "Episode": 498, "Episode Step": 55}
{"Training Time": 0.642956907749176, "Episode Reward": 2878.7329451236815, "Mean Reward": 20.416545710097033, "Episode": 499, "Episode Step": 141}
{"Training Time": 0.644855392244127, "Episode Reward": 2918.558476784005, "Mean Reward": 20.996823573985647, "Episode": 500, "Episode Step": 139}
{"Training Time": 0.646640466120508, "Episode Reward": 1518.1675736764894, "Mean Reward": 13.087651497211116, "Episode": 501, "Episode Step": 116}
{"Training Time": 0.6479233349694146, "Episode Reward": 2761.3502004885113, "Mean Reward": 25.103183640804648, "Episode": 502, "Episode Step": 110}
{"Training Time": 0.6493499991628858, "Episode Reward": 3411.790619260934, "Mean Reward": 28.196616688106893, "Episode": 503, "Episode Step": 121}
{"Training Time": 0.6510727269781961, "Episode Reward": 1488.730455741544, "Mean Reward": 14.044626940957961, "Episode": 504, "Episode Step": 106}
{"Training Time": 0.6525619377692541, "Episode Reward": 4278.626059186887, "Mean Reward": 33.68996896997549, "Episode": 505, "Episode Step": 127}
{"Training Time": 0.6533880060911179, "Episode Reward": 1811.0249806241054, "Mean Reward": 27.030223591404557, "Episode": 506, "Episode Step": 67}
{"Training Time": 0.6550632339053684, "Episode Reward": 1451.5091432206527, "Mean Reward": 14.230481796280909, "Episode": 507, "Episode Step": 102}
{"Training Time": 0.656271748609013, "Episode Reward": 3743.2356062692197, "Mean Reward": 36.69838829675706, "Episode": 508, "Episode Step": 102}
{"Training Time": 0.6577535055743323, "Episode Reward": 3204.217252037163, "Mean Reward": 25.230057102654825, "Episode": 509, "Episode Step": 127}
{"Training Time": 0.658961040576299, "Episode Reward": 253.77066348217244, "Mean Reward": 4.028105769558293, "Episode": 510, "Episode Step": 63}
{"Training Time": 0.660503206120597, "Episode Reward": 3398.6207272275014, "Mean Reward": 25.943669673492376, "Episode": 511, "Episode Step": 131}
{"Training Time": 0.6613237563769022, "Episode Reward": 1278.0284656802896, "Mean Reward": 18.79453626000426, "Episode": 512, "Episode Step": 68}
{"Training Time": 0.6626163966788186, "Episode Reward": 284.16422473318164, "Mean Reward": 3.9467253435164116, "Episode": 513, "Episode Step": 72}
{"Training Time": 0.6639032969209883, "Episode Reward": 3382.2920098609006, "Mean Reward": 31.317518609823153, "Episode": 514, "Episode Step": 108}
{"Training Time": 0.6646960041920345, "Episode Reward": 1598.965538631462, "Mean Reward": 23.8651572930069, "Episode": 515, "Episode Step": 67}
{"Training Time": 0.6664374180634817, "Episode Reward": 1963.1874168565869, "Mean Reward": 18.01089373262924, "Episode": 516, "Episode Step": 109}
{"Training Time": 0.6677189189195633, "Episode Reward": 2483.174368233586, "Mean Reward": 23.426173285222507, "Episode": 517, "Episode Step": 106}
{"Training Time": 0.6689203133185705, "Episode Reward": 2693.8523521053576, "Mean Reward": 26.410317177503504, "Episode": 518, "Episode Step": 102}
{"Training Time": 0.6705669603082869, "Episode Reward": 2088.9586931177587, "Mean Reward": 20.479987187429007, "Episode": 519, "Episode Step": 102}
{"Training Time": 0.6720611669619878, "Episode Reward": 3380.361219072529, "Mean Reward": 26.409072024004132, "Episode": 520, "Episode Step": 128}
{"Training Time": 0.67285126083427, "Episode Reward": 1666.975151402368, "Mean Reward": 25.257199263672245, "Episode": 521, "Episode Step": 66}
{"Training Time": 0.6744130135907067, "Episode Reward": 666.26745125404, "Mean Reward": 7.087951609085532, "Episode": 522, "Episode Step": 94}
{"Training Time": 0.6756537933482064, "Episode Reward": 2763.5437884272524, "Mean Reward": 26.071167815351437, "Episode": 523, "Episode Step": 106}
{"Training Time": 0.6770256502760781, "Episode Reward": 2667.018080334337, "Mean Reward": 22.411916641465016, "Episode": 524, "Episode Step": 119}
{"Training Time": 0.6786848797400793, "Episode Reward": 1276.5456168975936, "Mean Reward": 12.515153106839152, "Episode": 525, "Episode Step": 102}
{"Training Time": 0.6802040966351827, "Episode Reward": 3398.346954912789, "Mean Reward": 26.141130422406068, "Episode": 526, "Episode Step": 130}
{"Training Time": 0.6815313338571125, "Episode Reward": 2920.688611328102, "Mean Reward": 25.846801870160196, "Episode": 527, "Episode Step": 113}
{"Training Time": 0.683197578324212, "Episode Reward": 2580.758234687344, "Mean Reward": 24.814983025839847, "Episode": 528, "Episode Step": 104}
{"Training Time": 0.6846211930778292, "Episode Reward": 4129.409531391438, "Mean Reward": 34.127351499102794, "Episode": 529, "Episode Step": 121}
{"Training Time": 0.6853577058182823, "Episode Reward": 1727.0970436399841, "Mean Reward": 28.313066289180068, "Episode": 530, "Episode Step": 61}
{"Training Time": 0.6869744008117252, "Episode Reward": 1410.1913518376812, "Mean Reward": 14.101913518376811, "Episode": 531, "Episode Step": 100}
{"Training Time": 0.6886511574851142, "Episode Reward": 4378.723407856902, "Mean Reward": 30.198092467978633, "Episode": 532, "Episode Step": 145}
{"Training Time": 0.689474122789171, "Episode Reward": 1728.8362063818483, "Mean Reward": 25.424061858556595, "Episode": 533, "Episode Step": 68}
{"Training Time": 0.6914256083303028, "Episode Reward": 3510.6286640271437, "Mean Reward": 27.214175690132898, "Episode": 534, "Episode Step": 129}
{"Training Time": 0.6928273336092631, "Episode Reward": 3290.4186507754575, "Mean Reward": 27.19354256839221, "Episode": 535, "Episode Step": 121}
{"Training Time": 0.6936036805311839, "Episode Reward": 1684.2477440223643, "Mean Reward": 25.518905212460066, "Episode": 536, "Episode Step": 66}
{"Training Time": 0.6956415969133377, "Episode Reward": 2775.8344695172436, "Mean Reward": 20.261565470928787, "Episode": 537, "Episode Step": 137}
{"Training Time": 0.697032649450832, "Episode Reward": 3902.3109897024397, "Mean Reward": 33.07043211612237, "Episode": 538, "Episode Step": 118}
{"Training Time": 0.6978336052762137, "Episode Reward": 1842.0022575643134, "Mean Reward": 27.492571008422587, "Episode": 539, "Episode Step": 67}
{"Training Time": 0.699588550262981, "Episode Reward": 2680.512480868328, "Mean Reward": 24.368295280621165, "Episode": 540, "Episode Step": 110}
{"Training Time": 0.7008043327596453, "Episode Reward": 3245.30369880427, "Mean Reward": 31.50780290101233, "Episode": 541, "Episode Step": 103}
{"Training Time": 0.7015214638577567, "Episode Reward": 2129.6533446101816, "Mean Reward": 34.91234991164232, "Episode": 542, "Episode Step": 61}
{"Training Time": 0.7035491216844982, "Episode Reward": 2431.8724147122284, "Mean Reward": 17.881414814060502, "Episode": 543, "Episode Step": 136}
{"Training Time": 0.7047813161214193, "Episode Reward": 3106.4349471279784, "Mean Reward": 29.30599006724508, "Episode": 544, "Episode Step": 106}
{"Training Time": 0.7055325027969148, "Episode Reward": 1872.4628655083752, "Mean Reward": 29.721632785847227, "Episode": 545, "Episode Step": 63}
{"Training Time": 0.7075038446982702, "Episode Reward": 3264.163624943291, "Mean Reward": 24.91727957971978, "Episode": 546, "Episode Step": 131}
{"Training Time": 0.7088540424903234, "Episode Reward": 3165.2016810703067, "Mean Reward": 27.053005821113732, "Episode": 547, "Episode Step": 117}
{"Training Time": 0.7096052186356651, "Episode Reward": 1337.1499821126777, "Mean Reward": 20.89296847051059, "Episode": 548, "Episode Step": 64}
{"Training Time": 0.7115838669406043, "Episode Reward": 1221.1038236205668, "Mean Reward": 12.71983149604757, "Episode": 549, "Episode Step": 96}
{"Training Time": 0.7133330233229531, "Episode Reward": 3511.286989553884, "Mean Reward": 27.647929051605384, "Episode": 550, "Episode Step": 127}
{"Training Time": 0.7145671877596114, "Episode Reward": 2140.9053542578813, "Mean Reward": 20.58562840632578, "Episode": 551, "Episode Step": 104}
{"Training Time": 0.7161505136224958, "Episode Reward": 920.3834535667677, "Mean Reward": 9.488489212028533, "Episode": 552, "Episode Step": 97}
{"Training Time": 0.7175746458106571, "Episode Reward": 3785.957098706015, "Mean Reward": 30.78013901387004, "Episode": 553, "Episode Step": 123}
{"Training Time": 0.7183242850171195, "Episode Reward": 1661.6546304850017, "Mean Reward": 26.37547032515876, "Episode": 554, "Episode Step": 63}
{"Training Time": 0.7192556027571361, "Episode Reward": 134.1286235165482, "Mean Reward": 3.439195474783287, "Episode": 555, "Episode Step": 39}
{"Training Time": 0.7207288591729271, "Episode Reward": 3406.1402753671427, "Mean Reward": 27.032859328310657, "Episode": 556, "Episode Step": 126}
{"Training Time": 0.7215699625015258, "Episode Reward": 1728.9500333725493, "Mean Reward": 25.05724686047173, "Episode": 557, "Episode Step": 69}
{"Training Time": 0.7236547380685806, "Episode Reward": 3269.1758497566266, "Mean Reward": 23.18564432451508, "Episode": 558, "Episode Step": 141}
{"Training Time": 0.7250703744755851, "Episode Reward": 3832.625198523291, "Mean Reward": 31.159554459538953, "Episode": 559, "Episode Step": 123}
{"Training Time": 0.7257973900106218, "Episode Reward": 1427.6711270866608, "Mean Reward": 23.02695366268808, "Episode": 560, "Episode Step": 62}
{"Training Time": 0.7274621338976754, "Episode Reward": 1400.977727850125, "Mean Reward": 13.60172551310801, "Episode": 561, "Episode Step": 103}
{"Training Time": 0.7286729583475324, "Episode Reward": 3586.807844192084, "Mean Reward": 34.823377128078484, "Episode": 562, "Episode Step": 103}
{"Training Time": 0.729435535536872, "Episode Reward": 1647.9090577268125, "Mean Reward": 25.352447041950963, "Episode": 563, "Episode Step": 65}
{"Training Time": 0.7314997152487437, "Episode Reward": 3421.4862947221964, "Mean Reward": 24.97435251622041, "Episode": 564, "Episode Step": 137}
{"Training Time": 0.7326758183373345, "Episode Reward": 4181.868055662607, "Mean Reward": 40.99870642806477, "Episode": 565, "Episode Step": 102}
{"Training Time": 0.7333913047446144, "Episode Reward": 1731.1015941839344, "Mean Reward": 28.851693236398905, "Episode": 566, "Episode Step": 60}
{"Training Time": 0.734585996137725, "Episode Reward": 421.7012245225101, "Mean Reward": 6.8016326535888725, "Episode": 567, "Episode Step": 62}
{"Training Time": 0.7361068655384911, "Episode Reward": 4051.7550355398257, "Mean Reward": 31.903582957006503, "Episode": 568, "Episode Step": 127}
{"Training Time": 0.7369015158547295, "Episode Reward": 1493.92411637639, "Mean Reward": 22.983447944252152, "Episode": 569, "Episode Step": 65}
{"Training Time": 0.7385699947012795, "Episode Reward": 1408.110556252662, "Mean Reward": 13.80500545345747, "Episode": 570, "Episode Step": 102}
{"Training Time": 0.7400486419598261, "Episode Reward": 4002.976785625726, "Mean Reward": 31.7696570287756, "Episode": 571, "Episode Step": 126}
{"Training Time": 0.7407503547271093, "Episode Reward": 1174.057459244295, "Mean Reward": 19.56762432073825, "Episode": 572, "Episode Step": 60}
{"Training Time": 0.7427800363964505, "Episode Reward": 1327.5290243093534, "Mean Reward": 9.981421235408673, "Episode": 573, "Episode Step": 133}
{"Training Time": 0.7442802453041076, "Episode Reward": 3883.4670072661124, "Mean Reward": 30.10439540516366, "Episode": 574, "Episode Step": 129}
{"Training Time": 0.7450021855698692, "Episode Reward": 1381.6577466493386, "Mean Reward": 22.65012699425145, "Episode": 575, "Episode Step": 61}
{"Training Time": 0.7466968386040793, "Episode Reward": 573.9322439858761, "Mean Reward": 5.626786705743883, "Episode": 576, "Episode Step": 102}
{"Training Time": 0.7482004000080956, "Episode Reward": 4049.501411233101, "Mean Reward": 31.885837883725205, "Episode": 577, "Episode Step": 127}
{"Training Time": 0.7489413752820757, "Episode Reward": 1322.750220119998, "Mean Reward": 21.684429838032752, "Episode": 578, "Episode Step": 61}
{"Training Time": 0.7504942944314745, "Episode Reward": 1111.0753406955168, "Mean Reward": 11.947046674145342, "Episode": 579, "Episode Step": 93}
{"Training Time": 0.7517371741930644, "Episode Reward": 3739.8017556031623, "Mean Reward": 35.28114863776568, "Episode": 580, "Episode Step": 106}
{"Training Time": 0.7524333447217941, "Episode Reward": 1541.5973208180224, "Mean Reward": 26.579264152034867, "Episode": 581, "Episode Step": 58}
{"Training Time": 0.7544373913606008, "Episode Reward": 2410.7686049545314, "Mean Reward": 18.126079736500238, "Episode": 582, "Episode Step": 133}
{"Training Time": 0.755979781680637, "Episode Reward": 3817.936465088792, "Mean Reward": 29.14455316861673, "Episode": 583, "Episode Step": 131}
{"Training Time": 0.7566947438981798, "Episode Reward": 1301.6828559312914, "Mean Reward": 22.06242128697104, "Episode": 584, "Episode Step": 59}
{"Training Time": 0.758703471687105, "Episode Reward": 2786.6957770548975, "Mean Reward": 21.27248684774731, "Episode": 585, "Episode Step": 131}
{"Training Time": 0.7602546027633879, "Episode Reward": 4353.979051217625, "Mean Reward": 33.492146547827886, "Episode": 586, "Episode Step": 130}
{"Training Time": 0.7610015496942732, "Episode Reward": 1849.18034455915, "Mean Reward": 30.31443187801885, "Episode": 587, "Episode Step": 61}
{"Training Time": 0.7628153055244022, "Episode Reward": 2145.8999625519223, "Mean Reward": 18.823683882034405, "Episode": 588, "Episode Step": 114}
{"Training Time": 0.7640330835845736, "Episode Reward": 3850.060037413354, "Mean Reward": 37.01980805205148, "Episode": 589, "Episode Step": 104}
{"Training Time": 0.764761003057162, "Episode Reward": 1793.5081967011242, "Mean Reward": 29.401773716411874, "Episode": 590, "Episode Step": 61}
{"Training Time": 0.765771731932958, "Episode Reward": 114.49575902431269, "Mean Reward": 2.602176341461652, "Episode": 591, "Episode Step": 44}
{"Training Time": 0.7672506191995409, "Episode Reward": 4261.906610988295, "Mean Reward": 34.37021460474431, "Episode": 592, "Episode Step": 124}
{"Training Time": 0.7679858764012655, "Episode Reward": 1416.1198513988686, "Mean Reward": 23.601997523314477, "Episode": 593, "Episode Step": 60}
{"Training Time": 0.7691200830539068, "Episode Reward": 539.3294582072499, "Mean Reward": 9.630883182272319, "Episode": 594, "Episode Step": 56}
{"Training Time": 0.7706530853112539, "Episode Reward": 3691.2501487617483, "Mean Reward": 28.83789178720116, "Episode": 595, "Episode Step": 128}
{"Training Time": 0.7713269450267156, "Episode Reward": 1739.8397993790677, "Mean Reward": 31.633450897801232, "Episode": 596, "Episode Step": 55}
{"Training Time": 0.7723832416534424, "Episode Reward": 52.744254264734394, "Mean Reward": 1.0548850852946878, "Episode": 597, "Episode Step": 50}
{"Training Time": 0.7738378291659885, "Episode Reward": 4276.713907867568, "Mean Reward": 34.21371126294054, "Episode": 598, "Episode Step": 125}
{"Training Time": 0.7748795500066545, "Episode Reward": 1499.7776520248935, "Mean Reward": 24.99629420041489, "Episode": 599, "Episode Step": 60}
{"Training Time": 0.7768223947286605, "Episode Reward": 2832.9052768007805, "Mean Reward": 22.48337521270461, "Episode": 600, "Episode Step": 126}
{"Training Time": 0.7783434905608495, "Episode Reward": 4120.644712079722, "Mean Reward": 31.942982264183893, "Episode": 601, "Episode Step": 129}
{"Training Time": 0.779091769721773, "Episode Reward": 1487.9674176108933, "Mean Reward": 23.61853043826815, "Episode": 602, "Episode Step": 63}
{"Training Time": 0.7815292563703325, "Episode Reward": 3089.149705122718, "Mean Reward": 18.278992338004247, "Episode": 603, "Episode Step": 169}
{"Training Time": 0.7830429180463155, "Episode Reward": 3929.555430454228, "Mean Reward": 30.461670003521146, "Episode": 604, "Episode Step": 129}
{"Training Time": 0.7835567286279467, "Episode Reward": 385.59986412387946, "Mean Reward": 9.180949145806654, "Episode": 605, "Episode Step": 42}
{"Training Time": 0.7856191653013229, "Episode Reward": 2035.8274682474782, "Mean Reward": 14.860054512755315, "Episode": 606, "Episode Step": 137}
{"Training Time": 0.7871432136164771, "Episode Reward": 4023.435638419673, "Mean Reward": 30.949504910920563, "Episode": 607, "Episode Step": 130}
{"Training Time": 0.7878544302781423, "Episode Reward": 1580.0290260360835, "Mean Reward": 26.33381710060139, "Episode": 608, "Episode Step": 60}
{"Training Time": 0.7896780966387855, "Episode Reward": 1615.6330600034507, "Mean Reward": 13.9278712069263, "Episode": 609, "Episode Step": 116}
{"Training Time": 0.7909159144428042, "Episode Reward": 3386.4738655322785, "Mean Reward": 32.25213205268837, "Episode": 610, "Episode Step": 105}
{"Training Time": 0.7916559180286196, "Episode Reward": 1630.642659309342, "Mean Reward": 26.300688053376483, "Episode": 611, "Episode Step": 62}
{"Training Time": 0.7936909121937222, "Episode Reward": 2037.1944372979776, "Mean Reward": 15.090329165170205, "Episode": 612, "Episode Step": 135}
{"Training Time": 0.7951939394738939, "Episode Reward": 4136.856446583926, "Mean Reward": 32.0686546246816, "Episode": 613, "Episode Step": 129}
{"Training Time": 0.7962633411089579, "Episode Reward": 2702.4561084231445, "Mean Reward": 29.697319872781808, "Episode": 614, "Episode Step": 91}
{"Training Time": 0.7979677880472608, "Episode Reward": 2484.886389189569, "Mean Reward": 23.665584658948276, "Episode": 615, "Episode Step": 105}
{"Training Time": 0.7995486288600497, "Episode Reward": 3834.595349614171, "Mean Reward": 28.831543982061437, "Episode": 616, "Episode Step": 133}
{"Training Time": 0.800337378581365, "Episode Reward": 1609.37346726388, "Mean Reward": 24.384446473695153, "Episode": 617, "Episode Step": 66}
{"Training Time": 0.8017117275132073, "Episode Reward": 1220.2663342948742, "Mean Reward": 15.847614731102263, "Episode": 618, "Episode Step": 77}
{"Training Time": 0.803235212498241, "Episode Reward": 4106.347688338215, "Mean Reward": 31.346165559833707, "Episode": 619, "Episode Step": 131}
{"Training Time": 0.8039906477928161, "Episode Reward": 1431.007068272805, "Mean Reward": 23.080759165690406, "Episode": 620, "Episode Step": 62}
{"Training Time": 0.8060449463791317, "Episode Reward": 2786.2904105556554, "Mean Reward": 20.190510221417792, "Episode": 621, "Episode Step": 138}
{"Training Time": 0.807569142513805, "Episode Reward": 4296.374191970947, "Mean Reward": 33.04903224593036, "Episode": 622, "Episode Step": 130}
{"Training Time": 0.808701087501314, "Episode Reward": 2813.3058116982925, "Mean Reward": 29.613745386297815, "Episode": 623, "Episode Step": 95}
{"Training Time": 0.8107967430353165, "Episode Reward": 2858.9712332904965, "Mean Reward": 20.568138368996376, "Episode": 624, "Episode Step": 139}
{"Training Time": 0.812288096414672, "Episode Reward": 4298.279837511735, "Mean Reward": 34.386238700093884, "Episode": 625, "Episode Step": 125}
{"Training Time": 0.8130575413836373, "Episode Reward": 1195.4050206285915, "Mean Reward": 18.678203447321742, "Episode": 626, "Episode Step": 64}
{"Training Time": 0.8150344436036215, "Episode Reward": 3268.9345135333197, "Mean Reward": 25.145650104102458, "Episode": 627, "Episode Step": 130}
{"Training Time": 0.8164828766716851, "Episode Reward": 4361.848471971411, "Mean Reward": 35.46218269895456, "Episode": 628, "Episode Step": 123}
{"Training Time": 0.8172170625130335, "Episode Reward": 1746.5064247630276, "Mean Reward": 28.1694584639198, "Episode": 629, "Episode Step": 62}
{"Training Time": 0.8189289038711124, "Episode Reward": 2171.091493740875, "Mean Reward": 20.102699016119214, "Episode": 630, "Episode Step": 108}
{"Training Time": 0.8204205899768405, "Episode Reward": 3626.2368947666246, "Mean Reward": 28.329975740364254, "Episode": 631, "Episode Step": 128}
{"Training Time": 0.8215681027703815, "Episode Reward": 2622.9718218929743, "Mean Reward": 26.765018590744635, "Episode": 632, "Episode Step": 98}
{"Training Time": 0.8240752558575736, "Episode Reward": 2681.682431363832, "Mean Reward": 15.23683199638541, "Episode": 633, "Episode Step": 176}
{"Training Time": 0.8253568394316567, "Episode Reward": 3598.120404349023, "Mean Reward": 33.31592966989836, "Episode": 634, "Episode Step": 108}
{"Training Time": 0.8261096639103359, "Episode Reward": 1223.7709865354095, "Mean Reward": 19.42493629421285, "Episode": 635, "Episode Step": 63}
{"Training Time": 0.8282348803016875, "Episode Reward": 2398.418115947433, "Mean Reward": 17.010057559910873, "Episode": 636, "Episode Step": 141}
{"Training Time": 0.8297703939014011, "Episode Reward": 4581.366773734191, "Mean Reward": 35.51447111421854, "Episode": 637, "Episode Step": 129}
{"Training Time": 0.8304829811387592, "Episode Reward": 1494.0180673158504, "Mean Reward": 24.90030112193084, "Episode": 638, "Episode Step": 60}
{"Training Time": 0.8316191016965442, "Episode Reward": 43.56648816169573, "Mean Reward": 0.792117966576286, "Episode": 639, "Episode Step": 55}
{"Training Time": 0.8332267644670275, "Episode Reward": 4813.583288327748, "Mean Reward": 36.192355551336455, "Episode": 640, "Episode Step": 133}
{"Training Time": 0.833975782195727, "Episode Reward": 1563.5809101084765, "Mean Reward": 25.219046937233493, "Episode": 641, "Episode Step": 62}
{"Training Time": 0.8357816644509634, "Episode Reward": 1315.0690572328165, "Mean Reward": 11.53569348449839, "Episode": 642, "Episode Step": 114}
{"Training Time": 0.8372892366515265, "Episode Reward": 4171.3249272579205, "Mean Reward": 32.8450781673852, "Episode": 643, "Episode Step": 127}
{"Training Time": 0.838576693865988, "Episode Reward": 1817.7782027262715, "Mean Reward": 16.831279654872883, "Episode": 644, "Episode Step": 108}
{"Training Time": 0.8396831797228919, "Episode Reward": 83.80685186516797, "Mean Reward": 1.6116702281763071, "Episode": 645, "Episode Step": 52}
{"Training Time": 0.8411370102564494, "Episode Reward": 4562.85218214791, "Mean Reward": 37.09635920445455, "Episode": 646, "Episode Step": 123}
{"Training Time": 0.8418265389071571, "Episode Reward": 1196.0793141863362, "Mean Reward": 20.983847617304143, "Episode": 647, "Episode Step": 57}
{"Training Time": 0.8441995569732454, "Episode Reward": 4524.432597946814, "Mean Reward": 27.757255202127695, "Episode": 648, "Episode Step": 163}
{"Training Time": 0.8460578111145232, "Episode Reward": 4885.175697753521, "Mean Reward": 38.771235696456515, "Episode": 649, "Episode Step": 126}
{"Training Time": 0.8470241910881466, "Episode Reward": 1162.033692483972, "Mean Reward": 20.750601651499498, "Episode": 650, "Episode Step": 56}
{"Training Time": 0.8491915780305862, "Episode Reward": 2843.0820871224164, "Mean Reward": 19.607462669809767, "Episode": 651, "Episode Step": 145}
{"Training Time": 0.8507031724850337, "Episode Reward": 4007.585514925918, "Mean Reward": 31.55579145610959, "Episode": 652, "Episode Step": 127}
{"Training Time": 0.8519004097249773, "Episode Reward": 2621.5134363007237, "Mean Reward": 25.70111212059533, "Episode": 653, "Episode Step": 102}
{"Training Time": 0.8539692585998111, "Episode Reward": 3051.3084697628506, "Mean Reward": 22.272324596809128, "Episode": 654, "Episode Step": 137}
{"Training Time": 0.8555329069164064, "Episode Reward": 4982.480098732977, "Mean Reward": 37.74606135403771, "Episode": 655, "Episode Step": 132}
{"Training Time": 0.8569604253106647, "Episode Reward": 2309.2295440930952, "Mean Reward": 18.928111017156517, "Episode": 656, "Episode Step": 122}
{"Training Time": 0.859037780298127, "Episode Reward": 1589.5763654199172, "Mean Reward": 11.435801190071347, "Episode": 657, "Episode Step": 139}
{"Training Time": 0.8605141291353438, "Episode Reward": 4689.776524050347, "Mean Reward": 38.128264423173555, "Episode": 658, "Episode Step": 123}
{"Training Time": 0.8615478008323245, "Episode Reward": 2559.022639900937, "Mean Reward": 29.079802726147012, "Episode": 659, "Episode Step": 88}
{"Training Time": 0.8635305400027169, "Episode Reward": 2044.5343444937187, "Mean Reward": 15.488896549194838, "Episode": 660, "Episode Step": 132}
{"Training Time": 0.865054801636272, "Episode Reward": 4068.6827662814753, "Mean Reward": 30.823354290011178, "Episode": 661, "Episode Step": 132}
{"Training Time": 0.8667963938580618, "Episode Reward": 2391.514475011465, "Mean Reward": 16.268805952458944, "Episode": 662, "Episode Step": 147}
{"Training Time": 0.8695403933525085, "Episode Reward": 2717.024977222653, "Mean Reward": 13.93346142165463, "Episode": 663, "Episode Step": 195}
{"Training Time": 0.8710263294643826, "Episode Reward": 4020.006247251994, "Mean Reward": 31.904811486126935, "Episode": 664, "Episode Step": 126}
{"Training Time": 0.8716909636391533, "Episode Reward": 1446.9040415262625, "Mean Reward": 25.83757217011183, "Episode": 665, "Episode Step": 56}
{"Training Time": 0.8733515761295955, "Episode Reward": 20.337163447939766, "Mean Reward": 0.1993839553719585, "Episode": 666, "Episode Step": 102}
{"Training Time": 0.8748708083232244, "Episode Reward": 4524.160595635803, "Mean Reward": 34.80123535104463, "Episode": 667, "Episode Step": 130}
{"Training Time": 0.8763404366705153, "Episode Reward": 2670.8816281993827, "Mean Reward": 20.866262720307677, "Episode": 668, "Episode Step": 128}
{"Training Time": 0.8790438372559017, "Episode Reward": 4395.593647657468, "Mean Reward": 22.657699214729217, "Episode": 669, "Episode Step": 194}
{"Training Time": 0.8805991880761252, "Episode Reward": 4755.599252497875, "Mean Reward": 35.756385357126874, "Episode": 670, "Episode Step": 133}
{"Training Time": 0.8813003433412976, "Episode Reward": 1310.015656863406, "Mean Reward": 22.98273082216502, "Episode": 671, "Episode Step": 57}
{"Training Time": 0.8829609916607539, "Episode Reward": 3.3105977765136916, "Mean Reward": 0.032456840946212664, "Episode": 672, "Episode Step": 102}
{"Training Time": 0.8845102358526654, "Episode Reward": 4812.7043155546135, "Mean Reward": 36.45988117844404, "Episode": 673, "Episode Step": 132}
{"Training Time": 0.8857211736175749, "Episode Reward": 1342.852240345641, "Mean Reward": 13.165218042604323, "Episode": 674, "Episode Step": 102}
{"Training Time": 0.8874122027556102, "Episode Reward": 414.9717223761139, "Mean Reward": 3.9901127151549414, "Episode": 675, "Episode Step": 104}
{"Training Time": 0.8889354716406929, "Episode Reward": 4525.129932950792, "Mean Reward": 34.54297658741063, "Episode": 676, "Episode Step": 131}
{"Training Time": 0.8895624413755205, "Episode Reward": 1176.044865209259, "Mean Reward": 23.059703239397233, "Episode": 677, "Episode Step": 51}
{"Training Time": 0.8912210538652208, "Episode Reward": 4.286387909158703, "Mean Reward": 0.04202341087410494, "Episode": 678, "Episode Step": 102}
{"Training Time": 0.8926237933503257, "Episode Reward": 4688.7310155272335, "Mean Reward": 38.74984310353086, "Episode": 679, "Episode Step": 121}
{"Training Time": 0.8938770822021697, "Episode Reward": 1801.1989568862232, "Mean Reward": 16.8336351110862, "Episode": 680, "Episode Step": 107}
{"Training Time": 0.8955195444160038, "Episode Reward": 2.0808442469943453, "Mean Reward": 0.02040043379406221, "Episode": 681, "Episode Step": 102}
{"Training Time": 0.8970442983176973, "Episode Reward": 4241.083560042855, "Mean Reward": 32.87661674451826, "Episode": 682, "Episode Step": 129}
{"Training Time": 0.8982697372304068, "Episode Reward": 1974.6117760399288, "Mean Reward": 18.986651692691623, "Episode": 683, "Episode Step": 104}
{"Training Time": 0.8999171308014128, "Episode Reward": 3.417766924251934, "Mean Reward": 0.03350751886521504, "Episode": 684, "Episode Step": 102}
{"Training Time": 0.90136292775472, "Episode Reward": 4350.0644630171855, "Mean Reward": 35.3663777481072, "Episode": 685, "Episode Step": 123}
{"Training Time": 0.9030331155326632, "Episode Reward": 2716.551749584056, "Mean Reward": 18.734839652303833, "Episode": 686, "Episode Step": 145}
{"Training Time": 0.9046949711110857, "Episode Reward": 1.9191477644133337, "Mean Reward": 0.018815174160915035, "Episode": 687, "Episode Step": 102}
{"Training Time": 0.9061759941445456, "Episode Reward": 4778.897039372823, "Mean Reward": 37.6291105462427, "Episode": 688, "Episode Step": 127}
{"Training Time": 0.9074023922284444, "Episode Reward": 1561.4013780856014, "Mean Reward": 15.01347478928463, "Episode": 689, "Episode Step": 104}
{"Training Time": 0.9090510886245303, "Episode Reward": 2.8474256745795783, "Mean Reward": 0.027915937986074297, "Episode": 690, "Episode Step": 102}
{"Training Time": 0.9105630222294065, "Episode Reward": 4377.563673101657, "Mean Reward": 33.93460211706711, "Episode": 691, "Episode Step": 129}
{"Training Time": 0.9123405341969596, "Episode Reward": 2521.155852168281, "Mean Reward": 16.478142824629288, "Episode": 692, "Episode Step": 153}
{"Training Time": 0.9139997338586383, "Episode Reward": 2.2334104203379974, "Mean Reward": 0.021896180591548995, "Episode": 693, "Episode Step": 102}
{"Training Time": 0.915493632223871, "Episode Reward": 4823.968085062135, "Mean Reward": 37.395101434590195, "Episode": 694, "Episode Step": 129}
{"Training Time": 0.9167399477958679, "Episode Reward": 2184.738865714586, "Mean Reward": 20.610744016175342, "Episode": 695, "Episode Step": 106}
{"Training Time": 0.918373327255249, "Episode Reward": 2.9665649736846933, "Mean Reward": 0.02908397033024209, "Episode": 696, "Episode Step": 102}
{"Training Time": 0.9198314858145183, "Episode Reward": 4791.417079124438, "Mean Reward": 38.95461039938567, "Episode": 697, "Episode Step": 123}
{"Training Time": 0.9214630652798547, "Episode Reward": 2803.1224308826086, "Mean Reward": 20.022303077732918, "Episode": 698, "Episode Step": 140}
{"Training Time": 0.9235454205671946, "Episode Reward": 2.6769880542090454, "Mean Reward": 0.026244980923618093, "Episode": 699, "Episode Step": 102}
{"Training Time": 0.925305712223053, "Episode Reward": 4546.628973740509, "Mean Reward": 36.08435693444848, "Episode": 700, "Episode Step": 126}
{"Training Time": 0.926802262796296, "Episode Reward": 3113.794028379768, "Mean Reward": 24.137938204494326, "Episode": 701, "Episode Step": 129}
{"Training Time": 0.9284662152661217, "Episode Reward": 1.7604349206100902, "Mean Reward": 0.01725916588833422, "Episode": 702, "Episode Step": 102}
{"Training Time": 0.9299513794316185, "Episode Reward": 5206.021607015325, "Mean Reward": 41.31763180170893, "Episode": 703, "Episode Step": 126}
{"Training Time": 0.9316262391540739, "Episode Reward": 2733.539092645323, "Mean Reward": 19.115657990526735, "Episode": 704, "Episode Step": 143}
{"Training Time": 0.93330077416367, "Episode Reward": 3.035622429829082, "Mean Reward": 0.02976100421401061, "Episode": 705, "Episode Step": 102}
{"Training Time": 0.9347838491863675, "Episode Reward": 4853.635145341504, "Mean Reward": 38.21759956961814, "Episode": 706, "Episode Step": 127}
{"Training Time": 0.9364951658248901, "Episode Reward": 2886.1696862046574, "Mean Reward": 19.768285521949707, "Episode": 707, "Episode Step": 146}
{"Training Time": 0.9381234053108427, "Episode Reward": 13.239650594578391, "Mean Reward": 0.12980049602527835, "Episode": 708, "Episode Step": 102}
{"Training Time": 0.9395061272382736, "Episode Reward": 4888.014752396032, "Mean Reward": 41.075754221815394, "Episode": 709, "Episode Step": 119}
{"Training Time": 0.941171733074718, "Episode Reward": 2908.589496792136, "Mean Reward": 20.339786690854098, "Episode": 710, "Episode Step": 143}
{"Training Time": 0.9428321430418226, "Episode Reward": 4.949373498475401, "Mean Reward": 0.04852326959289609, "Episode": 711, "Episode Step": 102}
{"Training Time": 0.944364326397578, "Episode Reward": 4935.832417168898, "Mean Reward": 38.86482218243227, "Episode": 712, "Episode Step": 127}
{"Training Time": 0.9459573372205099, "Episode Reward": 3207.3149109437927, "Mean Reward": 23.583197874586713, "Episode": 713, "Episode Step": 136}
{"Training Time": 0.9476070394780901, "Episode Reward": 5.036769576605037, "Mean Reward": 0.049380093888284675, "Episode": 714, "Episode Step": 102}
{"Training Time": 0.949062616692649, "Episode Reward": 4907.113552508664, "Mean Reward": 38.94534565483067, "Episode": 715, "Episode Step": 126}
{"Training Time": 0.950278837747044, "Episode Reward": 2361.9082974859907, "Mean Reward": 22.494364737961817, "Episode": 716, "Episode Step": 105}
{"Training Time": 0.9519408224688636, "Episode Reward": 3.15840680217596, "Mean Reward": 0.03096477257035255, "Episode": 717, "Episode Step": 102}
{"Training Time": 0.9533519583278233, "Episode Reward": 5063.036289689728, "Mean Reward": 42.19196908074773, "Episode": 718, "Episode Step": 120}
{"Training Time": 0.9549694316916996, "Episode Reward": 3420.1905396635066, "Mean Reward": 24.783989417851497, "Episode": 719, "Episode Step": 138}
{"Training Time": 0.9566474316517511, "Episode Reward": 1.7271267799357701, "Mean Reward": 0.016932615489566375, "Episode": 720, "Episode Step": 102}
{"Training Time": 0.9581050274769465, "Episode Reward": 4796.188249581426, "Mean Reward": 38.99340040310103, "Episode": 721, "Episode Step": 123}
{"Training Time": 0.9597199686368306, "Episode Reward": 3696.565912851352, "Mean Reward": 26.786709513415595, "Episode": 722, "Episode Step": 138}
{"Training Time": 0.9613828486204148, "Episode Reward": 2.963137733306832, "Mean Reward": 0.029050369934380704, "Episode": 723, "Episode Step": 102}
{"Training Time": 0.9620953191651238, "Episode Reward": 1894.5364820072346, "Mean Reward": 31.57560803345391, "Episode": 724, "Episode Step": 60}
{"Training Time": 0.9637163941727744, "Episode Reward": 3227.4608327934334, "Mean Reward": 23.38739733908285, "Episode": 725, "Episode Step": 138}
{"Training Time": 0.9653919216659334, "Episode Reward": 3.302942131420317, "Mean Reward": 0.03238178560215997, "Episode": 726, "Episode Step": 102}
{"Training Time": 0.9667911071909798, "Episode Reward": 4252.353085531464, "Mean Reward": 36.65821625458158, "Episode": 727, "Episode Step": 116}
{"Training Time": 0.9683562478091982, "Episode Reward": 4530.701938963047, "Mean Reward": 35.121720457077885, "Episode": 728, "Episode Step": 129}
{"Training Time": 0.9709084608157476, "Episode Reward": 3835.8468232777095, "Mean Reward": 21.67145097897011, "Episode": 729, "Episode Step": 177}
{"Training Time": 0.9722584752904044, "Episode Reward": 4270.856250205387, "Mean Reward": 37.463651317591115, "Episode": 730, "Episode Step": 114}
{"Training Time": 0.9739482561084959, "Episode Reward": 3840.35614144498, "Mean Reward": 26.669139871145696, "Episode": 731, "Episode Step": 144}
{"Training Time": 0.9761499966515436, "Episode Reward": 4398.961654150192, "Mean Reward": 29.72271387939319, "Episode": 732, "Episode Step": 148}
{"Training Time": 0.9774792989095052, "Episode Reward": 4505.683771301107, "Mean Reward": 39.87330771062927, "Episode": 733, "Episode Step": 113}
{"Training Time": 0.979115513364474, "Episode Reward": 3782.627908940526, "Mean Reward": 26.82714829035834, "Episode": 734, "Episode Step": 141}
{"Training Time": 0.9811245703034931, "Episode Reward": 4852.1341882380075, "Mean Reward": 37.03919227662601, "Episode": 735, "Episode Step": 131}
{"Training Time": 0.9818808097309536, "Episode Reward": 1893.379528328163, "Mean Reward": 30.053643306796236, "Episode": 736, "Episode Step": 63}
{"Training Time": 0.9834618758493, "Episode Reward": 3844.246149094273, "Mean Reward": 28.688404097718454, "Episode": 737, "Episode Step": 134}
{"Training Time": 0.9851739799976349, "Episode Reward": 4272.6113637767685, "Mean Reward": 40.30765437525253, "Episode": 738, "Episode Step": 106}
{"Training Time": 0.9866177572144402, "Episode Reward": 4109.138640645198, "Mean Reward": 33.9598234764066, "Episode": 739, "Episode Step": 121}
{"Training Time": 0.9881999433040619, "Episode Reward": 3356.900852670074, "Mean Reward": 25.05149890052294, "Episode": 740, "Episode Step": 134}
{"Training Time": 0.9899728180302514, "Episode Reward": 4872.783520018089, "Mean Reward": 43.89895063079359, "Episode": 741, "Episode Step": 111}
{"Training Time": 0.9913434349828296, "Episode Reward": 3736.118470508278, "Mean Reward": 32.207917849209295, "Episode": 742, "Episode Step": 116}
{"Training Time": 0.9929643869400024, "Episode Reward": 3422.521480185463, "Mean Reward": 24.62245669198175, "Episode": 743, "Episode Step": 139}
{"Training Time": 0.9961891780296962, "Episode Reward": 9041.664876605497, "Mean Reward": 38.475169687682964, "Episode": 744, "Episode Step": 235}
{"Training Time": 0.9973656955692504, "Episode Reward": 3628.127263382109, "Mean Reward": 36.64775013517282, "Episode": 745, "Episode Step": 99}
{"Training Time": 0.9990157202879588, "Episode Reward": 3094.911733427304, "Mean Reward": 22.106512381623602, "Episode": 746, "Episode Step": 140}
{"Training Time": 1.0008028944333394, "Episode Reward": 4537.18371121311, "Mean Reward": 41.24712464739191, "Episode": 747, "Episode Step": 110}
{"Training Time": 1.0022148611148198, "Episode Reward": 4368.541985375247, "Mean Reward": 36.40451654479373, "Episode": 748, "Episode Step": 120}
{"Training Time": 1.0042586169640224, "Episode Reward": 3692.0320327542927, "Mean Reward": 26.184624345775127, "Episode": 749, "Episode Step": 141}
{"Training Time": 1.0060090649790234, "Episode Reward": 4543.419669574934, "Mean Reward": 42.068700644212356, "Episode": 750, "Episode Step": 108}
{"Training Time": 1.0074320619636112, "Episode Reward": 4753.880499327386, "Mean Reward": 39.615670827728216, "Episode": 751, "Episode Step": 120}
{"Training Time": 1.009187385837237, "Episode Reward": 3523.946048294416, "Mean Reward": 24.303076195133904, "Episode": 752, "Episode Step": 145}
{"Training Time": 1.0109566050105625, "Episode Reward": 4556.977961385395, "Mean Reward": 41.80713726041647, "Episode": 753, "Episode Step": 109}
{"Training Time": 1.0123494883378348, "Episode Reward": 4896.038510108212, "Mean Reward": 41.49185178057807, "Episode": 754, "Episode Step": 118}
{"Training Time": 1.0140035547150505, "Episode Reward": 3358.609174221041, "Mean Reward": 24.162655929647777, "Episode": 755, "Episode Step": 139}
{"Training Time": 1.0150803591807682, "Episode Reward": 1873.9006246571666, "Mean Reward": 36.03655047417628, "Episode": 756, "Episode Step": 52}
{"Training Time": 1.0162668697039285, "Episode Reward": 3732.378397256023, "Mean Reward": 37.70079189147498, "Episode": 757, "Episode Step": 99}
{"Training Time": 1.017951517502467, "Episode Reward": 3208.2974114360463, "Mean Reward": 22.435646233818506, "Episode": 758, "Episode Step": 143}
{"Training Time": 1.0197285047504636, "Episode Reward": 4823.347471117481, "Mean Reward": 44.250894230435605, "Episode": 759, "Episode Step": 109}
{"Training Time": 1.0204636269145542, "Episode Reward": 2230.4020672697698, "Mean Reward": 36.56396831589787, "Episode": 760, "Episode Step": 61}
{"Training Time": 1.0221380008591545, "Episode Reward": 3282.250579480868, "Mean Reward": 23.27837290411963, "Episode": 761, "Episode Step": 141}
{"Training Time": 1.0236401622162925, "Episode Reward": 4185.4268770729595, "Mean Reward": 48.10835490888459, "Episode": 762, "Episode Step": 87}
{"Training Time": 1.0250490933656693, "Episode Reward": 5314.736586809873, "Mean Reward": 44.66165198999894, "Episode": 763, "Episode Step": 119}
{"Training Time": 1.0266116344266467, "Episode Reward": 3889.528019019126, "Mean Reward": 29.69105358029867, "Episode": 764, "Episode Step": 131}
{"Training Time": 1.028708090848393, "Episode Reward": 5442.1692547647035, "Mean Reward": 38.87263753403359, "Episode": 765, "Episode Step": 140}
{"Training Time": 1.0301559374729792, "Episode Reward": 5308.325090106965, "Mean Reward": 44.607773866445086, "Episode": 766, "Episode Step": 119}
{"Training Time": 1.0317536330885357, "Episode Reward": 3375.107098396325, "Mean Reward": 25.376745100724246, "Episode": 767, "Episode Step": 133}
{"Training Time": 1.0335868166552649, "Episode Reward": 4140.488532523113, "Mean Reward": 35.693866659682, "Episode": 768, "Episode Step": 116}
{"Training Time": 1.0349342019690408, "Episode Reward": 5163.15745753893, "Mean Reward": 45.691658916273724, "Episode": 769, "Episode Step": 113}
{"Training Time": 1.0365323364072376, "Episode Reward": 3239.413224014508, "Mean Reward": 23.81921488245962, "Episode": 770, "Episode Step": 136}
{"Training Time": 1.0383591230710347, "Episode Reward": 4580.87993152206, "Mean Reward": 40.53876045594744, "Episode": 771, "Episode Step": 113}
{"Training Time": 1.0398278733094533, "Episode Reward": 5587.469962660602, "Mean Reward": 45.06024163435969, "Episode": 772, "Episode Step": 124}
{"Training Time": 1.0414698233207067, "Episode Reward": 3168.1245428392003, "Mean Reward": 22.62946102028, "Episode": 773, "Episode Step": 140}
{"Training Time": 1.0451954422394434, "Episode Reward": 12298.319345397103, "Mean Reward": 44.721161255989465, "Episode": 774, "Episode Step": 275}
{"Training Time": 1.046552953057819, "Episode Reward": 5385.068844292609, "Mean Reward": 46.82668560254443, "Episode": 775, "Episode Step": 115}
{"Training Time": 1.0481938905848398, "Episode Reward": 3467.312318507958, "Mean Reward": 24.944692938906172, "Episode": 776, "Episode Step": 139}
{"Training Time": 1.0501430500215954, "Episode Reward": 5014.331806102215, "Mean Reward": 39.7962841754144, "Episode": 777, "Episode Step": 126}
{"Training Time": 1.0515594189034567, "Episode Reward": 5498.6156776427115, "Mean Reward": 45.443104773906704, "Episode": 778, "Episode Step": 121}
{"Training Time": 1.053152167532179, "Episode Reward": 3127.211508864746, "Mean Reward": 22.826361378574788, "Episode": 779, "Episode Step": 137}
{"Training Time": 1.0548377850320605, "Episode Reward": 4502.282810996755, "Mean Reward": 42.87888391425481, "Episode": 780, "Episode Step": 105}
{"Training Time": 1.0561568627754847, "Episode Reward": 4908.450412244131, "Mean Reward": 43.43761426764718, "Episode": 781, "Episode Step": 113}
{"Training Time": 1.0579990866449145, "Episode Reward": 4430.346977059544, "Mean Reward": 28.218770554519388, "Episode": 782, "Episode Step": 157}
{"Training Time": 1.0610041885905797, "Episode Reward": 8660.330289668884, "Mean Reward": 39.90935617358932, "Episode": 783, "Episode Step": 217}
{"Training Time": 1.0625200202729967, "Episode Reward": 5016.201625936116, "Mean Reward": 39.18907520262591, "Episode": 784, "Episode Step": 128}
{"Training Time": 1.0643556130594678, "Episode Reward": 4278.580016937395, "Mean Reward": 27.25210201870952, "Episode": 785, "Episode Step": 157}
{"Training Time": 1.0663217788934707, "Episode Reward": 5216.610151626771, "Mean Reward": 41.401667870053735, "Episode": 786, "Episode Step": 126}
{"Training Time": 1.0675439349810283, "Episode Reward": 4123.880713085416, "Mean Reward": 40.43020306946486, "Episode": 787, "Episode Step": 102}
{"Training Time": 1.0692197924852371, "Episode Reward": 3092.4314736943115, "Mean Reward": 22.088796240673656, "Episode": 788, "Episode Step": 140}
{"Training Time": 1.0709953472349378, "Episode Reward": 4625.1417881376, "Mean Reward": 42.8253869272, "Episode": 789, "Episode Step": 108}
{"Training Time": 1.0729467480712467, "Episode Reward": 4909.597580266793, "Mean Reward": 29.936570611382884, "Episode": 790, "Episode Step": 164}
{"Training Time": 1.074757021135754, "Episode Reward": 3998.248924478761, "Mean Reward": 26.13234591162589, "Episode": 791, "Episode Step": 153}
{"Training Time": 1.0777864260805978, "Episode Reward": 8661.64244863691, "Mean Reward": 39.55087876089914, "Episode": 792, "Episode Step": 219}
{"Training Time": 1.079104333056344, "Episode Reward": 1865.4390262334425, "Mean Reward": 16.655705591370022, "Episode": 793, "Episode Step": 112}
{"Training Time": 1.080756668580903, "Episode Reward": 3088.4505192465713, "Mean Reward": 22.38007622642443, "Episode": 794, "Episode Step": 138}
{"Training Time": 1.0825999380482567, "Episode Reward": 5311.503454546461, "Mean Reward": 46.59213556619703, "Episode": 795, "Episode Step": 114}
{"Training Time": 1.085799143910408, "Episode Reward": 8420.074239292602, "Mean Reward": 31.07038464683617, "Episode": 796, "Episode Step": 271}
{"Training Time": 1.0873250310950808, "Episode Reward": 3559.91046211216, "Mean Reward": 28.030791040253227, "Episode": 797, "Episode Step": 127}
{"Training Time": 1.0888652558459175, "Episode Reward": 4151.321646491869, "Mean Reward": 44.637867166579234, "Episode": 798, "Episode Step": 93}
{"Training Time": 1.0906215283605787, "Episode Reward": 1693.1310361285693, "Mean Reward": 13.765292976655035, "Episode": 799, "Episode Step": 123}
{"Training Time": 1.0926406016614703, "Episode Reward": 4074.175536781352, "Mean Reward": 27.715479842050016, "Episode": 800, "Episode Step": 147}
{"Training Time": 1.0944071652491887, "Episode Reward": 5720.747901950098, "Mean Reward": 51.07810626741159, "Episode": 801, "Episode Step": 112}
{"Training Time": 1.096414598359002, "Episode Reward": 4900.656751087504, "Mean Reward": 28.49219041329944, "Episode": 802, "Episode Step": 172}
{"Training Time": 1.0981456736061308, "Episode Reward": 3794.6424989371217, "Mean Reward": 25.467399321725647, "Episode": 803, "Episode Step": 149}
{"Training Time": 1.1001040850083033, "Episode Reward": 5673.883910295157, "Mean Reward": 44.67625126216659, "Episode": 804, "Episode Step": 127}
{"Training Time": 1.1020983502599928, "Episode Reward": 3913.896505483857, "Mean Reward": 23.15915092002282, "Episode": 805, "Episode Step": 169}
{"Training Time": 1.1032523024744458, "Episode Reward": 1967.5009402034025, "Mean Reward": 21.385879784819593, "Episode": 806, "Episode Step": 92}
{"Training Time": 1.1074615897072686, "Episode Reward": 18007.982827203043, "Mean Reward": 56.099634975710416, "Episode": 807, "Episode Step": 321}
{"Training Time": 1.1094639078113768, "Episode Reward": 4012.757189823089, "Mean Reward": 23.604454057782878, "Episode": 808, "Episode Step": 170}
{"Training Time": 1.110910598900583, "Episode Reward": 4150.647288947609, "Mean Reward": 33.74509991014316, "Episode": 809, "Episode Step": 123}
{"Training Time": 1.1137729847431184, "Episode Reward": 7173.735876056433, "Mean Reward": 34.993833541738695, "Episode": 810, "Episode Step": 205}
{"Training Time": 1.1150880297025045, "Episode Reward": 2116.7302237389868, "Mean Reward": 19.06964165530619, "Episode": 811, "Episode Step": 111}
{"Training Time": 1.1167122305764092, "Episode Reward": 4515.804544937747, "Mean Reward": 32.7232213401286, "Episode": 812, "Episode Step": 138}
{"Training Time": 1.1184540714157951, "Episode Reward": 4777.625968439426, "Mean Reward": 44.237277485550244, "Episode": 813, "Episode Step": 108}
{"Training Time": 1.1206120586395263, "Episode Reward": 3747.5582613443985, "Mean Reward": 20.936079672315074, "Episode": 814, "Episode Step": 179}
{"Training Time": 1.1221693833669026, "Episode Reward": 3802.500701941045, "Mean Reward": 30.42000561552836, "Episode": 815, "Episode Step": 125}
{"Training Time": 1.1239657877551186, "Episode Reward": 5605.099654722353, "Mean Reward": 49.60265181170224, "Episode": 816, "Episode Step": 113}
{"Training Time": 1.126098152200381, "Episode Reward": 4163.803326942015, "Mean Reward": 23.39215352214615, "Episode": 817, "Episode Step": 178}
{"Training Time": 1.1275933886236615, "Episode Reward": 2865.127236412704, "Mean Reward": 23.10586480977987, "Episode": 818, "Episode Step": 124}
{"Training Time": 1.1297568425205018, "Episode Reward": 5589.547176524275, "Mean Reward": 39.08774249317675, "Episode": 819, "Episode Step": 143}
{"Training Time": 1.1319047011269463, "Episode Reward": 4019.959170825675, "Mean Reward": 22.08768775178942, "Episode": 820, "Episode Step": 182}
{"Training Time": 1.1337954641713037, "Episode Reward": 3654.4098106245233, "Mean Reward": 23.129176016610906, "Episode": 821, "Episode Step": 158}
{"Training Time": 1.1356462338897917, "Episode Reward": 4831.692341238597, "Mean Reward": 42.01471601077041, "Episode": 822, "Episode Step": 115}
{"Training Time": 1.1379933510886298, "Episode Reward": 4265.57156176977, "Mean Reward": 21.87472595779369, "Episode": 823, "Episode Step": 195}
{"Training Time": 1.140641041662958, "Episode Reward": 5353.578654236082, "Mean Reward": 24.22433780197322, "Episode": 824, "Episode Step": 221}
{"Training Time": 1.1423918463786442, "Episode Reward": 5587.576244938926, "Mean Reward": 51.73681708276783, "Episode": 825, "Episode Step": 108}
{"Training Time": 1.1448533208502663, "Episode Reward": 3969.8051042580923, "Mean Reward": 19.364902947600452, "Episode": 826, "Episode Step": 205}
{"Training Time": 1.146373990840382, "Episode Reward": 2993.1624786430275, "Mean Reward": 23.755257767008153, "Episode": 827, "Episode Step": 126}
{"Training Time": 1.1481286174721188, "Episode Reward": 5148.655328279142, "Mean Reward": 47.672734521103166, "Episode": 828, "Episode Step": 108}
{"Training Time": 1.150613820023007, "Episode Reward": 4601.847128257876, "Mean Reward": 22.124265039701324, "Episode": 829, "Episode Step": 208}
{"Training Time": 1.1520164322190816, "Episode Reward": 3380.6905776072595, "Mean Reward": 28.649920149214065, "Episode": 830, "Episode Step": 118}
{"Training Time": 1.1547198261155023, "Episode Reward": 8557.247919420228, "Mean Reward": 45.27644401809644, "Episode": 831, "Episode Step": 189}
{"Training Time": 1.1561630991432401, "Episode Reward": 2003.8626195869167, "Mean Reward": 16.560848095759642, "Episode": 832, "Episode Step": 121}
{"Training Time": 1.1576844491561253, "Episode Reward": 3073.04158079906, "Mean Reward": 24.389218895230634, "Episode": 833, "Episode Step": 126}
{"Training Time": 1.1606769530640708, "Episode Reward": 9605.095446696258, "Mean Reward": 44.67486254277329, "Episode": 834, "Episode Step": 215}
{"Training Time": 1.161923004190127, "Episode Reward": 1323.6844872346937, "Mean Reward": 12.851305701307707, "Episode": 835, "Episode Step": 103}
{"Training Time": 1.1638539069228702, "Episode Reward": 4172.201606463015, "Mean Reward": 25.914295692316866, "Episode": 836, "Episode Step": 161}
{"Training Time": 1.165627620021502, "Episode Reward": 5358.870362289849, "Mean Reward": 48.71700329354408, "Episode": 837, "Episode Step": 110}
{"Training Time": 1.1670293586121665, "Episode Reward": 2639.432276280901, "Mean Reward": 22.559250224623085, "Episode": 838, "Episode Step": 117}
{"Training Time": 1.1681941469510397, "Episode Reward": 2832.000399085031, "Mean Reward": 29.500004157135738, "Episode": 839, "Episode Step": 96}
{"Training Time": 1.1704024666547774, "Episode Reward": 6347.332806094244, "Mean Reward": 42.887383824961105, "Episode": 840, "Episode Step": 148}
{"Training Time": 1.1717938972181745, "Episode Reward": 1962.3330038629724, "Mean Reward": 16.916663826404935, "Episode": 841, "Episode Step": 116}
{"Training Time": 1.1729522236188252, "Episode Reward": 2499.1356773318225, "Mean Reward": 25.76428533331776, "Episode": 842, "Episode Step": 97}
{"Training Time": 1.1747877964046267, "Episode Reward": 5360.611466123419, "Mean Reward": 45.42891072985948, "Episode": 843, "Episode Step": 118}
{"Training Time": 1.1769304766919877, "Episode Reward": 3844.6849531757084, "Mean Reward": 21.00920739440278, "Episode": 844, "Episode Step": 183}
{"Training Time": 1.1788275719351238, "Episode Reward": 4442.61250320254, "Mean Reward": 27.94095913963862, "Episode": 845, "Episode Step": 159}
{"Training Time": 1.1816057030359903, "Episode Reward": 8235.32983331181, "Mean Reward": 41.592574915716206, "Episode": 846, "Episode Step": 198}
{"Training Time": 1.1838006116946538, "Episode Reward": 3539.099294600634, "Mean Reward": 19.234235296742575, "Episode": 847, "Episode Step": 184}
{"Training Time": 1.1851809805631637, "Episode Reward": 3829.743736349739, "Mean Reward": 32.732852447433665, "Episode": 848, "Episode Step": 117}
{"Training Time": 1.1874369449747932, "Episode Reward": 5475.558657366239, "Mean Reward": 43.804469258929906, "Episode": 849, "Episode Step": 125}
{"Training Time": 1.1897428933117125, "Episode Reward": 3752.1015802670277, "Mean Reward": 21.94211450448554, "Episode": 850, "Episode Step": 171}
{"Training Time": 1.1909882319635816, "Episode Reward": 2912.791480539313, "Mean Reward": 28.556779220973656, "Episode": 851, "Episode Step": 102}
{"Training Time": 1.192924503352907, "Episode Reward": 4982.12913399849, "Mean Reward": 39.85703307198792, "Episode": 852, "Episode Step": 125}
{"Training Time": 1.1941307575172848, "Episode Reward": -8.38743363601242, "Mean Reward": -0.08222974152953352, "Episode": 853, "Episode Step": 102}
{"Training Time": 1.195528664191564, "Episode Reward": 3174.012651586714, "Mean Reward": 26.672375223417767, "Episode": 854, "Episode Step": 119}
{"Training Time": 1.1983190002706317, "Episode Reward": 8372.826956994351, "Mean Reward": 41.86413478497175, "Episode": 855, "Episode Step": 200}
{"Training Time": 1.2000917644633187, "Episode Reward": 2213.927045146841, "Mean Reward": 14.858570772797592, "Episode": 856, "Episode Step": 149}
{"Training Time": 1.2012506047222349, "Episode Reward": 2255.8650381482717, "Mean Reward": 23.49859414737783, "Episode": 857, "Episode Step": 96}
{"Training Time": 1.2031234344508912, "Episode Reward": 5905.378286476407, "Mean Reward": 49.6250276174488, "Episode": 858, "Episode Step": 119}
{"Training Time": 1.2043330955505371, "Episode Reward": -12.471403281339889, "Mean Reward": -0.1222686596209793, "Episode": 859, "Episode Step": 102}
{"Training Time": 1.20545770280891, "Episode Reward": 2391.3476554863196, "Mean Reward": 25.17208058406652, "Episode": 860, "Episode Step": 95}
{"Training Time": 1.2075282014078563, "Episode Reward": 6051.896275705831, "Mean Reward": 44.4992373213664, "Episode": 861, "Episode Step": 136}
{"Training Time": 1.2087316044171652, "Episode Reward": -11.991861747470088, "Mean Reward": -0.11756727203402047, "Episode": 862, "Episode Step": 102}
{"Training Time": 1.21013578136762, "Episode Reward": 2869.9679421735595, "Mean Reward": 23.916399518112996, "Episode": 863, "Episode Step": 120}
{"Training Time": 1.21225386692418, "Episode Reward": 5859.092754286183, "Mean Reward": 41.850662530615594, "Episode": 864, "Episode Step": 140}
{"Training Time": 1.2134740969207551, "Episode Reward": -2.4460692602895735, "Mean Reward": -0.023981071179309543, "Episode": 865, "Episode Step": 102}
{"Training Time": 1.2149032408661313, "Episode Reward": 3519.398196139134, "Mean Reward": 28.847526197861754, "Episode": 866, "Episode Step": 122}
{"Training Time": 1.2170725599924723, "Episode Reward": 6064.256077460809, "Mean Reward": 41.253442703815026, "Episode": 867, "Episode Step": 147}
{"Training Time": 1.2184385369221369, "Episode Reward": 359.962701939141, "Mean Reward": 3.1301104516447045, "Episode": 868, "Episode Step": 115}
{"Training Time": 1.2195857455333075, "Episode Reward": 2803.3901344427736, "Mean Reward": 29.201980567112226, "Episode": 869, "Episode Step": 96}
{"Training Time": 1.2222678538825777, "Episode Reward": 7690.433918894696, "Mean Reward": 39.8468078699207, "Episode": 870, "Episode Step": 193}
{"Training Time": 1.2234603819582197, "Episode Reward": 39.76673596511802, "Mean Reward": 0.3898699604423336, "Episode": 871, "Episode Step": 102}
{"Training Time": 1.224660996662246, "Episode Reward": 3082.6061830956246, "Mean Reward": 30.221629246035537, "Episode": 872, "Episode Step": 102}
{"Training Time": 1.2268440730704202, "Episode Reward": 6498.551269383447, "Mean Reward": 44.207831764513244, "Episode": 873, "Episode Step": 147}
{"Training Time": 1.2280331536134084, "Episode Reward": 1800.0553653913348, "Mean Reward": 17.647601621483673, "Episode": 874, "Episode Step": 102}
{"Training Time": 1.2307273394531675, "Episode Reward": 5621.7813450993945, "Mean Reward": 24.875138695130065, "Episode": 875, "Episode Step": 226}
{"Training Time": 1.2335062124994065, "Episode Reward": 8469.634058525618, "Mean Reward": 42.77592958851322, "Episode": 876, "Episode Step": 198}
{"Training Time": 1.2365017197529475, "Episode Reward": 6956.724306631181, "Mean Reward": 27.388678372563707, "Episode": 877, "Episode Step": 254}
{"Training Time": 1.2379381566577488, "Episode Reward": 3171.3242679123637, "Mean Reward": 26.64978376396944, "Episode": 878, "Episode Step": 119}
{"Training Time": 1.2401043450170093, "Episode Reward": 6251.572908652284, "Mean Reward": 43.11429592173989, "Episode": 879, "Episode Step": 145}
{"Training Time": 1.2417887933386698, "Episode Reward": 4968.496003586697, "Mean Reward": 34.989408475962655, "Episode": 880, "Episode Step": 142}
{"Training Time": 1.244285246398714, "Episode Reward": 5688.35835079509, "Mean Reward": 26.70590775021169, "Episode": 881, "Episode Step": 213}
{"Training Time": 1.2469096561272939, "Episode Reward": 8125.413132869013, "Mean Reward": 43.68501684338179, "Episode": 882, "Episode Step": 186}
{"Training Time": 1.2497807794147067, "Episode Reward": 7815.7204343629355, "Mean Reward": 32.03164112443826, "Episode": 883, "Episode Step": 244}
{"Training Time": 1.2509093080626594, "Episode Reward": 2803.8074630156875, "Mean Reward": 29.827738968251996, "Episode": 884, "Episode Step": 94}
{"Training Time": 1.253701466123263, "Episode Reward": 8792.135548318282, "Mean Reward": 44.40472499150647, "Episode": 885, "Episode Step": 198}
{"Training Time": 1.255237225294113, "Episode Reward": 4508.363963574085, "Mean Reward": 34.41499208835179, "Episode": 886, "Episode Step": 131}
{"Training Time": 1.2563334477610058, "Episode Reward": 2179.4510594553326, "Mean Reward": 23.434957628551963, "Episode": 887, "Episode Step": 93}
{"Training Time": 1.2581478697061539, "Episode Reward": 5762.189473097289, "Mean Reward": 50.99282719555123, "Episode": 888, "Episode Step": 113}
{"Training Time": 1.259659251636929, "Episode Reward": 4532.465461199123, "Mean Reward": 34.865118932300945, "Episode": 889, "Episode Step": 130}
{"Training Time": 1.2614621133274502, "Episode Reward": 4085.781531817108, "Mean Reward": 26.359880850432955, "Episode": 890, "Episode Step": 155}
{"Training Time": 1.2632772930463154, "Episode Reward": 5512.904962999875, "Mean Reward": 47.93830402608587, "Episode": 891, "Episode Step": 115}
{"Training Time": 1.2647992661264207, "Episode Reward": 4926.7989740918265, "Mean Reward": 38.192240109238966, "Episode": 892, "Episode Step": 129}
{"Training Time": 1.2661847027805115, "Episode Reward": 2919.5633985255713, "Mean Reward": 25.168649987289406, "Episode": 893, "Episode Step": 116}
{"Training Time": 1.268397096130583, "Episode Reward": 6572.550328982212, "Mean Reward": 44.11107603343766, "Episode": 894, "Episode Step": 149}
{"Training Time": 1.2701561533080208, "Episode Reward": 5279.812898764579, "Mean Reward": 34.96564833618926, "Episode": 895, "Episode Step": 151}
{"Training Time": 1.2714805161290699, "Episode Reward": 2954.4877184585557, "Mean Reward": 26.145909012907573, "Episode": 896, "Episode Step": 113}
{"Training Time": 1.2725979344712364, "Episode Reward": 2505.55811655629, "Mean Reward": 44.74210922421946, "Episode": 897, "Episode Step": 56}
{"Training Time": 1.2741657594177458, "Episode Reward": 4337.3451668306, "Mean Reward": 32.61161779571879, "Episode": 898, "Episode Step": 133}
{"Training Time": 1.2755895672241846, "Episode Reward": 2223.2079974311273, "Mean Reward": 23.65114890884178, "Episode": 899, "Episode Step": 94}
{"Training Time": 1.2775180439154308, "Episode Reward": 5663.827210778304, "Mean Reward": 46.424813203100854, "Episode": 900, "Episode Step": 122}
{"Training Time": 1.2790303727653292, "Episode Reward": 4853.546352194167, "Mean Reward": 37.33497193995513, "Episode": 901, "Episode Step": 130}
{"Training Time": 1.2802358263731002, "Episode Reward": 2520.3440986238716, "Mean Reward": 24.709255868861487, "Episode": 902, "Episode Step": 102}
{"Training Time": 1.282306738032235, "Episode Reward": 6516.85537899443, "Mean Reward": 47.91805425731199, "Episode": 903, "Episode Step": 136}
{"Training Time": 1.2838571014006932, "Episode Reward": 5457.819164987764, "Mean Reward": 41.03623432321628, "Episode": 904, "Episode Step": 133}
{"Training Time": 1.284974136683676, "Episode Reward": 2342.8657585015285, "Mean Reward": 24.92410381384605, "Episode": 905, "Episode Step": 94}
{"Training Time": 1.2867871633503172, "Episode Reward": 5591.010204178723, "Mean Reward": 47.78641200152755, "Episode": 906, "Episode Step": 117}
{"Training Time": 1.2885860741800732, "Episode Reward": 5530.696837218593, "Mean Reward": 36.14834534129799, "Episode": 907, "Episode Step": 153}
{"Training Time": 1.2905380169550578, "Episode Reward": 4243.630565554291, "Mean Reward": 25.410961470384976, "Episode": 908, "Episode Step": 167}
{"Training Time": 1.2923703944683076, "Episode Reward": 6013.434166689402, "Mean Reward": 50.961306497367815, "Episode": 909, "Episode Step": 118}
{"Training Time": 1.293824414478408, "Episode Reward": 4983.99954080864, "Mean Reward": 39.871996326469116, "Episode": 910, "Episode Step": 125}
{"Training Time": 1.2951736911137899, "Episode Reward": 3381.306382377292, "Mean Reward": 29.149192951528377, "Episode": 911, "Episode Step": 116}
{"Training Time": 1.2970092730389702, "Episode Reward": 6038.450455670096, "Mean Reward": 50.320420463917465, "Episode": 912, "Episode Step": 120}
{"Training Time": 1.2985166658295526, "Episode Reward": 5597.093619989285, "Mean Reward": 43.72729390616629, "Episode": 913, "Episode Step": 128}
{"Training Time": 1.2998536749680838, "Episode Reward": 2642.667601068507, "Mean Reward": 22.78161725059058, "Episode": 914, "Episode Step": 116}
{"Training Time": 1.3016787208451166, "Episode Reward": 5584.665742324109, "Mean Reward": 47.73218583182999, "Episode": 915, "Episode Step": 117}
{"Training Time": 1.3032555386092928, "Episode Reward": 5281.104173003686, "Mean Reward": 39.119290170397676, "Episode": 916, "Episode Step": 135}
{"Training Time": 1.3045874352587594, "Episode Reward": 3192.461173576679, "Mean Reward": 28.25186879271397, "Episode": 917, "Episode Step": 113}
{"Training Time": 1.3056821025080152, "Episode Reward": 2219.0244544094307, "Mean Reward": 41.093045452026495, "Episode": 918, "Episode Step": 54}
{"Training Time": 1.3073246038622326, "Episode Reward": 4395.670370810613, "Mean Reward": 31.397645505790095, "Episode": 919, "Episode Step": 140}
{"Training Time": 1.3086541680494945, "Episode Reward": 3855.250702419895, "Mean Reward": 33.81798861771838, "Episode": 920, "Episode Step": 114}
{"Training Time": 1.310422537525495, "Episode Reward": 5653.933229633904, "Mean Reward": 50.48154669315986, "Episode": 921, "Episode Step": 112}
{"Training Time": 1.3120223852660922, "Episode Reward": 5191.086688694814, "Mean Reward": 37.616570207933435, "Episode": 922, "Episode Step": 138}
{"Training Time": 1.3134119925234053, "Episode Reward": 3121.516830497271, "Mean Reward": 26.231233869724964, "Episode": 923, "Episode Step": 119}
{"Training Time": 1.3154531521929635, "Episode Reward": 5689.224411766112, "Mean Reward": 42.14240305011935, "Episode": 924, "Episode Step": 135}
{"Training Time": 1.3167411708169514, "Episode Reward": 4655.458956360949, "Mean Reward": 43.50896220898083, "Episode": 925, "Episode Step": 107}
{"Training Time": 1.3185253877772225, "Episode Reward": 3676.433858066096, "Mean Reward": 24.347244093152955, "Episode": 926, "Episode Step": 151}
{"Training Time": 1.3208137996991476, "Episode Reward": 6469.857955989847, "Mean Reward": 41.74101907090224, "Episode": 927, "Episode Step": 155}
{"Training Time": 1.3223449533515506, "Episode Reward": 5234.982748510877, "Mean Reward": 39.96170037031204, "Episode": 928, "Episode Step": 131}
{"Training Time": 1.3236548402574326, "Episode Reward": 3128.881613682226, "Mean Reward": 28.18812264578582, "Episode": 929, "Episode Step": 111}
{"Training Time": 1.325525832242436, "Episode Reward": 5950.790543332157, "Mean Reward": 49.58992119443464, "Episode": 930, "Episode Step": 120}
{"Training Time": 1.3270544391870498, "Episode Reward": 5579.792973947579, "Mean Reward": 42.59383949578305, "Episode": 931, "Episode Step": 131}
{"Training Time": 1.3291116883357366, "Episode Reward": 4668.368429952746, "Mean Reward": 26.676391028301406, "Episode": 932, "Episode Step": 175}
{"Training Time": 1.3309255022472806, "Episode Reward": 5555.823683200018, "Mean Reward": 47.8950317517243, "Episode": 933, "Episode Step": 116}
{"Training Time": 1.3324683949682448, "Episode Reward": 5374.889055962563, "Mean Reward": 40.412699668891456, "Episode": 934, "Episode Step": 133}
{"Training Time": 1.333782419429885, "Episode Reward": 3961.6506812732605, "Mean Reward": 35.69054667813748, "Episode": 935, "Episode Step": 111}
{"Training Time": 1.335593363046646, "Episode Reward": 5207.155145930578, "Mean Reward": 44.50559953786819, "Episode": 936, "Episode Step": 117}
{"Training Time": 1.3371235505739847, "Episode Reward": 5479.265140383031, "Mean Reward": 42.14819338756178, "Episode": 937, "Episode Step": 130}
{"Training Time": 1.3374093325270546, "Episode Reward": 211.2170338294854, "Mean Reward": 9.183349296934148, "Episode": 938, "Episode Step": 23}
{"Training Time": 1.3392433405584758, "Episode Reward": 5347.477052946203, "Mean Reward": 45.70493207646327, "Episode": 939, "Episode Step": 117}
{"Training Time": 1.342273924416966, "Episode Reward": 9873.166423193326, "Mean Reward": 38.12033368028311, "Episode": 940, "Episode Step": 259}
{"Training Time": 1.3441011194388073, "Episode Reward": 3722.0824656026243, "Mean Reward": 23.859502984632208, "Episode": 941, "Episode Step": 156}
{"Training Time": 1.3451971371968587, "Episode Reward": 2451.089713500977, "Mean Reward": 46.246975726433526, "Episode": 942, "Episode Step": 53}
{"Training Time": 1.346750363310178, "Episode Reward": 5206.500612910283, "Mean Reward": 39.146621149701375, "Episode": 943, "Episode Step": 133}
{"Training Time": 1.3480786816941368, "Episode Reward": 4473.845584037872, "Mean Reward": 39.945049857481, "Episode": 944, "Episode Step": 112}
{"Training Time": 1.3498849041594398, "Episode Reward": 5652.708088100879, "Mean Reward": 49.15398337479025, "Episode": 945, "Episode Step": 115}
{"Training Time": 1.3514766016933653, "Episode Reward": 5951.760534280496, "Mean Reward": 45.08909495667043, "Episode": 946, "Episode Step": 132}
{"Training Time": 1.3541784238815309, "Episode Reward": 5869.160050047717, "Mean Reward": 25.969734734724412, "Episode": 947, "Episode Step": 226}
{"Training Time": 1.3553379144271214, "Episode Reward": 1853.2256054480026, "Mean Reward": 31.952165611172457, "Episode": 948, "Episode Step": 58}
{"Training Time": 1.3572099666463004, "Episode Reward": 5920.08338112356, "Mean Reward": 44.51190512122977, "Episode": 949, "Episode Step": 133}
{"Training Time": 1.3592842574914297, "Episode Reward": 3880.3786268661574, "Mean Reward": 25.528806755698405, "Episode": 950, "Episode Step": 152}
{"Training Time": 1.3601111272308561, "Episode Reward": 674.075005658694, "Mean Reward": 24.074107344953354, "Episode": 951, "Episode Step": 28}
{"Training Time": 1.3617391486300363, "Episode Reward": 5574.389575343939, "Mean Reward": 41.29177463217733, "Episode": 952, "Episode Step": 135}
{"Training Time": 1.363084377778901, "Episode Reward": 3409.086371457033, "Mean Reward": 30.168905942097634, "Episode": 953, "Episode Step": 113}
{"Training Time": 1.3649607144461737, "Episode Reward": 5916.869076853788, "Mean Reward": 50.142958278421936, "Episode": 954, "Episode Step": 118}
{"Training Time": 1.3662437652879291, "Episode Reward": 4808.034552472461, "Mean Reward": 44.93490235955571, "Episode": 955, "Episode Step": 107}
{"Training Time": 1.3688653369744619, "Episode Reward": 5343.688904789494, "Mean Reward": 24.179587804477347, "Episode": 956, "Episode Step": 221}
{"Training Time": 1.3707114250130124, "Episode Reward": 5592.6008272508925, "Mean Reward": 49.057901993428885, "Episode": 957, "Episode Step": 114}
{"Training Time": 1.372249838643604, "Episode Reward": 5003.301836790696, "Mean Reward": 38.48693720608228, "Episode": 958, "Episode Step": 130}
{"Training Time": 1.3735597466760212, "Episode Reward": 4548.466349260107, "Mean Reward": 40.977174317658616, "Episode": 959, "Episode Step": 111}
{"Training Time": 1.3754508713881175, "Episode Reward": 5236.025722744613, "Mean Reward": 43.63354768953844, "Episode": 960, "Episode Step": 120}
{"Training Time": 1.3770280616813235, "Episode Reward": 4751.283260477536, "Mean Reward": 35.72393428930478, "Episode": 961, "Episode Step": 133}
{"Training Time": 1.378592708044582, "Episode Reward": 4132.063926268548, "Mean Reward": 31.542472719607236, "Episode": 962, "Episode Step": 131}
{"Training Time": 1.3804840894540151, "Episode Reward": 5230.088936082371, "Mean Reward": 42.869581443298124, "Episode": 963, "Episode Step": 122}
{"Training Time": 1.383149969710244, "Episode Reward": 7949.355844683208, "Mean Reward": 34.56241671601395, "Episode": 964, "Episode Step": 230}
{"Training Time": 1.3857047344578637, "Episode Reward": 6772.664016971193, "Mean Reward": 31.210433257931765, "Episode": 965, "Episode Step": 217}
{"Training Time": 1.3875947978099188, "Episode Reward": 5321.473511391704, "Mean Reward": 44.34561259493087, "Episode": 966, "Episode Step": 120}
{"Training Time": 1.3891450419690874, "Episode Reward": 5358.222420745049, "Mean Reward": 40.902461227061444, "Episode": 967, "Episode Step": 131}
{"Training Time": 1.391910579999288, "Episode Reward": 7847.264820020262, "Mean Reward": 33.53531974367633, "Episode": 968, "Episode Step": 234}
{"Training Time": 1.3937580019235611, "Episode Reward": 5001.001230165605, "Mean Reward": 42.02522042155971, "Episode": 969, "Episode Step": 119}
{"Training Time": 1.39524941139751, "Episode Reward": 5977.519545352117, "Mean Reward": 47.06708303426864, "Episode": 970, "Episode Step": 127}
{"Training Time": 1.3967790616883171, "Episode Reward": 4398.49301030382, "Mean Reward": 33.321916744725904, "Episode": 971, "Episode Step": 132}
{"Training Time": 1.3987056322230234, "Episode Reward": 5087.954865820095, "Mean Reward": 40.70363892656076, "Episode": 972, "Episode Step": 125}
{"Training Time": 1.4002846033043332, "Episode Reward": 6175.341891970254, "Mean Reward": 46.43114204488913, "Episode": 973, "Episode Step": 133}
{"Training Time": 1.402638982468181, "Episode Reward": 5707.667112742297, "Mean Reward": 28.538335563711485, "Episode": 974, "Episode Step": 200}
{"Training Time": 1.4045351160897148, "Episode Reward": 5340.218853275686, "Mean Reward": 43.772285682587594, "Episode": 975, "Episode Step": 122}
{"Training Time": 1.4060608900255627, "Episode Reward": 5796.32070758021, "Mean Reward": 44.58708236600162, "Episode": 976, "Episode Step": 130}
{"Training Time": 1.4073636297384897, "Episode Reward": 3845.8061064108147, "Mean Reward": 34.64690185955689, "Episode": 977, "Episode Step": 111}
{"Training Time": 1.409197466108534, "Episode Reward": 5281.932039062263, "Mean Reward": 45.14471828258345, "Episode": 978, "Episode Step": 117}
{"Training Time": 1.410714370277193, "Episode Reward": 5435.073461634505, "Mean Reward": 42.13235241577136, "Episode": 979, "Episode Step": 129}
{"Training Time": 1.4122444380654229, "Episode Reward": 4125.761301232752, "Mean Reward": 31.73662539409809, "Episode": 980, "Episode Step": 130}
{"Training Time": 1.4140907438596089, "Episode Reward": 4729.570676449881, "Mean Reward": 40.77216100387828, "Episode": 981, "Episode Step": 116}
{"Training Time": 1.415578269428677, "Episode Reward": 5625.125711092817, "Mean Reward": 44.643854849943, "Episode": 982, "Episode Step": 126}
{"Training Time": 1.4179895277818044, "Episode Reward": 6155.309278101858, "Mean Reward": 30.62342924428785, "Episode": 983, "Episode Step": 201}
{"Training Time": 1.419318535261684, "Episode Reward": 2446.703152892759, "Mean Reward": 33.98198823462165, "Episode": 984, "Episode Step": 72}
{"Training Time": 1.4208489605453278, "Episode Reward": 5012.6639304227, "Mean Reward": 38.85785992575737, "Episode": 985, "Episode Step": 129}
{"Training Time": 1.4221822230683432, "Episode Reward": 4061.2263264134804, "Mean Reward": 35.94005598596, "Episode": 986, "Episode Step": 113}
{"Training Time": 1.424041001399358, "Episode Reward": 4953.717209679023, "Mean Reward": 41.28097674732519, "Episode": 987, "Episode Step": 120}
{"Training Time": 1.4256863663593928, "Episode Reward": 4922.8572324307, "Mean Reward": 34.913881081068794, "Episode": 988, "Episode Step": 141}
{"Training Time": 1.4271039224995508, "Episode Reward": 3716.5782620716022, "Mean Reward": 31.231750101442035, "Episode": 989, "Episode Step": 119}
{"Training Time": 1.4282375436358983, "Episode Reward": 2436.6187453686775, "Mean Reward": 43.51104902444067, "Episode": 990, "Episode Step": 56}
{"Training Time": 1.4297843033075333, "Episode Reward": 5384.25130923059, "Mean Reward": 40.78978264568629, "Episode": 991, "Episode Step": 132}
{"Training Time": 1.4301823386218813, "Episode Reward": 582.1436264779865, "Mean Reward": 18.191988327437077, "Episode": 992, "Episode Step": 32}
{"Training Time": 1.4331071199973424, "Episode Reward": 8064.518868229854, "Mean Reward": 38.586214680525615, "Episode": 993, "Episode Step": 209}
{"Training Time": 1.4346798344453175, "Episode Reward": 4964.399998066289, "Mean Reward": 37.04776117959917, "Episode": 994, "Episode Step": 134}
{"Training Time": 1.4360272328058878, "Episode Reward": 4016.0590803450564, "Mean Reward": 35.22858842407944, "Episode": 995, "Episode Step": 114}
{"Training Time": 1.4379575475056967, "Episode Reward": 5730.6207555049605, "Mean Reward": 46.21468351213678, "Episode": 996, "Episode Step": 124}
{"Training Time": 1.4392071697447035, "Episode Reward": 4355.981945694371, "Mean Reward": 41.485542339946385, "Episode": 997, "Episode Step": 105}
{"Training Time": 1.44057871805297, "Episode Reward": 4261.81498580199, "Mean Reward": 37.05926074610426, "Episode": 998, "Episode Step": 115}
{"Training Time": 1.4429766288730834, "Episode Reward": 6072.630420493324, "Mean Reward": 50.60525350411103, "Episode": 999, "Episode Step": 120}
{"Training Time": 1.4448002133104536, "Episode Reward": 5109.1285471753645, "Mean Reward": 39.60564765252221, "Episode": 1000, "Episode Step": 129}
{"Training Time": 1.4461545319689644, "Episode Reward": 3675.6252094207443, "Mean Reward": 32.24232639842758, "Episode": 1001, "Episode Step": 114}
{"Training Time": 1.4490642394622166, "Episode Reward": 8514.978697591729, "Mean Reward": 41.33484804656179, "Episode": 1002, "Episode Step": 206}
{"Training Time": 1.4508096463812723, "Episode Reward": 5226.67761914422, "Mean Reward": 35.07837328284712, "Episode": 1003, "Episode Step": 149}
{"Training Time": 1.4521383211347791, "Episode Reward": 4910.947559109653, "Mean Reward": 44.24277080278967, "Episode": 1004, "Episode Step": 111}
{"Training Time": 1.4541283933321636, "Episode Reward": 5791.2234631308875, "Mean Reward": 44.207812695655626, "Episode": 1005, "Episode Step": 131}
{"Training Time": 1.4555939161115223, "Episode Reward": 5162.004943593089, "Mean Reward": 41.62907212575072, "Episode": 1006, "Episode Step": 124}
{"Training Time": 1.456985570854611, "Episode Reward": 3923.117138253895, "Mean Reward": 33.53091571157175, "Episode": 1007, "Episode Step": 117}
{"Training Time": 1.4589672022395663, "Episode Reward": 5871.810984329002, "Mean Reward": 45.51791460720157, "Episode": 1008, "Episode Step": 129}
{"Training Time": 1.460460402501954, "Episode Reward": 5055.3651514476815, "Mean Reward": 39.80602481454867, "Episode": 1009, "Episode Step": 127}
{"Training Time": 1.4618441236019135, "Episode Reward": 4683.347173030843, "Mean Reward": 40.37368252612796, "Episode": 1010, "Episode Step": 116}
{"Training Time": 1.4637592238850063, "Episode Reward": 5577.093658694174, "Mean Reward": 44.616749269553395, "Episode": 1011, "Episode Step": 125}
{"Training Time": 1.4652893644571305, "Episode Reward": 4778.016255659899, "Mean Reward": 37.32825199734296, "Episode": 1012, "Episode Step": 128}
{"Training Time": 1.4666509375307295, "Episode Reward": 4851.595120241746, "Mean Reward": 43.317813573587024, "Episode": 1013, "Episode Step": 112}
{"Training Time": 1.4688755186398823, "Episode Reward": 6179.1169320432855, "Mean Reward": 41.47058343653212, "Episode": 1014, "Episode Step": 149}
{"Training Time": 1.4701926008197996, "Episode Reward": 4029.2713613754167, "Mean Reward": 36.62973964886743, "Episode": 1015, "Episode Step": 110}
{"Training Time": 1.4715213588873546, "Episode Reward": 3988.224267912696, "Mean Reward": 35.609145249220504, "Episode": 1016, "Episode Step": 112}
{"Training Time": 1.4734542052613364, "Episode Reward": 6287.533212961725, "Mean Reward": 50.3002657036938, "Episode": 1017, "Episode Step": 125}
{"Training Time": 1.474862808585167, "Episode Reward": 5331.484695480675, "Mean Reward": 44.42903912900563, "Episode": 1018, "Episode Step": 120}
{"Training Time": 1.476259736418724, "Episode Reward": 4477.5787004618505, "Mean Reward": 38.26990342275086, "Episode": 1019, "Episode Step": 117}
{"Training Time": 1.478220488362842, "Episode Reward": 5002.858956945409, "Mean Reward": 39.08483560113601, "Episode": 1020, "Episode Step": 128}
{"Training Time": 1.4799484174781377, "Episode Reward": 5803.41737079942, "Mean Reward": 39.749434046571366, "Episode": 1021, "Episode Step": 146}
{"Training Time": 1.4812831241554685, "Episode Reward": 4487.780074287276, "Mean Reward": 39.02417455901979, "Episode": 1022, "Episode Step": 115}
{"Training Time": 1.4831840638981926, "Episode Reward": 5783.670527893686, "Mean Reward": 46.64250425720714, "Episode": 1023, "Episode Step": 124}
{"Training Time": 1.484699009458224, "Episode Reward": 5418.120206789201, "Mean Reward": 42.0009318355752, "Episode": 1024, "Episode Step": 129}
{"Training Time": 1.4860621463590198, "Episode Reward": 4649.609926459964, "Mean Reward": 40.08284419362038, "Episode": 1025, "Episode Step": 116}
{"Training Time": 1.4880992258257335, "Episode Reward": 5729.945165377345, "Mean Reward": 42.760784816248844, "Episode": 1026, "Episode Step": 134}
{"Training Time": 1.4899264560805427, "Episode Reward": 5466.076794447965, "Mean Reward": 34.16297996529978, "Episode": 1027, "Episode Step": 160}
{"Training Time": 1.4912626928091048, "Episode Reward": 4104.874801439063, "Mean Reward": 36.32632567645189, "Episode": 1028, "Episode Step": 113}
{"Training Time": 1.493242317504353, "Episode Reward": 5727.474424204646, "Mean Reward": 44.7458939390988, "Episode": 1029, "Episode Step": 128}
{"Training Time": 1.4947127080625957, "Episode Reward": 5426.8713299264, "Mean Reward": 43.4149706394112, "Episode": 1030, "Episode Step": 125}
{"Training Time": 1.4961142455869252, "Episode Reward": 5000.145284841917, "Mean Reward": 42.374112583406074, "Episode": 1031, "Episode Step": 118}
{"Training Time": 1.4981401166650985, "Episode Reward": 5487.54148015757, "Mean Reward": 40.64845540857459, "Episode": 1032, "Episode Step": 135}
{"Training Time": 1.4997177147203022, "Episode Reward": 4783.9578015346915, "Mean Reward": 35.70117762339322, "Episode": 1033, "Episode Step": 134}
{"Training Time": 1.5010095961226357, "Episode Reward": 4181.536342917441, "Mean Reward": 38.36271874236185, "Episode": 1034, "Episode Step": 109}
{"Training Time": 1.5021714841657214, "Episode Reward": 2290.1403014626117, "Mean Reward": 38.16900502437686, "Episode": 1035, "Episode Step": 60}
{"Training Time": 1.503779983917872, "Episode Reward": 4611.517319322008, "Mean Reward": 33.660710360014654, "Episode": 1036, "Episode Step": 137}
{"Training Time": 1.5055100602573819, "Episode Reward": 5568.55143357781, "Mean Reward": 37.37282841327389, "Episode": 1037, "Episode Step": 149}
{"Training Time": 1.5075312944253285, "Episode Reward": 5794.890841095273, "Mean Reward": 43.570607827784, "Episode": 1038, "Episode Step": 133}
{"Training Time": 1.5091077822446823, "Episode Reward": 4960.399256886949, "Mean Reward": 37.29623501418759, "Episode": 1039, "Episode Step": 133}
{"Training Time": 1.5114315778017045, "Episode Reward": 6513.906679989947, "Mean Reward": 32.898518585807814, "Episode": 1040, "Episode Step": 198}
{"Training Time": 1.5134563510947758, "Episode Reward": 5490.892949546046, "Mean Reward": 42.23763807343112, "Episode": 1041, "Episode Step": 130}
{"Training Time": 1.5151272600226933, "Episode Reward": 5433.202564650576, "Mean Reward": 39.08778823489623, "Episode": 1042, "Episode Step": 139}
{"Training Time": 1.5164864936139848, "Episode Reward": 4356.445319387498, "Mean Reward": 38.55261344590706, "Episode": 1043, "Episode Step": 113}
{"Training Time": 1.5184956333372328, "Episode Reward": 5510.379993549737, "Mean Reward": 42.38753841192106, "Episode": 1044, "Episode Step": 130}
{"Training Time": 1.521220945848359, "Episode Reward": 7921.45165209374, "Mean Reward": 33.99764657550961, "Episode": 1045, "Episode Step": 233}
{"Training Time": 1.5226540702581406, "Episode Reward": 4365.249004991953, "Mean Reward": 36.07643805778474, "Episode": 1046, "Episode Step": 121}
{"Training Time": 1.5247840308480793, "Episode Reward": 4788.601791625287, "Mean Reward": 33.961714834221894, "Episode": 1047, "Episode Step": 141}
{"Training Time": 1.5263317402866152, "Episode Reward": 5611.745484553119, "Mean Reward": 43.16727295810092, "Episode": 1048, "Episode Step": 130}
{"Training Time": 1.5292878722482257, "Episode Reward": 6814.710588432956, "Mean Reward": 33.24249067528271, "Episode": 1049, "Episode Step": 205}
{"Training Time": 1.53135963526037, "Episode Reward": 5318.448132997079, "Mean Reward": 39.10623627203734, "Episode": 1050, "Episode Step": 136}
{"Training Time": 1.534169351392322, "Episode Reward": 9048.009264315646, "Mean Reward": 38.33902230642223, "Episode": 1051, "Episode Step": 236}
{"Training Time": 1.5365833661291335, "Episode Reward": 7085.243350017877, "Mean Reward": 34.90267660107328, "Episode": 1052, "Episode Step": 203}
{"Training Time": 1.538529442747434, "Episode Reward": 5822.193202526572, "Mean Reward": 45.84404096477616, "Episode": 1053, "Episode Step": 127}
{"Training Time": 1.541075016922421, "Episode Reward": 7975.7865707819965, "Mean Reward": 36.92493782769443, "Episode": 1054, "Episode Step": 216}
{"Training Time": 1.5433867030673556, "Episode Reward": 6543.629676605126, "Mean Reward": 33.21639429748795, "Episode": 1055, "Episode Step": 197}
{"Training Time": 1.545339588324229, "Episode Reward": 5426.208760121409, "Mean Reward": 42.39225593844851, "Episode": 1056, "Episode Step": 128}
{"Training Time": 1.5467978369527393, "Episode Reward": 5344.220034130539, "Mean Reward": 43.098548662343056, "Episode": 1057, "Episode Step": 124}
{"Training Time": 1.5485409280326632, "Episode Reward": 5252.354333923325, "Mean Reward": 35.48888063461706, "Episode": 1058, "Episode Step": 148}
{"Training Time": 1.5505227158466974, "Episode Reward": 4843.743156606941, "Mean Reward": 37.25956274313032, "Episode": 1059, "Episode Step": 130}
{"Training Time": 1.5522776675224303, "Episode Reward": 5502.401571334716, "Mean Reward": 36.68267714223144, "Episode": 1060, "Episode Step": 150}
{"Training Time": 1.5544295038779576, "Episode Reward": 5642.077202903691, "Mean Reward": 31.00042419177852, "Episode": 1061, "Episode Step": 182}
{"Training Time": 1.5564565789037281, "Episode Reward": 5061.424384208665, "Mean Reward": 38.93403372468204, "Episode": 1062, "Episode Step": 130}
{"Training Time": 1.5579216021961635, "Episode Reward": 5406.3656623388515, "Mean Reward": 43.59972308337783, "Episode": 1063, "Episode Step": 124}
{"Training Time": 1.5597063327497906, "Episode Reward": 4184.410381353066, "Mean Reward": 27.711327028828254, "Episode": 1064, "Episode Step": 151}
{"Training Time": 1.5621776552995046, "Episode Reward": 5345.264376719093, "Mean Reward": 31.442731627759372, "Episode": 1065, "Episode Step": 170}
{"Training Time": 1.5654157714049022, "Episode Reward": 10874.985029114965, "Mean Reward": 39.5454001058726, "Episode": 1066, "Episode Step": 275}
{"Training Time": 1.5659043377637862, "Episode Reward": 1082.4035000791314, "Mean Reward": 26.400085367783692, "Episode": 1067, "Episode Step": 41}
{"Training Time": 1.56827109919654, "Episode Reward": 5651.906870400381, "Mean Reward": 34.67427527852995, "Episode": 1068, "Episode Step": 163}
{"Training Time": 1.5700477647119098, "Episode Reward": 6268.777891040307, "Mean Reward": 40.97240451660331, "Episode": 1069, "Episode Step": 153}
{"Training Time": 1.5723039066791535, "Episode Reward": 6450.532980974136, "Mean Reward": 33.59652594257363, "Episode": 1070, "Episode Step": 192}
{"Training Time": 1.5747258514165878, "Episode Reward": 5125.431147888756, "Mean Reward": 30.691204478375784, "Episode": 1071, "Episode Step": 167}
{"Training Time": 1.5765441227621502, "Episode Reward": 6313.601131357893, "Mean Reward": 40.997409943882424, "Episode": 1072, "Episode Step": 154}
{"Training Time": 1.5788081314166387, "Episode Reward": 6462.5522978254785, "Mean Reward": 33.48472693173823, "Episode": 1073, "Episode Step": 193}
{"Training Time": 1.5828962963819504, "Episode Reward": 10384.579107439684, "Mean Reward": 34.047800352261255, "Episode": 1074, "Episode Step": 305}
{"Training Time": 1.5843621552652782, "Episode Reward": 5299.662012661896, "Mean Reward": 43.086683029771514, "Episode": 1075, "Episode Step": 123}
{"Training Time": 1.5866746869352129, "Episode Reward": 6640.688246855022, "Mean Reward": 34.054811522333445, "Episode": 1076, "Episode Step": 195}
{"Training Time": 1.5886315761009853, "Episode Reward": 5054.047679129102, "Mean Reward": 39.17866417929537, "Episode": 1077, "Episode Step": 129}
{"Training Time": 1.591762317750189, "Episode Reward": 11413.860293479067, "Mean Reward": 42.58903094581741, "Episode": 1078, "Episode Step": 268}
{"Training Time": 1.5940077996916242, "Episode Reward": 6748.226965360118, "Mean Reward": 35.331031232251924, "Episode": 1079, "Episode Step": 191}
{"Training Time": 1.5959008008241653, "Episode Reward": 5145.027611825807, "Mean Reward": 41.49215815988554, "Episode": 1080, "Episode Step": 124}
{"Training Time": 1.5976981905433867, "Episode Reward": 6306.771759127785, "Mean Reward": 42.0451450608519, "Episode": 1081, "Episode Step": 150}
{"Training Time": 1.5990758983294169, "Episode Reward": 4593.535614537939, "Mean Reward": 38.928267919813045, "Episode": 1082, "Episode Step": 118}
{"Training Time": 1.600940951373842, "Episode Reward": 5454.325604089545, "Mean Reward": 45.07707110817805, "Episode": 1083, "Episode Step": 121}
{"Training Time": 1.602606775297059, "Episode Reward": 5433.112959348259, "Mean Reward": 38.80794970963042, "Episode": 1084, "Episode Step": 140}
{"Training Time": 1.6050991939173804, "Episode Reward": 6472.669413191451, "Mean Reward": 30.24611875323108, "Episode": 1085, "Episode Step": 214}
{"Training Time": 1.6071303777562247, "Episode Reward": 5320.681468204499, "Mean Reward": 40.61588907026335, "Episode": 1086, "Episode Step": 131}
{"Training Time": 1.6091071955362957, "Episode Reward": 5652.173464360426, "Mean Reward": 34.049237737111, "Episode": 1087, "Episode Step": 166}
{"Training Time": 1.6115335416793823, "Episode Reward": 6463.5721477134175, "Mean Reward": 32.317860738567084, "Episode": 1088, "Episode Step": 200}
{"Training Time": 1.6135109649764168, "Episode Reward": 5830.146270169465, "Mean Reward": 45.90666354464146, "Episode": 1089, "Episode Step": 127}
{"Training Time": 1.616132578055064, "Episode Reward": 8234.794632311128, "Mean Reward": 37.77428730417949, "Episode": 1090, "Episode Step": 218}
{"Training Time": 1.6185370305511686, "Episode Reward": 6167.8639565732365, "Mean Reward": 30.2346272381041, "Episode": 1091, "Episode Step": 204}
{"Training Time": 1.620731963912646, "Episode Reward": 5778.258667499795, "Mean Reward": 39.5771141609575, "Episode": 1092, "Episode Step": 146}
{"Training Time": 1.6233895958132214, "Episode Reward": 7836.142207426635, "Mean Reward": 35.13965115437953, "Episode": 1093, "Episode Step": 223}
{"Training Time": 1.6257789741622077, "Episode Reward": 6346.4292511931435, "Mean Reward": 31.263198281739623, "Episode": 1094, "Episode Step": 203}
{"Training Time": 1.6277610425154367, "Episode Reward": 4889.457610741506, "Mean Reward": 38.198887583918015, "Episode": 1095, "Episode Step": 128}
{"Training Time": 1.629630038075977, "Episode Reward": 6629.815363843628, "Mean Reward": 42.773002347378245, "Episode": 1096, "Episode Step": 155}
{"Training Time": 1.632002404199706, "Episode Reward": 6524.310370889465, "Mean Reward": 32.621551854447326, "Episode": 1097, "Episode Step": 200}
{"Training Time": 1.6341523038678698, "Episode Reward": 5562.672226711366, "Mean Reward": 38.89980578119837, "Episode": 1098, "Episode Step": 143}
{"Training Time": 1.6361580038732952, "Episode Reward": 5457.872687041707, "Mean Reward": 42.639630367513334, "Episode": 1099, "Episode Step": 128}
{"Training Time": 1.6370511194732453, "Episode Reward": 1244.6431425904186, "Mean Reward": 25.40088046102895, "Episode": 1100, "Episode Step": 49}
{"Training Time": 1.6400928255584506, "Episode Reward": 8020.179384679576, "Mean Reward": 36.789813691190716, "Episode": 1101, "Episode Step": 218}
{"Training Time": 1.642737494442198, "Episode Reward": 8219.042802407683, "Mean Reward": 37.190238924921644, "Episode": 1102, "Episode Step": 221}
{"Training Time": 1.6452452474832535, "Episode Reward": 6165.21461751777, "Mean Reward": 29.08120102602722, "Episode": 1103, "Episode Step": 212}
{"Training Time": 1.6472704836395051, "Episode Reward": 4715.215475990799, "Mean Reward": 36.2708882768523, "Episode": 1104, "Episode Step": 130}
{"Training Time": 1.650058421360122, "Episode Reward": 6631.352324359109, "Mean Reward": 28.339112497261148, "Episode": 1105, "Episode Step": 234}
{"Training Time": 1.6525835066371495, "Episode Reward": 6438.936505678454, "Mean Reward": 30.229748852950486, "Episode": 1106, "Episode Step": 213}
{"Training Time": 1.6549820286035537, "Episode Reward": 5511.191267693199, "Mean Reward": 33.60482480300731, "Episode": 1107, "Episode Step": 164}
{"Training Time": 1.6565414972437753, "Episode Reward": 4913.51891019126, "Mean Reward": 37.22362810750955, "Episode": 1108, "Episode Step": 132}
{"Training Time": 1.6582730236318377, "Episode Reward": 4544.762849777092, "Mean Reward": 30.916754080116274, "Episode": 1109, "Episode Step": 147}
{"Training Time": 1.6602432891395358, "Episode Reward": 5096.997694426315, "Mean Reward": 40.45236265417711, "Episode": 1110, "Episode Step": 126}
{"Training Time": 1.6625882655382156, "Episode Reward": 7776.513652646526, "Mean Reward": 39.87955719305911, "Episode": 1111, "Episode Step": 195}
{"Training Time": 1.66610794670052, "Episode Reward": 7180.819030473046, "Mean Reward": 24.01611715877273, "Episode": 1112, "Episode Step": 299}
{"Training Time": 1.667981699705124, "Episode Reward": 4924.838824052659, "Mean Reward": 41.38520020212319, "Episode": 1113, "Episode Step": 119}
{"Training Time": 1.6695887911319733, "Episode Reward": 5795.019379368343, "Mean Reward": 42.61043661300252, "Episode": 1114, "Episode Step": 136}
{"Training Time": 1.6708075683646733, "Episode Reward": -613.4310986268941, "Mean Reward": -6.014030378695041, "Episode": 1115, "Episode Step": 102}
{"Training Time": 1.6727669799990124, "Episode Reward": 3955.5246264653624, "Mean Reward": 31.145863200514665, "Episode": 1116, "Episode Step": 127}
{"Training Time": 1.67420824944973, "Episode Reward": 3878.5260355909645, "Mean Reward": 31.791197013040694, "Episode": 1117, "Episode Step": 122}
{"Training Time": 1.6754400338729223, "Episode Reward": -413.9615620071488, "Mean Reward": -4.058446686344596, "Episode": 1118, "Episode Step": 102}
{"Training Time": 1.6773404747247695, "Episode Reward": 5947.460806555818, "Mean Reward": 48.7496787422608, "Episode": 1119, "Episode Step": 122}
{"Training Time": 1.6787050738599565, "Episode Reward": 5141.371551154581, "Mean Reward": 43.57094534876763, "Episode": 1120, "Episode Step": 118}
{"Training Time": 1.6799284236298666, "Episode Reward": -355.30871763783085, "Mean Reward": -3.483418800370891, "Episode": 1121, "Episode Step": 102}
{"Training Time": 1.6829106055365668, "Episode Reward": 7845.456466051972, "Mean Reward": 37.53806921555967, "Episode": 1122, "Episode Step": 209}
{"Training Time": 1.6846511616971758, "Episode Reward": 6048.798260750711, "Mean Reward": 41.715850074142836, "Episode": 1123, "Episode Step": 145}
{"Training Time": 1.6873811374770271, "Episode Reward": 7362.986946010081, "Mean Reward": 31.737012698319315, "Episode": 1124, "Episode Step": 232}
{"Training Time": 1.6903535777992673, "Episode Reward": 7623.694226851552, "Mean Reward": 35.45904291558862, "Episode": 1125, "Episode Step": 215}
{"Training Time": 1.6917397303051418, "Episode Reward": 4961.12162150305, "Mean Reward": 42.043403572059745, "Episode": 1126, "Episode Step": 118}
{"Training Time": 1.6929580108324687, "Episode Reward": -356.0067596705982, "Mean Reward": -3.4902623497117475, "Episode": 1127, "Episode Step": 102}
{"Training Time": 1.6959326086441675, "Episode Reward": 8264.75963510403, "Mean Reward": 38.26277608844458, "Episode": 1128, "Episode Step": 216}
{"Training Time": 1.6973428030808766, "Episode Reward": 5248.886210045383, "Mean Reward": 43.74071841704486, "Episode": 1129, "Episode Step": 120}
{"Training Time": 1.6985472286409802, "Episode Reward": -4.0631709343488325, "Mean Reward": -0.039835009160282674, "Episode": 1130, "Episode Step": 102}
{"Training Time": 1.701451406677564, "Episode Reward": 7226.272515420942, "Mean Reward": 34.24773703990968, "Episode": 1131, "Episode Step": 211}
{"Training Time": 1.7034980244768991, "Episode Reward": 5590.158440780653, "Mean Reward": 32.31305457098643, "Episode": 1132, "Episode Step": 173}
{"Training Time": 1.7061195727851657, "Episode Reward": 7034.487215615021, "Mean Reward": 31.403960783995633, "Episode": 1133, "Episode Step": 224}
{"Training Time": 1.7080371780527963, "Episode Reward": 5457.472963949201, "Mean Reward": 43.31327749166032, "Episode": 1134, "Episode Step": 126}
{"Training Time": 1.7099671514166725, "Episode Reward": 4863.288302876327, "Mean Reward": 29.12148684357082, "Episode": 1135, "Episode Step": 167}
{"Training Time": 1.7123326405551698, "Episode Reward": 6715.959059377489, "Mean Reward": 33.08354216442113, "Episode": 1136, "Episode Step": 203}
{"Training Time": 1.7153067294756572, "Episode Reward": 7707.288336961396, "Mean Reward": 36.015366060567274, "Episode": 1137, "Episode Step": 214}
{"Training Time": 1.7168633388810688, "Episode Reward": 4255.53324431491, "Mean Reward": 31.996490558758722, "Episode": 1138, "Episode Step": 133}
{"Training Time": 1.7192660213841333, "Episode Reward": 7188.022482692531, "Mean Reward": 35.40897774725385, "Episode": 1139, "Episode Step": 203}
{"Training Time": 1.7221412430869207, "Episode Reward": 8000.174026076509, "Mean Reward": 38.27834462237564, "Episode": 1140, "Episode Step": 209}
{"Training Time": 1.7241681719488569, "Episode Reward": 4115.219901563689, "Mean Reward": 23.650689089446487, "Episode": 1141, "Episode Step": 174}
{"Training Time": 1.7264671602514055, "Episode Reward": 7752.787897160727, "Mean Reward": 39.354253285079835, "Episode": 1142, "Episode Step": 197}
{"Training Time": 1.7286985191371707, "Episode Reward": 5864.507424201014, "Mean Reward": 38.58228568553299, "Episode": 1143, "Episode Step": 152}
{"Training Time": 1.7302752619319492, "Episode Reward": 4441.044164987363, "Mean Reward": 32.89662344435084, "Episode": 1144, "Episode Step": 135}
{"Training Time": 1.7325707669390573, "Episode Reward": 6868.32571025478, "Mean Reward": 34.68851368815545, "Episode": 1145, "Episode Step": 198}
{"Training Time": 1.7345078994168175, "Episode Reward": 5320.961687996204, "Mean Reward": 42.22985466663654, "Episode": 1146, "Episode Step": 126}
{"Training Time": 1.7366004014015197, "Episode Reward": 4202.771447984985, "Mean Reward": 23.61107555047744, "Episode": 1147, "Episode Step": 178}
{"Training Time": 1.7390436038706039, "Episode Reward": 6496.016784922702, "Mean Reward": 30.786809407216598, "Episode": 1148, "Episode Step": 211}
{"Training Time": 1.7418506805764304, "Episode Reward": 5624.217418977695, "Mean Reward": 36.759590973710424, "Episode": 1149, "Episode Step": 153}
{"Training Time": 1.7437330763869816, "Episode Reward": 4021.493560558054, "Mean Reward": 30.011145974313838, "Episode": 1150, "Episode Step": 134}
{"Training Time": 1.746174673901664, "Episode Reward": 6361.526774039762, "Mean Reward": 30.73201340115827, "Episode": 1151, "Episode Step": 207}
{"Training Time": 1.749098115828302, "Episode Reward": 7951.643557945626, "Mean Reward": 37.685514492633295, "Episode": 1152, "Episode Step": 211}
{"Training Time": 1.752083465854327, "Episode Reward": 6062.100004020089, "Mean Reward": 23.772941192235642, "Episode": 1153, "Episode Step": 255}
{"Training Time": 1.7545024158557256, "Episode Reward": 7325.242871806582, "Mean Reward": 35.3876467237033, "Episode": 1154, "Episode Step": 207}
{"Training Time": 1.756517718301879, "Episode Reward": 5100.520742017636, "Mean Reward": 38.93527283982928, "Episode": 1155, "Episode Step": 131}
{"Training Time": 1.759334651099311, "Episode Reward": 6673.581524288468, "Mean Reward": 27.57678315821681, "Episode": 1156, "Episode Step": 242}
{"Training Time": 1.7616879705588022, "Episode Reward": 6755.011886483593, "Mean Reward": 33.77505943241797, "Episode": 1157, "Episode Step": 200}
{"Training Time": 1.7639147477679782, "Episode Reward": 6136.8737133702025, "Mean Reward": 40.64154777066359, "Episode": 1158, "Episode Step": 151}
{"Training Time": 1.767066892782847, "Episode Reward": 6192.8158108775315, "Mean Reward": 23.194066707406485, "Episode": 1159, "Episode Step": 267}
{"Training Time": 1.769505471918318, "Episode Reward": 7241.991266983293, "Mean Reward": 35.326786668211184, "Episode": 1160, "Episode Step": 205}
{"Training Time": 1.7722271563609442, "Episode Reward": 6379.12364641967, "Mean Reward": 33.39855312261607, "Episode": 1161, "Episode Step": 191}
{"Training Time": 1.7750231266684002, "Episode Reward": 5810.605618415774, "Mean Reward": 24.312157399229182, "Episode": 1162, "Episode Step": 239}
{"Training Time": 1.7774314569764667, "Episode Reward": 7625.262604273752, "Mean Reward": 37.936629872008716, "Episode": 1163, "Episode Step": 201}
{"Training Time": 1.7844250872400071, "Episode Reward": 22980.878136665633, "Mean Reward": 41.11069434108342, "Episode": 1164, "Episode Step": 559}
{"Training Time": 1.7867956986029943, "Episode Reward": 6168.370732663295, "Mean Reward": 30.536488775560866, "Episode": 1165, "Episode Step": 202}
{"Training Time": 1.7892080185810726, "Episode Reward": 6380.349053940941, "Mean Reward": 31.276220852651672, "Episode": 1166, "Episode Step": 204}
{"Training Time": 1.7910850058661567, "Episode Reward": 4730.139810086022, "Mean Reward": 39.092064546165474, "Episode": 1167, "Episode Step": 121}
{"Training Time": 1.7935545630587473, "Episode Reward": 6213.447295953192, "Mean Reward": 29.44761751636584, "Episode": 1168, "Episode Step": 211}
{"Training Time": 1.796168747809198, "Episode Reward": 6897.645942636635, "Mean Reward": 30.793062243913546, "Episode": 1169, "Episode Step": 224}
{"Training Time": 1.7991612652937572, "Episode Reward": 6934.286504102111, "Mean Reward": 32.55533570000991, "Episode": 1170, "Episode Step": 213}
{"Training Time": 1.8015550144513448, "Episode Reward": 5658.107538025537, "Mean Reward": 27.600524575734326, "Episode": 1171, "Episode Step": 205}
{"Training Time": 1.8046253924899631, "Episode Reward": 10449.352857653299, "Mean Reward": 39.431520217559616, "Episode": 1172, "Episode Step": 265}
{"Training Time": 1.8075433146953583, "Episode Reward": 7432.036970905725, "Mean Reward": 35.05677816464964, "Episode": 1173, "Episode Step": 212}
{"Training Time": 1.8105196447504892, "Episode Reward": 6131.843920829747, "Mean Reward": 24.046446748351947, "Episode": 1174, "Episode Step": 255}
{"Training Time": 1.8122310833136241, "Episode Reward": 5022.2335144616645, "Mean Reward": 34.876621628206, "Episode": 1175, "Episode Step": 144}
{"Training Time": 1.8152069736189311, "Episode Reward": 7464.068241602235, "Mean Reward": 34.71659647256853, "Episode": 1176, "Episode Step": 215}
{"Training Time": 1.8179974344703886, "Episode Reward": 5856.876928088156, "Mean Reward": 24.6087265886057, "Episode": 1177, "Episode Step": 238}
{"Training Time": 1.8203399850262536, "Episode Reward": 7718.0237243445235, "Mean Reward": 39.17778540276408, "Episode": 1178, "Episode Step": 197}
{"Training Time": 1.8231831383042865, "Episode Reward": 6984.0640538164325, "Mean Reward": 33.73943987350933, "Episode": 1179, "Episode Step": 207}
{"Training Time": 1.8257571719752417, "Episode Reward": 6385.213687206182, "Mean Reward": 28.89236962536734, "Episode": 1180, "Episode Step": 221}
{"Training Time": 1.828623085286882, "Episode Reward": 8804.333955731121, "Mean Reward": 36.08333588414394, "Episode": 1181, "Episode Step": 244}
{"Training Time": 1.8315203352769216, "Episode Reward": 7148.467509760235, "Mean Reward": 33.71918636679356, "Episode": 1182, "Episode Step": 212}
{"Training Time": 1.8338644386000102, "Episode Reward": 5080.55189190031, "Mean Reward": 25.276377571643334, "Episode": 1183, "Episode Step": 201}
{"Training Time": 1.8356095669666925, "Episode Reward": 5863.77233406551, "Mean Reward": 39.88960771473136, "Episode": 1184, "Episode Step": 147}
{"Training Time": 1.8378749189111923, "Episode Reward": 5465.838818707467, "Mean Reward": 36.6834820047481, "Episode": 1185, "Episode Step": 149}
{"Training Time": 1.8396601105398602, "Episode Reward": 4229.986520791043, "Mean Reward": 28.199910138606956, "Episode": 1186, "Episode Step": 150}
{"Training Time": 1.8409539419412613, "Episode Reward": 4621.3342920655305, "Mean Reward": 42.3975623125278, "Episode": 1187, "Episode Step": 109}
{"Training Time": 1.8438950502872467, "Episode Reward": 7498.568258163102, "Mean Reward": 36.938759892429076, "Episode": 1188, "Episode Step": 203}
{"Training Time": 1.8467258719603221, "Episode Reward": 6020.90621764516, "Mean Reward": 25.8407992173612, "Episode": 1189, "Episode Step": 233}
{"Training Time": 1.849267375866572, "Episode Reward": 6870.546371415383, "Mean Reward": 33.191045272538084, "Episode": 1190, "Episode Step": 207}
{"Training Time": 1.8522688266966079, "Episode Reward": 7962.999242374287, "Mean Reward": 38.10047484389611, "Episode": 1191, "Episode Step": 209}
{"Training Time": 1.8552664769358105, "Episode Reward": 5471.9485790226, "Mean Reward": 22.153637971751415, "Episode": 1192, "Episode Step": 247}
{"Training Time": 1.858644178642167, "Episode Reward": 10259.505321545588, "Mean Reward": 36.51069509446828, "Episode": 1193, "Episode Step": 281}
{"Training Time": 1.8609067149957021, "Episode Reward": 4742.963614678291, "Mean Reward": 31.61975743118861, "Episode": 1194, "Episode Step": 150}
{"Training Time": 1.8629636922147539, "Episode Reward": 5146.256959837071, "Mean Reward": 29.920098603703902, "Episode": 1195, "Episode Step": 172}
{"Training Time": 1.865537194742097, "Episode Reward": 6429.596598826116, "Mean Reward": 30.18589952500524, "Episode": 1196, "Episode Step": 213}
{"Training Time": 1.8687675238980188, "Episode Reward": 8061.716813624351, "Mean Reward": 35.05094266793196, "Episode": 1197, "Episode Step": 230}
{"Training Time": 1.8715635869238112, "Episode Reward": 6679.2906006207695, "Mean Reward": 28.422513194130936, "Episode": 1198, "Episode Step": 235}
{"Training Time": 1.8745286133554246, "Episode Reward": 6344.952957310059, "Mean Reward": 30.50458152552913, "Episode": 1199, "Episode Step": 208}
{"Training Time": 1.8772320019536548, "Episode Reward": 5664.334222398639, "Mean Reward": 30.453409797842145, "Episode": 1200, "Episode Step": 186}
{"Training Time": 1.8800286738740073, "Episode Reward": 6642.671431653946, "Mean Reward": 28.88118013762585, "Episode": 1201, "Episode Step": 230}
{"Training Time": 1.8818343994352553, "Episode Reward": 5811.11447111585, "Mean Reward": 39.26428696699899, "Episode": 1202, "Episode Step": 148}
{"Training Time": 1.884752824968762, "Episode Reward": 7302.055876878913, "Mean Reward": 36.87907008524704, "Episode": 1203, "Episode Step": 198}
{"Training Time": 1.8868533983495501, "Episode Reward": 5268.794743038419, "Mean Reward": 30.280429557692063, "Episode": 1204, "Episode Step": 174}
{"Training Time": 1.889867568347189, "Episode Reward": 9305.649948586675, "Mean Reward": 37.37208814693444, "Episode": 1205, "Episode Step": 249}
{"Training Time": 1.8929616072442796, "Episode Reward": 7918.251825416566, "Mean Reward": 36.65857326581744, "Episode": 1206, "Episode Step": 216}
{"Training Time": 1.8942094166411294, "Episode Reward": 4385.6813225164915, "Mean Reward": 42.99687571094599, "Episode": 1207, "Episode Step": 102}
{"Training Time": 1.8966498005390167, "Episode Reward": 7017.57788987332, "Mean Reward": 35.0878894493666, "Episode": 1208, "Episode Step": 200}
{"Training Time": 1.8995481408304637, "Episode Reward": 5467.381787688539, "Mean Reward": 27.336908938442694, "Episode": 1209, "Episode Step": 200}
{"Training Time": 1.9022534975078371, "Episode Reward": 6332.346635949576, "Mean Reward": 28.269404624774893, "Episode": 1210, "Episode Step": 224}
{"Training Time": 1.9047548316584693, "Episode Reward": 7935.151133723174, "Mean Reward": 38.70805431084475, "Episode": 1211, "Episode Step": 205}
{"Training Time": 1.9077240441905128, "Episode Reward": 6920.8582300258595, "Mean Reward": 33.27335687512432, "Episode": 1212, "Episode Step": 208}
{"Training Time": 1.9113421561320623, "Episode Reward": 7934.544563235856, "Mean Reward": 26.27332636833065, "Episode": 1213, "Episode Step": 302}
{"Training Time": 1.9132127522097693, "Episode Reward": 4868.18524285355, "Mean Reward": 31.611592486062015, "Episode": 1214, "Episode Step": 154}
{"Training Time": 1.9196466510825687, "Episode Reward": 15712.654184953743, "Mean Reward": 31.936288993808418, "Episode": 1215, "Episode Step": 492}
{"Training Time": 1.9232643236054314, "Episode Reward": 7784.4895347079555, "Mean Reward": 26.03508205587945, "Episode": 1216, "Episode Step": 299}
{"Training Time": 1.9311954375108082, "Episode Reward": 31634.155928953205, "Mean Reward": 47.427520133363124, "Episode": 1217, "Episode Step": 667}
{"Training Time": 1.9339410858021842, "Episode Reward": 6873.76922912251, "Mean Reward": 37.15550934660816, "Episode": 1218, "Episode Step": 185}
{"Training Time": 1.9371171672476664, "Episode Reward": 8326.849128080157, "Mean Reward": 31.66102330068501, "Episode": 1219, "Episode Step": 263}
{"Training Time": 1.9419825219445759, "Episode Reward": 18189.878450956683, "Mean Reward": 45.02445161127892, "Episode": 1220, "Episode Step": 404}
{"Training Time": 1.9447655219501918, "Episode Reward": 6111.822237779604, "Mean Reward": 31.667472734609344, "Episode": 1221, "Episode Step": 193}
{"Training Time": 1.9469496499829821, "Episode Reward": 5651.079264378781, "Mean Reward": 30.382146582681617, "Episode": 1222, "Episode Step": 186}
{"Training Time": 1.9498197786013285, "Episode Reward": 9900.550446666772, "Mean Reward": 41.424897266388164, "Episode": 1223, "Episode Step": 239}
{"Training Time": 1.9523597239123451, "Episode Reward": 5143.194661046578, "Mean Reward": 29.72944890778369, "Episode": 1224, "Episode Step": 173}
{"Training Time": 1.9551332402891584, "Episode Reward": 8230.601497507032, "Mean Reward": 36.09912937503084, "Episode": 1225, "Episode Step": 228}
{"Training Time": 1.958391171362665, "Episode Reward": 11196.139129830603, "Mean Reward": 40.861821641717526, "Episode": 1226, "Episode Step": 274}
{"Training Time": 1.9611103436019686, "Episode Reward": 6141.102734801168, "Mean Reward": 32.32159334105878, "Episode": 1227, "Episode Step": 190}
{"Training Time": 1.9637754819128248, "Episode Reward": 7664.56030696165, "Mean Reward": 34.52504642775518, "Episode": 1228, "Episode Step": 222}
{"Training Time": 1.9655229736036723, "Episode Reward": 4967.497154006771, "Mean Reward": 34.25860106211566, "Episode": 1229, "Episode Step": 145}
{"Training Time": 1.9682480397489335, "Episode Reward": 6290.083283471208, "Mean Reward": 33.280863933710094, "Episode": 1230, "Episode Step": 189}
{"Training Time": 1.970300775302781, "Episode Reward": 5863.804460992078, "Mean Reward": 34.29125415784841, "Episode": 1231, "Episode Step": 171}
{"Training Time": 1.9720916683144039, "Episode Reward": 5892.65640648673, "Mean Reward": 40.086098003311086, "Episode": 1232, "Episode Step": 147}
{"Training Time": 1.9748934935861164, "Episode Reward": 6390.376231051767, "Mean Reward": 32.11244337211943, "Episode": 1233, "Episode Step": 199}
{"Training Time": 1.976948501666387, "Episode Reward": 6394.398208397516, "Mean Reward": 36.961839354898935, "Episode": 1234, "Episode Step": 173}
{"Training Time": 1.9785223866833581, "Episode Reward": 5883.738717784634, "Mean Reward": 44.23863697582431, "Episode": 1235, "Episode Step": 133}
{"Training Time": 1.9813958422342937, "Episode Reward": 6918.849742824896, "Mean Reward": 33.750486550365345, "Episode": 1236, "Episode Step": 205}
{"Training Time": 1.9845597408215205, "Episode Reward": 8496.579756972038, "Mean Reward": 32.0625651206492, "Episode": 1237, "Episode Step": 265}
{"Training Time": 1.987412571112315, "Episode Reward": 8745.456706836369, "Mean Reward": 36.28820210305547, "Episode": 1238, "Episode Step": 241}
{"Training Time": 1.990212685002221, "Episode Reward": 6421.919464520774, "Mean Reward": 32.59857596203439, "Episode": 1239, "Episode Step": 197}
{"Training Time": 1.9930492330259746, "Episode Reward": 6193.557462468389, "Mean Reward": 25.69940855796012, "Episode": 1240, "Episode Step": 241}
{"Training Time": 1.995927720533477, "Episode Reward": 9453.098325866531, "Mean Reward": 38.58407479945523, "Episode": 1241, "Episode Step": 245}
{"Training Time": 1.999463840259446, "Episode Reward": 8924.679341771915, "Mean Reward": 34.591780394464784, "Episode": 1242, "Episode Step": 258}
{"Training Time": 2.001640717784564, "Episode Reward": 6756.035988908726, "Mean Reward": 37.3261656845786, "Episode": 1243, "Episode Step": 181}
{"Training Time": 2.005050774415334, "Episode Reward": 13601.318319861257, "Mean Reward": 47.557057062451946, "Episode": 1244, "Episode Step": 286}
{"Training Time": 2.007888606919183, "Episode Reward": 6036.143901380475, "Mean Reward": 30.95458410964346, "Episode": 1245, "Episode Step": 195}
{"Training Time": 2.0099947369760938, "Episode Reward": 7184.567215934311, "Mean Reward": 41.290616183530524, "Episode": 1246, "Episode Step": 174}
{"Training Time": 2.0112234297063614, "Episode Reward": 4496.721570711352, "Mean Reward": 44.085505595209334, "Episode": 1247, "Episode Step": 102}
{"Training Time": 2.0139028822051155, "Episode Reward": 5780.507329815043, "Mean Reward": 30.584694866746258, "Episode": 1248, "Episode Step": 189}
{"Training Time": 2.0175739455885355, "Episode Reward": 6892.77497726021, "Mean Reward": 37.05792998526994, "Episode": 1249, "Episode Step": 186}
{"Training Time": 2.0206282208363215, "Episode Reward": 9368.7953745428, "Mean Reward": 40.2094222083382, "Episode": 1250, "Episode Step": 233}
{"Training Time": 2.0235050721963246, "Episode Reward": 6681.029797805763, "Mean Reward": 32.75014606767531, "Episode": 1251, "Episode Step": 204}
{"Training Time": 2.02715499414338, "Episode Reward": 12105.003331892955, "Mean Reward": 39.30195886978232, "Episode": 1252, "Episode Step": 308}
{"Training Time": 2.0297034869591397, "Episode Reward": 7852.903279736488, "Mean Reward": 36.52513153365808, "Episode": 1253, "Episode Step": 215}
{"Training Time": 2.032652486364047, "Episode Reward": 6260.499517926762, "Mean Reward": 30.24395902380078, "Episode": 1254, "Episode Step": 207}
{"Training Time": 2.0356587297386595, "Episode Reward": 9512.22161659891, "Mean Reward": 37.7469111769798, "Episode": 1255, "Episode Step": 252}
{"Training Time": 2.0380602319373025, "Episode Reward": 7589.589268033431, "Mean Reward": 37.759150587231, "Episode": 1256, "Episode Step": 201}
{"Training Time": 2.040915553304884, "Episode Reward": 6678.855620732614, "Mean Reward": 32.90076660459415, "Episode": 1257, "Episode Step": 203}
{"Training Time": 2.0434761730829876, "Episode Reward": 8991.613589619443, "Mean Reward": 41.43600732543522, "Episode": 1258, "Episode Step": 217}
{"Training Time": 2.0458299736181895, "Episode Reward": 7416.562737433679, "Mean Reward": 37.839605803233056, "Episode": 1259, "Episode Step": 196}
{"Training Time": 2.0486094197299747, "Episode Reward": 6782.321743066482, "Mean Reward": 33.911608715332406, "Episode": 1260, "Episode Step": 200}
{"Training Time": 2.0513349619176653, "Episode Reward": 9142.714245579207, "Mean Reward": 39.07142839991114, "Episode": 1261, "Episode Step": 234}
{"Training Time": 2.054683514436086, "Episode Reward": 11872.020989229975, "Mean Reward": 41.65621399729816, "Episode": 1262, "Episode Step": 285}
{"Training Time": 2.057417123582628, "Episode Reward": 8254.433989524987, "Mean Reward": 42.99184369544264, "Episode": 1263, "Episode Step": 192}
{"Training Time": 2.060248105261061, "Episode Reward": 10145.202361832378, "Mean Reward": 42.27167650763491, "Episode": 1264, "Episode Step": 240}
{"Training Time": 2.0635068227847415, "Episode Reward": 12088.349467279098, "Mean Reward": 43.7983676350692, "Episode": 1265, "Episode Step": 276}
{"Training Time": 2.066510714424981, "Episode Reward": 8404.76702277598, "Mean Reward": 38.73164526624876, "Episode": 1266, "Episode Step": 217}
{"Training Time": 2.0691014741526708, "Episode Reward": 10251.345822495876, "Mean Reward": 46.597026465890345, "Episode": 1267, "Episode Step": 220}
{"Training Time": 2.0718356466955608, "Episode Reward": 8312.969877889795, "Mean Reward": 35.67798230853989, "Episode": 1268, "Episode Step": 233}
{"Training Time": 2.0746358564164904, "Episode Reward": 6703.35086116153, "Mean Reward": 33.51675430580765, "Episode": 1269, "Episode Step": 200}
{"Training Time": 2.0761972947253122, "Episode Reward": 6502.41810369894, "Mean Reward": 50.01860079768416, "Episode": 1270, "Episode Step": 130}
{"Training Time": 2.078779692252477, "Episode Reward": 7727.602663092936, "Mean Reward": 35.12546665042244, "Episode": 1271, "Episode Step": 220}
{"Training Time": 2.0796342174874414, "Episode Reward": 817.4275279912954, "Mean Reward": 25.54461024972798, "Episode": 1272, "Episode Step": 32}
{"Training Time": 2.0802764147520065, "Episode Reward": 2306.4558494554494, "Mean Reward": 43.51803489538584, "Episode": 1273, "Episode Step": 53}
{"Training Time": 2.0821853302584756, "Episode Reward": 5143.997282993364, "Mean Reward": 31.753069648107186, "Episode": 1274, "Episode Step": 162}
{"Training Time": 2.084936575293541, "Episode Reward": 7974.740212064078, "Mean Reward": 41.10690830960865, "Episode": 1275, "Episode Step": 194}
{"Training Time": 2.0872340466578803, "Episode Reward": 8549.383855038554, "Mean Reward": 44.52804091165913, "Episode": 1276, "Episode Step": 192}
{"Training Time": 2.08909428636233, "Episode Reward": 4769.368904064126, "Mean Reward": 30.770121961704035, "Episode": 1277, "Episode Step": 155}
{"Training Time": 2.091895023915503, "Episode Reward": 7348.4814271510695, "Mean Reward": 38.07503330130088, "Episode": 1278, "Episode Step": 193}
{"Training Time": 2.0941903833548228, "Episode Reward": 8462.685907402178, "Mean Reward": 43.39838926872912, "Episode": 1279, "Episode Step": 195}
{"Training Time": 2.09617518166701, "Episode Reward": 4491.983434395264, "Mean Reward": 26.737996633305144, "Episode": 1280, "Episode Step": 168}
{"Training Time": 2.099018042484919, "Episode Reward": 7209.914778001699, "Mean Reward": 36.23072752764673, "Episode": 1281, "Episode Step": 199}
{"Training Time": 2.102620543307728, "Episode Reward": 15477.74042157447, "Mean Reward": 51.5924680719149, "Episode": 1282, "Episode Step": 300}
{"Training Time": 2.1038986847135757, "Episode Reward": 3034.2742549303316, "Mean Reward": 28.62522882009747, "Episode": 1283, "Episode Step": 106}
{"Training Time": 2.1059769874811174, "Episode Reward": 5200.504462081424, "Mean Reward": 37.959886584535944, "Episode": 1284, "Episode Step": 137}
{"Training Time": 2.109238764444987, "Episode Reward": 13189.758971432813, "Mean Reward": 48.31413542649382, "Episode": 1285, "Episode Step": 273}
{"Training Time": 2.1106177752547794, "Episode Reward": 3869.161488018444, "Mean Reward": 33.64488250450821, "Episode": 1286, "Episode Step": 115}
{"Training Time": 2.113466271691852, "Episode Reward": 7035.084818959343, "Mean Reward": 34.65559024117903, "Episode": 1287, "Episode Step": 203}
{"Training Time": 2.115824100838767, "Episode Reward": 8550.848578803254, "Mean Reward": 42.96908833569474, "Episode": 1288, "Episode Step": 199}
{"Training Time": 2.117160462803311, "Episode Reward": 4075.6435259428017, "Mean Reward": 36.389674338775016, "Episode": 1289, "Episode Step": 112}
{"Training Time": 2.1204607566859988, "Episode Reward": 9456.573184308378, "Mean Reward": 39.238892880947624, "Episode": 1290, "Episode Step": 241}
{"Training Time": 2.12329382830196, "Episode Reward": 12046.457711432613, "Mean Reward": 50.193573797635885, "Episode": 1291, "Episode Step": 240}
{"Training Time": 2.125370073053572, "Episode Reward": 5823.213579109518, "Mean Reward": 33.08644079039499, "Episode": 1292, "Episode Step": 176}
{"Training Time": 2.1287927722268636, "Episode Reward": 10904.615754886383, "Mean Reward": 43.61846301954553, "Episode": 1293, "Episode Step": 250}
{"Training Time": 2.131047172811296, "Episode Reward": 7441.318793477217, "Mean Reward": 38.75686871602717, "Episode": 1294, "Episode Step": 192}
{"Training Time": 2.1339368783103096, "Episode Reward": 7526.154209635822, "Mean Reward": 30.71899677402376, "Episode": 1295, "Episode Step": 245}
{"Training Time": 2.137376197775205, "Episode Reward": 11324.439211514442, "Mean Reward": 44.06396580355814, "Episode": 1296, "Episode Step": 257}
{"Training Time": 2.1386468794610765, "Episode Reward": 5960.892495185279, "Mean Reward": 55.709275655937184, "Episode": 1297, "Episode Step": 107}
{"Training Time": 2.1405426330698862, "Episode Reward": 4934.42920506779, "Mean Reward": 30.45943953745549, "Episode": 1298, "Episode Step": 162}
{"Training Time": 2.1515588735871845, "Episode Reward": 32206.060012147012, "Mean Reward": 41.98964799497655, "Episode": 1299, "Episode Step": 767}
{"Training Time": 2.1541831977499855, "Episode Reward": 8115.156815147809, "Mean Reward": 41.193689416993955, "Episode": 1300, "Episode Step": 197}
{"Training Time": 2.1647930247253844, "Episode Reward": 32298.78477213609, "Mean Reward": 35.96746633868161, "Episode": 1301, "Episode Step": 898}
{"Training Time": 2.166969509190983, "Episode Reward": 5581.0842405482135, "Mean Reward": 40.1516851838001, "Episode": 1302, "Episode Step": 139}
{"Training Time": 2.169514844417572, "Episode Reward": 8978.132672348978, "Mean Reward": 42.55039181208046, "Episode": 1303, "Episode Step": 211}
{"Training Time": 2.172496483922005, "Episode Reward": 9154.745737794645, "Mean Reward": 36.47309058882328, "Episode": 1304, "Episode Step": 251}
{"Training Time": 2.1747198508183163, "Episode Reward": 5559.4916563551305, "Mean Reward": 37.56413281321034, "Episode": 1305, "Episode Step": 148}
{"Training Time": 2.1773177669445674, "Episode Reward": 7482.337418123254, "Mean Reward": 34.64045100982988, "Episode": 1306, "Episode Step": 216}
{"Training Time": 2.1801664939191605, "Episode Reward": 8346.224079409822, "Mean Reward": 35.21613535615958, "Episode": 1307, "Episode Step": 237}
{"Training Time": 2.1824540941582784, "Episode Reward": 5546.767557225478, "Mean Reward": 36.73355998162568, "Episode": 1308, "Episode Step": 151}
{"Training Time": 2.1854540197054546, "Episode Reward": 13186.4593025658, "Mean Reward": 52.7458372102632, "Episode": 1309, "Episode Step": 250}
{"Training Time": 2.188160613046752, "Episode Reward": 7985.364489811482, "Mean Reward": 34.870587291753196, "Episode": 1310, "Episode Step": 229}
{"Training Time": 2.19037742945883, "Episode Reward": 6094.5800997811375, "Mean Reward": 41.74369931356944, "Episode": 1311, "Episode Step": 146}
{"Training Time": 2.1927019402715895, "Episode Reward": 8728.609268103239, "Mean Reward": 44.76209881078584, "Episode": 1312, "Episode Step": 195}
{"Training Time": 2.195594789452023, "Episode Reward": 10135.145918193593, "Mean Reward": 41.032979425884996, "Episode": 1313, "Episode Step": 247}
{"Training Time": 2.199298949175411, "Episode Reward": 10075.546475198942, "Mean Reward": 36.638350818905245, "Episode": 1314, "Episode Step": 275}
{"Training Time": 2.201619706087642, "Episode Reward": 8618.206318880322, "Mean Reward": 43.74724019736204, "Episode": 1315, "Episode Step": 197}
{"Training Time": 2.204624440537559, "Episode Reward": 8331.307838502926, "Mean Reward": 32.41754022763784, "Episode": 1316, "Episode Step": 257}
{"Training Time": 2.2069357844193775, "Episode Reward": 5482.386911336379, "Mean Reward": 34.480420826014964, "Episode": 1317, "Episode Step": 159}
{"Training Time": 2.2086354374885557, "Episode Reward": 5442.693268022834, "Mean Reward": 37.796481027936345, "Episode": 1318, "Episode Step": 144}
{"Training Time": 2.2116838077704113, "Episode Reward": 8006.583402457843, "Mean Reward": 31.033269001774585, "Episode": 1319, "Episode Step": 258}
{"Training Time": 2.2148974455727473, "Episode Reward": 8738.5088836658, "Mean Reward": 37.344055058400855, "Episode": 1320, "Episode Step": 234}
{"Training Time": 2.2172882958253224, "Episode Reward": 8183.258712154683, "Mean Reward": 40.31161927169794, "Episode": 1321, "Episode Step": 203}
{"Training Time": 2.2201966833406024, "Episode Reward": 8333.67430032105, "Mean Reward": 33.60352540452036, "Episode": 1322, "Episode Step": 248}
{"Training Time": 2.2224098916848503, "Episode Reward": 4715.938228867264, "Mean Reward": 31.65059214004875, "Episode": 1323, "Episode Step": 149}
{"Training Time": 2.22478000720342, "Episode Reward": 7574.373007955388, "Mean Reward": 37.87186503977694, "Episode": 1324, "Episode Step": 200}
{"Training Time": 2.2276126146978803, "Episode Reward": 8658.880846959617, "Mean Reward": 35.63325451423711, "Episode": 1325, "Episode Step": 243}
{"Training Time": 2.2306630935933853, "Episode Reward": 8072.776423139453, "Mean Reward": 36.69443828699752, "Episode": 1326, "Episode Step": 220}
{"Training Time": 2.2329708474874495, "Episode Reward": 8130.948661917668, "Mean Reward": 42.12926767832988, "Episode": 1327, "Episode Step": 193}
{"Training Time": 2.2363899536265266, "Episode Reward": 10529.995256753551, "Mean Reward": 36.947351778082634, "Episode": 1328, "Episode Step": 285}
{"Training Time": 2.2393339161078134, "Episode Reward": 8538.3594959445, "Mean Reward": 41.049805268963944, "Episode": 1329, "Episode Step": 208}
{"Training Time": 2.2416643963919745, "Episode Reward": 8117.096493056163, "Mean Reward": 41.84070357245445, "Episode": 1330, "Episode Step": 194}
{"Training Time": 2.2450610511170495, "Episode Reward": 11979.455232251585, "Mean Reward": 41.595330667540225, "Episode": 1331, "Episode Step": 288}
{"Training Time": 2.2461164196994567, "Episode Reward": 2746.5088055685055, "Mean Reward": 56.05120011364297, "Episode": 1332, "Episode Step": 49}
{"Training Time": 2.24832571943601, "Episode Reward": 8859.144426792836, "Mean Reward": 47.37510388659271, "Episode": 1333, "Episode Step": 187}
{"Training Time": 2.2516765152745775, "Episode Reward": 13381.98234136724, "Mean Reward": 46.465216463080694, "Episode": 1334, "Episode Step": 288}
{"Training Time": 2.2528166555696063, "Episode Reward": 2000.579214576068, "Mean Reward": 36.374167537746686, "Episode": 1335, "Episode Step": 55}
{"Training Time": 2.255565555559264, "Episode Reward": 12033.446105260666, "Mean Reward": 51.64569143888698, "Episode": 1336, "Episode Step": 233}
{"Training Time": 2.258152422507604, "Episode Reward": 8291.78714476484, "Mean Reward": 38.56645183611553, "Episode": 1337, "Episode Step": 215}
{"Training Time": 2.2592252788941067, "Episode Reward": 1572.5201592582316, "Mean Reward": 30.8337286129065, "Episode": 1338, "Episode Step": 51}
{"Training Time": 2.2614055405722726, "Episode Reward": 8631.472714187605, "Mean Reward": 47.16651756386669, "Episode": 1339, "Episode Step": 183}
{"Training Time": 2.2637336908446417, "Episode Reward": 8247.50652733708, "Mean Reward": 42.51292024400557, "Episode": 1340, "Episode Step": 194}
{"Training Time": 2.2659754961066776, "Episode Reward": 6351.4784660027335, "Mean Reward": 42.343189773351554, "Episode": 1341, "Episode Step": 150}
{"Training Time": 2.268166554437743, "Episode Reward": 9132.130075461644, "Mean Reward": 49.90235013913467, "Episode": 1342, "Episode Step": 183}
{"Training Time": 2.2707170208295184, "Episode Reward": 6668.457448019694, "Mean Reward": 31.45498796235705, "Episode": 1343, "Episode Step": 212}
{"Training Time": 2.2736207813686793, "Episode Reward": 9560.87567579721, "Mean Reward": 46.18780519708797, "Episode": 1344, "Episode Step": 207}
{"Training Time": 2.275834507809745, "Episode Reward": 8675.564365574823, "Mean Reward": 46.64281916975711, "Episode": 1345, "Episode Step": 186}
{"Training Time": 2.2785221113761267, "Episode Reward": 6743.434373487285, "Mean Reward": 29.706759354569535, "Episode": 1346, "Episode Step": 227}
{"Training Time": 2.2816664380497405, "Episode Reward": 10770.42452835969, "Mean Reward": 48.297867840177986, "Episode": 1347, "Episode Step": 223}
{"Training Time": 2.2839365386300616, "Episode Reward": 7521.669809547557, "Mean Reward": 40.00888196567849, "Episode": 1348, "Episode Step": 188}
{"Training Time": 2.287184712489446, "Episode Reward": 7968.567431598146, "Mean Reward": 36.056866206326454, "Episode": 1349, "Episode Step": 221}
{"Training Time": 2.2894082241588167, "Episode Reward": 5456.471140188899, "Mean Reward": 37.37309000129383, "Episode": 1350, "Episode Step": 146}
{"Training Time": 2.291586110525661, "Episode Reward": 8532.795192819854, "Mean Reward": 46.88349007043876, "Episode": 1351, "Episode Step": 182}
{"Training Time": 2.2944341716501446, "Episode Reward": 8273.316242262243, "Mean Reward": 34.76183295068169, "Episode": 1352, "Episode Step": 238}
{"Training Time": 2.2988953444692823, "Episode Reward": 14421.882101063056, "Mean Reward": 43.43940391886463, "Episode": 1353, "Episode Step": 332}
{"Training Time": 2.3010690889093612, "Episode Reward": 9207.341504230144, "Mean Reward": 50.58978848478101, "Episode": 1354, "Episode Step": 182}
{"Training Time": 2.3039006433222027, "Episode Reward": 7784.774146796957, "Mean Reward": 32.847148298721336, "Episode": 1355, "Episode Step": 237}
{"Training Time": 2.304979314141803, "Episode Reward": 2686.252501583119, "Mean Reward": 52.67161767810037, "Episode": 1356, "Episode Step": 51}
{"Training Time": 2.307140806383557, "Episode Reward": 9146.897031145587, "Mean Reward": 50.816094617475486, "Episode": 1357, "Episode Step": 180}
{"Training Time": 2.310963965588146, "Episode Reward": 11356.05782296556, "Mean Reward": 35.04956118199247, "Episode": 1358, "Episode Step": 324}
{"Training Time": 2.3120793669753605, "Episode Reward": 2368.2618533060877, "Mean Reward": 45.54349717896322, "Episode": 1359, "Episode Step": 52}
{"Training Time": 2.3142764125267665, "Episode Reward": 7373.604892318989, "Mean Reward": 39.22130261871803, "Episode": 1360, "Episode Step": 188}
{"Training Time": 2.318276659713851, "Episode Reward": 12184.961923058314, "Mean Reward": 35.94384048099798, "Episode": 1361, "Episode Step": 339}
{"Training Time": 2.3211478222078745, "Episode Reward": 7891.333233694504, "Mean Reward": 39.066006107398536, "Episode": 1362, "Episode Step": 202}
{"Training Time": 2.323314270575841, "Episode Reward": 8665.917801877666, "Mean Reward": 47.3547420867632, "Episode": 1363, "Episode Step": 183}
{"Training Time": 2.3258076080348755, "Episode Reward": 7938.457811036794, "Mean Reward": 37.983051727448775, "Episode": 1364, "Episode Step": 209}
{"Training Time": 2.327358906136619, "Episode Reward": 4179.036929338886, "Mean Reward": 46.43374365932095, "Episode": 1365, "Episode Step": 90}
{"Training Time": 2.3302015786038504, "Episode Reward": 11085.492837784963, "Mean Reward": 46.18955349077068, "Episode": 1366, "Episode Step": 240}
{"Training Time": 2.333079852196905, "Episode Reward": 8919.23911665809, "Mean Reward": 37.16349631940871, "Episode": 1367, "Episode Step": 240}
{"Training Time": 2.3359365489085517, "Episode Reward": 8288.330524461546, "Mean Reward": 40.62907119834091, "Episode": 1368, "Episode Step": 204}
{"Training Time": 2.338378219736947, "Episode Reward": 9599.47756534808, "Mean Reward": 45.930514666737224, "Episode": 1369, "Episode Step": 209}
{"Training Time": 2.3423287244637807, "Episode Reward": 13362.505698440536, "Mean Reward": 39.6513522208918, "Episode": 1370, "Episode Step": 337}
{"Training Time": 2.3439822233385508, "Episode Reward": 4140.780176325272, "Mean Reward": 40.99782352797299, "Episode": 1371, "Episode Step": 101}
{"Training Time": 2.346088835000992, "Episode Reward": 9018.302564373711, "Mean Reward": 50.10168091318728, "Episode": 1372, "Episode Step": 180}
{"Training Time": 2.3597509413957596, "Episode Reward": 40458.452058494775, "Mean Reward": 34.579873554269035, "Episode": 1373, "Episode Step": 1170}
{"Training Time": 2.362648820016119, "Episode Reward": 9101.916380546332, "Mean Reward": 43.75921336801121, "Episode": 1374, "Episode Step": 208}
{"Training Time": 2.364745098352432, "Episode Reward": 8130.409039585699, "Mean Reward": 45.16893910880944, "Episode": 1375, "Episode Step": 180}
{"Training Time": 2.3692768480380377, "Episode Reward": 12525.040988329614, "Mean Reward": 32.53257399566134, "Episode": 1376, "Episode Step": 385}
{"Training Time": 2.3723284205463195, "Episode Reward": 9111.509953892662, "Mean Reward": 41.22855182756861, "Episode": 1377, "Episode Step": 221}
{"Training Time": 2.3744637391964596, "Episode Reward": 9001.870070249299, "Mean Reward": 49.19054683196338, "Episode": 1378, "Episode Step": 183}
{"Training Time": 2.4033319647444618, "Episode Reward": 98088.37594980116, "Mean Reward": 39.53582263192308, "Episode": 1379, "Episode Step": 2481}
{"Training Time": 2.4059991633229787, "Episode Reward": 8571.127028698702, "Mean Reward": 46.330416371344334, "Episode": 1380, "Episode Step": 185}
{"Training Time": 2.408199301958084, "Episode Reward": 8324.09259992893, "Mean Reward": 45.98946187806039, "Episode": 1381, "Episode Step": 181}
{"Training Time": 2.412205914987458, "Episode Reward": 13870.234885466845, "Mean Reward": 41.403686225274164, "Episode": 1382, "Episode Step": 335}
{"Training Time": 2.4151322902573478, "Episode Reward": 8173.904259244647, "Mean Reward": 40.06815813355219, "Episode": 1383, "Episode Step": 204}
{"Training Time": 2.429421281086074, "Episode Reward": 66443.14704667885, "Mean Reward": 55.36928920556571, "Episode": 1384, "Episode Step": 1200}
{"Training Time": 2.4322385833660762, "Episode Reward": 9945.614466892717, "Mean Reward": 41.96461800376674, "Episode": 1385, "Episode Step": 237}
{"Training Time": 2.43502847108576, "Episode Reward": 7649.806102807427, "Mean Reward": 39.63630105081568, "Episode": 1386, "Episode Step": 193}
{"Training Time": 2.4377264338731766, "Episode Reward": 10088.532109893911, "Mean Reward": 44.05472537071577, "Episode": 1387, "Episode Step": 229}
{"Training Time": 2.4456140538718967, "Episode Reward": 37519.92506314884, "Mean Reward": 55.33912251201894, "Episode": 1388, "Episode Step": 678}
{"Training Time": 2.4467034366395737, "Episode Reward": 1940.9676124196203, "Mean Reward": 38.058188478816085, "Episode": 1389, "Episode Step": 51}
{"Training Time": 2.455243784189224, "Episode Reward": 38610.39039363946, "Mean Reward": 52.45976955657536, "Episode": 1390, "Episode Step": 736}
{"Training Time": 2.4610988977882595, "Episode Reward": 28242.927061759405, "Mean Reward": 56.712704943291975, "Episode": 1391, "Episode Step": 498}
{"Training Time": 2.4636263186401792, "Episode Reward": 8495.973372537652, "Mean Reward": 47.999849562359614, "Episode": 1392, "Episode Step": 177}
{"Training Time": 2.464940844443109, "Episode Reward": 5204.054636415494, "Mean Reward": 46.883375102842294, "Episode": 1393, "Episode Step": 111}
{"Training Time": 2.467465505533748, "Episode Reward": 9207.745742501073, "Mean Reward": 43.432762936325815, "Episode": 1394, "Episode Step": 212}
{"Training Time": 2.470435843335258, "Episode Reward": 10675.197433359857, "Mean Reward": 49.194458218248194, "Episode": 1395, "Episode Step": 217}
{"Training Time": 2.47265508890152, "Episode Reward": 8956.547939271046, "Mean Reward": 47.8959782848719, "Episode": 1396, "Episode Step": 187}
{"Training Time": 2.4870940247509217, "Episode Reward": 65269.89795442252, "Mean Reward": 53.02185049100124, "Episode": 1397, "Episode Step": 1231}
{"Training Time": 2.488570328619745, "Episode Reward": 4210.931943475355, "Mean Reward": 48.964324924132036, "Episode": 1398, "Episode Step": 86}
{"Training Time": 2.4896275636222627, "Episode Reward": 2013.6599992774177, "Mean Reward": 37.289999986618845, "Episode": 1399, "Episode Step": 54}
{"Training Time": 2.5030169975095324, "Episode Reward": 63621.032077421856, "Mean Reward": 56.6527445034923, "Episode": 1400, "Episode Step": 1123}
{"Training Time": 2.504511183036698, "Episode Reward": 3375.1741333456184, "Mean Reward": 38.35425151529112, "Episode": 1401, "Episode Step": 88}
{"Training Time": 2.5066771958271663, "Episode Reward": 7660.680717036164, "Mean Reward": 41.634134331718286, "Episode": 1402, "Episode Step": 184}
{"Training Time": 2.5093778389030033, "Episode Reward": 7761.290135347301, "Mean Reward": 34.0407462076636, "Episode": 1403, "Episode Step": 228}
{"Training Time": 2.512959311140908, "Episode Reward": 12925.403645564005, "Mean Reward": 48.59174302843611, "Episode": 1404, "Episode Step": 266}
{"Training Time": 2.5146013436052534, "Episode Reward": 6468.65966935099, "Mean Reward": 47.21649393686854, "Episode": 1405, "Episode Step": 137}
{"Training Time": 2.5187465983629225, "Episode Reward": 18476.75018895407, "Mean Reward": 52.79071482558305, "Episode": 1406, "Episode Step": 350}
{"Training Time": 2.5208724647098117, "Episode Reward": 6089.004115851073, "Mean Reward": 43.49288654179338, "Episode": 1407, "Episode Step": 140}
{"Training Time": 2.522515394422743, "Episode Reward": 6041.728065881729, "Mean Reward": 43.46566953871748, "Episode": 1408, "Episode Step": 139}
{"Training Time": 2.52639928691917, "Episode Reward": 19266.901495428447, "Mean Reward": 59.28277383208753, "Episode": 1409, "Episode Step": 325}
{"Training Time": 2.5274411188893846, "Episode Reward": 2177.85974082828, "Mean Reward": 45.3720779339225, "Episode": 1410, "Episode Step": 48}
{"Training Time": 2.529171398613188, "Episode Reward": 6514.508034501431, "Mean Reward": 45.23963912848216, "Episode": 1411, "Episode Step": 144}
{"Training Time": 2.530502979159355, "Episode Reward": 5805.333235650972, "Mean Reward": 53.259937941752035, "Episode": 1412, "Episode Step": 109}
{"Training Time": 2.53421780274974, "Episode Reward": 14581.834097490542, "Mean Reward": 54.409828721979636, "Episode": 1413, "Episode Step": 268}
{"Training Time": 2.53485575887892, "Episode Reward": 2596.7663144616185, "Mean Reward": 49.93781373964651, "Episode": 1414, "Episode Step": 52}
{"Training Time": 2.53589181833797, "Episode Reward": 4756.86759780967, "Mean Reward": 55.31241392801942, "Episode": 1415, "Episode Step": 86}
{"Training Time": 2.536975308060646, "Episode Reward": 2071.061000837846, "Mean Reward": 41.421220016756926, "Episode": 1416, "Episode Step": 50}
{"Training Time": 2.539287215007676, "Episode Reward": 8991.988567365386, "Mean Reward": 46.83327378836139, "Episode": 1417, "Episode Step": 192}
{"Training Time": 2.5405674536360636, "Episode Reward": 5466.99492286979, "Mean Reward": 52.066618313045616, "Episode": 1418, "Episode Step": 105}
{"Training Time": 2.5421124441756144, "Episode Reward": 4547.658824923162, "Mean Reward": 50.529542499146245, "Episode": 1419, "Episode Step": 90}
{"Training Time": 2.5513301580482057, "Episode Reward": 44237.651441342095, "Mean Reward": 57.15458842550658, "Episode": 1420, "Episode Step": 774}
{"Training Time": 2.5526755377981396, "Episode Reward": 5391.442544494904, "Mean Reward": 49.01311404086276, "Episode": 1421, "Episode Step": 110}
{"Training Time": 2.555542174180349, "Episode Reward": 8755.111360380983, "Mean Reward": 43.9955344742763, "Episode": 1422, "Episode Step": 199}
{"Training Time": 2.55776380194558, "Episode Reward": 8802.565316979722, "Mean Reward": 47.84002889662893, "Episode": 1423, "Episode Step": 184}
{"Training Time": 2.566702660587099, "Episode Reward": 40978.35426997927, "Mean Reward": 54.78389608285998, "Episode": 1424, "Episode Step": 748}
{"Training Time": 2.569650676118003, "Episode Reward": 8920.238708906152, "Mean Reward": 42.88576302358727, "Episode": 1425, "Episode Step": 208}
{"Training Time": 2.5707104447152878, "Episode Reward": 4511.397925803008, "Mean Reward": 50.689864334865256, "Episode": 1426, "Episode Step": 89}
{"Training Time": 2.573096778591474, "Episode Reward": 8670.33465009091, "Mean Reward": 43.56952085472819, "Episode": 1427, "Episode Step": 199}
{"Training Time": 2.5746624783674874, "Episode Reward": 4951.415833484869, "Mean Reward": 53.819737320487704, "Episode": 1428, "Episode Step": 92}
{"Training Time": 2.5756614172458647, "Episode Reward": 4395.932223932395, "Mean Reward": 52.33252647538565, "Episode": 1429, "Episode Step": 84}
{"Training Time": 2.577921661403444, "Episode Reward": 7970.926621885155, "Mean Reward": 41.73260011458196, "Episode": 1430, "Episode Step": 191}
{"Training Time": 2.5810266019238366, "Episode Reward": 11008.254129386078, "Mean Reward": 48.92557390838257, "Episode": 1431, "Episode Step": 225}
{"Training Time": 2.5821082344320083, "Episode Reward": 4038.2628937514237, "Mean Reward": 44.86958770834915, "Episode": 1432, "Episode Step": 90}
{"Training Time": 2.585369323624505, "Episode Reward": 11914.901118096837, "Mean Reward": 43.48504057699576, "Episode": 1433, "Episode Step": 274}
{"Training Time": 2.5883777808480795, "Episode Reward": 8978.691010943856, "Mean Reward": 42.960244071501705, "Episode": 1434, "Episode Step": 209}
{"Training Time": 2.5905701986286376, "Episode Reward": 8856.772965550355, "Mean Reward": 48.93244732348263, "Episode": 1435, "Episode Step": 181}
{"Training Time": 2.591676194137997, "Episode Reward": 4925.704930738298, "Mean Reward": 54.73005478598108, "Episode": 1436, "Episode Step": 90}
{"Training Time": 2.594416913059023, "Episode Reward": 8336.208189826883, "Mean Reward": 44.10692163929568, "Episode": 1437, "Episode Step": 189}
{"Training Time": 2.5954777977863945, "Episode Reward": 4626.705143698843, "Mean Reward": 53.18051889309015, "Episode": 1438, "Episode Step": 87}
{"Training Time": 2.59686054971483, "Episode Reward": 4653.479022450251, "Mean Reward": 40.465034977828275, "Episode": 1439, "Episode Step": 115}
{"Training Time": 2.600408878326416, "Episode Reward": 10461.674791522215, "Mean Reward": 40.549127098923314, "Episode": 1440, "Episode Step": 258}
{"Training Time": 2.6016748955514695, "Episode Reward": 5001.570659213708, "Mean Reward": 47.63400627822578, "Episode": 1441, "Episode Step": 105}
{"Training Time": 2.6054865027798546, "Episode Reward": 16635.66766372688, "Mean Reward": 51.50361505797795, "Episode": 1442, "Episode Step": 323}
{"Training Time": 2.6072255297501883, "Episode Reward": 2462.0116539987753, "Mean Reward": 23.447730038083574, "Episode": 1443, "Episode Step": 105}
{"Training Time": 2.608488298323419, "Episode Reward": 4849.586917617949, "Mean Reward": 46.63064343863413, "Episode": 1444, "Episode Step": 104}
{"Training Time": 2.6107373111115564, "Episode Reward": 7411.012766277421, "Mean Reward": 39.211707758081594, "Episode": 1445, "Episode Step": 189}
{"Training Time": 2.6141090636120903, "Episode Reward": 10106.317773993364, "Mean Reward": 41.761643694187455, "Episode": 1446, "Episode Step": 242}
{"Training Time": 2.616797936360041, "Episode Reward": 10484.804799145208, "Mean Reward": 46.59913244064537, "Episode": 1447, "Episode Step": 225}
{"Training Time": 2.620726251403491, "Episode Reward": 16018.17797631717, "Mean Reward": 48.24752402505172, "Episode": 1448, "Episode Step": 332}
{"Training Time": 2.6223494133022096, "Episode Reward": 2479.203557432588, "Mean Reward": 47.67699148908822, "Episode": 1449, "Episode Step": 52}
{"Training Time": 2.62393995947308, "Episode Reward": 5726.933361957742, "Mean Reward": 53.52274170053965, "Episode": 1450, "Episode Step": 107}
{"Training Time": 2.6276488330629135, "Episode Reward": 17536.420076180293, "Mean Reward": 55.84847158019202, "Episode": 1451, "Episode Step": 314}
{"Training Time": 2.6310816964175965, "Episode Reward": 9740.02001882271, "Mean Reward": 39.27427426944641, "Episode": 1452, "Episode Step": 248}
{"Training Time": 2.633993142777019, "Episode Reward": 12712.39569267169, "Mean Reward": 52.53056071351938, "Episode": 1453, "Episode Step": 242}
{"Training Time": 2.6365700291925007, "Episode Reward": 10942.920265668974, "Mean Reward": 50.428203989257945, "Episode": 1454, "Episode Step": 217}
{"Training Time": 2.640034405854013, "Episode Reward": 12452.894950882395, "Mean Reward": 49.613127294352175, "Episode": 1455, "Episode Step": 251}
{"Training Time": 2.6413022141986424, "Episode Reward": 4662.363338515282, "Mean Reward": 43.98455979731398, "Episode": 1456, "Episode Step": 106}
{"Training Time": 2.6442944783634608, "Episode Reward": 15430.406396185093, "Mean Reward": 60.74963148104367, "Episode": 1457, "Episode Step": 254}
{"Training Time": 2.647229672471682, "Episode Reward": 9074.722276931981, "Mean Reward": 43.419723813071684, "Episode": 1458, "Episode Step": 209}
{"Training Time": 2.649794174167845, "Episode Reward": 10045.250910002884, "Mean Reward": 46.29147884793956, "Episode": 1459, "Episode Step": 217}
{"Training Time": 2.6536162838670942, "Episode Reward": 17439.631771040495, "Mean Reward": 54.32907093782086, "Episode": 1460, "Episode Step": 321}
{"Training Time": 2.6569293361239965, "Episode Reward": 10725.532825517746, "Mean Reward": 45.06526397276364, "Episode": 1461, "Episode Step": 238}
{"Training Time": 2.6593679736057916, "Episode Reward": 8908.929546165633, "Mean Reward": 43.67122326551781, "Episode": 1462, "Episode Step": 204}
{"Training Time": 2.6603954955604343, "Episode Reward": 4916.548309876611, "Mean Reward": 57.84174482207777, "Episode": 1463, "Episode Step": 85}
{"Training Time": 2.66350033223629, "Episode Reward": 9806.331648928654, "Mean Reward": 44.17266508526421, "Episode": 1464, "Episode Step": 222}
{"Training Time": 2.6666733100016913, "Episode Reward": 12026.51827842101, "Mean Reward": 45.55499347886746, "Episode": 1465, "Episode Step": 264}
{"Training Time": 2.6691596586174433, "Episode Reward": 9338.628227780395, "Mean Reward": 45.554284037953146, "Episode": 1466, "Episode Step": 205}
{"Training Time": 2.672593785524368, "Episode Reward": 13341.463771581079, "Mean Reward": 54.01402336672501, "Episode": 1467, "Episode Step": 247}
{"Training Time": 2.6765540219677817, "Episode Reward": 18043.73685893243, "Mean Reward": 54.02316424830069, "Episode": 1468, "Episode Step": 334}
{"Training Time": 2.6787053008211985, "Episode Reward": 8325.056933911768, "Mean Reward": 45.994789690120264, "Episode": 1469, "Episode Step": 181}
{"Training Time": 2.6822052783436243, "Episode Reward": 12929.658544159236, "Mean Reward": 51.10536973975982, "Episode": 1470, "Episode Step": 253}
{"Training Time": 2.6846184702714284, "Episode Reward": 8481.31718080238, "Mean Reward": 41.98671871684346, "Episode": 1471, "Episode Step": 202}
{"Training Time": 2.6856546608606973, "Episode Reward": 4877.82408076869, "Mean Reward": 56.71888466010105, "Episode": 1472, "Episode Step": 86}
{"Training Time": 2.68925756447845, "Episode Reward": 14358.97446979796, "Mean Reward": 53.778930598494235, "Episode": 1473, "Episode Step": 267}
{"Training Time": 2.6911033313804205, "Episode Reward": 6454.858311766658, "Mean Reward": 42.46617310372801, "Episode": 1474, "Episode Step": 152}
{"Training Time": 2.7006899766789543, "Episode Reward": 42449.54621290527, "Mean Reward": 52.1493196718738, "Episode": 1475, "Episode Step": 814}
{"Training Time": 2.704503677487373, "Episode Reward": 10552.07042720214, "Mean Reward": 37.286467940643604, "Episode": 1476, "Episode Step": 283}
{"Training Time": 2.7062784119447074, "Episode Reward": 5896.171011542225, "Mean Reward": 39.04749014266374, "Episode": 1477, "Episode Step": 151}
{"Training Time": 2.707568729453617, "Episode Reward": 4992.244961123087, "Mean Reward": 45.800412487367765, "Episode": 1478, "Episode Step": 109}
{"Training Time": 2.709243043329981, "Episode Reward": -11.893429047663666, "Mean Reward": -0.11660224556533005, "Episode": 1479, "Episode Step": 102}
{"Training Time": 2.71166648639573, "Episode Reward": 5826.350198985983, "Mean Reward": 28.146619318772867, "Episode": 1480, "Episode Step": 207}
{"Training Time": 2.7141576658354865, "Episode Reward": 10299.656294991628, "Mean Reward": 48.81353694308828, "Episode": 1481, "Episode Step": 211}
{"Training Time": 2.7158184422387017, "Episode Reward": -4.700043726390863, "Mean Reward": -0.04607886006265552, "Episode": 1482, "Episode Step": 102}
{"Training Time": 2.7170260272423428, "Episode Reward": 0.5307997210698414, "Mean Reward": 0.0052039188340180535, "Episode": 1483, "Episode Step": 102}
{"Training Time": 2.7180571766694386, "Episode Reward": 4468.849519084599, "Mean Reward": 51.96336650098371, "Episode": 1484, "Episode Step": 86}
{"Training Time": 2.7217707466416887, "Episode Reward": 10406.538447484712, "Mean Reward": 37.16620874101683, "Episode": 1485, "Episode Step": 280}
{"Training Time": 2.722988707224528, "Episode Reward": -0.06609912434880227, "Mean Reward": -0.0006480306308706105, "Episode": 1486, "Episode Step": 102}
{"Training Time": 2.7253727605607776, "Episode Reward": 7795.869145675991, "Mean Reward": 38.215044831745054, "Episode": 1487, "Episode Step": 204}
{"Training Time": 2.733386814461814, "Episode Reward": 25865.300011808657, "Mean Reward": 39.73164364333127, "Episode": 1488, "Episode Step": 651}
{"Training Time": 2.7346071994304655, "Episode Reward": 0.921261952261387, "Mean Reward": 0.009031979924131244, "Episode": 1489, "Episode Step": 102}
{"Training Time": 2.736908470524682, "Episode Reward": 8711.467287670688, "Mean Reward": 43.99730953369034, "Episode": 1490, "Episode Step": 198}
{"Training Time": 2.7411998803085753, "Episode Reward": 14749.255888629137, "Mean Reward": 45.80514251127061, "Episode": 1491, "Episode Step": 322}
{"Training Time": 2.742429258889622, "Episode Reward": 1.0759456446048925, "Mean Reward": 0.010548486711812672, "Episode": 1492, "Episode Step": 102}
{"Training Time": 2.743718241386943, "Episode Reward": 4787.640099959171, "Mean Reward": 45.166416037350665, "Episode": 1493, "Episode Step": 106}
{"Training Time": 2.747628139721023, "Episode Reward": 10264.86790432213, "Mean Reward": 35.51857406339837, "Episode": 1494, "Episode Step": 289}
{"Training Time": 2.748842136396302, "Episode Reward": 0.5668281650426024, "Mean Reward": 0.00555713887296669, "Episode": 1495, "Episode Step": 102}
{"Training Time": 2.750454467203882, "Episode Reward": 5109.4663071988125, "Mean Reward": 37.847898571843054, "Episode": 1496, "Episode Step": 135}
{"Training Time": 2.7558144469393624, "Episode Reward": 19147.11713089925, "Mean Reward": 46.70028568512012, "Episode": 1497, "Episode Step": 410}
{"Training Time": 2.757066524691052, "Episode Reward": 0.9442848180166862, "Mean Reward": 0.009257694294281237, "Episode": 1498, "Episode Step": 102}
{"Training Time": 2.75973647110992, "Episode Reward": 7592.827981776539, "Mean Reward": 37.775263590928056, "Episode": 1499, "Episode Step": 201}
{"Training Time": 2.7627962636285357, "Episode Reward": 11642.376905946025, "Mean Reward": 52.44313921597308, "Episode": 1500, "Episode Step": 222}
{"Training Time": 2.7640467986133364, "Episode Reward": 1.4941416241438406, "Mean Reward": 0.014648447295527849, "Episode": 1501, "Episode Step": 102}
{"Training Time": 2.7650629619757336, "Episode Reward": 3463.7992518120377, "Mean Reward": 41.235705378714734, "Episode": 1502, "Episode Step": 84}
{"Training Time": 2.768219848341412, "Episode Reward": 10956.825354792792, "Mean Reward": 48.26795310481406, "Episode": 1503, "Episode Step": 227}
{"Training Time": 2.7694339869419733, "Episode Reward": 0.7965588674484221, "Mean Reward": 0.00780940066125904, "Episode": 1504, "Episode Step": 102}
{"Training Time": 2.7715326450268427, "Episode Reward": 7648.107572104851, "Mean Reward": 42.25473796743012, "Episode": 1505, "Episode Step": 181}
{"Training Time": 2.7747847319311565, "Episode Reward": 12051.712816846402, "Mean Reward": 51.72408934268842, "Episode": 1506, "Episode Step": 233}
{"Training Time": 2.7760207533174093, "Episode Reward": 0.9942486390151951, "Mean Reward": 0.00974753567661956, "Episode": 1507, "Episode Step": 102}
{"Training Time": 2.7786373994747797, "Episode Reward": 8193.244463462974, "Mean Reward": 37.58369019937144, "Episode": 1508, "Episode Step": 218}
{"Training Time": 2.7814998666445416, "Episode Reward": 8277.321439306703, "Mean Reward": 41.38660719653351, "Episode": 1509, "Episode Step": 200}
{"Training Time": 2.7834215002589757, "Episode Reward": 5532.111539921927, "Mean Reward": 34.79315433913162, "Episode": 1510, "Episode Step": 159}
{"Training Time": 2.7860560633076563, "Episode Reward": 8565.819944840438, "Mean Reward": 38.93554520382017, "Episode": 1511, "Episode Step": 220}
{"Training Time": 2.7890184441539976, "Episode Reward": 10189.495177740477, "Mean Reward": 48.521405608287985, "Episode": 1512, "Episode Step": 210}
{"Training Time": 2.7895973133378558, "Episode Reward": 2330.5619890357, "Mean Reward": 48.55337477157709, "Episode": 1513, "Episode Step": 48}
{"Training Time": 2.79245669497384, "Episode Reward": 12335.703543414702, "Mean Reward": 51.185491881388806, "Episode": 1514, "Episode Step": 241}
{"Training Time": 2.794568130572637, "Episode Reward": 5997.8985808769785, "Mean Reward": 42.84213272054985, "Episode": 1515, "Episode Step": 140}
{"Training Time": 2.795816489987903, "Episode Reward": 5013.047173969666, "Mean Reward": 47.74330641875872, "Episode": 1516, "Episode Step": 105}
{"Training Time": 2.799094192253219, "Episode Reward": 14035.659086166226, "Mean Reward": 50.307021814215865, "Episode": 1517, "Episode Step": 279}
{"Training Time": 2.8022543299860425, "Episode Reward": 11215.133034899805, "Mean Reward": 49.18917997763072, "Episode": 1518, "Episode Step": 228}
{"Training Time": 2.8051002422306275, "Episode Reward": 8111.088749733397, "Mean Reward": 33.93760983152049, "Episode": 1519, "Episode Step": 239}
{"Training Time": 2.8077595047156017, "Episode Reward": 9282.792916818158, "Mean Reward": 42.19451325826436, "Episode": 1520, "Episode Step": 220}
{"Training Time": 2.8112760149770315, "Episode Reward": 13551.098753742439, "Mean Reward": 54.42208334836321, "Episode": 1521, "Episode Step": 249}
{"Training Time": 2.813360173039966, "Episode Reward": 5347.866885273006, "Mean Reward": 31.092249332982593, "Episode": 1522, "Episode Step": 172}
{"Training Time": 2.817128373583158, "Episode Reward": 16097.938947116034, "Mean Reward": 52.266035542584525, "Episode": 1523, "Episode Step": 308}
{"Training Time": 2.8201374561256833, "Episode Reward": 8740.888186597647, "Mean Reward": 42.22651297873259, "Episode": 1524, "Episode Step": 207}
{"Training Time": 2.821276856131024, "Episode Reward": 2420.465161699103, "Mean Reward": 26.02650711504412, "Episode": 1525, "Episode Step": 93}
{"Training Time": 2.824006723364194, "Episode Reward": 10878.245151591036, "Mean Reward": 48.347756229293495, "Episode": 1526, "Episode Step": 225}
{"Training Time": 2.8262560830513634, "Episode Reward": 6467.894097065396, "Mean Reward": 43.99927957187344, "Episode": 1527, "Episode Step": 147}
{"Training Time": 2.826855011118783, "Episode Reward": 999.6755133665583, "Mean Reward": 21.26969177375656, "Episode": 1528, "Episode Step": 47}
{"Training Time": 2.828288536138005, "Episode Reward": 5162.692194909246, "Mean Reward": 43.38396802444744, "Episode": 1529, "Episode Step": 119}
{"Training Time": 2.831292028625806, "Episode Reward": 8603.609880912445, "Mean Reward": 41.16559751632749, "Episode": 1530, "Episode Step": 209}
{"Training Time": 2.832548018627697, "Episode Reward": 3825.472771272948, "Mean Reward": 37.50463501247989, "Episode": 1531, "Episode Step": 102}
{"Training Time": 2.833155657781495, "Episode Reward": 1968.9315457976036, "Mean Reward": 48.02272062920984, "Episode": 1532, "Episode Step": 41}
{"Training Time": 2.8361391572157544, "Episode Reward": 8659.104149958324, "Mean Reward": 41.23382928551583, "Episode": 1533, "Episode Step": 210}
{"Training Time": 2.8375477300087613, "Episode Reward": 3588.527984377473, "Mean Reward": 30.935586072219593, "Episode": 1534, "Episode Step": 116}
{"Training Time": 2.839666884740194, "Episode Reward": 7866.793215104357, "Mean Reward": 44.95310408631061, "Episode": 1535, "Episode Step": 175}
{"Training Time": 2.8419381991359924, "Episode Reward": 6212.252133996761, "Mean Reward": 41.69296734226014, "Episode": 1536, "Episode Step": 149}
{"Training Time": 2.844819939997461, "Episode Reward": 8381.28699160141, "Mean Reward": 34.77712444647888, "Episode": 1537, "Episode Step": 241}
{"Training Time": 2.8454435311423407, "Episode Reward": 2310.8439746733948, "Mean Reward": 45.31066617006656, "Episode": 1538, "Episode Step": 51}
{"Training Time": 2.848455612791909, "Episode Reward": 8284.340649902788, "Mean Reward": 38.531816976292035, "Episode": 1539, "Episode Step": 215}
{"Training Time": 2.8503158275286355, "Episode Reward": 5753.193121951429, "Mean Reward": 36.879443089432236, "Episode": 1540, "Episode Step": 156}
{"Training Time": 2.8531603816482756, "Episode Reward": 11297.800470167236, "Mean Reward": 47.07416862569682, "Episode": 1541, "Episode Step": 240}
{"Training Time": 2.856294575267368, "Episode Reward": 8448.161472530324, "Mean Reward": 37.053339791799665, "Episode": 1542, "Episode Step": 228}
{"Training Time": 2.8579077483548057, "Episode Reward": 5470.241156971379, "Mean Reward": 40.52030486645466, "Episode": 1543, "Episode Step": 135}
{"Training Time": 2.860104323360655, "Episode Reward": 8064.4575729004, "Mean Reward": 43.828573765763046, "Episode": 1544, "Episode Step": 184}
{"Training Time": 2.8630853302611246, "Episode Reward": 9431.477808073812, "Mean Reward": 44.2792385355578, "Episode": 1545, "Episode Step": 213}
{"Training Time": 2.864951265586747, "Episode Reward": 5677.691697050236, "Mean Reward": 35.934757576267316, "Episode": 1546, "Episode Step": 158}
{"Training Time": 2.86778762002786, "Episode Reward": 11356.159523837356, "Mean Reward": 47.7149559825099, "Episode": 1547, "Episode Step": 238}
{"Training Time": 2.8712660158342787, "Episode Reward": 13215.239866086122, "Mean Reward": 51.421166794109425, "Episode": 1548, "Episode Step": 257}
{"Training Time": 2.8761360219452117, "Episode Reward": 16287.337723965959, "Mean Reward": 44.62284307935879, "Episode": 1549, "Episode Step": 365}
{"Training Time": 2.877676388025284, "Episode Reward": 5822.229987634038, "Mean Reward": 54.413364370411564, "Episode": 1550, "Episode Step": 107}
{"Training Time": 2.8806548702716825, "Episode Reward": 9521.249676154612, "Mean Reward": 44.28488221467261, "Episode": 1551, "Episode Step": 215}
{"Training Time": 2.8822871728075876, "Episode Reward": 5494.278877468583, "Mean Reward": 39.81361505412017, "Episode": 1552, "Episode Step": 138}
{"Training Time": 2.8843613811333975, "Episode Reward": 7537.64455102326, "Mean Reward": 42.58556243515966, "Episode": 1553, "Episode Step": 177}
{"Training Time": 2.887259436117278, "Episode Reward": 9826.391972425852, "Mean Reward": 47.470492620414745, "Episode": 1554, "Episode Step": 207}
{"Training Time": 2.8885116433435014, "Episode Reward": 4476.9839826173065, "Mean Reward": 42.637942691593395, "Episode": 1555, "Episode Step": 105}
{"Training Time": 2.8910622097386254, "Episode Reward": 11338.504145885825, "Mean Reward": 52.01148690773314, "Episode": 1556, "Episode Step": 218}
{"Training Time": 2.8941789491971335, "Episode Reward": 10141.606881179598, "Mean Reward": 45.88962389674026, "Episode": 1557, "Episode Step": 221}
{"Training Time": 2.9027866199943753, "Episode Reward": 28081.343034992668, "Mean Reward": 38.573273399715205, "Episode": 1558, "Episode Step": 728}
{"Training Time": 2.906475152240859, "Episode Reward": 16908.059843254494, "Mean Reward": 54.89629819238472, "Episode": 1559, "Episode Step": 308}
{"Training Time": 2.909427632490794, "Episode Reward": 9203.536746573382, "Mean Reward": 44.03606098838939, "Episode": 1560, "Episode Step": 209}
{"Training Time": 2.9121949013736512, "Episode Reward": 8914.785787215902, "Mean Reward": 38.260883206935205, "Episode": 1561, "Episode Step": 233}
{"Training Time": 2.9151338977946177, "Episode Reward": 13056.70889464258, "Mean Reward": 52.226835578570316, "Episode": 1562, "Episode Step": 250}
{"Training Time": 2.918133447236485, "Episode Reward": 9846.439340986391, "Mean Reward": 45.58536731938144, "Episode": 1563, "Episode Step": 216}
{"Training Time": 2.920797295305464, "Episode Reward": 8871.05656641565, "Mean Reward": 39.60293110006986, "Episode": 1564, "Episode Step": 224}
{"Training Time": 2.923437751928965, "Episode Reward": 9872.819006065427, "Mean Reward": 43.879195582513006, "Episode": 1565, "Episode Step": 225}
{"Training Time": 2.9262465941905975, "Episode Reward": 9938.712016892294, "Mean Reward": 49.943276466795446, "Episode": 1566, "Episode Step": 199}
{"Training Time": 2.929096006684833, "Episode Reward": 9964.436387775615, "Mean Reward": 41.1753569742794, "Episode": 1567, "Episode Step": 242}
{"Training Time": 2.9317125302553175, "Episode Reward": 8535.968963413176, "Mean Reward": 38.62429395209582, "Episode": 1568, "Episode Step": 221}
{"Training Time": 2.9352711441781785, "Episode Reward": 14598.919746430704, "Mean Reward": 55.509200556770736, "Episode": 1569, "Episode Step": 263}
{"Training Time": 2.9365796617004607, "Episode Reward": 4820.794928014765, "Mean Reward": 43.042811857274685, "Episode": 1570, "Episode Step": 112}
{"Training Time": 2.937581734723515, "Episode Reward": 4200.125429909633, "Mean Reward": 48.83866778964689, "Episode": 1571, "Episode Step": 86}
{"Training Time": 2.9403775236341687, "Episode Reward": 8936.651288828172, "Mean Reward": 44.4609516857123, "Episode": 1572, "Episode Step": 201}
{"Training Time": 2.942829428050253, "Episode Reward": 7189.818823616651, "Mean Reward": 34.401047002950484, "Episode": 1573, "Episode Step": 209}
{"Training Time": 2.9434682458639143, "Episode Reward": 2009.2882388870084, "Mean Reward": 38.640158440134776, "Episode": 1574, "Episode Step": 52}
{"Training Time": 2.9518480977747177, "Episode Reward": 37557.41153266862, "Mean Reward": 55.80596067261311, "Episode": 1575, "Episode Step": 673}
{"Training Time": 2.9531591005457773, "Episode Reward": 4667.245274140706, "Mean Reward": 43.21523401982135, "Episode": 1576, "Episode Step": 108}
{"Training Time": 2.954167144695918, "Episode Reward": 4139.986345059902, "Mean Reward": 49.2855517269036, "Episode": 1577, "Episode Step": 84}
{"Training Time": 2.9579858722289405, "Episode Reward": 14321.467910138372, "Mean Reward": 50.78534719907224, "Episode": 1578, "Episode Step": 282}
{"Training Time": 2.960573916700151, "Episode Reward": 8586.184874724753, "Mean Reward": 39.935743603370945, "Episode": 1579, "Episode Step": 215}
{"Training Time": 2.9615662783384322, "Episode Reward": 4410.981814746709, "Mean Reward": 52.51168827079415, "Episode": 1580, "Episode Step": 84}
{"Training Time": 2.964855738348431, "Episode Reward": 10698.62662214864, "Mean Reward": 44.57761092561933, "Episode": 1581, "Episode Step": 240}
{"Training Time": 2.967245806919204, "Episode Reward": 7699.124093728455, "Mean Reward": 38.11447571152701, "Episode": 1582, "Episode Step": 202}
{"Training Time": 2.9682601838641696, "Episode Reward": 3566.890579853823, "Mean Reward": 41.47547185876538, "Episode": 1583, "Episode Step": 86}
{"Training Time": 2.971125842531522, "Episode Reward": 9962.60964777083, "Mean Reward": 49.076894816605076, "Episode": 1584, "Episode Step": 203}
{"Training Time": 2.972643906937705, "Episode Reward": 4910.685489245906, "Mean Reward": 38.36473038473364, "Episode": 1585, "Episode Step": 128}
{"Training Time": 2.973920489417182, "Episode Reward": 4859.126290895722, "Mean Reward": 45.84081406505398, "Episode": 1586, "Episode Step": 106}
{"Training Time": 2.976881066362063, "Episode Reward": 8642.004478954968, "Mean Reward": 40.57279098100924, "Episode": 1587, "Episode Step": 213}
{"Training Time": 2.980617571141985, "Episode Reward": 15098.935054597878, "Mean Reward": 46.60165140307987, "Episode": 1588, "Episode Step": 324}
{"Training Time": 2.9834400822056666, "Episode Reward": 11126.28970035406, "Mean Reward": 45.976403720471325, "Episode": 1589, "Episode Step": 242}
{"Training Time": 2.986534207529492, "Episode Reward": 10646.810368785962, "Mean Reward": 47.31915719460427, "Episode": 1590, "Episode Step": 225}
{"Training Time": 2.9890723611248866, "Episode Reward": 8965.506455994313, "Mean Reward": 41.894889981281835, "Episode": 1591, "Episode Step": 214}
{"Training Time": 2.9914351197083793, "Episode Reward": 9191.153801812563, "Mean Reward": 45.72713334235106, "Episode": 1592, "Episode Step": 201}
{"Training Time": 2.9948659483591715, "Episode Reward": 14020.934174382648, "Mean Reward": 54.76927411868222, "Episode": 1593, "Episode Step": 256}
{"Training Time": 2.9976626347170936, "Episode Reward": 11022.349288576095, "Mean Reward": 46.11861627019287, "Episode": 1594, "Episode Step": 239}
{"Training Time": 2.9999817152818045, "Episode Reward": 9183.80364417029, "Mean Reward": 45.91901822085145, "Episode": 1595, "Episode Step": 200}
{"Training Time": 3.0029400536086825, "Episode Reward": 9518.942026456645, "Mean Reward": 44.48103750680675, "Episode": 1596, "Episode Step": 214}
{"Training Time": 3.005538695255915, "Episode Reward": 8865.190073272051, "Mean Reward": 39.75421557521099, "Episode": 1597, "Episode Step": 223}
{"Training Time": 3.006580404970381, "Episode Reward": 3993.9829735391286, "Mean Reward": 45.38617015385373, "Episode": 1598, "Episode Step": 88}
{"Training Time": 3.017118457224634, "Episode Reward": 42066.914213446114, "Mean Reward": 56.164104423826586, "Episode": 1599, "Episode Step": 749}
{"Training Time": 3.0214296047555074, "Episode Reward": 15967.425252618006, "Mean Reward": 47.24090311425446, "Episode": 1600, "Episode Step": 338}
{"Training Time": 3.0241474422481325, "Episode Reward": 10418.408903135185, "Mean Reward": 45.29743001363124, "Episode": 1601, "Episode Step": 230}
{"Training Time": 3.026752792795499, "Episode Reward": 8838.237772668337, "Mean Reward": 48.561746003672184, "Episode": 1602, "Episode Step": 182}
{"Training Time": 3.0280756002664564, "Episode Reward": 5066.507313353955, "Mean Reward": 46.48171847113721, "Episode": 1603, "Episode Step": 109}
{"Training Time": 3.0307090355290307, "Episode Reward": 11426.501368304336, "Mean Reward": 51.703626100924595, "Episode": 1604, "Episode Step": 221}
{"Training Time": 3.0335216152668, "Episode Reward": 9048.973695952756, "Mean Reward": 45.472229627903296, "Episode": 1605, "Episode Step": 199}
{"Training Time": 3.03633268641101, "Episode Reward": 10705.419061770144, "Mean Reward": 44.792548375607296, "Episode": 1606, "Episode Step": 239}
{"Training Time": 3.0373408991760678, "Episode Reward": 4817.273630927571, "Mean Reward": 57.3484956062806, "Episode": 1607, "Episode Step": 84}
{"Training Time": 3.0429583050145044, "Episode Reward": 22551.073836257518, "Mean Reward": 51.604287954822695, "Episode": 1608, "Episode Step": 437}
{"Training Time": 3.0459743180539873, "Episode Reward": 12191.362482317147, "Mean Reward": 47.07089761512412, "Episode": 1609, "Episode Step": 259}
{"Training Time": 3.0479951652553345, "Episode Reward": 7683.4238043774185, "Mean Reward": 44.93230294957554, "Episode": 1610, "Episode Step": 171}
{"Training Time": 3.0502006883091397, "Episode Reward": 6553.408832566196, "Mean Reward": 43.98260961453823, "Episode": 1611, "Episode Step": 149}
{"Training Time": 3.0533203822374344, "Episode Reward": 12314.310991449718, "Mean Reward": 45.60855922759155, "Episode": 1612, "Episode Step": 270}
{"Training Time": 3.0559200911389457, "Episode Reward": 11243.400843508965, "Mean Reward": 50.64594974553588, "Episode": 1613, "Episode Step": 222}
{"Training Time": 3.059326216644711, "Episode Reward": 14016.195329038293, "Mean Reward": 55.61982273427894, "Episode": 1614, "Episode Step": 252}
{"Training Time": 3.062711269458135, "Episode Reward": 11553.704626120074, "Mean Reward": 40.11702995180581, "Episode": 1615, "Episode Step": 288}
{"Training Time": 3.064845541914304, "Episode Reward": 7708.164943101156, "Mean Reward": 42.35255463242393, "Episode": 1616, "Episode Step": 182}
{"Training Time": 3.0679908491505516, "Episode Reward": 11874.895599715133, "Mean Reward": 52.08287543734708, "Episode": 1617, "Episode Step": 228}
{"Training Time": 3.074602752526601, "Episode Reward": 30374.396591672976, "Mean Reward": 53.47605033745242, "Episode": 1618, "Episode Step": 568}
{"Training Time": 3.076713815861278, "Episode Reward": 7707.425305442236, "Mean Reward": 43.0582419298449, "Episode": 1619, "Episode Step": 179}
{"Training Time": 3.080053507486979, "Episode Reward": 13072.867765310133, "Mean Reward": 53.35864394004136, "Episode": 1620, "Episode Step": 245}
{"Training Time": 3.082961762216356, "Episode Reward": 10223.926840810433, "Mean Reward": 41.73031363596095, "Episode": 1621, "Episode Step": 245}
{"Training Time": 3.0839883269204034, "Episode Reward": 4072.9336771598328, "Mean Reward": 46.81532962252681, "Episode": 1622, "Episode Step": 87}
{"Training Time": 3.087046514749527, "Episode Reward": 11328.717868765836, "Mean Reward": 52.691711017515516, "Episode": 1623, "Episode Step": 215}
{"Training Time": 3.0897254947159025, "Episode Reward": 8521.214596318114, "Mean Reward": 37.70448936423944, "Episode": 1624, "Episode Step": 226}
{"Training Time": 3.0921131730741926, "Episode Reward": 8541.412530522859, "Mean Reward": 42.7070626526143, "Episode": 1625, "Episode Step": 200}
{"Training Time": 3.0950741461250515, "Episode Reward": 10811.61844409784, "Mean Reward": 50.998200208008676, "Episode": 1626, "Episode Step": 212}
{"Training Time": 3.096623084743818, "Episode Reward": 5004.048472367297, "Mean Reward": 38.492680556671516, "Episode": 1627, "Episode Step": 130}
{"Training Time": 3.099418388605118, "Episode Reward": 11400.51495515118, "Mean Reward": 48.512829596388, "Episode": 1628, "Episode Step": 235}
{"Training Time": 3.10251655028926, "Episode Reward": 10452.269217452302, "Mean Reward": 47.295335825576025, "Episode": 1629, "Episode Step": 221}
{"Training Time": 3.105084719459216, "Episode Reward": 8651.067079754359, "Mean Reward": 40.05123648034425, "Episode": 1630, "Episode Step": 216}
{"Training Time": 3.107225793864992, "Episode Reward": 8290.391328759653, "Mean Reward": 46.0577296042203, "Episode": 1631, "Episode Step": 180}
{"Training Time": 3.110813105305036, "Episode Reward": 15999.003047031869, "Mean Reward": 59.92135972671112, "Episode": 1632, "Episode Step": 267}
{"Training Time": 3.1122391047080358, "Episode Reward": 4392.615177371645, "Mean Reward": 36.60512647809704, "Episode": 1633, "Episode Step": 120}
{"Training Time": 3.1138384677966435, "Episode Reward": 4743.8470594340215, "Mean Reward": 34.88122837819134, "Episode": 1634, "Episode Step": 136}
{"Training Time": 3.117032133075926, "Episode Reward": 12461.126709611191, "Mean Reward": 53.944271470178315, "Episode": 1635, "Episode Step": 231}
{"Training Time": 3.1185287786192366, "Episode Reward": 4913.773535061139, "Mean Reward": 38.6911301973318, "Episode": 1636, "Episode Step": 127}
{"Training Time": 3.1221516591972773, "Episode Reward": 14478.53299001475, "Mean Reward": 46.55476845663907, "Episode": 1637, "Episode Step": 311}
{"Training Time": 3.1250897400246727, "Episode Reward": 9225.695833173912, "Mean Reward": 43.51743317534864, "Episode": 1638, "Episode Step": 212}
{"Training Time": 3.1281183771954644, "Episode Reward": 11845.992364918366, "Mean Reward": 45.73742225837207, "Episode": 1639, "Episode Step": 259}
{"Training Time": 3.1317108949687746, "Episode Reward": 14171.952555779913, "Mean Reward": 46.012832973311404, "Episode": 1640, "Episode Step": 308}
{"Training Time": 3.135040994750129, "Episode Reward": 11429.730540322313, "Mean Reward": 46.84315795214063, "Episode": 1641, "Episode Step": 244}
{"Training Time": 3.1378369988997776, "Episode Reward": 11763.3364751571, "Mean Reward": 49.21898106760293, "Episode": 1642, "Episode Step": 239}
{"Training Time": 3.141303496360779, "Episode Reward": 18399.38348611083, "Mean Reward": 61.3312782870361, "Episode": 1643, "Episode Step": 300}
{"Training Time": 3.1453413330846365, "Episode Reward": 15637.15152779371, "Mean Reward": 51.778647443025534, "Episode": 1644, "Episode Step": 302}
{"Training Time": 3.1485746702882977, "Episode Reward": 12454.075421646852, "Mean Reward": 46.12620526535871, "Episode": 1645, "Episode Step": 270}
{"Training Time": 3.15058229247729, "Episode Reward": 8307.972332285246, "Mean Reward": 49.45221626360266, "Episode": 1646, "Episode Step": 168}
{"Training Time": 3.153685748047299, "Episode Reward": 10953.71436212463, "Mean Reward": 48.46776266426828, "Episode": 1647, "Episode Step": 226}
{"Training Time": 3.157177821132872, "Episode Reward": 14489.981357796389, "Mean Reward": 49.793750370434324, "Episode": 1648, "Episode Step": 291}
{"Training Time": 3.160076759722498, "Episode Reward": 8910.315490396253, "Mean Reward": 50.05795219323738, "Episode": 1649, "Episode Step": 178}
{"Training Time": 3.1636167724927264, "Episode Reward": 13024.176724703246, "Mean Reward": 50.286396620475855, "Episode": 1650, "Episode Step": 259}
{"Training Time": 3.166643355819914, "Episode Reward": 12393.593803038182, "Mean Reward": 48.793676389914104, "Episode": 1651, "Episode Step": 254}
{"Training Time": 3.1682801175117494, "Episode Reward": 5603.728266931309, "Mean Reward": 41.20388431567139, "Episode": 1652, "Episode Step": 136}
{"Training Time": 3.1713966608047484, "Episode Reward": 11708.63282556072, "Mean Reward": 51.57988028881375, "Episode": 1653, "Episode Step": 227}
{"Training Time": 3.1742623974879582, "Episode Reward": 11220.847820954097, "Mean Reward": 45.61320252420365, "Episode": 1654, "Episode Step": 246}
{"Training Time": 3.1778859594133166, "Episode Reward": 17992.318829835083, "Mean Reward": 58.41661957738663, "Episode": 1655, "Episode Step": 308}
{"Training Time": 3.1813723238971496, "Episode Reward": 12836.786003805866, "Mean Reward": 49.94858367239637, "Episode": 1656, "Episode Step": 257}
{"Training Time": 3.1842974199851355, "Episode Reward": 12333.854573593575, "Mean Reward": 49.53355250439187, "Episode": 1657, "Episode Step": 249}
{"Training Time": 3.1851130069626703, "Episode Reward": 3159.572760230636, "Mean Reward": 45.79090956855994, "Episode": 1658, "Episode Step": 69}
{"Training Time": 3.186754278341929, "Episode Reward": 5237.427283337369, "Mean Reward": 51.3473263072291, "Episode": 1659, "Episode Step": 102}
{"Training Time": 3.1896578849686517, "Episode Reward": 12179.439724045054, "Mean Reward": 49.110644048568766, "Episode": 1660, "Episode Step": 248}
{"Training Time": 3.1924984711408615, "Episode Reward": 13059.316380013972, "Mean Reward": 53.74204271610688, "Episode": 1661, "Episode Step": 243}
{"Training Time": 3.1944506800174715, "Episode Reward": 6021.283578796713, "Mean Reward": 47.04127795934932, "Episode": 1662, "Episode Step": 128}
{"Training Time": 3.198354580865966, "Episode Reward": 6829.6367320247955, "Mean Reward": 20.509419615690078, "Episode": 1663, "Episode Step": 333}
{"Training Time": 3.202053307493528, "Episode Reward": 15138.656162443933, "Mean Reward": 48.21228077211443, "Episode": 1664, "Episode Step": 314}
{"Training Time": 3.2046679613987603, "Episode Reward": 8848.581841868941, "Mean Reward": 48.090118705809466, "Episode": 1665, "Episode Step": 184}
{"Training Time": 3.207673496140374, "Episode Reward": 11999.88431293731, "Mean Reward": 46.69215685967825, "Episode": 1666, "Episode Step": 257}
{"Training Time": 3.2112650250064, "Episode Reward": 14389.394014889785, "Mean Reward": 46.71881173665515, "Episode": 1667, "Episode Step": 308}
{"Training Time": 3.2129485266738467, "Episode Reward": 5209.066563792865, "Mean Reward": 49.61015775040824, "Episode": 1668, "Episode Step": 105}
{"Training Time": 3.2159779338704215, "Episode Reward": 12231.958379914418, "Mean Reward": 47.04599376890161, "Episode": 1669, "Episode Step": 260}
{"Training Time": 3.219650657773018, "Episode Reward": 18637.117362143385, "Mean Reward": 60.31429567036694, "Episode": 1670, "Episode Step": 309}
{"Training Time": 3.221846969458792, "Episode Reward": 6007.660429530574, "Mean Reward": 41.148359106373796, "Episode": 1671, "Episode Step": 146}
{"Training Time": 3.224823387530115, "Episode Reward": 12442.42927229707, "Mean Reward": 49.969595471072566, "Episode": 1672, "Episode Step": 249}
{"Training Time": 3.229085508055157, "Episode Reward": 20473.289455020906, "Mean Reward": 56.09120398635864, "Episode": 1673, "Episode Step": 365}
{"Training Time": 3.232500990562969, "Episode Reward": 10560.006050325515, "Mean Reward": 41.90478591399014, "Episode": 1674, "Episode Step": 252}
{"Training Time": 3.2350066772434447, "Episode Reward": 9281.363610502414, "Mean Reward": 44.19696957382102, "Episode": 1675, "Episode Step": 210}
{"Training Time": 3.2418609711196686, "Episode Reward": 33770.84094236224, "Mean Reward": 59.35121430995122, "Episode": 1676, "Episode Step": 569}
{"Training Time": 3.2452648269467885, "Episode Reward": 12570.902834853348, "Mean Reward": 50.89434346094473, "Episode": 1677, "Episode Step": 247}
{"Training Time": 3.2564760500192644, "Episode Reward": 42055.86342972418, "Mean Reward": 43.89964867403359, "Episode": 1678, "Episode Step": 958}
{"Training Time": 3.259003383583493, "Episode Reward": 10640.2865753134, "Mean Reward": 49.03357868808018, "Episode": 1679, "Episode Step": 217}
{"Training Time": 3.262263080014123, "Episode Reward": 11622.994988513337, "Mean Reward": 48.836113397114865, "Episode": 1680, "Episode Step": 238}
{"Training Time": 3.265883836083942, "Episode Reward": 11994.455248726934, "Mean Reward": 38.44376682284274, "Episode": 1681, "Episode Step": 312}
{"Training Time": 3.2672002549966175, "Episode Reward": 4962.652494701647, "Mean Reward": 44.30939727412185, "Episode": 1682, "Episode Step": 112}
{"Training Time": 3.2692451169755725, "Episode Reward": 6407.012808822988, "Mean Reward": 46.76651685272254, "Episode": 1683, "Episode Step": 137}
{"Training Time": 3.270458850529459, "Episode Reward": 220.60038602497278, "Mean Reward": 2.1627488825977723, "Episode": 1684, "Episode Step": 102}
{"Training Time": 3.272973711689313, "Episode Reward": 8996.503232885485, "Mean Reward": 41.458540243711916, "Episode": 1685, "Episode Step": 217}
{"Training Time": 3.278653764459822, "Episode Reward": 24764.174349987105, "Mean Reward": 54.787996349528996, "Episode": 1686, "Episode Step": 452}
{"Training Time": 3.279882335861524, "Episode Reward": 275.9195828121368, "Mean Reward": 2.7050939491385964, "Episode": 1687, "Episode Step": 102}
{"Training Time": 3.281163885858324, "Episode Reward": 5585.0107574487965, "Mean Reward": 51.71306256897034, "Episode": 1688, "Episode Step": 108}
{"Training Time": 3.284406816098425, "Episode Reward": 11755.977872357136, "Mean Reward": 49.813465560835326, "Episode": 1689, "Episode Step": 236}
{"Training Time": 3.2964579225248762, "Episode Reward": 43031.01695269792, "Mean Reward": 42.022477492869065, "Episode": 1690, "Episode Step": 1024}
{"Training Time": 3.3007907078001235, "Episode Reward": 18806.096312944508, "Mean Reward": 51.103522589523116, "Episode": 1691, "Episode Step": 368}
{"Training Time": 3.3025849097304874, "Episode Reward": 6079.864753830748, "Mean Reward": 54.77355634081755, "Episode": 1692, "Episode Step": 111}
{"Training Time": 3.305969515575303, "Episode Reward": 15978.178576875805, "Mean Reward": 56.26119217209791, "Episode": 1693, "Episode Step": 284}
{"Training Time": 3.307316573858261, "Episode Reward": 5012.7292466076815, "Mean Reward": 45.15972294241155, "Episode": 1694, "Episode Step": 111}
{"Training Time": 3.30911393807994, "Episode Reward": 6115.522512900812, "Mean Reward": 56.105711127530384, "Episode": 1695, "Episode Step": 109}
{"Training Time": 3.317272954715623, "Episode Reward": 34104.30847985781, "Mean Reward": 49.21256634900117, "Episode": 1696, "Episode Step": 693}
{"Training Time": 3.3216850916544596, "Episode Reward": 21427.627273313945, "Mean Reward": 57.14033939550385, "Episode": 1697, "Episode Step": 375}
{"Training Time": 3.3235005678070917, "Episode Reward": 5745.708473991388, "Mean Reward": 49.962682382533806, "Episode": 1698, "Episode Step": 115}
{"Training Time": 3.330470334159003, "Episode Reward": 23823.571042197873, "Mean Reward": 48.421892362190796, "Episode": 1699, "Episode Step": 492}
{"Training Time": 3.3335683658387927, "Episode Reward": 11683.873589593793, "Mean Reward": 49.09190583862939, "Episode": 1700, "Episode Step": 238}
{"Training Time": 3.3353505452473957, "Episode Reward": 5716.373346613141, "Mean Reward": 50.587374748788854, "Episode": 1701, "Episode Step": 113}
{"Training Time": 3.338655795256297, "Episode Reward": 14974.88999985349, "Mean Reward": 53.8665107908399, "Episode": 1702, "Episode Step": 278}
{"Training Time": 3.342373866107729, "Episode Reward": 17347.681002727077, "Mean Reward": 55.6015416754073, "Episode": 1703, "Episode Step": 312}
{"Training Time": 3.3441546644767124, "Episode Reward": 6104.095661812397, "Mean Reward": 55.491778743749066, "Episode": 1704, "Episode Step": 110}
{"Training Time": 3.352687064475483, "Episode Reward": 38815.00958908758, "Mean Reward": 54.05990193466237, "Episode": 1705, "Episode Step": 718}
{"Training Time": 3.3541700272427666, "Episode Reward": 5384.14977083023, "Mean Reward": 43.073198166641845, "Episode": 1706, "Episode Step": 125}
{"Training Time": 3.355914724469185, "Episode Reward": 5904.862043796348, "Mean Reward": 54.173046273360995, "Episode": 1707, "Episode Step": 109}
{"Training Time": 3.3600645771953794, "Episode Reward": 16665.826401234004, "Mean Reward": 47.078605653203404, "Episode": 1708, "Episode Step": 354}
{"Training Time": 3.362133208049668, "Episode Reward": 8023.228827743971, "Mean Reward": 45.586527430363475, "Episode": 1709, "Episode Step": 176}
{"Training Time": 3.3639199860890705, "Episode Reward": 5491.8810111948615, "Mean Reward": 49.0346518856684, "Episode": 1710, "Episode Step": 112}
{"Training Time": 3.3651900647083917, "Episode Reward": 5408.2814185939405, "Mean Reward": 49.166194714490366, "Episode": 1711, "Episode Step": 110}
{"Training Time": 3.366659459140566, "Episode Reward": 5497.282812930429, "Mean Reward": 43.97826250344343, "Episode": 1712, "Episode Step": 125}
{"Training Time": 3.3684537647167843, "Episode Reward": 4796.1683436976155, "Mean Reward": 42.07165213769838, "Episode": 1713, "Episode Step": 114}
{"Training Time": 3.3712021778027217, "Episode Reward": 12628.98916419139, "Mean Reward": 53.74037942209102, "Episode": 1714, "Episode Step": 235}
{"Training Time": 3.37266472114457, "Episode Reward": 6825.798610327075, "Mean Reward": 55.04676298650867, "Episode": 1715, "Episode Step": 124}
{"Training Time": 3.3761269280645583, "Episode Reward": 12393.559365672958, "Mean Reward": 48.037051804933945, "Episode": 1716, "Episode Step": 258}
{"Training Time": 3.378571549720234, "Episode Reward": 8075.405136931814, "Mean Reward": 38.45431017586578, "Episode": 1717, "Episode Step": 210}
{"Training Time": 3.381183171669642, "Episode Reward": 12584.129067753358, "Mean Reward": 56.68526607096107, "Episode": 1718, "Episode Step": 222}
{"Training Time": 3.382913068069352, "Episode Reward": 5082.069136197525, "Mean Reward": 48.40065843997643, "Episode": 1719, "Episode Step": 105}
{"Training Time": 3.38508233944575, "Episode Reward": 8209.76960282849, "Mean Reward": 45.10862419136533, "Episode": 1720, "Episode Step": 182}
{"Training Time": 3.389493865304523, "Episode Reward": 19168.007431482813, "Mean Reward": 51.114686483954166, "Episode": 1721, "Episode Step": 375}
{"Training Time": 3.392109280559752, "Episode Reward": 7873.2764232590425, "Mean Reward": 43.023368433109525, "Episode": 1722, "Episode Step": 183}
{"Training Time": 3.3978528686364493, "Episode Reward": 27144.883111239495, "Mean Reward": 54.83814769947373, "Episode": 1723, "Episode Step": 495}
{"Training Time": 3.4022240827480954, "Episode Reward": 20499.013872024098, "Mean Reward": 55.703842043543744, "Episode": 1724, "Episode Step": 368}
{"Training Time": 3.4056944297419656, "Episode Reward": 14170.345127721712, "Mean Reward": 56.231528284609965, "Episode": 1725, "Episode Step": 252}
{"Training Time": 3.411411195264922, "Episode Reward": 29166.280943283567, "Mean Reward": 59.76696914607288, "Episode": 1726, "Episode Step": 488}
{"Training Time": 3.413515948057175, "Episode Reward": 7438.044920296271, "Mean Reward": 41.09417083036614, "Episode": 1727, "Episode Step": 181}
{"Training Time": 3.41655850774712, "Episode Reward": 12296.263718585118, "Mean Reward": 54.894034457969276, "Episode": 1728, "Episode Step": 224}
{"Training Time": 3.4193085461192663, "Episode Reward": 13859.222496616798, "Mean Reward": 58.975414879220416, "Episode": 1729, "Episode Step": 235}
{"Training Time": 3.4220601922273635, "Episode Reward": 12767.568983542704, "Mean Reward": 54.56226061343036, "Episode": 1730, "Episode Step": 234}
{"Training Time": 3.442805222802692, "Episode Reward": 101075.62538899551, "Mean Reward": 57.88981981042126, "Episode": 1731, "Episode Step": 1746}
{"Training Time": 3.4451744072304833, "Episode Reward": 8737.57333880557, "Mean Reward": 43.68786669402785, "Episode": 1732, "Episode Step": 200}
{"Training Time": 3.4466564989089967, "Episode Reward": 5175.858608214793, "Mean Reward": 41.078242922339626, "Episode": 1733, "Episode Step": 126}
{"Training Time": 3.449560811916987, "Episode Reward": 10531.168389789438, "Mean Reward": 49.91075066250919, "Episode": 1734, "Episode Step": 211}
{"Training Time": 3.4576873572005167, "Episode Reward": 40802.46977931394, "Mean Reward": 58.206090983329446, "Episode": 1735, "Episode Step": 701}
{"Training Time": 3.4583200844128927, "Episode Reward": 2560.1610319401984, "Mean Reward": 49.23386599884997, "Episode": 1736, "Episode Step": 52}
{"Training Time": 3.466718208326234, "Episode Reward": 38096.56179030893, "Mean Reward": 55.5343466331034, "Episode": 1737, "Episode Step": 686}
{"Training Time": 3.470754407511817, "Episode Reward": 19950.634508172854, "Mean Reward": 57.660793376222124, "Episode": 1738, "Episode Step": 346}
{"Training Time": 3.474286839697096, "Episode Reward": 17946.109639324804, "Mean Reward": 59.033255392515805, "Episode": 1739, "Episode Step": 304}
{"Training Time": 3.481659161647161, "Episode Reward": 33135.87069672024, "Mean Reward": 55.59709848442993, "Episode": 1740, "Episode Step": 596}
{"Training Time": 3.4954861227671303, "Episode Reward": 75162.51380736985, "Mean Reward": 63.26810926546283, "Episode": 1741, "Episode Step": 1188}
{"Training Time": 3.4985226047039033, "Episode Reward": 14945.774760414008, "Mean Reward": 57.705694055652536, "Episode": 1742, "Episode Step": 259}
{"Training Time": 3.507566988600625, "Episode Reward": 41052.0546103393, "Mean Reward": 55.92922971435872, "Episode": 1743, "Episode Step": 734}
{"Training Time": 3.5112216005722683, "Episode Reward": 18681.786714792284, "Mean Reward": 59.68621953607759, "Episode": 1744, "Episode Step": 313}
{"Training Time": 3.511834670835071, "Episode Reward": 2330.047732409916, "Mean Reward": 46.600954648198325, "Episode": 1745, "Episode Step": 50}
{"Training Time": 3.51517691830794, "Episode Reward": 13963.177209425263, "Mean Reward": 56.30313390897283, "Episode": 1746, "Episode Step": 248}
{"Training Time": 3.5179448925124275, "Episode Reward": 12794.051453206645, "Mean Reward": 54.21208242884171, "Episode": 1747, "Episode Step": 236}
{"Training Time": 3.520684533317884, "Episode Reward": 10496.112650532405, "Mean Reward": 44.28739514992576, "Episode": 1748, "Episode Step": 237}
{"Training Time": 3.528694879743788, "Episode Reward": 32387.2925881096, "Mean Reward": 58.672631500198555, "Episode": 1749, "Episode Step": 552}
{"Training Time": 3.53118567082617, "Episode Reward": 8896.484106954493, "Mean Reward": 47.0713444812407, "Episode": 1750, "Episode Step": 189}
{"Training Time": 3.5349136549896665, "Episode Reward": 16419.63037322982, "Mean Reward": 52.2918164752542, "Episode": 1751, "Episode Step": 314}
{"Training Time": 3.5381464613808524, "Episode Reward": 12832.66743801668, "Mean Reward": 54.14627610977502, "Episode": 1752, "Episode Step": 237}
{"Training Time": 3.5409096788697774, "Episode Reward": 14346.672354480088, "Mean Reward": 61.049669593532286, "Episode": 1753, "Episode Step": 235}
{"Training Time": 3.544543355570899, "Episode Reward": 16099.987631699289, "Mean Reward": 52.272687115906784, "Episode": 1754, "Episode Step": 308}
{"Training Time": 3.548178303307957, "Episode Reward": 16212.77252199679, "Mean Reward": 60.04730563702515, "Episode": 1755, "Episode Step": 270}
{"Training Time": 3.551154505279329, "Episode Reward": 15893.564827389493, "Mean Reward": 63.32097540792627, "Episode": 1756, "Episode Step": 251}
{"Training Time": 3.5542300766706467, "Episode Reward": 16176.28186383289, "Mean Reward": 61.74153383142325, "Episode": 1757, "Episode Step": 262}
{"Training Time": 3.5625955349869196, "Episode Reward": 36681.915413073264, "Mean Reward": 54.66753414765017, "Episode": 1758, "Episode Step": 671}
{"Training Time": 3.5646655469470554, "Episode Reward": 8829.439913780017, "Mean Reward": 50.45394236445724, "Episode": 1759, "Episode Step": 175}
{"Training Time": 3.56763606025113, "Episode Reward": 14664.933008219408, "Mean Reward": 57.964162087823745, "Episode": 1760, "Episode Step": 253}
{"Training Time": 3.569753424723943, "Episode Reward": 6582.9155088171565, "Mean Reward": 47.02082506297969, "Episode": 1761, "Episode Step": 140}
{"Training Time": 3.577910207245085, "Episode Reward": 42554.624122690264, "Mean Reward": 61.1417013257044, "Episode": 1762, "Episode Step": 696}
{"Training Time": 3.581012354426914, "Episode Reward": 14653.288997711796, "Mean Reward": 55.08755262297667, "Episode": 1763, "Episode Step": 266}
{"Training Time": 3.5845653205447725, "Episode Reward": 14928.131373733744, "Mean Reward": 56.33257122163677, "Episode": 1764, "Episode Step": 265}
{"Training Time": 3.5865962608655293, "Episode Reward": 8358.632129354855, "Mean Reward": 48.038115685947446, "Episode": 1765, "Episode Step": 174}
{"Training Time": 3.589642372197575, "Episode Reward": 15529.789468635661, "Mean Reward": 59.960577098979385, "Episode": 1766, "Episode Step": 259}
{"Training Time": 3.5920428041617076, "Episode Reward": 6662.604056123497, "Mean Reward": 40.8748715099601, "Episode": 1767, "Episode Step": 163}
{"Training Time": 3.599308663341734, "Episode Reward": 37419.548286030295, "Mean Reward": 59.49053781562845, "Episode": 1768, "Episode Step": 629}
{"Training Time": 3.6029162394338186, "Episode Reward": 18362.24049914839, "Mean Reward": 59.81185830341495, "Episode": 1769, "Episode Step": 307}
{"Training Time": 3.6061304766601987, "Episode Reward": 12158.961973405463, "Mean Reward": 52.184386151954776, "Episode": 1770, "Episode Step": 233}
{"Training Time": 3.609097873634762, "Episode Reward": 16062.440888279898, "Mean Reward": 64.24976355311959, "Episode": 1771, "Episode Step": 250}
{"Training Time": 3.6117518366707695, "Episode Reward": 13031.23764537122, "Mean Reward": 58.69926867284334, "Episode": 1772, "Episode Step": 222}
{"Training Time": 3.6152584085861843, "Episode Reward": 15405.038960188227, "Mean Reward": 59.941785837308274, "Episode": 1773, "Episode Step": 257}
{"Training Time": 3.6227129097117317, "Episode Reward": 37336.054132011915, "Mean Reward": 58.88967528708504, "Episode": 1774, "Episode Step": 634}
{"Training Time": 3.625625565846761, "Episode Reward": 14697.210077344696, "Mean Reward": 59.50287480706355, "Episode": 1775, "Episode Step": 247}
{"Training Time": 3.6325526747438643, "Episode Reward": 30342.935924470527, "Mean Reward": 55.26946434329786, "Episode": 1776, "Episode Step": 549}
{"Training Time": 3.6408292711443373, "Episode Reward": 44089.3916180185, "Mean Reward": 62.62697673013991, "Episode": 1777, "Episode Step": 704}
{"Training Time": 3.6439379225174586, "Episode Reward": 16590.393771701467, "Mean Reward": 63.081345139549306, "Episode": 1778, "Episode Step": 263}
{"Training Time": 3.649238375292884, "Episode Reward": 22991.330702573843, "Mean Reward": 55.267621881187125, "Episode": 1779, "Episode Step": 416}
{"Training Time": 3.6514155244164996, "Episode Reward": 8810.97327923515, "Mean Reward": 47.62688259046027, "Episode": 1780, "Episode Step": 185}
{"Training Time": 3.6527366047435335, "Episode Reward": 6195.052644472199, "Mean Reward": 55.31297003993035, "Episode": 1781, "Episode Step": 112}
{"Training Time": 3.6541983822319244, "Episode Reward": 3764.311518397997, "Mean Reward": 45.35315082407225, "Episode": 1782, "Episode Step": 83}
{"Training Time": 3.656769150826666, "Episode Reward": 12625.052574138042, "Mean Reward": 57.91308520246808, "Episode": 1783, "Episode Step": 218}
{"Training Time": 3.6583223244216705, "Episode Reward": 5950.152527574923, "Mean Reward": 45.07691308768881, "Episode": 1784, "Episode Step": 132}
{"Training Time": 3.661006718344159, "Episode Reward": 8523.871609013018, "Mean Reward": 45.58220111771668, "Episode": 1785, "Episode Step": 187}
{"Training Time": 3.6631422852807574, "Episode Reward": 8666.063568256499, "Mean Reward": 47.61573389151923, "Episode": 1786, "Episode Step": 182}
{"Training Time": 3.6644260583321255, "Episode Reward": 5994.247658383781, "Mean Reward": 54.99309778333744, "Episode": 1787, "Episode Step": 109}
{"Training Time": 3.6660847183068594, "Episode Reward": 4680.886826689549, "Mean Reward": 45.891047320485775, "Episode": 1788, "Episode Step": 102}
{"Training Time": 3.668525384465853, "Episode Reward": 10226.994446351382, "Mean Reward": 49.168242530535494, "Episode": 1789, "Episode Step": 208}
{"Training Time": 3.6715054888857734, "Episode Reward": 15771.827917318586, "Mean Reward": 62.5866187195182, "Episode": 1790, "Episode Step": 252}
{"Training Time": 3.673185899456342, "Episode Reward": 4752.848507562443, "Mean Reward": 46.596553995710224, "Episode": 1791, "Episode Step": 102}
{"Training Time": 3.675702387491862, "Episode Reward": 9939.433065432768, "Mean Reward": 47.106317845652924, "Episode": 1792, "Episode Step": 211}
{"Training Time": 3.6773186586300532, "Episode Reward": 5900.967591211732, "Mean Reward": 43.3894675824392, "Episode": 1793, "Episode Step": 136}
{"Training Time": 3.679038119978375, "Episode Reward": 4431.131479519645, "Mean Reward": 43.442465485486714, "Episode": 1794, "Episode Step": 102}
{"Training Time": 3.682125509182612, "Episode Reward": 15782.458092775545, "Mean Reward": 61.65022692490447, "Episode": 1795, "Episode Step": 256}
{"Training Time": 3.6831243775288263, "Episode Reward": 4882.700879492764, "Mean Reward": 58.12739142253291, "Episode": 1796, "Episode Step": 84}
{"Training Time": 3.684836361143324, "Episode Reward": 4119.918982080227, "Mean Reward": 40.391362569413985, "Episode": 1797, "Episode Step": 102}
{"Training Time": 3.6878892655505076, "Episode Reward": 15947.31354475566, "Mean Reward": 62.784698995101024, "Episode": 1798, "Episode Step": 254}
{"Training Time": 3.689843074745602, "Episode Reward": 6009.510156242669, "Mean Reward": 54.13973113732134, "Episode": 1799, "Episode Step": 111}
{"Training Time": 3.693259604970614, "Episode Reward": 15070.375210919445, "Mean Reward": 60.523595224576084, "Episode": 1800, "Episode Step": 249}
{"Training Time": 3.7096291510926354, "Episode Reward": 89108.92558863774, "Mean Reward": 63.51313299261421, "Episode": 1801, "Episode Step": 1403}
{"Training Time": 3.7112941777706148, "Episode Reward": 6395.345692238674, "Mean Reward": 45.357061647082794, "Episode": 1802, "Episode Step": 141}
{"Training Time": 3.712808510263761, "Episode Reward": 4267.320458905429, "Mean Reward": 47.94742088657786, "Episode": 1803, "Episode Step": 89}
{"Training Time": 3.714411572217941, "Episode Reward": 6811.4628046705, "Mean Reward": 50.08428532845956, "Episode": 1804, "Episode Step": 136}
{"Training Time": 3.716108704739147, "Episode Reward": 6649.170425394508, "Mean Reward": 46.49769528247908, "Episode": 1805, "Episode Step": 143}
{"Training Time": 3.7177896228101517, "Episode Reward": 4294.17148961773, "Mean Reward": 42.099720486448334, "Episode": 1806, "Episode Step": 102}
{"Training Time": 3.7193938733471765, "Episode Reward": 7112.748143178704, "Mean Reward": 52.29961869984341, "Episode": 1807, "Episode Step": 136}
{"Training Time": 3.722411902215746, "Episode Reward": 14079.411188058259, "Mean Reward": 54.78370112084926, "Episode": 1808, "Episode Step": 257}
{"Training Time": 3.7290814566612243, "Episode Reward": 31423.86276257862, "Mean Reward": 59.290307099204945, "Episode": 1809, "Episode Step": 530}
{"Training Time": 3.7307205072376464, "Episode Reward": 6812.075787712275, "Mean Reward": 50.08879255670791, "Episode": 1810, "Episode Step": 136}
{"Training Time": 3.7322483150164287, "Episode Reward": 5829.400671034922, "Mean Reward": 45.54219274246033, "Episode": 1811, "Episode Step": 128}
{"Training Time": 3.73561171664132, "Episode Reward": 15007.79837381094, "Mean Reward": 61.007310462646096, "Episode": 1812, "Episode Step": 246}
{"Training Time": 3.7372564480702084, "Episode Reward": 6649.573228041173, "Mean Reward": 48.537030861614404, "Episode": 1813, "Episode Step": 137}
{"Training Time": 3.7388791288932164, "Episode Reward": 6234.139892865168, "Mean Reward": 46.17881402122347, "Episode": 1814, "Episode Step": 135}
{"Training Time": 3.740427631404665, "Episode Reward": 3772.5488573488688, "Mean Reward": 41.00596584074857, "Episode": 1815, "Episode Step": 92}
{"Training Time": 3.7426124769449234, "Episode Reward": 8785.154388690748, "Mean Reward": 47.745404286362756, "Episode": 1816, "Episode Step": 184}
{"Training Time": 3.7443377930588193, "Episode Reward": 5039.916379145717, "Mean Reward": 34.5199751996282, "Episode": 1817, "Episode Step": 146}
{"Training Time": 3.7457348089085687, "Episode Reward": 4180.805903424431, "Mean Reward": 51.61488769659791, "Episode": 1818, "Episode Step": 81}
{"Training Time": 3.748718493580818, "Episode Reward": 15279.740486588673, "Mean Reward": 61.36441962485411, "Episode": 1819, "Episode Step": 249}
{"Training Time": 3.7502642291784287, "Episode Reward": 6678.038205168315, "Mean Reward": 51.76773802456058, "Episode": 1820, "Episode Step": 129}
{"Training Time": 3.751921772758166, "Episode Reward": 4003.609249035356, "Mean Reward": 40.03609249035356, "Episode": 1821, "Episode Step": 100}
{"Training Time": 3.7543330316411123, "Episode Reward": 9318.314072228852, "Mean Reward": 46.35977150362613, "Episode": 1822, "Episode Step": 201}
{"Training Time": 3.7549388360977174, "Episode Reward": 2313.643104188573, "Mean Reward": 48.20089800392861, "Episode": 1823, "Episode Step": 48}
{"Training Time": 3.7565420680575903, "Episode Reward": 4072.262687648915, "Mean Reward": 42.41940299634286, "Episode": 1824, "Episode Step": 96}
{"Training Time": 3.7587387558486727, "Episode Reward": 8935.00140899244, "Mean Reward": 48.29730491347265, "Episode": 1825, "Episode Step": 185}
{"Training Time": 3.7618174330393472, "Episode Reward": 15323.156882526167, "Mean Reward": 59.3920809400239, "Episode": 1826, "Episode Step": 258}
{"Training Time": 3.7634394269519382, "Episode Reward": 4177.334967484766, "Mean Reward": 43.513905911299645, "Episode": 1827, "Episode Step": 96}
{"Training Time": 3.765518520275752, "Episode Reward": 7529.177633001276, "Mean Reward": 43.271135821846414, "Episode": 1828, "Episode Step": 174}
{"Training Time": 3.772239965862698, "Episode Reward": 31727.151282141385, "Mean Reward": 56.154250056887406, "Episode": 1829, "Episode Step": 565}
{"Training Time": 3.7738843788703282, "Episode Reward": 4169.391029599672, "Mean Reward": 42.54480642448645, "Episode": 1830, "Episode Step": 98}
{"Training Time": 3.775515686670939, "Episode Reward": 6571.26953186936, "Mean Reward": 48.67607060643971, "Episode": 1831, "Episode Step": 135}
{"Training Time": 3.7787740530570346, "Episode Reward": 15495.926265743688, "Mean Reward": 56.970317153469445, "Episode": 1832, "Episode Step": 272}
{"Training Time": 3.7839956553114784, "Episode Reward": 24343.849704869648, "Mean Reward": 60.707854625610096, "Episode": 1833, "Episode Step": 401}
{"Training Time": 3.785633887251218, "Episode Reward": 6762.687061021548, "Mean Reward": 49.72564015457021, "Episode": 1834, "Episode Step": 136}
{"Training Time": 3.7879512874947654, "Episode Reward": 8813.582435916991, "Mean Reward": 45.90407518706766, "Episode": 1835, "Episode Step": 192}
{"Training Time": 3.7896062099933623, "Episode Reward": 4460.925128847541, "Mean Reward": 44.609251288475406, "Episode": 1836, "Episode Step": 100}
{"Training Time": 3.7912742733293108, "Episode Reward": 6437.12382816668, "Mean Reward": 46.64582484178754, "Episode": 1837, "Episode Step": 138}
{"Training Time": 3.792232807477315, "Episode Reward": 5204.120269299961, "Mean Reward": 65.87494011772102, "Episode": 1838, "Episode Step": 79}
{"Training Time": 3.7957445344660017, "Episode Reward": 15498.622289862817, "Mean Reward": 59.840240501400835, "Episode": 1839, "Episode Step": 259}
{"Training Time": 3.797390768064393, "Episode Reward": 6314.472512102764, "Mean Reward": 46.42994494193209, "Episode": 1840, "Episode Step": 136}
{"Training Time": 3.798970345258713, "Episode Reward": 6331.153651672706, "Mean Reward": 48.701181935943886, "Episode": 1841, "Episode Step": 130}
{"Training Time": 3.8016398300064935, "Episode Reward": 8559.671216364217, "Mean Reward": 46.77415965226348, "Episode": 1842, "Episode Step": 183}
{"Training Time": 3.8033388605382705, "Episode Reward": 5084.161094432659, "Mean Reward": 36.057880102359285, "Episode": 1843, "Episode Step": 141}
{"Training Time": 3.8046333838833704, "Episode Reward": 6146.047121299696, "Mean Reward": 57.43969272242707, "Episode": 1844, "Episode Step": 107}
{"Training Time": 3.8081240038739312, "Episode Reward": 14508.341732168878, "Mean Reward": 57.345224237821654, "Episode": 1845, "Episode Step": 253}
{"Training Time": 3.8087556174728605, "Episode Reward": 2453.978284980738, "Mean Reward": 48.11722127413211, "Episode": 1846, "Episode Step": 51}
{"Training Time": 3.811654272476832, "Episode Reward": 15317.16510314965, "Mean Reward": 63.556701672820125, "Episode": 1847, "Episode Step": 241}
{"Training Time": 3.81517847749922, "Episode Reward": 14964.845532977286, "Mean Reward": 59.384307670544786, "Episode": 1848, "Episode Step": 252}
{"Training Time": 3.816252152191268, "Episode Reward": 2622.489533132062, "Mean Reward": 51.421363394746315, "Episode": 1849, "Episode Step": 51}
{"Training Time": 3.819313882191976, "Episode Reward": 12545.602943985554, "Mean Reward": 54.30996945448292, "Episode": 1850, "Episode Step": 231}
{"Training Time": 3.821955938604143, "Episode Reward": 8697.180229119705, "Mean Reward": 48.31766793955392, "Episode": 1851, "Episode Step": 180}
{"Training Time": 3.823261908027861, "Episode Reward": 5304.134887258533, "Mean Reward": 49.11236006720864, "Episode": 1852, "Episode Step": 108}
{"Training Time": 3.82613462527593, "Episode Reward": 14045.422117711136, "Mean Reward": 58.52259215712973, "Episode": 1853, "Episode Step": 240}
{"Training Time": 3.827704063322809, "Episode Reward": 4205.968350143494, "Mean Reward": 46.73298166826104, "Episode": 1854, "Episode Step": 90}
{"Training Time": 3.829894682765007, "Episode Reward": 9122.453954284125, "Mean Reward": 48.52369124619215, "Episode": 1855, "Episode Step": 188}
{"Training Time": 3.8329952394300038, "Episode Reward": 16600.028043399543, "Mean Reward": 63.84626170538286, "Episode": 1856, "Episode Step": 260}
{"Training Time": 3.835588241087066, "Episode Reward": 8790.772795910714, "Mean Reward": 49.3863640219703, "Episode": 1857, "Episode Step": 178}
{"Training Time": 3.8455573350191115, "Episode Reward": 54127.11120637581, "Mean Reward": 64.13164834878651, "Episode": 1858, "Episode Step": 844}
{"Training Time": 3.847704544994566, "Episode Reward": 9087.080608972514, "Mean Reward": 50.48378116095841, "Episode": 1859, "Episode Step": 180}
{"Training Time": 3.8528994111220043, "Episode Reward": 25957.283205431075, "Mean Reward": 64.25070100354226, "Episode": 1860, "Episode Step": 404}
{"Training Time": 3.855815938313802, "Episode Reward": 14910.712582058253, "Mean Reward": 60.36725741723989, "Episode": 1861, "Episode Step": 247}
{"Training Time": 3.858997581402461, "Episode Reward": 16807.332832837747, "Mean Reward": 63.664139518324795, "Episode": 1862, "Episode Step": 264}
{"Training Time": 3.8604828474919, "Episode Reward": 3829.550086200844, "Mean Reward": 46.13915766507041, "Episode": 1863, "Episode Step": 83}
{"Training Time": 3.8633614399698044, "Episode Reward": 15188.52768046139, "Mean Reward": 62.762511076286735, "Episode": 1864, "Episode Step": 242}
{"Training Time": 3.8670396880308786, "Episode Reward": 16561.786821181206, "Mean Reward": 52.744544016500654, "Episode": 1865, "Episode Step": 314}
{"Training Time": 3.8695881936285232, "Episode Reward": 7720.905079794761, "Mean Reward": 44.37301769996989, "Episode": 1866, "Episode Step": 174}
{"Training Time": 3.871688353088167, "Episode Reward": 8752.799936320493, "Mean Reward": 48.89832366659493, "Episode": 1867, "Episode Step": 179}
{"Training Time": 3.87317791223526, "Episode Reward": 6764.659312693677, "Mean Reward": 53.68777232296569, "Episode": 1868, "Episode Step": 126}
{"Training Time": 3.8756602885988025, "Episode Reward": 8304.383984391754, "Mean Reward": 48.28130223483578, "Episode": 1869, "Episode Step": 172}
{"Training Time": 3.8778375711043678, "Episode Reward": 8847.248385676021, "Mean Reward": 47.05983183870224, "Episode": 1870, "Episode Step": 188}
{"Training Time": 3.879943544997109, "Episode Reward": 8427.872800748888, "Mean Reward": 46.56283315330877, "Episode": 1871, "Episode Step": 181}
{"Training Time": 3.8824974827633962, "Episode Reward": 8219.01087203939, "Mean Reward": 46.17421838224376, "Episode": 1872, "Episode Step": 178}
{"Training Time": 3.885369233356582, "Episode Reward": 12749.429261371093, "Mean Reward": 51.826948216955664, "Episode": 1873, "Episode Step": 246}
{"Training Time": 3.886971002486017, "Episode Reward": 5796.56636449796, "Mean Reward": 42.31070339049606, "Episode": 1874, "Episode Step": 137}
{"Training Time": 3.8895036239094205, "Episode Reward": 8120.819361932587, "Mean Reward": 46.1410191018897, "Episode": 1875, "Episode Step": 176}
{"Training Time": 3.8936111658149297, "Episode Reward": 21840.55695976425, "Mean Reward": 62.04703681751207, "Episode": 1876, "Episode Step": 352}
{"Training Time": 3.8964727338817386, "Episode Reward": 13190.171172762117, "Mean Reward": 53.83743335821272, "Episode": 1877, "Episode Step": 245}
{"Training Time": 3.8980445710817975, "Episode Reward": 4386.818366956329, "Mean Reward": 47.170089967272354, "Episode": 1878, "Episode Step": 93}
{"Training Time": 3.9007181897428302, "Episode Reward": 13991.887909454264, "Mean Reward": 60.57094333097084, "Episode": 1879, "Episode Step": 231}
{"Training Time": 3.901703534722328, "Episode Reward": 4596.457621865936, "Mean Reward": 55.37900749236067, "Episode": 1880, "Episode Step": 83}
{"Training Time": 3.9042101605733235, "Episode Reward": 8789.21438028552, "Mean Reward": 50.22408217306012, "Episode": 1881, "Episode Step": 175}
{"Training Time": 3.9063444494538837, "Episode Reward": 9164.8235652671, "Mean Reward": 50.35617343553351, "Episode": 1882, "Episode Step": 182}
{"Training Time": 3.909423327777121, "Episode Reward": 14782.812577914721, "Mean Reward": 55.99550218907091, "Episode": 1883, "Episode Step": 264}
{"Training Time": 3.911987871925036, "Episode Reward": 8113.508773548598, "Mean Reward": 44.336113516659005, "Episode": 1884, "Episode Step": 183}
{"Training Time": 3.91414488196373, "Episode Reward": 8526.789085291342, "Mean Reward": 46.09075181238563, "Episode": 1885, "Episode Step": 185}
{"Training Time": 3.9219038585821786, "Episode Reward": 36690.11827407591, "Mean Reward": 54.84322611969493, "Episode": 1886, "Episode Step": 669}
{"Training Time": 3.9235714052783117, "Episode Reward": 4887.221783396655, "Mean Reward": 47.91393905290838, "Episode": 1887, "Episode Step": 102}
{"Training Time": 3.92666280441814, "Episode Reward": 14328.254068095826, "Mean Reward": 54.48005349085866, "Episode": 1888, "Episode Step": 263}
{"Training Time": 3.927611311144299, "Episode Reward": 4945.69338532413, "Mean Reward": 61.05794302869296, "Episode": 1889, "Episode Step": 81}
{"Training Time": 3.930960230562422, "Episode Reward": 14588.676282440863, "Mean Reward": 58.589061375264514, "Episode": 1890, "Episode Step": 249}
{"Training Time": 3.9331153586175707, "Episode Reward": 8276.736934527313, "Mean Reward": 44.739118565012504, "Episode": 1891, "Episode Step": 185}
{"Training Time": 3.935261466105779, "Episode Reward": 8784.109727490488, "Mean Reward": 46.723987912183446, "Episode": 1892, "Episode Step": 188}
{"Training Time": 3.9386635461118487, "Episode Reward": 15352.952206981516, "Mean Reward": 60.207655713653004, "Episode": 1893, "Episode Step": 255}
{"Training Time": 3.9416133130258983, "Episode Reward": 15990.099323854483, "Mean Reward": 63.960397295417934, "Episode": 1894, "Episode Step": 250}
{"Training Time": 3.9446226980288825, "Episode Reward": 16043.01494861492, "Mean Reward": 62.66802714302703, "Episode": 1895, "Episode Step": 256}
{"Training Time": 3.9470738816923565, "Episode Reward": 8399.388874220163, "Mean Reward": 48.55138077583909, "Episode": 1896, "Episode Step": 173}
{"Training Time": 3.949469808604982, "Episode Reward": 8784.021066108167, "Mean Reward": 42.640878961690134, "Episode": 1897, "Episode Step": 206}
{"Training Time": 3.950812563896179, "Episode Reward": 5734.994057652058, "Mean Reward": 51.20530408617908, "Episode": 1898, "Episode Step": 112}
{"Training Time": 3.954435964160495, "Episode Reward": 8294.35897028697, "Mean Reward": 47.944271504548965, "Episode": 1899, "Episode Step": 173}
{"Training Time": 3.95764456278748, "Episode Reward": 16473.772070710693, "Mean Reward": 65.3721113917091, "Episode": 1900, "Episode Step": 252}
{"Training Time": 3.9606999544302623, "Episode Reward": 15686.225735748862, "Mean Reward": 62.246927522812946, "Episode": 1901, "Episode Step": 252}
{"Training Time": 3.9691743438773686, "Episode Reward": 44845.42858120356, "Mean Reward": 66.14369997227664, "Episode": 1902, "Episode Step": 678}
{"Training Time": 3.9791493646966085, "Episode Reward": 51520.726888686775, "Mean Reward": 60.399445356022014, "Episode": 1903, "Episode Step": 853}
{"Training Time": 3.98879049413734, "Episode Reward": 49565.94221279222, "Mean Reward": 61.49620621934519, "Episode": 1904, "Episode Step": 806}
{"Training Time": 3.9914316925075317, "Episode Reward": 8757.498084796627, "Mean Reward": 49.477390309585466, "Episode": 1905, "Episode Step": 177}
{"Training Time": 4.0002763464053475, "Episode Reward": 44698.96079574402, "Mean Reward": 60.485738559870114, "Episode": 1906, "Episode Step": 739}
{"Training Time": 4.003293049732844, "Episode Reward": 15632.187108165732, "Mean Reward": 61.787300822789454, "Episode": 1907, "Episode Step": 253}
{"Training Time": 4.004799025257428, "Episode Reward": 4436.786035124301, "Mean Reward": 52.19748276616824, "Episode": 1908, "Episode Step": 85}
{"Training Time": 4.0110374372535285, "Episode Reward": 28457.474226831986, "Mean Reward": 54.62087183652972, "Episode": 1909, "Episode Step": 521}
{"Training Time": 4.012764622502857, "Episode Reward": 7063.554088404461, "Mean Reward": 50.81693588780188, "Episode": 1910, "Episode Step": 139}
{"Training Time": 4.016856855286492, "Episode Reward": 18757.675640849775, "Mean Reward": 63.370525813681674, "Episode": 1911, "Episode Step": 296}
{"Training Time": 4.020126337475247, "Episode Reward": 14551.311401833647, "Mean Reward": 54.295938066543464, "Episode": 1912, "Episode Step": 268}
{"Training Time": 4.022890721956889, "Episode Reward": 13390.242110031495, "Mean Reward": 58.47267296956985, "Episode": 1913, "Episode Step": 229}
{"Training Time": 4.024387555850876, "Episode Reward": 4836.548138106635, "Mean Reward": 58.271664314537766, "Episode": 1914, "Episode Step": 83}
{"Training Time": 4.027404047250748, "Episode Reward": 13795.419243716073, "Mean Reward": 55.62669049885513, "Episode": 1915, "Episode Step": 248}
{"Training Time": 4.029537720547782, "Episode Reward": 8601.026825639936, "Mean Reward": 48.593371896270824, "Episode": 1916, "Episode Step": 177}
{"Training Time": 4.036050308081839, "Episode Reward": 31729.604656105403, "Mean Reward": 63.33254422376328, "Episode": 1917, "Episode Step": 501}
{"Training Time": 4.037758448918661, "Episode Reward": 6427.041791456879, "Mean Reward": 45.26085768631605, "Episode": 1918, "Episode Step": 142}
{"Training Time": 4.040779464178615, "Episode Reward": 17472.458663663503, "Mean Reward": 69.33515342723612, "Episode": 1919, "Episode Step": 252}
{"Training Time": 4.044376369449828, "Episode Reward": 16198.78537380308, "Mean Reward": 63.276505366418284, "Episode": 1920, "Episode Step": 256}
{"Training Time": 4.046220173305936, "Episode Reward": 6357.899860718876, "Mean Reward": 42.385999071459175, "Episode": 1921, "Episode Step": 150}
{"Training Time": 4.047905017203755, "Episode Reward": 7327.451855005977, "Mean Reward": 53.48505003653998, "Episode": 1922, "Episode Step": 137}
{"Training Time": 4.051344110303455, "Episode Reward": 14744.870990879092, "Mean Reward": 60.18314690154731, "Episode": 1923, "Episode Step": 245}
{"Training Time": 4.059283556143443, "Episode Reward": 37430.41441080784, "Mean Reward": 56.62695069713743, "Episode": 1924, "Episode Step": 661}
{"Training Time": 4.061403290033341, "Episode Reward": 8919.521103409432, "Mean Reward": 50.67909717846268, "Episode": 1925, "Episode Step": 176}
{"Training Time": 4.063127475844489, "Episode Reward": 4848.720800421488, "Mean Reward": 47.53647843550478, "Episode": 1926, "Episode Step": 102}
{"Training Time": 4.064864181412591, "Episode Reward": 6497.929632271457, "Mean Reward": 45.76006783289758, "Episode": 1927, "Episode Step": 142}
{"Training Time": 4.067833479179276, "Episode Reward": 14196.873476157323, "Mean Reward": 58.66476643040216, "Episode": 1928, "Episode Step": 242}
{"Training Time": 4.070508630805546, "Episode Reward": 8721.363480169864, "Mean Reward": 48.452019334277026, "Episode": 1929, "Episode Step": 180}
{"Training Time": 4.075274565021197, "Episode Reward": 26341.482718529325, "Mean Reward": 66.01875368052463, "Episode": 1930, "Episode Step": 399}
{"Training Time": 4.07801984389623, "Episode Reward": 13251.847595961197, "Mean Reward": 57.86833011336767, "Episode": 1931, "Episode Step": 229}
{"Training Time": 4.081591257784102, "Episode Reward": 15963.768587552684, "Mean Reward": 62.35847104512767, "Episode": 1932, "Episode Step": 256}
{"Training Time": 4.085834379196167, "Episode Reward": 22171.63996465029, "Mean Reward": 62.98761353593832, "Episode": 1933, "Episode Step": 352}
{"Training Time": 4.088949743310611, "Episode Reward": 15804.441444384589, "Mean Reward": 61.49588110655482, "Episode": 1934, "Episode Step": 257}
{"Training Time": 4.091627853910128, "Episode Reward": 8316.305212850539, "Mean Reward": 45.69398468599197, "Episode": 1935, "Episode Step": 182}
{"Training Time": 4.093384596970346, "Episode Reward": 6337.932868915191, "Mean Reward": 43.11518958445708, "Episode": 1936, "Episode Step": 147}
{"Training Time": 4.096351599428389, "Episode Reward": 14361.410383466407, "Mean Reward": 57.908912836558095, "Episode": 1937, "Episode Step": 248}
{"Training Time": 4.098911041683621, "Episode Reward": 8809.964861938015, "Mean Reward": 49.773812779310816, "Episode": 1938, "Episode Step": 177}
{"Training Time": 4.101239496933089, "Episode Reward": 9803.817894046126, "Mean Reward": 50.796983906974745, "Episode": 1939, "Episode Step": 193}
{"Training Time": 4.104248679147826, "Episode Reward": 16430.174381861234, "Mean Reward": 64.94140071881911, "Episode": 1940, "Episode Step": 253}
{"Training Time": 4.107779143320189, "Episode Reward": 16543.962686888623, "Mean Reward": 64.37339566882733, "Episode": 1941, "Episode Step": 257}
{"Training Time": 4.110099055568377, "Episode Reward": 9996.449583532332, "Mean Reward": 51.79507556234369, "Episode": 1942, "Episode Step": 193}
{"Training Time": 4.113205047514704, "Episode Reward": 16277.095689154934, "Mean Reward": 62.364351299444195, "Episode": 1943, "Episode Step": 261}
{"Training Time": 4.122215990556611, "Episode Reward": 46605.455124967484, "Mean Reward": 64.01848231451578, "Episode": 1944, "Episode Step": 728}
{"Training Time": 4.124510128895442, "Episode Reward": 9053.191495100424, "Mean Reward": 46.66593554175476, "Episode": 1945, "Episode Step": 194}
{"Training Time": 4.1444706566466225, "Episode Reward": 101521.79784020652, "Mean Reward": 59.438991709722785, "Episode": 1946, "Episode Step": 1708}
{"Training Time": 4.147660531136725, "Episode Reward": 13713.294854777747, "Mean Reward": 59.10902954645581, "Episode": 1947, "Episode Step": 232}
{"Training Time": 4.150017072227266, "Episode Reward": 9272.798449718002, "Mean Reward": 47.31019617203062, "Episode": 1948, "Episode Step": 196}
{"Training Time": 4.153755092488395, "Episode Reward": 16582.273663757216, "Mean Reward": 64.27237854169464, "Episode": 1949, "Episode Step": 258}
{"Training Time": 4.156410310268402, "Episode Reward": 9034.316606563261, "Mean Reward": 49.63910223386407, "Episode": 1950, "Episode Step": 182}
{"Training Time": 4.1592568030622274, "Episode Reward": 14607.911131658802, "Mean Reward": 60.36326913908596, "Episode": 1951, "Episode Step": 242}
{"Training Time": 4.162487113608254, "Episode Reward": 15691.885613841452, "Mean Reward": 58.11809486607945, "Episode": 1952, "Episode Step": 270}
{"Training Time": 4.173978616926405, "Episode Reward": 57697.1230265308, "Mean Reward": 62.24069366400302, "Episode": 1953, "Episode Step": 927}
{"Training Time": 4.178840709461106, "Episode Reward": 25627.385756339074, "Mean Reward": 62.65864488102463, "Episode": 1954, "Episode Step": 409}
{"Training Time": 4.183632340298758, "Episode Reward": 23157.209986535996, "Mean Reward": 57.46205951994044, "Episode": 1955, "Episode Step": 403}
{"Training Time": 4.189924062225554, "Episode Reward": 29929.08747088208, "Mean Reward": 60.5851973094779, "Episode": 1956, "Episode Step": 494}
{"Training Time": 4.192820227808422, "Episode Reward": 14998.623462954452, "Mean Reward": 61.21887127736511, "Episode": 1957, "Episode Step": 245}
{"Training Time": 4.195818920003044, "Episode Reward": 16556.504321401844, "Mean Reward": 64.92746792706606, "Episode": 1958, "Episode Step": 255}
{"Training Time": 4.20760485721959, "Episode Reward": 59253.17095795376, "Mean Reward": 61.465944977130455, "Episode": 1959, "Episode Step": 964}
{"Training Time": 4.209792299138175, "Episode Reward": 9062.803091153291, "Mean Reward": 48.72474780189942, "Episode": 1960, "Episode Step": 186}
{"Training Time": 4.218459292782677, "Episode Reward": 47208.86853134762, "Mean Reward": 63.79576828560489, "Episode": 1961, "Episode Step": 740}
{"Training Time": 4.232967364192009, "Episode Reward": 70693.08610031675, "Mean Reward": 58.6178160035794, "Episode": 1962, "Episode Step": 1206}
{"Training Time": 4.241307303905487, "Episode Reward": 46210.031252700704, "Mean Reward": 64.00281336939156, "Episode": 1963, "Episode Step": 722}
{"Training Time": 4.243039929469426, "Episode Reward": 6614.7429206513225, "Mean Reward": 45.3064583606255, "Episode": 1964, "Episode Step": 146}
{"Training Time": 4.246488899721039, "Episode Reward": 16030.529099836136, "Mean Reward": 63.11231929069345, "Episode": 1965, "Episode Step": 254}
{"Training Time": 4.248717068897354, "Episode Reward": 9402.924978589628, "Mean Reward": 49.48907883468225, "Episode": 1966, "Episode Step": 190}
{"Training Time": 4.251885728306241, "Episode Reward": 16523.48868719073, "Mean Reward": 60.52559958677923, "Episode": 1967, "Episode Step": 273}
{"Training Time": 4.2605048630634945, "Episode Reward": 44243.36168461176, "Mean Reward": 63.114638637106644, "Episode": 1968, "Episode Step": 701}
{"Training Time": 4.263501314189699, "Episode Reward": 16759.986048415998, "Mean Reward": 64.71037084330501, "Episode": 1969, "Episode Step": 259}
{"Training Time": 4.265683705276913, "Episode Reward": 9418.170053570513, "Mean Reward": 50.36454574101879, "Episode": 1970, "Episode Step": 187}
{"Training Time": 4.322302337752448, "Episode Reward": 291173.8582196206, "Mean Reward": 59.86304650896805, "Episode": 1971, "Episode Step": 4864}
{"Training Time": 4.324469769994418, "Episode Reward": 9085.598908267946, "Mean Reward": 49.92087312235135, "Episode": 1972, "Episode Step": 182}
{"Training Time": 4.3266117660866845, "Episode Reward": 9070.062271675179, "Mean Reward": 50.110841279973364, "Episode": 1973, "Episode Step": 181}
{"Training Time": 4.339907036688593, "Episode Reward": 61700.153872547075, "Mean Reward": 57.02417178608787, "Episode": 1974, "Episode Step": 1082}
{"Training Time": 4.342267927792337, "Episode Reward": 9466.846528151502, "Mean Reward": 47.334232640757506, "Episode": 1975, "Episode Step": 200}
{"Training Time": 4.345268180569013, "Episode Reward": 16145.511449187125, "Mean Reward": 63.31573117328284, "Episode": 1976, "Episode Step": 255}
{"Training Time": 4.348788924415906, "Episode Reward": 16244.794807329768, "Mean Reward": 62.47998002819142, "Episode": 1977, "Episode Step": 260}
{"Training Time": 4.351709156367514, "Episode Reward": 16535.89005426157, "Mean Reward": 66.94692329660555, "Episode": 1978, "Episode Step": 247}
{"Training Time": 4.354640917248196, "Episode Reward": 16791.527858436562, "Mean Reward": 66.63304705728794, "Episode": 1979, "Episode Step": 252}
{"Training Time": 4.3634048658609395, "Episode Reward": 44385.964425597806, "Mean Reward": 62.16521628234987, "Episode": 1980, "Episode Step": 714}
{"Training Time": 4.36566528638204, "Episode Reward": 9578.133875350837, "Mean Reward": 49.886113934118946, "Episode": 1981, "Episode Step": 192}
{"Training Time": 4.368426008621852, "Episode Reward": 15072.06181948921, "Mean Reward": 63.8646687266492, "Episode": 1982, "Episode Step": 236}
{"Training Time": 4.37195253305965, "Episode Reward": 14788.161500872386, "Mean Reward": 56.01576326088025, "Episode": 1983, "Episode Step": 264}
{"Training Time": 4.374737430546019, "Episode Reward": 13833.143884700667, "Mean Reward": 57.63809951958611, "Episode": 1984, "Episode Step": 240}
{"Training Time": 4.382969648904271, "Episode Reward": 45434.74824759498, "Mean Reward": 63.545102444188785, "Episode": 1985, "Episode Step": 715}
{"Training Time": 4.386498681637976, "Episode Reward": 15481.14439611842, "Mean Reward": 58.86366690539323, "Episode": 1986, "Episode Step": 263}
{"Training Time": 4.388745653033257, "Episode Reward": 8077.524635634059, "Mean Reward": 42.07044081059406, "Episode": 1987, "Episode Step": 192}
{"Training Time": 4.391672963301341, "Episode Reward": 17724.492993915952, "Mean Reward": 70.89797197566381, "Episode": 1988, "Episode Step": 250}
{"Training Time": 4.3951382236348255, "Episode Reward": 15231.848468121769, "Mean Reward": 59.03817235706112, "Episode": 1989, "Episode Step": 258}
{"Training Time": 4.398003478315141, "Episode Reward": 15013.595878553568, "Mean Reward": 61.030877555095806, "Episode": 1990, "Episode Step": 246}
{"Training Time": 4.400054222477807, "Episode Reward": 9288.458757270313, "Mean Reward": 52.77533384812678, "Episode": 1991, "Episode Step": 176}
{"Training Time": 4.402655427787039, "Episode Reward": 8350.002528893488, "Mean Reward": 45.380448526595046, "Episode": 1992, "Episode Step": 184}
{"Training Time": 4.404772873587079, "Episode Reward": 9305.989462046497, "Mean Reward": 51.41430642014639, "Episode": 1993, "Episode Step": 181}
{"Training Time": 4.407641539971034, "Episode Reward": 16935.240847984365, "Mean Reward": 68.84244247148116, "Episode": 1994, "Episode Step": 246}
{"Training Time": 4.427031694451968, "Episode Reward": 94484.41224703248, "Mean Reward": 58.25179546672779, "Episode": 1995, "Episode Step": 1622}
{"Training Time": 4.432783478895823, "Episode Reward": 30224.30571320558, "Mean Reward": 61.8083961415247, "Episode": 1996, "Episode Step": 489}
{"Training Time": 4.43570675585005, "Episode Reward": 16900.216111790458, "Mean Reward": 68.42192757809902, "Episode": 1997, "Episode Step": 247}
{"Training Time": 4.4447647169563504, "Episode Reward": 44664.42146721109, "Mean Reward": 62.20671513539149, "Episode": 1998, "Episode Step": 718}
{"Training Time": 4.4475094944238664, "Episode Reward": 9084.948366528857, "Mean Reward": 50.471935369604765, "Episode": 1999, "Episode Step": 180}
{"Training Time": 4.450757010579109, "Episode Reward": 15138.469583018781, "Mean Reward": 60.07329199610628, "Episode": 2000, "Episode Step": 252}
{"Training Time": 4.453471374445491, "Episode Reward": 9284.524208253139, "Mean Reward": 48.3568969179851, "Episode": 2001, "Episode Step": 192}
{"Training Time": 4.4575273980697, "Episode Reward": 22826.634482956393, "Mean Reward": 65.59377724987469, "Episode": 2002, "Episode Step": 348}
{"Training Time": 4.459558791650666, "Episode Reward": 8736.744156237419, "Mean Reward": 50.2111733117093, "Episode": 2003, "Episode Step": 174}
{"Training Time": 4.470416614744399, "Episode Reward": 52907.685043269994, "Mean Reward": 59.24712770802911, "Episode": 2004, "Episode Step": 893}
{"Training Time": 4.4734204400248, "Episode Reward": 16702.331865623953, "Mean Reward": 65.24348385009357, "Episode": 2005, "Episode Step": 256}
{"Training Time": 4.4754740913709, "Episode Reward": 8485.166904964819, "Mean Reward": 48.211175596391016, "Episode": 2006, "Episode Step": 176}
{"Training Time": 4.478142178058624, "Episode Reward": 8580.45430656986, "Mean Reward": 45.64071439664819, "Episode": 2007, "Episode Step": 188}
{"Training Time": 4.480346193909645, "Episode Reward": 8971.224025893836, "Mean Reward": 47.466793787798075, "Episode": 2008, "Episode Step": 189}
{"Training Time": 4.482389379739761, "Episode Reward": 9337.437771442746, "Mean Reward": 53.66343546806176, "Episode": 2009, "Episode Step": 174}
{"Training Time": 4.488328239189254, "Episode Reward": 27561.531292084113, "Mean Reward": 58.14669048962893, "Episode": 2010, "Episode Step": 474}
{"Training Time": 4.490551674697135, "Episode Reward": 9704.556972338994, "Mean Reward": 50.809198808057566, "Episode": 2011, "Episode Step": 191}
{"Training Time": 4.496479563580619, "Episode Reward": 32792.86403394155, "Mean Reward": 64.68020519515099, "Episode": 2012, "Episode Step": 507}
{"Training Time": 4.499097719457414, "Episode Reward": 9158.850693849316, "Mean Reward": 49.776362466572365, "Episode": 2013, "Episode Step": 184}
{"Training Time": 4.500764621959792, "Episode Reward": 7357.728096303029, "Mean Reward": 51.8149865936833, "Episode": 2014, "Episode Step": 142}
{"Training Time": 4.501356158918805, "Episode Reward": 2622.5577142428115, "Mean Reward": 52.45115428485623, "Episode": 2015, "Episode Step": 50}
{"Training Time": 4.504152481092347, "Episode Reward": 8635.2435183277, "Mean Reward": 44.97522665795677, "Episode": 2016, "Episode Step": 192}
{"Training Time": 4.508324386080106, "Episode Reward": 21162.45315001748, "Mean Reward": 60.81164698280885, "Episode": 2017, "Episode Step": 348}
{"Training Time": 4.510460196137428, "Episode Reward": 9271.71087720949, "Mean Reward": 52.98120501262566, "Episode": 2018, "Episode Step": 175}
{"Training Time": 4.542304794722133, "Episode Reward": 154522.2810221005, "Mean Reward": 58.02564063916655, "Episode": 2019, "Episode Step": 2663}
{"Training Time": 4.543535973628362, "Episode Reward": 4999.934506271418, "Mean Reward": 49.018965747759005, "Episode": 2020, "Episode Step": 102}
{"Training Time": 4.5452223769161435, "Episode Reward": 6298.314719080829, "Mean Reward": 45.97310013927612, "Episode": 2021, "Episode Step": 137}
{"Training Time": 4.5545476316743425, "Episode Reward": 44570.63182244329, "Mean Reward": 59.42750909659105, "Episode": 2022, "Episode Step": 750}
{"Training Time": 4.556663291388088, "Episode Reward": 8669.510265926332, "Mean Reward": 48.16394592181295, "Episode": 2023, "Episode Step": 180}
{"Training Time": 4.558311128881242, "Episode Reward": 7275.101114868901, "Mean Reward": 53.1029278457584, "Episode": 2024, "Episode Step": 137}
{"Training Time": 4.569616802798377, "Episode Reward": 50078.038742089564, "Mean Reward": 55.09135175147367, "Episode": 2025, "Episode Step": 909}
{"Training Time": 4.583693989978896, "Episode Reward": 75814.64115388654, "Mean Reward": 63.443214354716766, "Episode": 2026, "Episode Step": 1195}
{"Training Time": 4.58653596719106, "Episode Reward": 15789.159573075467, "Mean Reward": 66.06342917604798, "Episode": 2027, "Episode Step": 239}
{"Training Time": 4.5901802849769595, "Episode Reward": 14620.395660603339, "Mean Reward": 54.75803618203498, "Episode": 2028, "Episode Step": 267}
{"Training Time": 4.592532421085569, "Episode Reward": 9802.460353060449, "Mean Reward": 49.7586819952307, "Episode": 2029, "Episode Step": 197}
{"Training Time": 4.594133376677831, "Episode Reward": 6396.8136107577975, "Mean Reward": 47.73741500565521, "Episode": 2030, "Episode Step": 134}
{"Training Time": 4.602999808059798, "Episode Reward": 42605.18272948685, "Mean Reward": 59.33869460931316, "Episode": 2031, "Episode Step": 718}
{"Training Time": 4.605227108067936, "Episode Reward": 9564.014897813388, "Mean Reward": 50.60325342758406, "Episode": 2032, "Episode Step": 189}
{"Training Time": 4.608186896973186, "Episode Reward": 16561.54678305255, "Mean Reward": 64.94724228648059, "Episode": 2033, "Episode Step": 255}
{"Training Time": 4.6287114419539765, "Episode Reward": 96955.19924672252, "Mean Reward": 57.23447417161896, "Episode": 2034, "Episode Step": 1694}
{"Training Time": 4.630409769746993, "Episode Reward": 7002.605207451694, "Mean Reward": 49.31412117923728, "Episode": 2035, "Episode Step": 142}
{"Training Time": 4.632506883078151, "Episode Reward": 8853.48961771467, "Mean Reward": 50.59136924408382, "Episode": 2036, "Episode Step": 175}
{"Training Time": 4.635129591955079, "Episode Reward": 8255.069646106049, "Mean Reward": 45.35752552805521, "Episode": 2037, "Episode Step": 182}
{"Training Time": 4.636774156689643, "Episode Reward": 6959.319653185214, "Mean Reward": 49.356876972944775, "Episode": 2038, "Episode Step": 141}
{"Training Time": 4.639002082811461, "Episode Reward": 9255.295567051575, "Mean Reward": 48.969817815087694, "Episode": 2039, "Episode Step": 189}
{"Training Time": 4.648058184451527, "Episode Reward": 43816.782174206724, "Mean Reward": 59.69588852071761, "Episode": 2040, "Episode Step": 734}
{"Training Time": 4.650472777485848, "Episode Reward": 9820.123177017238, "Mean Reward": 49.10061588508619, "Episode": 2041, "Episode Step": 200}
{"Training Time": 4.652788211637073, "Episode Reward": 10255.047410900077, "Mean Reward": 52.86106912835091, "Episode": 2042, "Episode Step": 194}
{"Training Time": 4.655515116651853, "Episode Reward": 7763.469370228116, "Mean Reward": 41.07655751443448, "Episode": 2043, "Episode Step": 189}
{"Training Time": 4.657765693863233, "Episode Reward": 8936.674124668296, "Mean Reward": 47.035126971938396, "Episode": 2044, "Episode Step": 190}
{"Training Time": 4.660860280527009, "Episode Reward": 16335.51182590629, "Mean Reward": 62.588167915349764, "Episode": 2045, "Episode Step": 261}
{"Training Time": 4.664332974420653, "Episode Reward": 15001.064780919118, "Mean Reward": 59.52803484491714, "Episode": 2046, "Episode Step": 252}
{"Training Time": 4.667127267784543, "Episode Reward": 12000.630349393428, "Mean Reward": 52.176653693014906, "Episode": 2047, "Episode Step": 230}
{"Training Time": 4.66774457719591, "Episode Reward": 2899.7022519381467, "Mean Reward": 57.994045038762934, "Episode": 2048, "Episode Step": 50}
{"Training Time": 4.68776800526513, "Episode Reward": 90904.73688009488, "Mean Reward": 56.0103123105945, "Episode": 2049, "Episode Step": 1623}
{"Training Time": 4.690939657224549, "Episode Reward": 15501.022995707357, "Mean Reward": 63.01228860043641, "Episode": 2050, "Episode Step": 246}
{"Training Time": 4.691558993061384, "Episode Reward": 2924.8662027769437, "Mean Reward": 57.3503177015087, "Episode": 2051, "Episode Step": 51}
{"Training Time": 4.693662293023533, "Episode Reward": 5620.589690224116, "Mean Reward": 40.14706921588654, "Episode": 2052, "Episode Step": 140}
{"Training Time": 4.696653877496719, "Episode Reward": 14471.635043717159, "Mean Reward": 56.97494111699669, "Episode": 2053, "Episode Step": 254}
{"Training Time": 4.697634083893564, "Episode Reward": 5102.766978568996, "Mean Reward": 62.22886559230483, "Episode": 2054, "Episode Step": 82}
{"Training Time": 4.726473423639933, "Episode Reward": 137876.12418098445, "Mean Reward": 56.230066957987134, "Episode": 2055, "Episode Step": 2452}
{"Training Time": 4.728681779172685, "Episode Reward": 8472.309439330453, "Mean Reward": 46.04515999636116, "Episode": 2056, "Episode Step": 184}
{"Training Time": 4.729303874439664, "Episode Reward": 2943.1283604277232, "Mean Reward": 57.708399224073005, "Episode": 2057, "Episode Step": 51}
{"Training Time": 4.738529152207905, "Episode Reward": 40786.32595059869, "Mean Reward": 54.74674624241435, "Episode": 2058, "Episode Step": 745}
{"Training Time": 4.740751004748875, "Episode Reward": 9585.70049265825, "Mean Reward": 50.717992024646826, "Episode": 2059, "Episode Step": 189}
{"Training Time": 4.742322144707044, "Episode Reward": 6947.706251978181, "Mean Reward": 51.848554119240156, "Episode": 2060, "Episode Step": 134}
{"Training Time": 4.751581004725562, "Episode Reward": 42344.165533849016, "Mean Reward": 55.936810480645995, "Episode": 2061, "Episode Step": 757}
{"Training Time": 4.754503061970075, "Episode Reward": 14364.043668142309, "Mean Reward": 57.91953091992867, "Episode": 2062, "Episode Step": 248}
{"Training Time": 4.7574051602681475, "Episode Reward": 15956.829043971195, "Mean Reward": 64.08365077900078, "Episode": 2063, "Episode Step": 249}
{"Training Time": 4.787574405802621, "Episode Reward": 148243.14746007917, "Mean Reward": 58.20304179822504, "Episode": 2064, "Episode Step": 2547}
{"Training Time": 4.789959606925646, "Episode Reward": 8579.484723213742, "Mean Reward": 42.89742361606871, "Episode": 2065, "Episode Step": 200}
{"Training Time": 4.792060235540072, "Episode Reward": 9171.531322310844, "Mean Reward": 51.81656114299912, "Episode": 2066, "Episode Step": 177}
{"Training Time": 4.795410928593742, "Episode Reward": 13004.13919747743, "Mean Reward": 52.64833683189243, "Episode": 2067, "Episode Step": 247}
{"Training Time": 4.7996027486191855, "Episode Reward": 21390.177110895405, "Mean Reward": 59.58266604706241, "Episode": 2068, "Episode Step": 359}
{"Training Time": 4.80259377333853, "Episode Reward": 17156.859699671535, "Mean Reward": 67.01898320184193, "Episode": 2069, "Episode Step": 256}
{"Training Time": 4.812653461694717, "Episode Reward": 45446.1859552605, "Mean Reward": 55.15313829521906, "Episode": 2070, "Episode Step": 824}
{"Training Time": 4.814286683069335, "Episode Reward": 7000.435943000565, "Mean Reward": 50.36284851079543, "Episode": 2071, "Episode Step": 139}
{"Training Time": 4.8182480494181315, "Episode Reward": 22637.530707917835, "Mean Reward": 66.58097267034657, "Episode": 2072, "Episode Step": 340}
{"Training Time": 4.825788591967688, "Episode Reward": 33966.25127944994, "Mean Reward": 55.95758036153203, "Episode": 2073, "Episode Step": 607}
{"Training Time": 4.828119414978557, "Episode Reward": 9470.42092458106, "Mean Reward": 47.59005489739226, "Episode": 2074, "Episode Step": 199}
{"Training Time": 4.830297153062291, "Episode Reward": 8809.84436747174, "Mean Reward": 46.61293316122614, "Episode": 2075, "Episode Step": 189}
{"Training Time": 4.840673428310288, "Episode Reward": 47563.09766364191, "Mean Reward": 55.890831567146776, "Episode": 2076, "Episode Step": 851}
{"Training Time": 4.842823722230063, "Episode Reward": 9021.012980488438, "Mean Reward": 49.8398507209306, "Episode": 2077, "Episode Step": 181}
{"Training Time": 4.845950418048435, "Episode Reward": 16237.542303738057, "Mean Reward": 61.27374454240776, "Episode": 2078, "Episode Step": 265}
{"Training Time": 4.847820383906364, "Episode Reward": 5843.1091648818165, "Mean Reward": 49.94110397334886, "Episode": 2079, "Episode Step": 117}
{"Training Time": 4.849970853593614, "Episode Reward": 8955.962473061461, "Mean Reward": 50.314395916075625, "Episode": 2080, "Episode Step": 178}
{"Training Time": 4.852993804746204, "Episode Reward": 14822.35007604109, "Mean Reward": 58.355708960791695, "Episode": 2081, "Episode Step": 254}
{"Training Time": 4.854829831388262, "Episode Reward": 5249.023050225525, "Mean Reward": 46.451531417925004, "Episode": 2082, "Episode Step": 113}
{"Training Time": 4.855867930849393, "Episode Reward": 4531.719646180931, "Mean Reward": 53.94904340691584, "Episode": 2083, "Episode Step": 84}
{"Training Time": 4.858862774173419, "Episode Reward": 16731.926336179167, "Mean Reward": 67.1964913099565, "Episode": 2084, "Episode Step": 249}
{"Training Time": 4.860722263918983, "Episode Reward": 6148.980670732089, "Mean Reward": 53.46939713680077, "Episode": 2085, "Episode Step": 115}
{"Training Time": 4.866725292801857, "Episode Reward": 31228.648247154855, "Mean Reward": 62.45729649430971, "Episode": 2086, "Episode Step": 500}
{"Training Time": 4.869814405573739, "Episode Reward": 16999.40471587201, "Mean Reward": 64.88322410638172, "Episode": 2087, "Episode Step": 262}
{"Training Time": 4.874601475265291, "Episode Reward": 19991.46615504086, "Mean Reward": 54.47265982299962, "Episode": 2088, "Episode Step": 367}
{"Training Time": 4.876687656641007, "Episode Reward": 8163.054953798434, "Mean Reward": 46.91410892987606, "Episode": 2089, "Episode Step": 174}
{"Training Time": 4.879663136137856, "Episode Reward": 16855.952454629365, "Mean Reward": 66.62431800248761, "Episode": 2090, "Episode Step": 253}
{"Training Time": 4.881551165580749, "Episode Reward": 5837.792796888304, "Mean Reward": 50.32579997317504, "Episode": 2091, "Episode Step": 116}
{"Training Time": 4.8826169366969, "Episode Reward": 5086.874986368734, "Mean Reward": 59.84558807492629, "Episode": 2092, "Episode Step": 85}
{"Training Time": 4.885630249182383, "Episode Reward": 16301.647056315043, "Mean Reward": 64.94680102117547, "Episode": 2093, "Episode Step": 251}
{"Training Time": 4.900994443032476, "Episode Reward": 68977.4620119437, "Mean Reward": 54.87467144943811, "Episode": 2094, "Episode Step": 1257}
{"Training Time": 4.901566430860096, "Episode Reward": 2559.3186650299285, "Mean Reward": 54.453588617658056, "Episode": 2095, "Episode Step": 47}
{"Training Time": 4.904650669429038, "Episode Reward": 17410.705526266203, "Mean Reward": 67.48335475296977, "Episode": 2096, "Episode Step": 258}
{"Training Time": 4.908095446957482, "Episode Reward": 14512.400185939247, "Mean Reward": 58.28273167043874, "Episode": 2097, "Episode Step": 249}
{"Training Time": 4.909134721093707, "Episode Reward": 4887.461428246836, "Mean Reward": 57.499546214668655, "Episode": 2098, "Episode Step": 85}
{"Training Time": 4.913223699198829, "Episode Reward": 14561.706516909675, "Mean Reward": 59.193928930527136, "Episode": 2099, "Episode Step": 246}
{"Training Time": 4.916609696679645, "Episode Reward": 11904.655291563806, "Mean Reward": 48.99035099408974, "Episode": 2100, "Episode Step": 243}
{"Training Time": 4.9187752985954285, "Episode Reward": 8438.360446231518, "Mean Reward": 47.141678470567136, "Episode": 2101, "Episode Step": 179}
{"Training Time": 4.920962856411934, "Episode Reward": 9203.090420093105, "Mean Reward": 50.016795761375576, "Episode": 2102, "Episode Step": 184}
{"Training Time": 4.923159124453862, "Episode Reward": 6652.936687029986, "Mean Reward": 46.20094921548602, "Episode": 2103, "Episode Step": 144}
{"Training Time": 4.9237987652752135, "Episode Reward": 2409.523020264914, "Mean Reward": 47.2455494169591, "Episode": 2104, "Episode Step": 51}
{"Training Time": 4.926820913354556, "Episode Reward": 15250.569158632909, "Mean Reward": 59.11073317299577, "Episode": 2105, "Episode Step": 258}
{"Training Time": 4.92901236169868, "Episode Reward": 6876.286475855131, "Mean Reward": 47.42266535072504, "Episode": 2106, "Episode Step": 145}
{"Training Time": 4.932613470024533, "Episode Reward": 17749.453782576875, "Mean Reward": 58.19493043467828, "Episode": 2107, "Episode Step": 305}
{"Training Time": 4.935688677231471, "Episode Reward": 16122.857909220402, "Mean Reward": 62.010991958540004, "Episode": 2108, "Episode Step": 260}
{"Training Time": 4.937852807243665, "Episode Reward": 5683.9681790116265, "Mean Reward": 40.02794492261709, "Episode": 2109, "Episode Step": 142}
{"Training Time": 4.939540793895722, "Episode Reward": 7110.3061805906, "Mean Reward": 51.153281874752516, "Episode": 2110, "Episode Step": 139}
{"Training Time": 4.945893826418453, "Episode Reward": 29962.42120729913, "Mean Reward": 57.509445695391804, "Episode": 2111, "Episode Step": 521}
{"Training Time": 4.948546802202861, "Episode Reward": 7921.720616599934, "Mean Reward": 43.05282943804312, "Episode": 2112, "Episode Step": 184}
{"Training Time": 4.951649906966422, "Episode Reward": 16004.55939414378, "Mean Reward": 61.08610455780069, "Episode": 2113, "Episode Step": 262}
{"Training Time": 4.954054429994689, "Episode Reward": 8653.07782507898, "Mean Reward": 43.265389125394904, "Episode": 2114, "Episode Step": 200}
{"Training Time": 4.957380170557234, "Episode Reward": 13325.636486034975, "Mean Reward": 55.523485358479064, "Episode": 2115, "Episode Step": 240}
{"Training Time": 4.957989066110717, "Episode Reward": 2318.173605037354, "Mean Reward": 46.363472100747074, "Episode": 2116, "Episode Step": 50}
{"Training Time": 4.959794177479214, "Episode Reward": 6839.42603830511, "Mean Reward": 44.996223936217824, "Episode": 2117, "Episode Step": 152}
{"Training Time": 4.967609086102909, "Episode Reward": 34832.20037753328, "Mean Reward": 55.731520604053244, "Episode": 2118, "Episode Step": 625}
{"Training Time": 4.9693322849935955, "Episode Reward": 7199.8321249603105, "Mean Reward": 50.34847639832385, "Episode": 2119, "Episode Step": 143}
{"Training Time": 4.971577932238579, "Episode Reward": 9042.415217406196, "Mean Reward": 47.3424880492471, "Episode": 2120, "Episode Step": 191}
{"Training Time": 4.979320700565974, "Episode Reward": 32494.179608155697, "Mean Reward": 52.409967109928544, "Episode": 2121, "Episode Step": 620}
{"Training Time": 4.981644251412815, "Episode Reward": 9516.262400284308, "Mean Reward": 48.3059005090574, "Episode": 2122, "Episode Step": 197}
{"Training Time": 4.9833527480893665, "Episode Reward": 6850.133489119031, "Mean Reward": 47.57037145221549, "Episode": 2123, "Episode Step": 144}
{"Training Time": 4.987276954717106, "Episode Reward": 17301.77327575942, "Mean Reward": 58.451936742430476, "Episode": 2124, "Episode Step": 296}
{"Training Time": 4.98942284391986, "Episode Reward": 8961.213363011644, "Mean Reward": 49.78451868339802, "Episode": 2125, "Episode Step": 180}
{"Training Time": 4.991080739431911, "Episode Reward": 6144.505448266919, "Mean Reward": 44.20507516738791, "Episode": 2126, "Episode Step": 139}
{"Training Time": 5.004854857789145, "Episode Reward": 61164.465287229454, "Mean Reward": 54.223816743997745, "Episode": 2127, "Episode Step": 1128}
{"Training Time": 5.007946002218459, "Episode Reward": 15104.779781140298, "Mean Reward": 58.31961305459574, "Episode": 2128, "Episode Step": 259}
{"Training Time": 5.00947622358799, "Episode Reward": 7277.476020230934, "Mean Reward": 55.55325206283156, "Episode": 2129, "Episode Step": 131}
{"Training Time": 5.017465381688542, "Episode Reward": 35150.12836179866, "Mean Reward": 55.18073526185034, "Episode": 2130, "Episode Step": 637}
{"Training Time": 5.0242239730887945, "Episode Reward": 33402.19585669511, "Mean Reward": 57.989923362317896, "Episode": 2131, "Episode Step": 576}
{"Training Time": 5.028482460843192, "Episode Reward": 21104.871198923545, "Mean Reward": 58.46224708843087, "Episode": 2132, "Episode Step": 361}
{"Training Time": 5.039747653603554, "Episode Reward": 51920.09027233902, "Mean Reward": 56.37360507311511, "Episode": 2133, "Episode Step": 921}
{"Training Time": 5.042020451360279, "Episode Reward": 9033.582714612863, "Mean Reward": 46.806128054988925, "Episode": 2134, "Episode Step": 193}
{"Training Time": 5.043800668583976, "Episode Reward": 7017.562981671943, "Mean Reward": 46.78375321114628, "Episode": 2135, "Episode Step": 150}
{"Training Time": 5.050244377520349, "Episode Reward": 28354.304574264926, "Mean Reward": 55.70590289639475, "Episode": 2136, "Episode Step": 509}
{"Training Time": 5.053301359746191, "Episode Reward": 16497.92548688127, "Mean Reward": 63.2104424784723, "Episode": 2137, "Episode Step": 261}
{"Training Time": 5.0550782897075015, "Episode Reward": 6807.654066017054, "Mean Reward": 45.384360440113696, "Episode": 2138, "Episode Step": 150}
{"Training Time": 5.058537419173453, "Episode Reward": 13559.170581989674, "Mean Reward": 53.17321796858696, "Episode": 2139, "Episode Step": 255}
{"Training Time": 5.061727378037241, "Episode Reward": 15728.13544675916, "Mean Reward": 57.612217753696555, "Episode": 2140, "Episode Step": 273}
{"Training Time": 5.0646338105863995, "Episode Reward": 14563.977927021486, "Mean Reward": 58.72571744766728, "Episode": 2141, "Episode Step": 248}
{"Training Time": 5.066758873595131, "Episode Reward": 6572.119363051927, "Mean Reward": 46.9437097360852, "Episode": 2142, "Episode Step": 140}
{"Training Time": 5.069542755020989, "Episode Reward": 12878.647848098442, "Mean Reward": 54.802756800418905, "Episode": 2143, "Episode Step": 235}
{"Training Time": 5.072442337208324, "Episode Reward": 16146.536804381029, "Mean Reward": 64.58614721752411, "Episode": 2144, "Episode Step": 250}
{"Training Time": 5.075861370828417, "Episode Reward": 16303.496596912233, "Mean Reward": 64.18699447603241, "Episode": 2145, "Episode Step": 254}
{"Training Time": 5.077629580828878, "Episode Reward": 7153.269513537359, "Mean Reward": 48.00852022508295, "Episode": 2146, "Episode Step": 149}
{"Training Time": 5.080476456681887, "Episode Reward": 13293.099780830948, "Mean Reward": 55.38791575346228, "Episode": 2147, "Episode Step": 240}
{"Training Time": 5.08957725306352, "Episode Reward": 43017.34476845929, "Mean Reward": 58.21020942957956, "Episode": 2148, "Episode Step": 739}
{"Training Time": 5.093364529742135, "Episode Reward": 16418.201552927538, "Mean Reward": 56.226717647012116, "Episode": 2149, "Episode Step": 292}
{"Training Time": 5.097912253604995, "Episode Reward": 21874.1906690892, "Mean Reward": 59.60269937081526, "Episode": 2150, "Episode Step": 367}
{"Training Time": 5.100090391635895, "Episode Reward": 5972.688153279956, "Mean Reward": 40.356001035675376, "Episode": 2151, "Episode Step": 148}
{"Training Time": 5.102584230303765, "Episode Reward": 9588.604489376477, "Mean Reward": 45.22926645932301, "Episode": 2152, "Episode Step": 212}
{"Training Time": 5.103918219738536, "Episode Reward": 6239.888663932412, "Mean Reward": 55.22025366311869, "Episode": 2153, "Episode Step": 113}
{"Training Time": 5.106869299742911, "Episode Reward": 9902.162340429802, "Mean Reward": 47.37876717908996, "Episode": 2154, "Episode Step": 209}
{"Training Time": 5.108689788315031, "Episode Reward": 6797.243325968363, "Mean Reward": 45.01485646336664, "Episode": 2155, "Episode Step": 151}
{"Training Time": 5.1149258241388535, "Episode Reward": 30429.38237514571, "Mean Reward": 57.74076352020059, "Episode": 2156, "Episode Step": 527}
{"Training Time": 5.117114467488395, "Episode Reward": 6428.1337527246715, "Mean Reward": 45.26854755439909, "Episode": 2157, "Episode Step": 142}
{"Training Time": 5.1203464411364665, "Episode Reward": 14712.799125996677, "Mean Reward": 53.69634717517035, "Episode": 2158, "Episode Step": 274}
{"Training Time": 5.123493529425727, "Episode Reward": 16313.559036582514, "Mean Reward": 60.87148894247207, "Episode": 2159, "Episode Step": 268}
{"Training Time": 5.126647655566534, "Episode Reward": 12189.730148395167, "Mean Reward": 53.46372872103144, "Episode": 2160, "Episode Step": 228}
{"Training Time": 5.129017874730958, "Episode Reward": 9463.180711660707, "Mean Reward": 47.31590355830353, "Episode": 2161, "Episode Step": 200}
{"Training Time": 5.130395184424188, "Episode Reward": 6046.908466757164, "Mean Reward": 52.58181275441012, "Episode": 2162, "Episode Step": 115}
{"Training Time": 5.134026878873507, "Episode Reward": 15041.114231931871, "Mean Reward": 56.545542225307784, "Episode": 2163, "Episode Step": 266}
{"Training Time": 5.135785696374046, "Episode Reward": 6578.695175304425, "Mean Reward": 44.15231661278138, "Episode": 2164, "Episode Step": 149}
{"Training Time": 5.145199378596412, "Episode Reward": 46198.196761683976, "Mean Reward": 58.11093932287292, "Episode": 2165, "Episode Step": 795}
{"Training Time": 5.147833128637738, "Episode Reward": 8303.492220476674, "Mean Reward": 44.88374173230634, "Episode": 2166, "Episode Step": 185}
{"Training Time": 5.15324070168866, "Episode Reward": 25645.623410412383, "Mean Reward": 55.872817887608676, "Episode": 2167, "Episode Step": 459}
{"Training Time": 5.156379021935993, "Episode Reward": 16362.748846049948, "Mean Reward": 61.05503300764906, "Episode": 2168, "Episode Step": 268}
{"Training Time": 5.159878271950616, "Episode Reward": 14309.50895458734, "Mean Reward": 55.036572902258996, "Episode": 2169, "Episode Step": 260}
{"Training Time": 5.170093716118071, "Episode Reward": 47790.923702881, "Mean Reward": 55.05866786046198, "Episode": 2170, "Episode Step": 868}
{"Training Time": 5.171717014445199, "Episode Reward": 6476.243745650157, "Mean Reward": 48.33017720634445, "Episode": 2171, "Episode Step": 134}
{"Training Time": 5.173697763880094, "Episode Reward": 6464.580961994458, "Mean Reward": 50.902212299168966, "Episode": 2172, "Episode Step": 127}
{"Training Time": 5.177773901952637, "Episode Reward": 18882.208356698895, "Mean Reward": 55.86452176538135, "Episode": 2173, "Episode Step": 338}
{"Training Time": 5.179302403595712, "Episode Reward": 5257.828729721054, "Mean Reward": 41.72879944223058, "Episode": 2174, "Episode Step": 126}
{"Training Time": 5.18076858136389, "Episode Reward": 3983.262426666278, "Mean Reward": 47.419790793646165, "Episode": 2175, "Episode Step": 84}
{"Training Time": 5.182735465831227, "Episode Reward": 6458.3649535074765, "Mean Reward": 39.86645033029306, "Episode": 2176, "Episode Step": 162}
{"Training Time": 5.191843964192603, "Episode Reward": 43388.41164370981, "Mean Reward": 56.42186169533136, "Episode": 2177, "Episode Step": 769}
{"Training Time": 5.198847712212139, "Episode Reward": 32251.59741549549, "Mean Reward": 58.32115265008226, "Episode": 2178, "Episode Step": 553}
{"Training Time": 5.200899200571908, "Episode Reward": 6600.711115965519, "Mean Reward": 38.37622741840418, "Episode": 2179, "Episode Step": 172}
{"Training Time": 5.202532702220811, "Episode Reward": 5813.779471226289, "Mean Reward": 42.74837846489919, "Episode": 2180, "Episode Step": 136}
{"Training Time": 5.205314747492472, "Episode Reward": 8533.198657052717, "Mean Reward": 44.2134645443146, "Episode": 2181, "Episode Step": 193}
{"Training Time": 5.207122175031238, "Episode Reward": 7065.546336006883, "Mean Reward": 46.79169758944956, "Episode": 2182, "Episode Step": 151}
{"Training Time": 5.208538206418355, "Episode Reward": 5897.899818421418, "Mean Reward": 49.98220185102897, "Episode": 2183, "Episode Step": 118}
{"Training Time": 5.211876975562838, "Episode Reward": 13473.342839698162, "Mean Reward": 56.61068420041244, "Episode": 2184, "Episode Step": 238}
{"Training Time": 5.21377828889423, "Episode Reward": 6754.174682717709, "Mean Reward": 43.020220909029995, "Episode": 2185, "Episode Step": 157}
{"Training Time": 5.215217504170206, "Episode Reward": 5647.9693401674685, "Mean Reward": 47.46192722829805, "Episode": 2186, "Episode Step": 119}
{"Training Time": 5.2188452466991215, "Episode Reward": 16035.005875023997, "Mean Reward": 60.969604087543715, "Episode": 2187, "Episode Step": 263}
{"Training Time": 5.22457904027568, "Episode Reward": 25603.193047218145, "Mean Reward": 53.1186577743115, "Episode": 2188, "Episode Step": 482}
{"Training Time": 5.226181097229322, "Episode Reward": 6132.128993746502, "Mean Reward": 45.42317773145557, "Episode": 2189, "Episode Step": 135}
{"Training Time": 5.235418319702148, "Episode Reward": 40414.903587612054, "Mean Reward": 54.911553787516375, "Episode": 2190, "Episode Step": 736}
{"Training Time": 5.238626293871138, "Episode Reward": 15102.340163859682, "Mean Reward": 55.934593199480304, "Episode": 2191, "Episode Step": 270}
{"Training Time": 5.241725235250261, "Episode Reward": 12881.998822967395, "Mean Reward": 49.167934438806846, "Episode": 2192, "Episode Step": 262}
{"Training Time": 5.245322875844108, "Episode Reward": 15822.90240545209, "Mean Reward": 60.8573169440465, "Episode": 2193, "Episode Step": 260}
{"Training Time": 5.247070011960136, "Episode Reward": 6975.732312791258, "Mean Reward": 47.77898844377574, "Episode": 2194, "Episode Step": 146}
{"Training Time": 5.248797765572866, "Episode Reward": 6665.785975842487, "Mean Reward": 47.275077842854515, "Episode": 2195, "Episode Step": 141}
{"Training Time": 5.26351711915599, "Episode Reward": 72268.51652054394, "Mean Reward": 59.529255782985125, "Episode": 2196, "Episode Step": 1214}
{"Training Time": 5.266038744714525, "Episode Reward": 9268.876392133358, "Mean Reward": 43.721115057232815, "Episode": 2197, "Episode Step": 212}
{"Training Time": 5.269389628039466, "Episode Reward": 17335.62256385817, "Mean Reward": 61.9129377280649, "Episode": 2198, "Episode Step": 280}
{"Training Time": 5.2733426902691525, "Episode Reward": 8751.03981011536, "Mean Reward": 46.05810426376505, "Episode": 2199, "Episode Step": 190}
{"Training Time": 5.276841054426299, "Episode Reward": 16633.999825787705, "Mean Reward": 61.38007315788821, "Episode": 2200, "Episode Step": 271}
{"Training Time": 5.285996940268411, "Episode Reward": 45557.28660762302, "Mean Reward": 58.632286496297326, "Episode": 2201, "Episode Step": 777}
{"Training Time": 5.296992932491833, "Episode Reward": 53440.661911304895, "Mean Reward": 59.710236772407704, "Episode": 2202, "Episode Step": 895}
{"Training Time": 5.2988810325331155, "Episode Reward": 6490.406449102891, "Mean Reward": 41.34016846562351, "Episode": 2203, "Episode Step": 157}
{"Training Time": 5.3014591430293185, "Episode Reward": 8482.575467268856, "Mean Reward": 39.453839382645846, "Episode": 2204, "Episode Step": 215}
{"Training Time": 5.3050643438763085, "Episode Reward": 15129.616513191562, "Mean Reward": 57.09289250260967, "Episode": 2205, "Episode Step": 265}
{"Training Time": 5.306787583364381, "Episode Reward": 7232.649377411016, "Mean Reward": 49.880340533869074, "Episode": 2206, "Episode Step": 145}
{"Training Time": 5.30845189359453, "Episode Reward": 6656.310585353871, "Mean Reward": 48.58620865221803, "Episode": 2207, "Episode Step": 137}
{"Training Time": 5.3120530674854916, "Episode Reward": 15995.758104772534, "Mean Reward": 60.36135133876428, "Episode": 2208, "Episode Step": 265}
{"Training Time": 5.314523618883557, "Episode Reward": 9708.332890549318, "Mean Reward": 47.35772141731375, "Episode": 2209, "Episode Step": 205}
{"Training Time": 5.316274463335673, "Episode Reward": 6071.6397093111955, "Mean Reward": 42.16416464799441, "Episode": 2210, "Episode Step": 144}
{"Training Time": 5.3202543310986625, "Episode Reward": 18289.313832613392, "Mean Reward": 62.20855045106596, "Episode": 2211, "Episode Step": 294}
{"Training Time": 5.323206315305498, "Episode Reward": 13129.819356087046, "Mean Reward": 52.3100372752472, "Episode": 2212, "Episode Step": 251}
{"Training Time": 5.328531077239249, "Episode Reward": 24494.905526054146, "Mean Reward": 53.95353640100032, "Episode": 2213, "Episode Step": 454}
{"Training Time": 5.337695698340734, "Episode Reward": 43286.39431258527, "Mean Reward": 58.8130357507952, "Episode": 2214, "Episode Step": 736}
{"Training Time": 5.340028752485911, "Episode Reward": 9028.509723634052, "Mean Reward": 44.47541735780321, "Episode": 2215, "Episode Step": 203}
{"Training Time": 5.341715780562825, "Episode Reward": 6233.240596842281, "Mean Reward": 43.89606054114282, "Episode": 2216, "Episode Step": 142}
{"Training Time": 5.344984432193968, "Episode Reward": 13631.511622334465, "Mean Reward": 56.32856042286969, "Episode": 2217, "Episode Step": 242}
{"Training Time": 5.346817758613162, "Episode Reward": 7049.223148546323, "Mean Reward": 45.18732787529694, "Episode": 2218, "Episode Step": 156}
{"Training Time": 5.349879630804062, "Episode Reward": 12763.33232378638, "Mean Reward": 48.90165641297464, "Episode": 2219, "Episode Step": 261}
{"Training Time": 5.3534334433078765, "Episode Reward": 14070.593429785911, "Mean Reward": 53.2977023855527, "Episode": 2220, "Episode Step": 264}
{"Training Time": 5.355285311672422, "Episode Reward": 6518.479426678063, "Mean Reward": 41.25619890302571, "Episode": 2221, "Episode Step": 158}
{"Training Time": 5.35670515358448, "Episode Reward": 6033.169002230439, "Mean Reward": 49.45220493631508, "Episode": 2222, "Episode Step": 122}
{"Training Time": 5.371151690019501, "Episode Reward": 72369.48152396837, "Mean Reward": 60.35819976978179, "Episode": 2223, "Episode Step": 1199}
{"Training Time": 5.37345727192031, "Episode Reward": 8620.862465589054, "Mean Reward": 44.20955110558489, "Episode": 2224, "Episode Step": 195}
{"Training Time": 5.376868493027157, "Episode Reward": 15969.644048398186, "Mean Reward": 55.64335905365222, "Episode": 2225, "Episode Step": 287}
{"Training Time": 5.38037139972051, "Episode Reward": 15037.938619639228, "Mean Reward": 58.741947732965734, "Episode": 2226, "Episode Step": 256}
{"Training Time": 5.382675567468008, "Episode Reward": 9870.666738437005, "Mean Reward": 50.87972545586085, "Episode": 2227, "Episode Step": 194}
{"Training Time": 5.385745343036122, "Episode Reward": 12867.086577901839, "Mean Reward": 49.87242859651875, "Episode": 2228, "Episode Step": 258}
{"Training Time": 5.389254143900342, "Episode Reward": 14735.031352572241, "Mean Reward": 56.24057768157344, "Episode": 2229, "Episode Step": 262}
{"Training Time": 5.391459666954146, "Episode Reward": 9391.356270608872, "Mean Reward": 49.95402271600464, "Episode": 2230, "Episode Step": 188}
{"Training Time": 5.400523291693793, "Episode Reward": 44592.33324306378, "Mean Reward": 57.538494507179074, "Episode": 2231, "Episode Step": 775}
{"Training Time": 5.423341921965281, "Episode Reward": 108499.42098948806, "Mean Reward": 56.89534399029264, "Episode": 2232, "Episode Step": 1907}
{"Training Time": 5.425620111094581, "Episode Reward": 9588.098712897086, "Mean Reward": 49.938014129672325, "Episode": 2233, "Episode Step": 192}
{"Training Time": 5.428792808320787, "Episode Reward": 14885.684138213941, "Mean Reward": 54.92872375724701, "Episode": 2234, "Episode Step": 271}
{"Training Time": 5.43142936276065, "Episode Reward": 8239.798826704762, "Mean Reward": 45.02622309674734, "Episode": 2235, "Episode Step": 183}
{"Training Time": 5.433695494466358, "Episode Reward": 9569.093387133023, "Mean Reward": 49.58079475198458, "Episode": 2236, "Episode Step": 193}
{"Training Time": 5.4362946766614915, "Episode Reward": 9073.415844464374, "Mean Reward": 41.056180291694005, "Episode": 2237, "Episode Step": 221}
{"Training Time": 5.438954831096861, "Episode Reward": 7922.431008539017, "Mean Reward": 42.59371509967213, "Episode": 2238, "Episode Step": 186}
{"Training Time": 5.44191834780905, "Episode Reward": 16811.34910393475, "Mean Reward": 66.1864137950187, "Episode": 2239, "Episode Step": 254}
{"Training Time": 5.445193079445097, "Episode Reward": 15509.565036812146, "Mean Reward": 55.78980229069117, "Episode": 2240, "Episode Step": 278}
{"Training Time": 5.454159461922115, "Episode Reward": 41246.18680757862, "Mean Reward": 56.73478240382203, "Episode": 2241, "Episode Step": 727}
{"Training Time": 5.456317178342077, "Episode Reward": 8954.245903106777, "Mean Reward": 49.74581057281543, "Episode": 2242, "Episode Step": 180}
{"Training Time": 5.4611510841714015, "Episode Reward": 22050.599902731592, "Mean Reward": 53.91344719494277, "Episode": 2243, "Episode Step": 409}
{"Training Time": 5.464646861950556, "Episode Reward": 15554.878319166011, "Mean Reward": 60.057445247745214, "Episode": 2244, "Episode Step": 259}
{"Training Time": 5.466836704148187, "Episode Reward": 9761.336249886293, "Mean Reward": 52.48030241874351, "Episode": 2245, "Episode Step": 186}
{"Training Time": 5.4702819355328876, "Episode Reward": 16624.903785635935, "Mean Reward": 56.93460200560252, "Episode": 2246, "Episode Step": 292}
{"Training Time": 5.483993360002835, "Episode Reward": 60318.45346461108, "Mean Reward": 53.9521050667362, "Episode": 2247, "Episode Step": 1118}
{"Training Time": 5.486351453330782, "Episode Reward": 9567.884395640376, "Mean Reward": 47.60141490368346, "Episode": 2248, "Episode Step": 201}
{"Training Time": 5.490231405297915, "Episode Reward": 14384.976001385825, "Mean Reward": 52.49991241381688, "Episode": 2249, "Episode Step": 274}
{"Training Time": 5.4927623408370545, "Episode Reward": 6960.42022438926, "Mean Reward": 40.233642915544856, "Episode": 2250, "Episode Step": 173}
{"Training Time": 5.495074606935183, "Episode Reward": 9543.234505797494, "Mean Reward": 48.939664132294844, "Episode": 2251, "Episode Step": 195}
{"Training Time": 5.496308377782504, "Episode Reward": -13.193017418842167, "Mean Reward": -0.1293433080278644, "Episode": 2252, "Episode Step": 102}
{"Training Time": 5.497739327748617, "Episode Reward": 5280.508042228744, "Mean Reward": 65.19145731146597, "Episode": 2253, "Episode Step": 81}
{"Training Time": 5.499969687528081, "Episode Reward": 9242.527116637875, "Mean Reward": 49.42527869859826, "Episode": 2254, "Episode Step": 187}
{"Training Time": 5.501174368063609, "Episode Reward": -9.789685306970904, "Mean Reward": -0.0959773069310873, "Episode": 2255, "Episode Step": 102}
{"Training Time": 5.503741079701317, "Episode Reward": 8912.219425682, "Mean Reward": 49.78893533900559, "Episode": 2256, "Episode Step": 179}
{"Training Time": 5.512331264747513, "Episode Reward": 46297.578339212865, "Mean Reward": 63.508337913872246, "Episode": 2257, "Episode Step": 729}
{"Training Time": 5.516627895832062, "Episode Reward": 15213.7978772906, "Mean Reward": 42.855768668424226, "Episode": 2258, "Episode Step": 355}
{"Training Time": 5.519216671387355, "Episode Reward": 6861.110849367221, "Mean Reward": 38.7633381320182, "Episode": 2259, "Episode Step": 177}
{"Training Time": 5.521540681123733, "Episode Reward": 9763.294467439388, "Mean Reward": 49.81272687469075, "Episode": 2260, "Episode Step": 196}
{"Training Time": 5.5239411050081255, "Episode Reward": 7230.596197069592, "Mean Reward": 36.15298098534796, "Episode": 2261, "Episode Step": 200}
{"Training Time": 5.527462486690945, "Episode Reward": 16597.562648294523, "Mean Reward": 65.34473483580521, "Episode": 2262, "Episode Step": 254}
{"Training Time": 5.530500998033418, "Episode Reward": 16652.027215366143, "Mean Reward": 65.81828938879899, "Episode": 2263, "Episode Step": 253}
{"Training Time": 5.531739940841993, "Episode Reward": 11.095284516685762, "Mean Reward": 0.10877729918319375, "Episode": 2264, "Episode Step": 102}
{"Training Time": 5.534433516131507, "Episode Reward": 7972.699473889523, "Mean Reward": 42.40797592494427, "Episode": 2265, "Episode Step": 188}
{"Training Time": 5.53651083694564, "Episode Reward": 8496.22265522967, "Mean Reward": 48.54984374416954, "Episode": 2266, "Episode Step": 175}
{"Training Time": 5.5377378627989025, "Episode Reward": -9.597668514214753, "Mean Reward": -0.0940947893550466, "Episode": 2267, "Episode Step": 102}
{"Training Time": 5.539771845804321, "Episode Reward": 5290.12735496813, "Mean Reward": 41.008739185799456, "Episode": 2268, "Episode Step": 129}
{"Training Time": 5.542272509998745, "Episode Reward": 9757.855948210301, "Mean Reward": 47.36823275830243, "Episode": 2269, "Episode Step": 206}
{"Training Time": 5.543526023030281, "Episode Reward": 3.8007605468491086, "Mean Reward": 0.03726235830244224, "Episode": 2270, "Episode Step": 102}
{"Training Time": 5.552508779697948, "Episode Reward": 41247.09644291766, "Mean Reward": 57.20817814551687, "Episode": 2271, "Episode Step": 721}
{"Training Time": 5.55535751024882, "Episode Reward": 13510.711911824174, "Mean Reward": 56.76769710850493, "Episode": 2272, "Episode Step": 238}
{"Training Time": 5.561509763333532, "Episode Reward": 24782.050048320398, "Mean Reward": 47.6577885544623, "Episode": 2273, "Episode Step": 520}
{"Training Time": 5.5707905141512555, "Episode Reward": 41855.073252846356, "Mean Reward": 56.79114416939804, "Episode": 2274, "Episode Step": 737}
{"Training Time": 5.573178450001611, "Episode Reward": 9625.077232696913, "Mean Reward": 47.88595638157668, "Episode": 2275, "Episode Step": 201}
{"Training Time": 5.576831236084303, "Episode Reward": 11646.476184886023, "Mean Reward": 37.936404511029394, "Episode": 2276, "Episode Step": 307}
{"Training Time": 5.58018032391866, "Episode Reward": 12406.342023219995, "Mean Reward": 51.90938085029287, "Episode": 2277, "Episode Step": 239}
{"Training Time": 5.588747411105368, "Episode Reward": 45556.78655702803, "Mean Reward": 63.0980423227535, "Episode": 2278, "Episode Step": 722}
{"Training Time": 5.592027309735616, "Episode Reward": 15408.329557507446, "Mean Reward": 55.827281005461764, "Episode": 2279, "Episode Step": 276}
{"Training Time": 5.595508919424481, "Episode Reward": 13508.55268496257, "Mean Reward": 52.562461809192875, "Episode": 2280, "Episode Step": 257}
{"Training Time": 5.604093231956164, "Episode Reward": 46282.324954646945, "Mean Reward": 63.662070088922896, "Episode": 2281, "Episode Step": 727}
{"Training Time": 5.6072133163611095, "Episode Reward": 15969.495988543204, "Mean Reward": 61.185808385223005, "Episode": 2282, "Episode Step": 261}
{"Training Time": 5.610790106389258, "Episode Reward": 14678.884522147544, "Mean Reward": 56.67522981524148, "Episode": 2283, "Episode Step": 259}
{"Training Time": 5.613896708885829, "Episode Reward": 17047.296947140163, "Mean Reward": 65.3153139737171, "Episode": 2284, "Episode Step": 261}
{"Training Time": 5.6169673677947785, "Episode Reward": 15613.525489494688, "Mean Reward": 60.75301746885093, "Episode": 2285, "Episode Step": 257}
{"Training Time": 5.620602443085777, "Episode Reward": 16269.233529183539, "Mean Reward": 61.860203533017255, "Episode": 2286, "Episode Step": 263}
{"Training Time": 5.623377932773696, "Episode Reward": 13879.916340135553, "Mean Reward": 59.827225604032556, "Episode": 2287, "Episode Step": 232}
{"Training Time": 5.62666072414981, "Episode Reward": 15596.885854285938, "Mean Reward": 56.51045599378963, "Episode": 2288, "Episode Step": 276}
{"Training Time": 5.630749965575006, "Episode Reward": 18189.865449434823, "Mean Reward": 59.83508371524613, "Episode": 2289, "Episode Step": 304}
{"Training Time": 5.638197268909878, "Episode Reward": 36629.10447758774, "Mean Reward": 59.17464374408358, "Episode": 2290, "Episode Step": 619}
{"Training Time": 5.6406448816590835, "Episode Reward": 8691.458746257285, "Mean Reward": 42.39735973784042, "Episode": 2291, "Episode Step": 205}
{"Training Time": 5.644740336934725, "Episode Reward": 17773.995477852746, "Mean Reward": 58.660051082022264, "Episode": 2292, "Episode Step": 303}
{"Training Time": 5.646850193871392, "Episode Reward": 9343.41861049374, "Mean Reward": 52.491115789290674, "Episode": 2293, "Episode Step": 178}
{"Training Time": 5.649552862246831, "Episode Reward": 11235.075384086602, "Mean Reward": 50.1565865361009, "Episode": 2294, "Episode Step": 224}
{"Training Time": 5.658672726684147, "Episode Reward": 42151.27718000504, "Mean Reward": 57.741475589048, "Episode": 2295, "Episode Step": 730}
{"Training Time": 5.662396663890944, "Episode Reward": 19756.502621409967, "Mean Reward": 64.14448903055184, "Episode": 2296, "Episode Step": 308}
{"Training Time": 5.6675293519761825, "Episode Reward": 23789.156167368747, "Mean Reward": 55.32361899388081, "Episode": 2297, "Episode Step": 430}
{"Training Time": 5.671101212501526, "Episode Reward": 14203.708929454131, "Mean Reward": 54.4203407258779, "Episode": 2298, "Episode Step": 261}
{"Training Time": 5.674521630009015, "Episode Reward": 9143.037525281514, "Mean Reward": 47.86930641508646, "Episode": 2299, "Episode Step": 191}
{"Training Time": 5.67715391808086, "Episode Reward": 8174.03068311318, "Mean Reward": 41.91810606724708, "Episode": 2300, "Episode Step": 195}
{"Training Time": 5.68638426721096, "Episode Reward": 40355.74625496598, "Mean Reward": 54.24159442871772, "Episode": 2301, "Episode Step": 744}
{"Training Time": 5.689282968309191, "Episode Reward": 14652.584245914, "Mean Reward": 59.563350593146346, "Episode": 2302, "Episode Step": 246}
{"Training Time": 5.690812008049753, "Episode Reward": 6365.1943624025025, "Mean Reward": 49.342591956608544, "Episode": 2303, "Episode Step": 129}
{"Training Time": 5.699081682496601, "Episode Reward": 36177.01927858297, "Mean Reward": 54.40153274974883, "Episode": 2304, "Episode Step": 665}
{"Training Time": 5.701308072805404, "Episode Reward": 9634.499468721302, "Mean Reward": 51.52138753326899, "Episode": 2305, "Episode Step": 187}
{"Training Time": 5.704243343340026, "Episode Reward": 14205.847725847487, "Mean Reward": 56.3724116105059, "Episode": 2306, "Episode Step": 252}
{"Training Time": 5.720350806978014, "Episode Reward": 75502.43642708605, "Mean Reward": 57.19881547506519, "Episode": 2307, "Episode Step": 1320}
{"Training Time": 5.722585097220209, "Episode Reward": 9165.970280772828, "Mean Reward": 49.27941011168187, "Episode": 2308, "Episode Step": 186}
{"Training Time": 5.723218775524034, "Episode Reward": 2455.68257486772, "Mean Reward": 48.150638722896474, "Episode": 2309, "Episode Step": 51}
{"Training Time": 5.72677673637867, "Episode Reward": 15399.953127904284, "Mean Reward": 59.45927848611693, "Episode": 2310, "Episode Step": 259}
{"Training Time": 5.729810831414329, "Episode Reward": 16239.77190185043, "Mean Reward": 63.189773937161206, "Episode": 2311, "Episode Step": 257}
{"Training Time": 5.732705122497347, "Episode Reward": 12371.459654946426, "Mean Reward": 51.121734111348864, "Episode": 2312, "Episode Step": 242}
{"Training Time": 5.736229913632075, "Episode Reward": 14544.624111744437, "Mean Reward": 55.94086196824784, "Episode": 2313, "Episode Step": 260}
{"Training Time": 5.739347909159131, "Episode Reward": 16654.30827453768, "Mean Reward": 63.32436606288092, "Episode": 2314, "Episode Step": 263}
{"Training Time": 5.741721732219061, "Episode Reward": 8643.816929971112, "Mean Reward": 43.87724329934574, "Episode": 2315, "Episode Step": 197}
{"Training Time": 5.744444838364919, "Episode Reward": 8292.251514741012, "Mean Reward": 44.58199739108071, "Episode": 2316, "Episode Step": 186}
{"Training Time": 5.747677774429321, "Episode Reward": 16727.06446266783, "Mean Reward": 62.41441963682026, "Episode": 2317, "Episode Step": 268}
{"Training Time": 5.750907112227546, "Episode Reward": 14423.869831586568, "Mean Reward": 53.82040981935287, "Episode": 2318, "Episode Step": 268}
{"Training Time": 5.756881598366632, "Episode Reward": 24607.693031676394, "Mean Reward": 53.14836507921467, "Episode": 2319, "Episode Step": 463}
{"Training Time": 5.760028075575828, "Episode Reward": 17218.51206203331, "Mean Reward": 65.46962761229396, "Episode": 2320, "Episode Step": 263}
{"Training Time": 5.761704183883137, "Episode Reward": 6186.142447120225, "Mean Reward": 45.15432443153449, "Episode": 2321, "Episode Step": 137}
{"Training Time": 5.7643977533446416, "Episode Reward": 7973.547797470657, "Mean Reward": 43.10025836470626, "Episode": 2322, "Episode Step": 185}
{"Training Time": 5.76614450527562, "Episode Reward": 7299.97764493695, "Mean Reward": 49.65971187031939, "Episode": 2323, "Episode Step": 147}
{"Training Time": 5.767821365263727, "Episode Reward": 7052.7924422112665, "Mean Reward": 51.10719161022657, "Episode": 2324, "Episode Step": 138}
{"Training Time": 5.770471061401897, "Episode Reward": 7861.221749622672, "Mean Reward": 42.724031247949306, "Episode": 2325, "Episode Step": 184}
{"Training Time": 5.771472353339195, "Episode Reward": 4909.84942128815, "Mean Reward": 59.154812304676504, "Episode": 2326, "Episode Step": 83}
{"Training Time": 5.772082041369544, "Episode Reward": 2736.0970097750073, "Mean Reward": 54.721940195500146, "Episode": 2327, "Episode Step": 50}
{"Training Time": 5.774762690530883, "Episode Reward": 7995.295547152366, "Mean Reward": 42.9854599309267, "Episode": 2328, "Episode Step": 186}
{"Training Time": 5.777854349414508, "Episode Reward": 17250.15494354621, "Mean Reward": 65.3414959982811, "Episode": 2329, "Episode Step": 264}
{"Training Time": 5.780670203897688, "Episode Reward": 12681.996429799243, "Mean Reward": 53.51053345906853, "Episode": 2330, "Episode Step": 237}
{"Training Time": 5.784834696915414, "Episode Reward": 17258.949155427435, "Mean Reward": 55.31714472893409, "Episode": 2331, "Episode Step": 312}
{"Training Time": 5.78795193499989, "Episode Reward": 17047.76697075877, "Mean Reward": 65.56833450291835, "Episode": 2332, "Episode Step": 260}
{"Training Time": 5.790768046379089, "Episode Reward": 12266.054004229216, "Mean Reward": 52.41903420610776, "Episode": 2333, "Episode Step": 234}
{"Training Time": 5.794886421362559, "Episode Reward": 17447.097766419247, "Mean Reward": 56.46309956769983, "Episode": 2334, "Episode Step": 309}
{"Training Time": 5.79785904917452, "Episode Reward": 14811.16990336052, "Mean Reward": 59.008645033308845, "Episode": 2335, "Episode Step": 251}
{"Training Time": 5.800983160866632, "Episode Reward": 15694.836140701998, "Mean Reward": 59.225796757366034, "Episode": 2336, "Episode Step": 265}
{"Training Time": 5.808108087513182, "Episode Reward": 31995.667949550138, "Mean Reward": 57.03327620240666, "Episode": 2337, "Episode Step": 561}
{"Training Time": 5.811205725537406, "Episode Reward": 17171.025174795122, "Mean Reward": 66.29739449727846, "Episode": 2338, "Episode Step": 259}
{"Training Time": 5.811810816393958, "Episode Reward": 2759.947943102549, "Mean Reward": 57.4989154813031, "Episode": 2339, "Episode Step": 48}
{"Training Time": 5.820920105576516, "Episode Reward": 42311.35465340443, "Mean Reward": 58.11999265577531, "Episode": 2340, "Episode Step": 728}
{"Training Time": 5.823023281693459, "Episode Reward": 8877.492775483895, "Mean Reward": 50.44029986070395, "Episode": 2341, "Episode Step": 176}
{"Training Time": 5.826183674732844, "Episode Reward": 16113.087931014197, "Mean Reward": 61.500335614558004, "Episode": 2342, "Episode Step": 262}
{"Training Time": 5.829736711647776, "Episode Reward": 14885.327221242058, "Mean Reward": 56.5982023621371, "Episode": 2343, "Episode Step": 263}
{"Training Time": 5.8320214700036574, "Episode Reward": 9675.457328809596, "Mean Reward": 50.13190325808081, "Episode": 2344, "Episode Step": 193}
{"Training Time": 5.834988001121415, "Episode Reward": 16616.478490191836, "Mean Reward": 65.41920665429856, "Episode": 2345, "Episode Step": 254}
{"Training Time": 5.838513511419296, "Episode Reward": 16047.133834377973, "Mean Reward": 61.48327139608419, "Episode": 2346, "Episode Step": 261}
{"Training Time": 5.842054089705149, "Episode Reward": 19370.792275067994, "Mean Reward": 64.78525844504345, "Episode": 2347, "Episode Step": 299}
{"Training Time": 5.845099783870909, "Episode Reward": 16565.118747104705, "Mean Reward": 63.9579874405587, "Episode": 2348, "Episode Step": 259}
{"Training Time": 5.8608512086338465, "Episode Reward": 71255.53042130297, "Mean Reward": 56.41768046025572, "Episode": 2349, "Episode Step": 1263}
{"Training Time": 5.863432192206383, "Episode Reward": 9942.851663961957, "Mean Reward": 50.47132824346171, "Episode": 2350, "Episode Step": 197}
{"Training Time": 5.866545658045345, "Episode Reward": 16675.130504025103, "Mean Reward": 62.92502076990605, "Episode": 2351, "Episode Step": 265}
{"Training Time": 5.869356557793087, "Episode Reward": 8190.3138438799015, "Mean Reward": 40.74783006905424, "Episode": 2352, "Episode Step": 201}
{"Training Time": 5.871625231968032, "Episode Reward": 9689.419424427222, "Mean Reward": 50.465726168891784, "Episode": 2353, "Episode Step": 192}
{"Training Time": 5.874150114986632, "Episode Reward": 8992.039910798892, "Mean Reward": 42.018878087845295, "Episode": 2354, "Episode Step": 214}
{"Training Time": 5.909103122486009, "Episode Reward": 157866.89117141603, "Mean Reward": 53.55050582476799, "Episode": 2355, "Episode Step": 2948}
{"Training Time": 5.911420792208777, "Episode Reward": 9289.62334813924, "Mean Reward": 48.636771456226384, "Episode": 2356, "Episode Step": 191}
{"Training Time": 5.913414675858285, "Episode Reward": 5744.606231840221, "Mean Reward": 34.39883971161809, "Episode": 2357, "Episode Step": 167}
{"Training Time": 5.923447551925977, "Episode Reward": 44117.4682058067, "Mean Reward": 54.8724728927944, "Episode": 2358, "Episode Step": 804}
{"Training Time": 5.926640488306681, "Episode Reward": 17260.35233637394, "Mean Reward": 64.16487857388081, "Episode": 2359, "Episode Step": 269}
{"Training Time": 5.929608297215568, "Episode Reward": 13176.24364591512, "Mean Reward": 51.874974983917795, "Episode": 2360, "Episode Step": 254}
{"Training Time": 5.932356178363165, "Episode Reward": 7931.762241540595, "Mean Reward": 41.09721368673883, "Episode": 2361, "Episode Step": 193}
{"Training Time": 5.934746886094411, "Episode Reward": 9384.711480318878, "Mean Reward": 47.88118102203509, "Episode": 2362, "Episode Step": 196}
{"Training Time": 5.937906095584234, "Episode Reward": 13814.190624374562, "Mean Reward": 52.72591841364336, "Episode": 2363, "Episode Step": 262}
{"Training Time": 5.940241458084849, "Episode Reward": 6466.179473669469, "Mean Reward": 41.1858565201877, "Episode": 2364, "Episode Step": 157}
{"Training Time": 5.943515933884514, "Episode Reward": 16359.535682766513, "Mean Reward": 59.70633460863691, "Episode": 2365, "Episode Step": 274}
{"Training Time": 5.946508526139789, "Episode Reward": 13046.676736354091, "Mean Reward": 51.16343818178075, "Episode": 2366, "Episode Step": 255}
{"Training Time": 5.966743497252464, "Episode Reward": 89041.82265146074, "Mean Reward": 52.81246895104433, "Episode": 2367, "Episode Step": 1686}
{"Training Time": 5.9750420297516715, "Episode Reward": 43245.47873125082, "Mean Reward": 61.428236834163094, "Episode": 2368, "Episode Step": 704}
{"Training Time": 5.977412157522307, "Episode Reward": 8197.810828271917, "Mean Reward": 40.785128498865255, "Episode": 2369, "Episode Step": 201}
{"Training Time": 5.986466420557764, "Episode Reward": 40632.79350247229, "Mean Reward": 55.66136096229081, "Episode": 2370, "Episode Step": 730}
{"Training Time": 5.9907665258646015, "Episode Reward": 22178.05728594275, "Mean Reward": 60.43067380365871, "Episode": 2371, "Episode Step": 367}
{"Training Time": 5.993971818089485, "Episode Reward": 12961.510702390035, "Mean Reward": 47.132766190509216, "Episode": 2372, "Episode Step": 275}
{"Training Time": 6.008456724749671, "Episode Reward": 65730.80550812127, "Mean Reward": 54.45799959247827, "Episode": 2373, "Episode Step": 1207}
{"Training Time": 6.011411674155129, "Episode Reward": 15553.433554186848, "Mean Reward": 60.51919670889824, "Episode": 2374, "Episode Step": 257}
{"Training Time": 6.014527632527881, "Episode Reward": 12617.902901028221, "Mean Reward": 48.53039577318547, "Episode": 2375, "Episode Step": 260}
{"Training Time": 6.034229358898269, "Episode Reward": 93777.24141287866, "Mean Reward": 57.56736734983343, "Episode": 2376, "Episode Step": 1629}
{"Training Time": 6.037251461082034, "Episode Reward": 17259.515503689854, "Mean Reward": 67.68437452427393, "Episode": 2377, "Episode Step": 255}
{"Training Time": 6.042310152252515, "Episode Reward": 24148.949061470714, "Mean Reward": 55.900345049700725, "Episode": 2378, "Episode Step": 432}
{"Training Time": 6.056873949170113, "Episode Reward": 70979.64049351086, "Mean Reward": 58.51577946703286, "Episode": 2379, "Episode Step": 1213}
{"Training Time": 6.059775408903758, "Episode Reward": 16022.08175554459, "Mean Reward": 65.13041364042516, "Episode": 2380, "Episode Step": 246}
{"Training Time": 6.0629894763893555, "Episode Reward": 14893.005896282584, "Mean Reward": 53.765364246507524, "Episode": 2381, "Episode Step": 277}
{"Training Time": 6.105479701956114, "Episode Reward": 214086.3578651089, "Mean Reward": 59.30370023964235, "Episode": 2382, "Episode Step": 3610}
{"Training Time": 6.1085689722167125, "Episode Reward": 16500.926053565687, "Mean Reward": 61.801221174403324, "Episode": 2383, "Episode Step": 267}
{"Training Time": 6.111758788029353, "Episode Reward": 16043.901214191155, "Mean Reward": 57.920220989859764, "Episode": 2384, "Episode Step": 277}
{"Training Time": 6.170633043580585, "Episode Reward": 292885.7679037953, "Mean Reward": 58.57715358075906, "Episode": 2385, "Episode Step": 5000}
{"Training Time": 6.174165997240278, "Episode Reward": 15479.301227502508, "Mean Reward": 56.08442473732793, "Episode": 2386, "Episode Step": 276}
{"Training Time": 6.17743847919835, "Episode Reward": 16313.023559256313, "Mean Reward": 58.46961849195811, "Episode": 2387, "Episode Step": 279}
{"Training Time": 6.183643620014191, "Episode Reward": 25386.083766654963, "Mean Reward": 51.4930705205983, "Episode": 2388, "Episode Step": 493}
{"Training Time": 6.18671906332175, "Episode Reward": 15330.033993705438, "Mean Reward": 58.511580128646706, "Episode": 2389, "Episode Step": 262}
{"Training Time": 6.188156066669358, "Episode Reward": 6169.105607664274, "Mean Reward": 50.984343864994, "Episode": 2390, "Episode Step": 121}
{"Training Time": 6.191719272202915, "Episode Reward": 14539.404797105222, "Mean Reward": 54.86567847964235, "Episode": 2391, "Episode Step": 265}
{"Training Time": 6.200976175533401, "Episode Reward": 47843.74238808307, "Mean Reward": 60.63845676563127, "Episode": 2392, "Episode Step": 789}
{"Training Time": 6.202327742245462, "Episode Reward": 6401.528605939937, "Mean Reward": 57.156505410178006, "Episode": 2393, "Episode Step": 112}
{"Training Time": 6.2172948808140225, "Episode Reward": 75401.48188025947, "Mean Reward": 61.00443517820345, "Episode": 2394, "Episode Step": 1236}
{"Training Time": 6.220464654697312, "Episode Reward": 15890.12121055234, "Mean Reward": 59.513562586338345, "Episode": 2395, "Episode Step": 267}
{"Training Time": 6.221856874161296, "Episode Reward": 6403.57904906554, "Mean Reward": 55.2032676643581, "Episode": 2396, "Episode Step": 116}
{"Training Time": 6.28030858165688, "Episode Reward": 287361.6490158223, "Mean Reward": 57.472329803164456, "Episode": 2397, "Episode Step": 5000}
{"Training Time": 6.282940495808919, "Episode Reward": 9834.008204135504, "Mean Reward": 48.68320893136388, "Episode": 2398, "Episode Step": 202}
{"Training Time": 6.287649876144197, "Episode Reward": 16048.858634514594, "Mean Reward": 53.318467224300974, "Episode": 2399, "Episode Step": 301}
{"Training Time": 6.303069129188856, "Episode Reward": 72763.5297928862, "Mean Reward": 56.757823551393294, "Episode": 2400, "Episode Step": 1282}
{"Training Time": 6.306042676965395, "Episode Reward": 15751.122166774685, "Mean Reward": 62.257399868674646, "Episode": 2401, "Episode Step": 253}
{"Training Time": 6.309504726926486, "Episode Reward": 14990.242060494511, "Mean Reward": 51.161235701346456, "Episode": 2402, "Episode Step": 293}
{"Training Time": 6.328503765265147, "Episode Reward": 86865.21169933732, "Mean Reward": 55.50492760341043, "Episode": 2403, "Episode Step": 1565}
{"Training Time": 6.331458021402359, "Episode Reward": 16005.094387697542, "Mean Reward": 63.76531628564758, "Episode": 2404, "Episode Step": 251}
{"Training Time": 6.33305299308565, "Episode Reward": 5721.372143255035, "Mean Reward": 43.67459651339721, "Episode": 2405, "Episode Step": 131}
{"Training Time": 6.365800474749671, "Episode Reward": 158577.05955792873, "Mean Reward": 58.214779573395276, "Episode": 2406, "Episode Step": 2724}
{"Training Time": 6.368313060535325, "Episode Reward": 9206.58253444961, "Mean Reward": 43.84086921166481, "Episode": 2407, "Episode Step": 210}
{"Training Time": 6.370115859707196, "Episode Reward": 2565.778942994159, "Mean Reward": 16.6609022272348, "Episode": 2408, "Episode Step": 154}
{"Training Time": 6.416028524703449, "Episode Reward": 228114.74621476975, "Mean Reward": 59.281378953942244, "Episode": 2409, "Episode Step": 3848}
{"Training Time": 6.418844778868888, "Episode Reward": 12457.40404564273, "Mean Reward": 52.785610362892925, "Episode": 2410, "Episode Step": 236}
{"Training Time": 6.420075551138984, "Episode Reward": 61.05269150210218, "Mean Reward": 0.5985557990402174, "Episode": 2411, "Episode Step": 102}
{"Training Time": 6.474087076385816, "Episode Reward": 269790.9481323002, "Mean Reward": 59.38607707072424, "Episode": 2412, "Episode Step": 4543}
{"Training Time": 6.477297091947661, "Episode Reward": 16610.3919958849, "Mean Reward": 61.06761763192978, "Episode": 2413, "Episode Step": 272}
{"Training Time": 6.481385833024978, "Episode Reward": 3748.0386118275865, "Mean Reward": 10.83248153707395, "Episode": 2414, "Episode Step": 346}
{"Training Time": 6.48854892803563, "Episode Reward": 30112.656202067716, "Mean Reward": 53.581238793714796, "Episode": 2415, "Episode Step": 562}
{"Training Time": 6.491843044161796, "Episode Reward": 15490.968414275298, "Mean Reward": 56.330794233728355, "Episode": 2416, "Episode Step": 275}
{"Training Time": 6.4938202491733765, "Episode Reward": 2140.053138943293, "Mean Reward": 13.129160361615295, "Episode": 2417, "Episode Step": 163}
{"Training Time": 6.520787068605423, "Episode Reward": 127967.91225666046, "Mean Reward": 57.64320371921642, "Episode": 2418, "Episode Step": 2220}
{"Training Time": 6.523994874755542, "Episode Reward": 16362.836624885293, "Mean Reward": 62.216108839868035, "Episode": 2419, "Episode Step": 263}
{"Training Time": 6.525789718892839, "Episode Reward": 2181.821469363807, "Mean Reward": 14.742036955160858, "Episode": 2420, "Episode Step": 148}
{"Training Time": 6.562026086118486, "Episode Reward": 177963.02132091805, "Mean Reward": 59.53931793941722, "Episode": 2421, "Episode Step": 2989}
{"Training Time": 6.565220834149255, "Episode Reward": 16705.38412349788, "Mean Reward": 63.277970164764696, "Episode": 2422, "Episode Step": 264}
{"Training Time": 6.567004744741652, "Episode Reward": 2433.3617830226085, "Mean Reward": 16.898345715434782, "Episode": 2423, "Episode Step": 144}
{"Training Time": 6.568847534457842, "Episode Reward": 5925.580653306201, "Mean Reward": 53.38360948924506, "Episode": 2424, "Episode Step": 111}
{"Training Time": 6.572527897490396, "Episode Reward": 17996.399822050265, "Mean Reward": 58.620194860098586, "Episode": 2425, "Episode Step": 307}
{"Training Time": 6.574429980847571, "Episode Reward": 2205.0216328624724, "Mean Reward": 14.13475405681072, "Episode": 2426, "Episode Step": 156}
{"Training Time": 6.57650415831142, "Episode Reward": 6874.203759993227, "Mean Reward": 52.077301212069905, "Episode": 2427, "Episode Step": 132}
{"Training Time": 6.579662864473131, "Episode Reward": 15174.180783353322, "Mean Reward": 57.69650487967043, "Episode": 2428, "Episode Step": 263}
{"Training Time": 6.581494718591372, "Episode Reward": 1999.4476155846808, "Mean Reward": 13.241374937646892, "Episode": 2429, "Episode Step": 151}
{"Training Time": 6.586267391641934, "Episode Reward": 21346.1872630192, "Mean Reward": 59.79324163310701, "Episode": 2430, "Episode Step": 357}
{"Training Time": 6.589576192763117, "Episode Reward": 15523.7140525108, "Mean Reward": 56.44986928185746, "Episode": 2431, "Episode Step": 275}
{"Training Time": 6.5912478080723025, "Episode Reward": 2090.7982654570983, "Mean Reward": 15.373516657772782, "Episode": 2432, "Episode Step": 136}
{"Training Time": 6.635335041417016, "Episode Reward": 206771.2044935882, "Mean Reward": 56.5566751897123, "Episode": 2433, "Episode Step": 3656}
{"Training Time": 6.638480383621322, "Episode Reward": 16058.016755656632, "Mean Reward": 61.29014028876577, "Episode": 2434, "Episode Step": 262}
{"Training Time": 6.640155567526818, "Episode Reward": 2055.2463002218838, "Mean Reward": 14.680330715870598, "Episode": 2435, "Episode Step": 140}
{"Training Time": 6.643481135831939, "Episode Reward": 12303.958872918301, "Mean Reward": 51.266495303826254, "Episode": 2436, "Episode Step": 240}
{"Training Time": 6.646742327213287, "Episode Reward": 16577.81070010691, "Mean Reward": 60.72458131907293, "Episode": 2437, "Episode Step": 273}
{"Training Time": 6.651365865535206, "Episode Reward": 8152.294561693893, "Mean Reward": 21.011068457973952, "Episode": 2438, "Episode Step": 388}
{"Training Time": 6.687416773902045, "Episode Reward": 163673.54966833853, "Mean Reward": 54.48520295217661, "Episode": 2439, "Episode Step": 3004}
{"Training Time": 6.690573856963051, "Episode Reward": 16688.30492283919, "Mean Reward": 62.038308263342714, "Episode": 2440, "Episode Step": 269}
{"Training Time": 6.693455093635453, "Episode Reward": 10262.481402680869, "Mean Reward": 42.05935001098717, "Episode": 2441, "Episode Step": 244}
{"Training Time": 6.703900984194544, "Episode Reward": 48306.72063812893, "Mean Reward": 56.6980289179917, "Episode": 2442, "Episode Step": 852}
{"Training Time": 6.706957786083222, "Episode Reward": 16342.807125442772, "Mean Reward": 62.61611925457001, "Episode": 2443, "Episode Step": 261}
{"Training Time": 6.709475227793058, "Episode Reward": 6999.908960650625, "Mean Reward": 32.55771609604942, "Episode": 2444, "Episode Step": 215}
{"Training Time": 6.724066546691788, "Episode Reward": 69391.33003011133, "Mean Reward": 57.15925043666502, "Episode": 2445, "Episode Step": 1214}
{"Training Time": 6.727114141119851, "Episode Reward": 16040.738918331464, "Mean Reward": 60.991402731298344, "Episode": 2446, "Episode Step": 263}
{"Training Time": 6.7295099111398065, "Episode Reward": 8657.386539411566, "Mean Reward": 42.438169310841005, "Episode": 2447, "Episode Step": 204}
{"Training Time": 6.7351281530327265, "Episode Reward": 24686.01781034524, "Mean Reward": 55.724645170079555, "Episode": 2448, "Episode Step": 443}
{"Training Time": 6.738679791688919, "Episode Reward": 16336.684810587922, "Mean Reward": 64.82811432772985, "Episode": 2449, "Episode Step": 252}
{"Training Time": 6.745789925588502, "Episode Reward": 26890.92503840101, "Mean Reward": 45.655220778269964, "Episode": 2450, "Episode Step": 589}
{"Training Time": 6.793795293900701, "Episode Reward": 233443.6920231183, "Mean Reward": 56.798951830442405, "Episode": 2451, "Episode Step": 4110}
{"Training Time": 6.801876163615121, "Episode Reward": 38063.916987874494, "Mean Reward": 55.56776202609415, "Episode": 2452, "Episode Step": 685}
{"Training Time": 6.80438787413968, "Episode Reward": 8441.933657056914, "Mean Reward": 39.633491347685045, "Episode": 2453, "Episode Step": 213}
{"Training Time": 6.836196481916639, "Episode Reward": 157206.1310204857, "Mean Reward": 58.39752266734239, "Episode": 2454, "Episode Step": 2692}
{"Training Time": 6.839521422518624, "Episode Reward": 15811.27627685296, "Mean Reward": 57.495550097647126, "Episode": 2455, "Episode Step": 275}
{"Training Time": 6.84194828722212, "Episode Reward": 8099.0667761456625, "Mean Reward": 39.89688067066829, "Episode": 2456, "Episode Step": 203}
{"Training Time": 6.845235803325971, "Episode Reward": 14667.500386131183, "Mean Reward": 61.62815288290413, "Episode": 2457, "Episode Step": 238}
{"Training Time": 6.847035971085231, "Episode Reward": 6713.423947968823, "Mean Reward": 44.459761244826645, "Episode": 2458, "Episode Step": 151}
{"Training Time": 6.850122833914227, "Episode Reward": 14942.168473932748, "Mean Reward": 57.69177016962451, "Episode": 2459, "Episode Step": 259}
{"Training Time": 6.871114936934577, "Episode Reward": 97837.69304824788, "Mean Reward": 56.196262520532954, "Episode": 2460, "Episode Step": 1741}
{"Training Time": 6.87293477859762, "Episode Reward": 7230.111712835527, "Mean Reward": 47.56652442654952, "Episode": 2461, "Episode Step": 152}
{"Training Time": 6.875955066680908, "Episode Reward": 13685.903544240578, "Mean Reward": 53.88151001669519, "Episode": 2462, "Episode Step": 254}
{"Training Time": 6.8796624444590675, "Episode Reward": 14536.016552182147, "Mean Reward": 53.44123732419907, "Episode": 2463, "Episode Step": 272}
{"Training Time": 6.881491210261981, "Episode Reward": 7187.284957181545, "Mean Reward": 46.975718674389185, "Episode": 2464, "Episode Step": 153}
{"Training Time": 6.88310127556324, "Episode Reward": 6466.708638457566, "Mean Reward": 47.90154547005604, "Episode": 2465, "Episode Step": 135}
{"Training Time": 6.886784993343883, "Episode Reward": 13424.286614839384, "Mean Reward": 50.657685339016545, "Episode": 2466, "Episode Step": 265}
{"Training Time": 6.889253898064296, "Episode Reward": 7931.589874532391, "Mean Reward": 39.07187130311523, "Episode": 2467, "Episode Step": 203}
{"Training Time": 6.890986023081673, "Episode Reward": 5896.452122904676, "Mean Reward": 41.52431072468082, "Episode": 2468, "Episode Step": 142}
{"Training Time": 6.9069515275292925, "Episode Reward": 71170.59663055997, "Mean Reward": 54.915583819876524, "Episode": 2469, "Episode Step": 1296}
{"Training Time": 6.908820681373278, "Episode Reward": 6609.0392594005825, "Mean Reward": 42.91583934675703, "Episode": 2470, "Episode Step": 154}
{"Training Time": 6.910511200560464, "Episode Reward": 6207.072476374217, "Mean Reward": 44.0217906125831, "Episode": 2471, "Episode Step": 141}
{"Training Time": 6.914360980523957, "Episode Reward": 15570.529435000892, "Mean Reward": 55.41113677936261, "Episode": 2472, "Episode Step": 281}
{"Training Time": 6.91623255583975, "Episode Reward": 6334.209240451844, "Mean Reward": 41.131228834102885, "Episode": 2473, "Episode Step": 154}
{"Training Time": 6.917870298624039, "Episode Reward": 6327.405602046346, "Mean Reward": 46.185442350703255, "Episode": 2474, "Episode Step": 137}
{"Training Time": 6.920973782208231, "Episode Reward": 9697.289759106328, "Mean Reward": 43.48560430092524, "Episode": 2475, "Episode Step": 223}
{"Training Time": 6.922772827810712, "Episode Reward": 6679.27462623227, "Mean Reward": 43.6553897139364, "Episode": 2476, "Episode Step": 153}
{"Training Time": 6.924049118889703, "Episode Reward": 5869.298200630397, "Mean Reward": 54.85325421149904, "Episode": 2477, "Episode Step": 107}
{"Training Time": 6.9412530930836995, "Episode Reward": 80120.40430933826, "Mean Reward": 55.716553761709505, "Episode": 2478, "Episode Step": 1438}
{"Training Time": 6.944226597481304, "Episode Reward": 14476.192868923601, "Mean Reward": 57.67407517499443, "Episode": 2479, "Episode Step": 251}
{"Training Time": 6.947376004987293, "Episode Reward": 14168.37406800668, "Mean Reward": 52.867067417935374, "Episode": 2480, "Episode Step": 268}
{"Training Time": 6.9509477839205, "Episode Reward": 14517.15041847402, "Mean Reward": 55.19829056454, "Episode": 2481, "Episode Step": 263}
{"Training Time": 6.9538708730538685, "Episode Reward": 14031.42859503737, "Mean Reward": 56.57834110902166, "Episode": 2482, "Episode Step": 248}
{"Training Time": 6.956145404974619, "Episode Reward": 8947.176103597274, "Mean Reward": 46.59987553956913, "Episode": 2483, "Episode Step": 192}
{"Training Time": 6.969609478910764, "Episode Reward": 62593.50852326877, "Mean Reward": 56.49233621233643, "Episode": 2484, "Episode Step": 1108}
{"Training Time": 6.971325353052881, "Episode Reward": 6388.872687821061, "Mean Reward": 43.75940197137713, "Episode": 2485, "Episode Step": 146}
{"Training Time": 6.973495727247662, "Episode Reward": 9064.638256985425, "Mean Reward": 49.5335423878985, "Episode": 2486, "Episode Step": 183}
{"Training Time": 6.983083222243521, "Episode Reward": 41096.29144433837, "Mean Reward": 53.1646719849138, "Episode": 2487, "Episode Step": 773}
{"Training Time": 6.988018062776989, "Episode Reward": 25118.149798482536, "Mean Reward": 59.947851547691016, "Episode": 2488, "Episode Step": 419}
{"Training Time": 6.990810190836589, "Episode Reward": 13185.679365440761, "Mean Reward": 55.87152273491848, "Episode": 2489, "Episode Step": 236}
{"Training Time": 7.005594753623009, "Episode Reward": 70222.01500885435, "Mean Reward": 56.99838880588827, "Episode": 2490, "Episode Step": 1232}
{"Training Time": 7.018323634200626, "Episode Reward": 63990.58230721148, "Mean Reward": 58.22618954250362, "Episode": 2491, "Episode Step": 1099}
{"Training Time": 7.021513734989696, "Episode Reward": 13902.761624459792, "Mean Reward": 50.372324726303596, "Episode": 2492, "Episode Step": 276}
{"Training Time": 7.047798672252231, "Episode Reward": 124674.5161538378, "Mean Reward": 55.93293681195056, "Episode": 2493, "Episode Step": 2229}
{"Training Time": 7.050842772788472, "Episode Reward": 16352.830008572246, "Mean Reward": 62.895500032970176, "Episode": 2494, "Episode Step": 260}
{"Training Time": 7.05419740445084, "Episode Reward": 15006.27364010611, "Mean Reward": 52.46948825211927, "Episode": 2495, "Episode Step": 286}
{"Training Time": 7.063308115866449, "Episode Reward": 40620.815291542654, "Mean Reward": 54.161087055390205, "Episode": 2496, "Episode Step": 750}
{"Training Time": 7.067553455299802, "Episode Reward": 21365.465844581162, "Mean Reward": 58.21652818686965, "Episode": 2497, "Episode Step": 367}
{"Training Time": 7.070213623907831, "Episode Reward": 9008.049676584436, "Mean Reward": 39.16543337645407, "Episode": 2498, "Episode Step": 230}
{"Training Time": 7.074792590538661, "Episode Reward": 13741.440483170809, "Mean Reward": 54.3139940046277, "Episode": 2499, "Episode Step": 253}
{"Training Time": 7.07669376803769, "Episode Reward": 6935.490799137215, "Mean Reward": 50.6240204316585, "Episode": 2500, "Episode Step": 137}
{"Training Time": 7.078430566125446, "Episode Reward": 6486.755625655057, "Mean Reward": 43.53527265540307, "Episode": 2501, "Episode Step": 149}
{"Training Time": 7.123964330289099, "Episode Reward": 197385.76953750558, "Mean Reward": 51.617617556879075, "Episode": 2502, "Episode Step": 3824}
{"Training Time": 7.13201350722048, "Episode Reward": 39259.57969126718, "Mean Reward": 58.076301318442574, "Episode": 2503, "Episode Step": 676}
{"Training Time": 7.133045571115282, "Episode Reward": 4875.379675892627, "Mean Reward": 58.73951416738105, "Episode": 2504, "Episode Step": 83}
{"Training Time": 7.154948453042242, "Episode Reward": 97430.2651965862, "Mean Reward": 54.430315752282795, "Episode": 2505, "Episode Step": 1790}
{"Training Time": 7.163469403584799, "Episode Reward": 43824.872170062736, "Mean Reward": 61.63835748250737, "Episode": 2506, "Episode Step": 711}
{"Training Time": 7.168004573318694, "Episode Reward": 18537.644107829034, "Mean Reward": 49.30224496763041, "Episode": 2507, "Episode Step": 376}
{"Training Time": 7.180904212527805, "Episode Reward": 56510.21499308685, "Mean Reward": 54.180455410438014, "Episode": 2508, "Episode Step": 1043}
{"Training Time": 7.188609798351924, "Episode Reward": 35185.200850785244, "Mean Reward": 54.89110897158385, "Episode": 2509, "Episode Step": 641}
{"Training Time": 7.18968549085988, "Episode Reward": 4377.999384068483, "Mean Reward": 49.74999300077821, "Episode": 2510, "Episode Step": 88}
{"Training Time": 7.204705560273594, "Episode Reward": 69660.5692305734, "Mean Reward": 57.052063251902865, "Episode": 2511, "Episode Step": 1221}
{"Training Time": 7.213281431661712, "Episode Reward": 43933.40332667655, "Mean Reward": 60.59779769196765, "Episode": 2512, "Episode Step": 725}
{"Training Time": 7.213899038036664, "Episode Reward": 2066.7702971150734, "Mean Reward": 41.33540594230147, "Episode": 2513, "Episode Step": 50}
{"Training Time": 7.217404295537207, "Episode Reward": 13527.430490726123, "Mean Reward": 52.229461354154914, "Episode": 2514, "Episode Step": 259}
{"Training Time": 7.230640083617634, "Episode Reward": 67273.9118420515, "Mean Reward": 59.74592525937078, "Episode": 2515, "Episode Step": 1126}
{"Training Time": 7.23678307056427, "Episode Reward": 30867.587654519302, "Mean Reward": 59.82090630720795, "Episode": 2516, "Episode Step": 516}
{"Training Time": 7.240144591927528, "Episode Reward": 14392.645986687774, "Mean Reward": 58.03486284954747, "Episode": 2517, "Episode Step": 248}
{"Training Time": 7.242502583596441, "Episode Reward": 9958.301681754414, "Mean Reward": 50.294452938153604, "Episode": 2518, "Episode Step": 198}
{"Training Time": 7.2446062869495815, "Episode Reward": 9304.832383303972, "Mean Reward": 52.569674481943345, "Episode": 2519, "Episode Step": 177}
{"Training Time": 7.247356244987912, "Episode Reward": 8481.923968928251, "Mean Reward": 44.40797889491231, "Episode": 2520, "Episode Step": 191}
{"Training Time": 7.250322068863444, "Episode Reward": 15952.351952127683, "Mean Reward": 63.809407808510734, "Episode": 2521, "Episode Step": 250}
{"Training Time": 7.252554267247518, "Episode Reward": 8116.1479554526395, "Mean Reward": 42.71656818659284, "Episode": 2522, "Episode Step": 190}
{"Training Time": 7.255916754735841, "Episode Reward": 13182.98993999685, "Mean Reward": 53.37242890686984, "Episode": 2523, "Episode Step": 247}
{"Training Time": 7.267548158632384, "Episode Reward": 58539.88952257412, "Mean Reward": 59.91800360550064, "Episode": 2524, "Episode Step": 977}
{"Training Time": 7.270707753896713, "Episode Reward": 15975.871157679225, "Mean Reward": 59.83472343700084, "Episode": 2525, "Episode Step": 267}
{"Training Time": 7.280546787778537, "Episode Reward": 40925.68358637311, "Mean Reward": 51.60868043678828, "Episode": 2526, "Episode Step": 793}
{"Training Time": 7.284830975267623, "Episode Reward": 21960.317094069396, "Mean Reward": 60.83190330767146, "Episode": 2527, "Episode Step": 361}
{"Training Time": 7.28656372057067, "Episode Reward": 6791.796868131113, "Mean Reward": 46.83997840090423, "Episode": 2528, "Episode Step": 145}
{"Training Time": 7.3249963527917865, "Episode Reward": 186066.63952212973, "Mean Reward": 57.42797516115115, "Episode": 2529, "Episode Step": 3240}
{"Training Time": 7.327878135840098, "Episode Reward": 13806.336959378508, "Mean Reward": 57.28770522563696, "Episode": 2530, "Episode Step": 241}
{"Training Time": 7.33062737358941, "Episode Reward": 12308.220521873298, "Mean Reward": 53.052674663246975, "Episode": 2531, "Episode Step": 232}
{"Training Time": 7.3453129649824564, "Episode Reward": 70924.29531289617, "Mean Reward": 58.32590075073698, "Episode": 2532, "Episode Step": 1216}
{"Training Time": 7.349386445813709, "Episode Reward": 22043.55847359097, "Mean Reward": 62.623745663610705, "Episode": 2533, "Episode Step": 352}
{"Training Time": 7.352570534414715, "Episode Reward": 15506.675870344632, "Mean Reward": 57.22020616363333, "Episode": 2534, "Episode Step": 271}
{"Training Time": 7.356030518876182, "Episode Reward": 16184.851289353091, "Mean Reward": 62.73198174167865, "Episode": 2535, "Episode Step": 258}
{"Training Time": 7.3587718663613, "Episode Reward": 14297.015472558458, "Mean Reward": 61.36058142728952, "Episode": 2536, "Episode Step": 233}
{"Training Time": 7.360359587470691, "Episode Reward": 6812.054173280094, "Mean Reward": 50.45966054281551, "Episode": 2537, "Episode Step": 135}
{"Training Time": 7.369527011646165, "Episode Reward": 42406.386978859344, "Mean Reward": 56.92132480383805, "Episode": 2538, "Episode Step": 745}
{"Training Time": 7.371591147515509, "Episode Reward": 9016.371323785466, "Mean Reward": 50.93995098183879, "Episode": 2539, "Episode Step": 177}
{"Training Time": 7.372167438599798, "Episode Reward": 2255.7041069399793, "Mean Reward": 46.99383556124957, "Episode": 2540, "Episode Step": 48}
{"Training Time": 7.3825264863835445, "Episode Reward": 50334.82878654229, "Mean Reward": 58.94008054630245, "Episode": 2541, "Episode Step": 854}
{"Training Time": 7.386576183040937, "Episode Reward": 22568.428230625694, "Mean Reward": 65.22667118677946, "Episode": 2542, "Episode Step": 346}
{"Training Time": 7.389932845301098, "Episode Reward": 15954.02899172699, "Mean Reward": 56.775903885149425, "Episode": 2543, "Episode Step": 281}
{"Training Time": 7.405358865857124, "Episode Reward": 72703.27817563513, "Mean Reward": 57.06693734351266, "Episode": 2544, "Episode Step": 1274}
{"Training Time": 7.409650134709146, "Episode Reward": 21872.70827739306, "Mean Reward": 60.58921960496692, "Episode": 2545, "Episode Step": 361}
{"Training Time": 7.411375718315442, "Episode Reward": 6318.641062467871, "Mean Reward": 43.278363441560764, "Episode": 2546, "Episode Step": 146}
{"Training Time": 7.420988169974751, "Episode Reward": 43535.82605908898, "Mean Reward": 55.67241184026723, "Episode": 2547, "Episode Step": 782}
{"Training Time": 7.423810546398163, "Episode Reward": 15590.48473638491, "Mean Reward": 64.96035306827045, "Episode": 2548, "Episode Step": 240}
{"Training Time": 7.428195731110043, "Episode Reward": 15594.707875615975, "Mean Reward": 57.12347207185339, "Episode": 2549, "Episode Step": 273}
{"Training Time": 7.431721892489327, "Episode Reward": 15322.003619098785, "Mean Reward": 58.930783150379945, "Episode": 2550, "Episode Step": 260}
{"Training Time": 7.434244707756572, "Episode Reward": 11387.288670422171, "Mean Reward": 52.71892902973227, "Episode": 2551, "Episode Step": 216}
{"Training Time": 7.437333363029692, "Episode Reward": 16108.878417625981, "Mean Reward": 61.250488279946694, "Episode": 2552, "Episode Step": 263}
{"Training Time": 7.444051841696103, "Episode Reward": 29506.037002781828, "Mean Reward": 55.254750941539, "Episode": 2553, "Episode Step": 534}
{"Training Time": 7.451787362496058, "Episode Reward": 36937.774272812014, "Mean Reward": 55.96632465577578, "Episode": 2554, "Episode Step": 660}
{"Training Time": 7.454967922502094, "Episode Reward": 14104.016399449334, "Mean Reward": 52.23709777573828, "Episode": 2555, "Episode Step": 270}
{"Training Time": 7.470215059717496, "Episode Reward": 72424.67745369623, "Mean Reward": 57.2980043146331, "Episode": 2556, "Episode Step": 1264}
{"Training Time": 7.4784193674723305, "Episode Reward": 40866.056491574476, "Mean Reward": 58.80008128284097, "Episode": 2557, "Episode Step": 695}
{"Training Time": 7.481480478909281, "Episode Reward": 15776.798232185405, "Mean Reward": 60.44750280530807, "Episode": 2558, "Episode Step": 261}
{"Training Time": 7.49435578028361, "Episode Reward": 58347.44115006826, "Mean Reward": 55.14881016074505, "Episode": 2559, "Episode Step": 1058}
{"Training Time": 7.497230670584573, "Episode Reward": 14424.323673250177, "Mean Reward": 59.604643277893295, "Episode": 2560, "Episode Step": 242}
{"Training Time": 7.499883494973183, "Episode Reward": 12379.308607750569, "Mean Reward": 55.26477057031504, "Episode": 2561, "Episode Step": 224}
{"Training Time": 7.502209726638264, "Episode Reward": 6446.103937820331, "Mean Reward": 40.798126188736276, "Episode": 2562, "Episode Step": 158}
{"Training Time": 7.50504786113898, "Episode Reward": 15295.824871349152, "Mean Reward": 63.46815299315001, "Episode": 2563, "Episode Step": 241}
{"Training Time": 7.508279738028844, "Episode Reward": 15291.747164969025, "Mean Reward": 55.80929622251469, "Episode": 2564, "Episode Step": 274}
{"Training Time": 7.512042568590906, "Episode Reward": 16038.894255141422, "Mean Reward": 56.875511543054685, "Episode": 2565, "Episode Step": 282}
{"Training Time": 7.514872654146618, "Episode Reward": 15042.126779351393, "Mean Reward": 62.157548675005756, "Episode": 2566, "Episode Step": 242}
{"Training Time": 7.517904593348503, "Episode Reward": 15380.171262359012, "Mean Reward": 59.84502436715569, "Episode": 2567, "Episode Step": 257}
{"Training Time": 7.521659367746777, "Episode Reward": 15751.168671500776, "Mean Reward": 55.26725849649395, "Episode": 2568, "Episode Step": 285}
{"Training Time": 7.5367179713646575, "Episode Reward": 79615.06763908513, "Mean Reward": 62.247902767072034, "Episode": 2569, "Episode Step": 1279}
{"Training Time": 7.539587040278647, "Episode Reward": 15092.228435209665, "Mean Reward": 61.60093238861088, "Episode": 2570, "Episode Step": 245}
{"Training Time": 7.548982164992227, "Episode Reward": 44567.94236573137, "Mean Reward": 58.106834896651065, "Episode": 2571, "Episode Step": 767}
{"Training Time": 7.556656353871028, "Episode Reward": 37359.602489355515, "Mean Reward": 57.47631152208541, "Episode": 2572, "Episode Step": 650}
{"Training Time": 7.559746454159419, "Episode Reward": 14435.513114115643, "Mean Reward": 55.308479364427754, "Episode": 2573, "Episode Step": 261}
{"Training Time": 7.616608677771357, "Episode Reward": 271225.6972806931, "Mean Reward": 56.03836720675477, "Episode": 2574, "Episode Step": 4840}
{"Training Time": 7.640863187776672, "Episode Reward": 120060.56448935368, "Mean Reward": 58.53757410499936, "Episode": 2575, "Episode Step": 2051}
{"Training Time": 7.64405315776666, "Episode Reward": 15557.777551130557, "Mean Reward": 59.15504772292987, "Episode": 2576, "Episode Step": 263}
{"Training Time": 7.648018452194002, "Episode Reward": 15727.08747288483, "Mean Reward": 54.04497413362485, "Episode": 2577, "Episode Step": 291}
{"Training Time": 7.6563777955373125, "Episode Reward": 44388.81064701742, "Mean Reward": 62.96285198158499, "Episode": 2578, "Episode Step": 705}
{"Training Time": 7.659533826973703, "Episode Reward": 15302.085418849558, "Mean Reward": 58.182834292203644, "Episode": 2579, "Episode Step": 263}
{"Training Time": 7.700647636122174, "Episode Reward": 191609.92253319253, "Mean Reward": 55.65202513307944, "Episode": 2580, "Episode Step": 3443}
{"Training Time": 7.702732902500364, "Episode Reward": 9062.474875219454, "Mean Reward": 51.785570715539734, "Episode": 2581, "Episode Step": 175}
{"Training Time": 7.705807518627909, "Episode Reward": 16013.961373336853, "Mean Reward": 62.55453661459708, "Episode": 2582, "Episode Step": 256}
{"Training Time": 7.728762985865275, "Episode Reward": 102044.7651978895, "Mean Reward": 54.221448032884965, "Episode": 2583, "Episode Step": 1882}
{"Training Time": 7.731491218871541, "Episode Reward": 14113.956090870211, "Mean Reward": 62.451133145443414, "Episode": 2584, "Episode Step": 226}
{"Training Time": 7.73368250058757, "Episode Reward": 8501.058391511731, "Mean Reward": 46.45387099186738, "Episode": 2585, "Episode Step": 183}
{"Training Time": 7.743309109475877, "Episode Reward": 45548.81789819288, "Mean Reward": 58.69693028117639, "Episode": 2586, "Episode Step": 776}
{"Training Time": 7.745471397505866, "Episode Reward": 9430.34248240998, "Mean Reward": 52.979452148370676, "Episode": 2587, "Episode Step": 178}
{"Training Time": 7.74674638417032, "Episode Reward": 5883.95099808175, "Mean Reward": 56.576451904632215, "Episode": 2588, "Episode Step": 104}
{"Training Time": 7.7885304266876645, "Episode Reward": 205662.27837918495, "Mean Reward": 58.86155649089438, "Episode": 2589, "Episode Step": 3494}
{"Training Time": 7.796219305528535, "Episode Reward": 35529.33254620314, "Mean Reward": 54.913960658737466, "Episode": 2590, "Episode Step": 647}
{"Training Time": 7.799426559474733, "Episode Reward": 15338.510759481374, "Mean Reward": 57.881172677288205, "Episode": 2591, "Episode Step": 265}
{"Training Time": 7.803145468036334, "Episode Reward": 17138.069735903533, "Mean Reward": 63.2401097265813, "Episode": 2592, "Episode Step": 271}
{"Training Time": 7.808865548306041, "Episode Reward": 28791.000047145262, "Mean Reward": 59.732365243039965, "Episode": 2593, "Episode Step": 482}
{"Training Time": 7.812154448628426, "Episode Reward": 15667.130652026535, "Mean Reward": 57.17930894900196, "Episode": 2594, "Episode Step": 274}
{"Training Time": 7.82529026442104, "Episode Reward": 65898.77232863293, "Mean Reward": 62.2273581951208, "Episode": 2595, "Episode Step": 1059}
{"Training Time": 7.828430132468541, "Episode Reward": 15190.978726744386, "Mean Reward": 58.426841256709174, "Episode": 2596, "Episode Step": 260}
{"Training Time": 7.831720463898447, "Episode Reward": 14423.48900534725, "Mean Reward": 52.449050928535456, "Episode": 2597, "Episode Step": 275}
{"Training Time": 7.837353594700495, "Episode Reward": 25606.532560256874, "Mean Reward": 59.828347103403914, "Episode": 2598, "Episode Step": 428}
{"Training Time": 7.841191890305943, "Episode Reward": 11601.757149504994, "Mean Reward": 52.49663868554296, "Episode": 2599, "Episode Step": 221}
{"Training Time": 7.844607992238468, "Episode Reward": 15319.741453421373, "Mean Reward": 59.60988892381857, "Episode": 2600, "Episode Step": 257}
{"Training Time": 7.852807498309347, "Episode Reward": 36401.48253495847, "Mean Reward": 56.788584297907136, "Episode": 2601, "Episode Step": 641}
{"Training Time": 7.855153516663445, "Episode Reward": 8777.700789225064, "Mean Reward": 45.24588035683023, "Episode": 2602, "Episode Step": 194}
{"Training Time": 7.85848167889648, "Episode Reward": 15427.539766818632, "Mean Reward": 56.100144606613206, "Episode": 2603, "Episode Step": 275}
{"Training Time": 7.861885921690199, "Episode Reward": 14022.169242194417, "Mean Reward": 58.67016419328208, "Episode": 2604, "Episode Step": 239}
{"Training Time": 7.8668594505389535, "Episode Reward": 25982.937539294337, "Mean Reward": 62.76071869394767, "Episode": 2605, "Episode Step": 414}
{"Training Time": 7.876192184156841, "Episode Reward": 43534.24894462617, "Mean Reward": 55.670395069854436, "Episode": 2606, "Episode Step": 782}
{"Training Time": 7.880815068615807, "Episode Reward": 22231.07817572538, "Mean Reward": 64.8136389962839, "Episode": 2607, "Episode Step": 343}
{"Training Time": 7.883042545848423, "Episode Reward": 9555.54719285871, "Mean Reward": 51.93232170031908, "Episode": 2608, "Episode Step": 184}
{"Training Time": 7.886283439464039, "Episode Reward": 15998.45650606873, "Mean Reward": 59.253542615069364, "Episode": 2609, "Episode Step": 270}
{"Training Time": 7.9006833791732785, "Episode Reward": 75516.32357868299, "Mean Reward": 64.21456086622703, "Episode": 2610, "Episode Step": 1176}
{"Training Time": 7.903779281112882, "Episode Reward": 15794.119470885375, "Mean Reward": 61.93772341523676, "Episode": 2611, "Episode Step": 255}
{"Training Time": 7.9090455424785615, "Episode Reward": 25657.49650825554, "Mean Reward": 58.0486346340623, "Episode": 2612, "Episode Step": 442}
{"Training Time": 7.9136835075087015, "Episode Reward": 21726.20907605027, "Mean Reward": 61.89803155569877, "Episode": 2613, "Episode Step": 351}
{"Training Time": 7.921834929453002, "Episode Reward": 45760.43532970655, "Mean Reward": 65.74775191049793, "Episode": 2614, "Episode Step": 696}
{"Training Time": 7.931201511687703, "Episode Reward": 43932.50920507127, "Mean Reward": 55.12234530121866, "Episode": 2615, "Episode Step": 797}
{"Training Time": 7.9377229289213815, "Episode Reward": 30496.107531057474, "Mean Reward": 59.56271002159663, "Episode": 2616, "Episode Step": 512}
{"Training Time": 7.940442844430605, "Episode Reward": 14391.394522548751, "Mean Reward": 62.57128053282066, "Episode": 2617, "Episode Step": 230}
{"Training Time": 7.948817686637242, "Episode Reward": 38214.275208612395, "Mean Reward": 54.20464568597503, "Episode": 2618, "Episode Step": 705}
{"Training Time": 7.957863142225477, "Episode Reward": 46224.63023528782, "Mean Reward": 63.32141128121619, "Episode": 2619, "Episode Step": 730}
{"Training Time": 7.965325001411967, "Episode Reward": 35868.986450373886, "Mean Reward": 56.84466949346099, "Episode": 2620, "Episode Step": 631}
{"Training Time": 7.966718081964387, "Episode Reward": 5965.299110046806, "Mean Reward": 51.424992327989706, "Episode": 2621, "Episode Step": 116}
{"Training Time": 7.975766883360015, "Episode Reward": 46812.3095988457, "Mean Reward": 65.10752378142656, "Episode": 2622, "Episode Step": 719}
{"Training Time": 7.978752759165234, "Episode Reward": 15578.217521762996, "Mean Reward": 61.81832349905951, "Episode": 2623, "Episode Step": 252}
{"Training Time": 7.981941639449861, "Episode Reward": 16282.485285250259, "Mean Reward": 61.212350696429546, "Episode": 2624, "Episode Step": 266}
{"Training Time": 7.991087311969863, "Episode Reward": 46831.5100567971, "Mean Reward": 64.32899733076525, "Episode": 2625, "Episode Step": 728}
{"Training Time": 7.993937641978264, "Episode Reward": 13579.97349269379, "Mean Reward": 57.058712154175595, "Episode": 2626, "Episode Step": 238}
{"Training Time": 7.997171689139472, "Episode Reward": 15319.381541527822, "Mean Reward": 56.3212556673817, "Episode": 2627, "Episode Step": 272}
{"Training Time": 8.005282310578558, "Episode Reward": 36970.45198020624, "Mean Reward": 57.05316663612074, "Episode": 2628, "Episode Step": 648}
{"Training Time": 8.007646455830997, "Episode Reward": 9319.317471310307, "Mean Reward": 47.791371647745166, "Episode": 2629, "Episode Step": 195}
{"Training Time": 8.009022286666765, "Episode Reward": 6162.090534622284, "Mean Reward": 54.53177464267508, "Episode": 2630, "Episode Step": 113}
{"Training Time": 8.011165039141973, "Episode Reward": 6451.442083181708, "Mean Reward": 47.43707414104197, "Episode": 2631, "Episode Step": 136}
{"Training Time": 8.013426000012291, "Episode Reward": 9167.800723996772, "Mean Reward": 49.02567232083835, "Episode": 2632, "Episode Step": 187}
{"Training Time": 8.014836893876394, "Episode Reward": 5809.150183711087, "Mean Reward": 50.51434942357467, "Episode": 2633, "Episode Step": 115}
{"Training Time": 8.01833391222689, "Episode Reward": 17089.111669653732, "Mean Reward": 67.01612419472052, "Episode": 2634, "Episode Step": 255}
{"Training Time": 8.020525148908296, "Episode Reward": 8930.518910551558, "Mean Reward": 49.06878522281076, "Episode": 2635, "Episode Step": 182}
{"Training Time": 8.029656663603253, "Episode Reward": 44697.979947079075, "Mean Reward": 57.674812834940745, "Episode": 2636, "Episode Step": 775}
{"Training Time": 8.03854845000638, "Episode Reward": 45333.68815386963, "Mean Reward": 63.85026500545019, "Episode": 2637, "Episode Step": 710}
{"Training Time": 8.049665459725592, "Episode Reward": 60622.550588025384, "Mean Reward": 64.49207509364402, "Episode": 2638, "Episode Step": 940}
{"Training Time": 8.060236868858338, "Episode Reward": 53547.33076583614, "Mean Reward": 60.23321795932074, "Episode": 2639, "Episode Step": 889}
{"Training Time": 8.069302778906293, "Episode Reward": 46737.25178652293, "Mean Reward": 64.64350177942315, "Episode": 2640, "Episode Step": 723}
{"Training Time": 8.077475851972897, "Episode Reward": 44076.017907581365, "Mean Reward": 63.693667496504865, "Episode": 2641, "Episode Step": 692}
{"Training Time": 8.078990088038974, "Episode Reward": 6083.430346602667, "Mean Reward": 47.15837477986563, "Episode": 2642, "Episode Step": 129}
{"Training Time": 8.084323890010516, "Episode Reward": 25274.296231974266, "Mean Reward": 61.34537920382103, "Episode": 2643, "Episode Step": 412}
{"Training Time": 8.086662771105766, "Episode Reward": 9342.476402318556, "Mean Reward": 48.157094857312146, "Episode": 2644, "Episode Step": 194}
{"Training Time": 8.093714533580673, "Episode Reward": 33721.08825914018, "Mean Reward": 57.2514231903908, "Episode": 2645, "Episode Step": 589}
{"Training Time": 8.097343657215436, "Episode Reward": 15611.115691668092, "Mean Reward": 59.35785434094331, "Episode": 2646, "Episode Step": 263}
{"Training Time": 8.099573688639534, "Episode Reward": 8958.475978709912, "Mean Reward": 47.90628865620274, "Episode": 2647, "Episode Step": 187}
{"Training Time": 8.101478257245487, "Episode Reward": 6986.074079547346, "Mean Reward": 43.937572827341796, "Episode": 2648, "Episode Step": 159}
{"Training Time": 8.121318314737744, "Episode Reward": 98198.17250708184, "Mean Reward": 61.64354834091766, "Episode": 2649, "Episode Step": 1593}
{"Training Time": 8.123463018337885, "Episode Reward": 7045.653688668011, "Mean Reward": 47.929616929714356, "Episode": 2650, "Episode Step": 147}
{"Training Time": 8.126612262792058, "Episode Reward": 15220.273123337263, "Mean Reward": 58.31522269477879, "Episode": 2651, "Episode Step": 261}
{"Training Time": 8.136935809453329, "Episode Reward": 51886.00340166772, "Mean Reward": 62.96845073017927, "Episode": 2652, "Episode Step": 824}
{"Training Time": 8.139389740029971, "Episode Reward": 9649.442084927614, "Mean Reward": 46.61566224602712, "Episode": 2653, "Episode Step": 207}
{"Training Time": 8.14192816807164, "Episode Reward": 9364.542299685987, "Mean Reward": 44.38171706012316, "Episode": 2654, "Episode Step": 211}
{"Training Time": 8.14531594057878, "Episode Reward": 15970.77605559288, "Mean Reward": 64.13966287386698, "Episode": 2655, "Episode Step": 249}
{"Training Time": 8.149559736119377, "Episode Reward": 22050.053513962102, "Mean Reward": 61.250148649894726, "Episode": 2656, "Episode Step": 360}
{"Training Time": 8.15154300192992, "Episode Reward": 6526.390868610876, "Mean Reward": 39.08018484198129, "Episode": 2657, "Episode Step": 167}
{"Training Time": 8.154147702190611, "Episode Reward": 8315.196032987324, "Mean Reward": 45.68789029113914, "Episode": 2658, "Episode Step": 182}
{"Training Time": 8.158310503032473, "Episode Reward": 21698.941524315185, "Mean Reward": 61.99697578375767, "Episode": 2659, "Episode Step": 350}
{"Training Time": 8.160711122221416, "Episode Reward": 8750.850116845648, "Mean Reward": 43.75425058422824, "Episode": 2660, "Episode Step": 200}
{"Training Time": 8.164244969156053, "Episode Reward": 17100.774628376697, "Mean Reward": 65.77221010914114, "Episode": 2661, "Episode Step": 260}
{"Training Time": 8.177044359180663, "Episode Reward": 65543.10433313822, "Mean Reward": 60.4641183885039, "Episode": 2662, "Episode Step": 1084}
{"Training Time": 8.179493180844519, "Episode Reward": 8648.573905674939, "Mean Reward": 43.027730874004675, "Episode": 2663, "Episode Step": 201}
{"Training Time": 8.186162335276604, "Episode Reward": 33975.16010726415, "Mean Reward": 65.84333354120959, "Episode": 2664, "Episode Step": 516}
{"Training Time": 8.199569613602426, "Episode Reward": 71788.28850476815, "Mean Reward": 63.75514076800013, "Episode": 2665, "Episode Step": 1126}
{"Training Time": 8.202838038073645, "Episode Reward": 14764.699381675102, "Mean Reward": 52.92006946836954, "Episode": 2666, "Episode Step": 279}
{"Training Time": 8.214558396935463, "Episode Reward": 55518.97613925409, "Mean Reward": 58.37957533044594, "Episode": 2667, "Episode Step": 951}
{"Training Time": 8.216909098890092, "Episode Reward": 9408.733163028925, "Mean Reward": 48.498624551695485, "Episode": 2668, "Episode Step": 194}
{"Training Time": 8.21886440469159, "Episode Reward": 7189.935914060619, "Mean Reward": 43.575369176124966, "Episode": 2669, "Episode Step": 165}
{"Training Time": 8.249464749164051, "Episode Reward": 159917.91009751952, "Mean Reward": 62.2975886628436, "Episode": 2670, "Episode Step": 2567}
{"Training Time": 8.250730868048137, "Episode Reward": 6078.075597727654, "Mean Reward": 57.886434264072896, "Episode": 2671, "Episode Step": 105}
{"Training Time": 8.253866766691209, "Episode Reward": 15775.271265475443, "Mean Reward": 59.75481539952819, "Episode": 2672, "Episode Step": 264}
{"Training Time": 8.273839036689864, "Episode Reward": 104997.28231490623, "Mean Reward": 63.71194315224893, "Episode": 2673, "Episode Step": 1648}
{"Training Time": 8.27513490696748, "Episode Reward": 6046.694883761358, "Mean Reward": 55.474264988636314, "Episode": 2674, "Episode Step": 109}
{"Training Time": 8.277252385020256, "Episode Reward": 8674.260224587357, "Mean Reward": 48.19033458104087, "Episode": 2675, "Episode Step": 180}
{"Training Time": 8.291868459184965, "Episode Reward": 75204.68817226727, "Mean Reward": 62.82764258334776, "Episode": 2676, "Episode Step": 1197}
{"Training Time": 8.31310395638148, "Episode Reward": 111765.75649580016, "Mean Reward": 62.126601720845, "Episode": 2677, "Episode Step": 1799}
{"Training Time": 8.315174071921243, "Episode Reward": 8915.29359557273, "Mean Reward": 51.83310229984145, "Episode": 2678, "Episode Step": 172}
{"Training Time": 8.318794634143512, "Episode Reward": 16648.960140164716, "Mean Reward": 63.30403095119664, "Episode": 2679, "Episode Step": 263}
{"Training Time": 8.324596391386455, "Episode Reward": 29400.449402913582, "Mean Reward": 59.3948472786133, "Episode": 2680, "Episode Step": 495}
{"Training Time": 8.326415702237023, "Episode Reward": 6875.316253407401, "Mean Reward": 45.23234377241711, "Episode": 2681, "Episode Step": 152}
{"Training Time": 8.328544207480219, "Episode Reward": 7129.985910427653, "Mean Reward": 50.567275960479805, "Episode": 2682, "Episode Step": 141}
{"Training Time": 8.331431179443996, "Episode Reward": 16155.672917080046, "Mean Reward": 65.9415221105308, "Episode": 2683, "Episode Step": 245}
{"Training Time": 8.333587912784683, "Episode Reward": 7227.976188961011, "Mean Reward": 39.93357010475697, "Episode": 2684, "Episode Step": 181}
{"Training Time": 8.344468279149797, "Episode Reward": 54513.270324562014, "Mean Reward": 60.637675555686336, "Episode": 2685, "Episode Step": 899}
{"Training Time": 8.370642374753952, "Episode Reward": 140455.50570560968, "Mean Reward": 62.928093954126204, "Episode": 2686, "Episode Step": 2232}
{"Training Time": 8.372791822751363, "Episode Reward": 8249.2284546846, "Mean Reward": 44.832763340677175, "Episode": 2687, "Episode Step": 184}
{"Training Time": 8.375328640275532, "Episode Reward": 8581.304568888165, "Mean Reward": 48.209576229708794, "Episode": 2688, "Episode Step": 178}
{"Training Time": 8.383437455031608, "Episode Reward": 45400.395974711784, "Mean Reward": 65.13686653473714, "Episode": 2689, "Episode Step": 697}
{"Training Time": 8.385667970577876, "Episode Reward": 9223.309523681322, "Mean Reward": 48.54373433516486, "Episode": 2690, "Episode Step": 190}
{"Training Time": 8.401778657237688, "Episode Reward": 86786.58625349135, "Mean Reward": 65.0574109846262, "Episode": 2691, "Episode Step": 1334}
{"Training Time": 8.420442037251261, "Episode Reward": 107851.5872809171, "Mean Reward": 67.23914419009795, "Episode": 2692, "Episode Step": 1604}
{"Training Time": 8.421723120278783, "Episode Reward": 5989.136795725817, "Mean Reward": 55.973241081549695, "Episode": 2693, "Episode Step": 107}
{"Training Time": 8.42493784752157, "Episode Reward": 15585.495921692323, "Mean Reward": 65.21128000708084, "Episode": 2694, "Episode Step": 239}
{"Training Time": 8.434164849983322, "Episode Reward": 52168.70517469771, "Mean Reward": 65.9528510426014, "Episode": 2695, "Episode Step": 791}
{"Training Time": 8.437135672767957, "Episode Reward": 16061.614987407162, "Mean Reward": 63.484644219000636, "Episode": 2696, "Episode Step": 253}
{"Training Time": 8.43972240553962, "Episode Reward": 8829.887052333926, "Mean Reward": 47.98851658877134, "Episode": 2697, "Episode Step": 184}
{"Training Time": 8.452439867191844, "Episode Reward": 68698.3439876562, "Mean Reward": 62.738213687357266, "Episode": 2698, "Episode Step": 1095}
{"Training Time": 8.454537046419249, "Episode Reward": 4665.635684846187, "Mean Reward": 54.25157773076962, "Episode": 2699, "Episode Step": 86}
{"Training Time": 8.459791386127472, "Episode Reward": 26123.947535773044, "Mean Reward": 63.561916145433194, "Episode": 2700, "Episode Step": 411}
{"Training Time": 8.478403948876593, "Episode Reward": 103929.99544101501, "Mean Reward": 64.67330145676105, "Episode": 2701, "Episode Step": 1607}
{"Training Time": 8.480484795835283, "Episode Reward": 8754.360058708013, "Mean Reward": 49.181798082629285, "Episode": 2702, "Episode Step": 178}
{"Training Time": 8.483055928349495, "Episode Reward": 8578.588693114918, "Mean Reward": 47.395517641518886, "Episode": 2703, "Episode Step": 181}
{"Training Time": 8.485146197213068, "Episode Reward": 8962.81795852862, "Mean Reward": 50.0716087068638, "Episode": 2704, "Episode Step": 179}
{"Training Time": 8.48675569170051, "Episode Reward": 6895.6717188716575, "Mean Reward": 50.70346852111513, "Episode": 2705, "Episode Step": 136}
{"Training Time": 8.4893546336227, "Episode Reward": 9081.63500064561, "Mean Reward": 50.17477900909177, "Episode": 2706, "Episode Step": 181}
{"Training Time": 8.496733731362555, "Episode Reward": 37822.72015008607, "Mean Reward": 60.13151057247388, "Episode": 2707, "Episode Step": 629}
{"Training Time": 8.50710032860438, "Episode Reward": 53928.217871754285, "Mean Reward": 60.72997508080437, "Episode": 2708, "Episode Step": 888}
{"Training Time": 8.5096646296978, "Episode Reward": 8784.410976614347, "Mean Reward": 49.35062346412554, "Episode": 2709, "Episode Step": 178}
{"Training Time": 8.52633925696214, "Episode Reward": 89012.0285461349, "Mean Reward": 62.906027241084736, "Episode": 2710, "Episode Step": 1415}
{"Training Time": 8.527613594465786, "Episode Reward": 5335.981806587531, "Mean Reward": 52.31354712340716, "Episode": 2711, "Episode Step": 102}
{"Training Time": 8.530272916091812, "Episode Reward": 8236.748615586213, "Mean Reward": 46.53530291291646, "Episode": 2712, "Episode Step": 177}
{"Training Time": 8.53246363169617, "Episode Reward": 9075.683603141953, "Mean Reward": 50.141898359900296, "Episode": 2713, "Episode Step": 181}
{"Training Time": 8.533939219978121, "Episode Reward": 5181.320882034189, "Mean Reward": 42.4698432953622, "Episode": 2714, "Episode Step": 122}
{"Training Time": 8.53658116194937, "Episode Reward": 8430.026926685772, "Mean Reward": 47.09512249545124, "Episode": 2715, "Episode Step": 179}
{"Training Time": 8.544035533335474, "Episode Reward": 39399.16923486935, "Mean Reward": 62.737530628772845, "Episode": 2716, "Episode Step": 628}
{"Training Time": 8.546188866098722, "Episode Reward": 9482.165758073894, "Mean Reward": 52.97299306186533, "Episode": 2717, "Episode Step": 179}
{"Training Time": 8.547882778313426, "Episode Reward": 5597.930339685787, "Mean Reward": 54.88166999691948, "Episode": 2718, "Episode Step": 102}
{"Training Time": 8.550604954428144, "Episode Reward": 14352.66859105659, "Mean Reward": 62.950300837967504, "Episode": 2719, "Episode Step": 228}
{"Training Time": 8.552686333325173, "Episode Reward": 9265.944304523433, "Mean Reward": 52.647410821155866, "Episode": 2720, "Episode Step": 176}
{"Training Time": 8.556136857204967, "Episode Reward": 16986.018207857935, "Mean Reward": 67.67337931417504, "Episode": 2721, "Episode Step": 251}
{"Training Time": 8.558988875548044, "Episode Reward": 15237.06746588757, "Mean Reward": 63.75342035936222, "Episode": 2722, "Episode Step": 239}
{"Training Time": 8.560661715533998, "Episode Reward": 6651.508207894176, "Mean Reward": 48.19933483981287, "Episode": 2723, "Episode Step": 138}
{"Training Time": 8.566024801135063, "Episode Reward": 27469.83058634495, "Mean Reward": 67.65968124715505, "Episode": 2724, "Episode Step": 406}
{"Training Time": 8.595458144744237, "Episode Reward": 157656.18278882798, "Mean Reward": 63.67374102941356, "Episode": 2725, "Episode Step": 2476}
{"Training Time": 8.597622729738553, "Episode Reward": 8416.041167520094, "Mean Reward": 47.01698976268209, "Episode": 2726, "Episode Step": 179}
{"Training Time": 8.617270331382752, "Episode Reward": 105238.31318108617, "Mean Reward": 64.68242973637749, "Episode": 2727, "Episode Step": 1627}
{"Training Time": 8.63743183804883, "Episode Reward": 107279.56030178175, "Mean Reward": 62.77329450075, "Episode": 2728, "Episode Step": 1709}
{"Training Time": 8.640529629190763, "Episode Reward": 15394.28242801146, "Mean Reward": 59.667761348881626, "Episode": 2729, "Episode Step": 258}
{"Training Time": 8.64310866885715, "Episode Reward": 8634.7824272085, "Mean Reward": 47.971013484491664, "Episode": 2730, "Episode Step": 180}
{"Training Time": 8.646073246399562, "Episode Reward": 16112.457548178612, "Mean Reward": 65.23262165254499, "Episode": 2731, "Episode Step": 247}
{"Training Time": 8.649087247517373, "Episode Reward": 16645.773414075724, "Mean Reward": 65.53454100029812, "Episode": 2732, "Episode Step": 254}
{"Training Time": 8.651723496384092, "Episode Reward": 8737.58220922101, "Mean Reward": 48.00869345725829, "Episode": 2733, "Episode Step": 182}
{"Training Time": 8.654592598610455, "Episode Reward": 13903.369988499157, "Mean Reward": 57.215514355963606, "Episode": 2734, "Episode Step": 243}
{"Training Time": 8.656663906971614, "Episode Reward": 8097.303533339202, "Mean Reward": 46.80522273606475, "Episode": 2735, "Episode Step": 173}
{"Training Time": 8.65925659444597, "Episode Reward": 8925.115844183134, "Mean Reward": 49.310032288304605, "Episode": 2736, "Episode Step": 181}
{"Training Time": 8.665137110551198, "Episode Reward": 32983.88299379755, "Mean Reward": 66.23269677469388, "Episode": 2737, "Episode Step": 498}
{"Training Time": 8.666797644694647, "Episode Reward": 7109.981183034347, "Mean Reward": 51.15094376283703, "Episode": 2738, "Episode Step": 139}
{"Training Time": 8.675550066100227, "Episode Reward": 45101.02867983118, "Mean Reward": 63.88247688361357, "Episode": 2739, "Episode Step": 706}
{"Training Time": 8.682388949725363, "Episode Reward": 36251.24196421718, "Mean Reward": 61.7568006204722, "Episode": 2740, "Episode Step": 587}
{"Training Time": 8.68398095442189, "Episode Reward": 6557.840720991341, "Mean Reward": 48.57659793326919, "Episode": 2741, "Episode Step": 135}
{"Training Time": 8.686579973366525, "Episode Reward": 8512.014811067967, "Mean Reward": 47.02770613849706, "Episode": 2742, "Episode Step": 181}
{"Training Time": 8.699877941939565, "Episode Reward": 71906.01872578487, "Mean Reward": 63.97332626849188, "Episode": 2743, "Episode Step": 1124}
{"Training Time": 8.701359210809072, "Episode Reward": 6776.942264195462, "Mean Reward": 54.65276019512469, "Episode": 2744, "Episode Step": 124}
{"Training Time": 8.704862139754825, "Episode Reward": 17326.25058296498, "Mean Reward": 67.15601001149217, "Episode": 2745, "Episode Step": 258}
{"Training Time": 8.717561785247591, "Episode Reward": 64529.97052879311, "Mean Reward": 59.20180782458083, "Episode": 2746, "Episode Step": 1090}
{"Training Time": 8.725819087492095, "Episode Reward": 46289.5744257117, "Mean Reward": 65.8457673196468, "Episode": 2747, "Episode Step": 703}
{"Training Time": 8.733773545026779, "Episode Reward": 37936.0583179062, "Mean Reward": 60.02540873086424, "Episode": 2748, "Episode Step": 632}
{"Training Time": 8.743110935025745, "Episode Reward": 41726.45642491083, "Mean Reward": 59.609223464158326, "Episode": 2749, "Episode Step": 700}
{"Training Time": 8.746345023314158, "Episode Reward": 15566.462343595174, "Mean Reward": 62.767993320948285, "Episode": 2750, "Episode Step": 248}
{"Training Time": 8.748930222789447, "Episode Reward": 8843.020673129207, "Mean Reward": 49.96056877474128, "Episode": 2751, "Episode Step": 177}
{"Training Time": 8.75126410279009, "Episode Reward": 8811.016178358244, "Mean Reward": 46.37376935978023, "Episode": 2752, "Episode Step": 190}
{"Training Time": 8.75425712664922, "Episode Reward": 15147.20848272036, "Mean Reward": 61.07745355935629, "Episode": 2753, "Episode Step": 248}
{"Training Time": 8.756802753872341, "Episode Reward": 8339.689766000542, "Mean Reward": 47.929251528738746, "Episode": 2754, "Episode Step": 174}
{"Training Time": 8.758959630264176, "Episode Reward": 8037.473862777446, "Mean Reward": 44.16194430097498, "Episode": 2755, "Episode Step": 182}
{"Training Time": 8.760375601649285, "Episode Reward": 5733.223371069314, "Mean Reward": 48.17834765604466, "Episode": 2756, "Episode Step": 119}
{"Training Time": 8.763827468355498, "Episode Reward": 16615.13467605846, "Mean Reward": 66.46053870423384, "Episode": 2757, "Episode Step": 250}
{"Training Time": 8.771449149979485, "Episode Reward": 37778.636232012366, "Mean Reward": 58.571529041879636, "Episode": 2758, "Episode Step": 645}
{"Training Time": 8.772733454969194, "Episode Reward": 5357.057124629917, "Mean Reward": 51.019591663142066, "Episode": 2759, "Episode Step": 105}
{"Training Time": 8.775884397758379, "Episode Reward": 13310.485445779466, "Mean Reward": 58.3793221306117, "Episode": 2760, "Episode Step": 228}
{"Training Time": 8.778627774715424, "Episode Reward": 14713.604109029044, "Mean Reward": 63.695255883242616, "Episode": 2761, "Episode Step": 231}
{"Training Time": 8.780768274731106, "Episode Reward": 8996.120030466269, "Mean Reward": 50.540000171158816, "Episode": 2762, "Episode Step": 178}
{"Training Time": 8.783413448068831, "Episode Reward": 7410.840535912416, "Mean Reward": 41.40134377604702, "Episode": 2763, "Episode Step": 179}
{"Training Time": 8.78502012497849, "Episode Reward": 6491.059379608177, "Mean Reward": 48.80495774141486, "Episode": 2764, "Episode Step": 133}
{"Training Time": 8.789748285810152, "Episode Reward": 23243.629899812233, "Mean Reward": 58.109074749530585, "Episode": 2765, "Episode Step": 400}
{"Training Time": 8.79236642446783, "Episode Reward": 7954.117341926605, "Mean Reward": 43.945399679152516, "Episode": 2766, "Episode Step": 181}
{"Training Time": 8.794535279737579, "Episode Reward": 8605.888333048028, "Mean Reward": 48.07758845278228, "Episode": 2767, "Episode Step": 179}
{"Training Time": 8.808296756943067, "Episode Reward": 76905.86439614708, "Mean Reward": 65.78773686582299, "Episode": 2768, "Episode Step": 1169}
{"Training Time": 8.811561030017005, "Episode Reward": 13305.127180933947, "Mean Reward": 56.13977713474239, "Episode": 2769, "Episode Step": 237}
{"Training Time": 8.813728238079284, "Episode Reward": 8435.133484612023, "Mean Reward": 46.34688727808803, "Episode": 2770, "Episode Step": 182}
{"Training Time": 8.817819994423125, "Episode Reward": 20459.354847389735, "Mean Reward": 58.79124956146476, "Episode": 2771, "Episode Step": 348}
{"Training Time": 8.825747681922383, "Episode Reward": 37175.8897734237, "Mean Reward": 58.54470830460426, "Episode": 2772, "Episode Step": 635}
{"Training Time": 8.832954266667366, "Episode Reward": 32745.329425171185, "Mean Reward": 55.03416710112804, "Episode": 2773, "Episode Step": 595}
{"Training Time": 8.83513061026732, "Episode Reward": 9109.71090644153, "Mean Reward": 52.05549089395161, "Episode": 2774, "Episode Step": 175}
{"Training Time": 8.83775787777371, "Episode Reward": 8888.084522047151, "Mean Reward": 50.21516679122684, "Episode": 2775, "Episode Step": 177}
{"Training Time": 8.839903293914265, "Episode Reward": 9006.851835193886, "Mean Reward": 50.317608017842936, "Episode": 2776, "Episode Step": 179}
{"Training Time": 8.843528368605508, "Episode Reward": 17116.170140313963, "Mean Reward": 56.489010364072485, "Episode": 2777, "Episode Step": 303}
{"Training Time": 8.847018171416389, "Episode Reward": 16815.350964719582, "Mean Reward": 66.2021691524393, "Episode": 2778, "Episode Step": 254}
{"Training Time": 8.854710089166959, "Episode Reward": 36042.305206233235, "Mean Reward": 55.53513899265521, "Episode": 2779, "Episode Step": 649}
{"Training Time": 8.85767454750008, "Episode Reward": 15605.819637594552, "Mean Reward": 62.42327855037821, "Episode": 2780, "Episode Step": 250}
{"Training Time": 8.865604366130299, "Episode Reward": 37364.05308824754, "Mean Reward": 59.026940107816024, "Episode": 2781, "Episode Step": 633}
{"Training Time": 8.867254699468612, "Episode Reward": 6486.032358951628, "Mean Reward": 47.69141440405609, "Episode": 2782, "Episode Step": 136}
{"Training Time": 8.872610525290172, "Episode Reward": 26744.136087613453, "Mean Reward": 59.69673233842288, "Episode": 2783, "Episode Step": 448}
{"Training Time": 8.874802765581343, "Episode Reward": 6389.944359736457, "Mean Reward": 44.99960816715815, "Episode": 2784, "Episode Step": 142}
{"Training Time": 8.87642247027821, "Episode Reward": 6784.987493138186, "Mean Reward": 50.25916661583842, "Episode": 2785, "Episode Step": 135}
{"Training Time": 8.879396131634712, "Episode Reward": 14285.456301371103, "Mean Reward": 58.30798490355552, "Episode": 2786, "Episode Step": 245}
{"Training Time": 8.88204834110207, "Episode Reward": 8376.608372615314, "Mean Reward": 46.53671318119619, "Episode": 2787, "Episode Step": 180}
{"Training Time": 8.884186008042759, "Episode Reward": 9030.5021952569, "Mean Reward": 51.019786413880794, "Episode": 2788, "Episode Step": 177}
{"Training Time": 8.887631342212359, "Episode Reward": 19337.620034626558, "Mean Reward": 66.91218005061093, "Episode": 2789, "Episode Step": 289}
{"Training Time": 8.902127771377563, "Episode Reward": 70433.78255860925, "Mean Reward": 60.045850433596975, "Episode": 2790, "Episode Step": 1173}
{"Training Time": 8.914583210282856, "Episode Reward": 66883.84287360404, "Mean Reward": 63.82046075725576, "Episode": 2791, "Episode Step": 1048}
{"Training Time": 8.915924203594527, "Episode Reward": 5936.667667057849, "Mean Reward": 53.96970606416227, "Episode": 2792, "Episode Step": 110}
{"Training Time": 8.929329134755664, "Episode Reward": 60579.86688755959, "Mean Reward": 56.30099153118921, "Episode": 2793, "Episode Step": 1076}
{"Training Time": 8.93750749833054, "Episode Reward": 44119.46404441194, "Mean Reward": 64.59657986004677, "Episode": 2794, "Episode Step": 683}
{"Training Time": 8.941047891378403, "Episode Reward": 17281.38802083579, "Mean Reward": 57.797284350621375, "Episode": 2795, "Episode Step": 299}
{"Training Time": 8.94462316777971, "Episode Reward": 14825.109489412687, "Mean Reward": 57.01965188235649, "Episode": 2796, "Episode Step": 260}
{"Training Time": 8.946693919698397, "Episode Reward": 9253.268687680562, "Mean Reward": 52.57539027091229, "Episode": 2797, "Episode Step": 176}
{"Training Time": 8.949270406100485, "Episode Reward": 11754.246764854652, "Mean Reward": 55.18425711199367, "Episode": 2798, "Episode Step": 213}
{"Training Time": 8.959565371407402, "Episode Reward": 43495.27224864957, "Mean Reward": 58.6980732100534, "Episode": 2799, "Episode Step": 741}
{"Training Time": 8.96670996222231, "Episode Reward": 36206.64253594869, "Mean Reward": 62.53306137469549, "Episode": 2800, "Episode Step": 579}
{"Training Time": 8.974876221087245, "Episode Reward": 45577.27042599222, "Mean Reward": 66.05401511013365, "Episode": 2801, "Episode Step": 690}
{"Training Time": 8.977061320543289, "Episode Reward": 6250.942258177329, "Mean Reward": 42.81467300121458, "Episode": 2802, "Episode Step": 146}
{"Training Time": 8.980051148864957, "Episode Reward": 16465.64949780968, "Mean Reward": 66.93353454394179, "Episode": 2803, "Episode Step": 246}
{"Training Time": 8.983058319158024, "Episode Reward": 13873.291373830158, "Mean Reward": 54.619257377284086, "Episode": 2804, "Episode Step": 254}
{"Training Time": 8.99134612666236, "Episode Reward": 36766.097842227835, "Mean Reward": 55.96057510232547, "Episode": 2805, "Episode Step": 657}
{"Training Time": 8.99414119164149, "Episode Reward": 14354.791346701672, "Mean Reward": 62.141953881825415, "Episode": 2806, "Episode Step": 231}
{"Training Time": 8.997165152496763, "Episode Reward": 16693.871466301065, "Mean Reward": 66.77548586520426, "Episode": 2807, "Episode Step": 250}
{"Training Time": 8.999739961094326, "Episode Reward": 8081.976461460058, "Mean Reward": 46.44814058310378, "Episode": 2808, "Episode Step": 174}
{"Training Time": 9.013448267247941, "Episode Reward": 74574.77930959512, "Mean Reward": 65.47390632975866, "Episode": 2809, "Episode Step": 1139}
{"Training Time": 9.015511074463527, "Episode Reward": 9218.490142412888, "Mean Reward": 53.59587292100516, "Episode": 2810, "Episode Step": 172}
{"Training Time": 9.018076603611311, "Episode Reward": 7849.920691340588, "Mean Reward": 45.11448673184246, "Episode": 2811, "Episode Step": 174}
{"Training Time": 9.021056174702114, "Episode Reward": 15436.895812460614, "Mean Reward": 61.74758324984246, "Episode": 2812, "Episode Step": 250}
{"Training Time": 9.026363571418656, "Episode Reward": 27157.323202124844, "Mean Reward": 60.890859197589336, "Episode": 2813, "Episode Step": 446}
{"Training Time": 9.028904492788845, "Episode Reward": 8185.06486720019, "Mean Reward": 46.50605038181926, "Episode": 2814, "Episode Step": 176}
{"Training Time": 9.036402841673956, "Episode Reward": 37472.23767185667, "Mean Reward": 60.051662935667736, "Episode": 2815, "Episode Step": 624}
{"Training Time": 9.060828852785958, "Episode Reward": 134298.67006723446, "Mean Reward": 65.28860965835413, "Episode": 2816, "Episode Step": 2057}
{"Training Time": 9.063461308611764, "Episode Reward": 8753.944981718529, "Mean Reward": 47.835764927423654, "Episode": 2817, "Episode Step": 183}
{"Training Time": 9.066170218918058, "Episode Reward": 13563.74813274686, "Mean Reward": 59.752194417387045, "Episode": 2818, "Episode Step": 227}
{"Training Time": 9.069194120301141, "Episode Reward": 15834.315739324727, "Mean Reward": 62.83458626716162, "Episode": 2819, "Episode Step": 252}
{"Training Time": 9.072680115832222, "Episode Reward": 16168.878019365686, "Mean Reward": 63.15967976314721, "Episode": 2820, "Episode Step": 256}
{"Training Time": 9.090699517528217, "Episode Reward": 97803.26191524227, "Mean Reward": 64.30194734729932, "Episode": 2821, "Episode Step": 1521}
{"Training Time": 9.092824883858363, "Episode Reward": 8889.456532935694, "Mean Reward": 49.38586962742052, "Episode": 2822, "Episode Step": 180}
{"Training Time": 9.100894907249344, "Episode Reward": 34570.03701370583, "Mean Reward": 54.52687226136566, "Episode": 2823, "Episode Step": 634}
{"Training Time": 9.103014752798611, "Episode Reward": 9207.029223179881, "Mean Reward": 52.91396105275794, "Episode": 2824, "Episode Step": 174}
{"Training Time": 9.10734672665596, "Episode Reward": 20066.218439468994, "Mean Reward": 55.585092630108015, "Episode": 2825, "Episode Step": 361}
{"Training Time": 9.109962315559388, "Episode Reward": 8273.720974727748, "Mean Reward": 46.48157850970645, "Episode": 2826, "Episode Step": 178}
{"Training Time": 9.117313481105699, "Episode Reward": 39421.138280709136, "Mean Reward": 64.51904792260088, "Episode": 2827, "Episode Step": 611}
{"Training Time": 9.120474500523674, "Episode Reward": 15112.885004074296, "Mean Reward": 58.12648078490114, "Episode": 2828, "Episode Step": 260}
{"Training Time": 9.123107235564126, "Episode Reward": 8586.113709060885, "Mean Reward": 47.70063171700492, "Episode": 2829, "Episode Step": 180}
{"Training Time": 9.130913546416494, "Episode Reward": 44280.552142127286, "Mean Reward": 67.19355408517039, "Episode": 2830, "Episode Step": 659}
{"Training Time": 9.134054061373075, "Episode Reward": 15315.326563586477, "Mean Reward": 58.67941212102099, "Episode": 2831, "Episode Step": 261}
{"Training Time": 9.158535749183761, "Episode Reward": 126416.10975182845, "Mean Reward": 62.706403646740306, "Episode": 2832, "Episode Step": 2016}
{"Training Time": 9.176428734461467, "Episode Reward": 98659.13205519709, "Mean Reward": 65.46724091253954, "Episode": 2833, "Episode Step": 1507}
{"Training Time": 9.179565873874559, "Episode Reward": 16032.040491278927, "Mean Reward": 60.95832886417843, "Episode": 2834, "Episode Step": 263}
{"Training Time": 9.18774276362525, "Episode Reward": 37868.760566060366, "Mean Reward": 57.81490162757308, "Episode": 2835, "Episode Step": 655}
{"Training Time": 9.189804384443494, "Episode Reward": 9100.354643919847, "Mean Reward": 52.90903862744097, "Episode": 2836, "Episode Step": 172}
{"Training Time": 9.196795356406106, "Episode Reward": 37086.00470837142, "Mean Reward": 62.75127700232051, "Episode": 2837, "Episode Step": 591}
{"Training Time": 9.206956384976705, "Episode Reward": 49438.32164282266, "Mean Reward": 61.33786804320429, "Episode": 2838, "Episode Step": 806}
{"Training Time": 9.209097665813234, "Episode Reward": 10072.210966749406, "Mean Reward": 56.58545486937869, "Episode": 2839, "Episode Step": 178}
{"Training Time": 9.212172931697634, "Episode Reward": 14301.048741054166, "Mean Reward": 55.64610405079442, "Episode": 2840, "Episode Step": 257}
{"Training Time": 9.234030480848418, "Episode Reward": 110246.75036348733, "Mean Reward": 61.282240335457104, "Episode": 2841, "Episode Step": 1799}
{"Training Time": 9.252478930817711, "Episode Reward": 105117.0185564564, "Mean Reward": 66.31988552457817, "Episode": 2842, "Episode Step": 1585}
{"Training Time": 9.256733469698164, "Episode Reward": 21531.931165625985, "Mean Reward": 59.3166147813388, "Episode": 2843, "Episode Step": 363}
{"Training Time": 9.259238097204102, "Episode Reward": 8095.327702996912, "Mean Reward": 46.79380175142724, "Episode": 2844, "Episode Step": 173}
{"Training Time": 9.261885381407208, "Episode Reward": 14532.707656840736, "Mean Reward": 63.73994586333656, "Episode": 2845, "Episode Step": 228}
{"Training Time": 9.264930530852741, "Episode Reward": 15705.71528696517, "Mean Reward": 61.591040341039886, "Episode": 2846, "Episode Step": 255}
{"Training Time": 9.267570989463064, "Episode Reward": 8474.259811441625, "Mean Reward": 46.81911498034047, "Episode": 2847, "Episode Step": 181}
{"Training Time": 9.270487003061506, "Episode Reward": 16929.3299427624, "Mean Reward": 68.81841440147318, "Episode": 2848, "Episode Step": 246}
{"Training Time": 9.273216993874973, "Episode Reward": 5982.65943691733, "Mean Reward": 43.990142918509775, "Episode": 2849, "Episode Step": 136}
{"Training Time": 9.275830079714456, "Episode Reward": 8267.401558021345, "Mean Reward": 45.67625170177539, "Episode": 2850, "Episode Step": 181}
{"Training Time": 9.283354843325085, "Episode Reward": 38166.201102536055, "Mean Reward": 60.87113413482624, "Episode": 2851, "Episode Step": 627}
{"Training Time": 9.286857978304226, "Episode Reward": 18716.452498718063, "Mean Reward": 63.87867747002752, "Episode": 2852, "Episode Step": 293}
{"Training Time": 9.28902185804314, "Episode Reward": 6633.519416911918, "Mean Reward": 46.38824767071271, "Episode": 2853, "Episode Step": 143}
{"Training Time": 9.30239663945304, "Episode Reward": 75322.86042748444, "Mean Reward": 66.13069396618477, "Episode": 2854, "Episode Step": 1139}
{"Training Time": 9.322394168310694, "Episode Reward": 107377.03296578159, "Mean Reward": 62.42850753824511, "Episode": 2855, "Episode Step": 1720}
{"Training Time": 9.330380111402935, "Episode Reward": 36887.77239393095, "Mean Reward": 57.190344796792175, "Episode": 2856, "Episode Step": 645}
{"Training Time": 9.338448943628205, "Episode Reward": 46757.25747249578, "Mean Reward": 67.56829114522512, "Episode": 2857, "Episode Step": 692}
{"Training Time": 9.352863396141265, "Episode Reward": 76878.51890973457, "Mean Reward": 63.32662183668416, "Episode": 2858, "Episode Step": 1214}
{"Training Time": 9.361661144163874, "Episode Reward": 42432.73380192423, "Mean Reward": 60.61819114560604, "Episode": 2859, "Episode Step": 700}
{"Training Time": 9.36374605304665, "Episode Reward": 8460.222229116609, "Mean Reward": 48.6219668340035, "Episode": 2860, "Episode Step": 174}
{"Training Time": 9.365848518080181, "Episode Reward": 8907.744285726636, "Mean Reward": 50.90139591843792, "Episode": 2861, "Episode Step": 175}
{"Training Time": 9.37499362303151, "Episode Reward": 45694.60515470354, "Mean Reward": 62.59534952699115, "Episode": 2862, "Episode Step": 730}
{"Training Time": 9.37719576113754, "Episode Reward": 9481.382558363635, "Mean Reward": 51.8108336522603, "Episode": 2863, "Episode Step": 183}
{"Training Time": 9.380653887788455, "Episode Reward": 18864.801113077086, "Mean Reward": 64.60548326396263, "Episode": 2864, "Episode Step": 292}
{"Training Time": 9.413345708317227, "Episode Reward": 167557.41169507962, "Mean Reward": 62.40499504472239, "Episode": 2865, "Episode Step": 2685}
{"Training Time": 9.436277736094263, "Episode Reward": 128606.76267270527, "Mean Reward": 66.15574211558913, "Episode": 2866, "Episode Step": 1944}
{"Training Time": 9.447267979449697, "Episode Reward": 59345.78687747603, "Mean Reward": 63.40361845884191, "Episode": 2867, "Episode Step": 936}
{"Training Time": 9.467541158066856, "Episode Reward": 100909.8789734948, "Mean Reward": 61.45546831516126, "Episode": 2868, "Episode Step": 1642}
{"Training Time": 9.46963441669941, "Episode Reward": 9665.626593183579, "Mean Reward": 55.23215196104902, "Episode": 2869, "Episode Step": 175}
{"Training Time": 9.471747207509146, "Episode Reward": 9261.704131283062, "Mean Reward": 52.62331892774467, "Episode": 2870, "Episode Step": 176}
{"Training Time": 9.47397830473052, "Episode Reward": 6472.174074333659, "Mean Reward": 44.63568327126661, "Episode": 2871, "Episode Step": 145}
{"Training Time": 9.48690950082408, "Episode Reward": 68451.17440558209, "Mean Reward": 63.97306019213279, "Episode": 2872, "Episode Step": 1070}
{"Training Time": 9.489179380867217, "Episode Reward": 9302.177128278561, "Mean Reward": 50.01170499074495, "Episode": 2873, "Episode Step": 186}
{"Training Time": 9.526163655850622, "Episode Reward": 186891.60640544363, "Mean Reward": 61.05573551304921, "Episode": 2874, "Episode Step": 3061}
{"Training Time": 9.528209704690509, "Episode Reward": 9114.155835311734, "Mean Reward": 52.38020595006744, "Episode": 2875, "Episode Step": 174}
{"Training Time": 9.535512693921724, "Episode Reward": 38163.79942878894, "Mean Reward": 60.867303714176934, "Episode": 2876, "Episode Step": 627}
{"Training Time": 9.54452136192057, "Episode Reward": 44927.53430384286, "Mean Reward": 61.54456753951077, "Episode": 2877, "Episode Step": 730}
{"Training Time": 9.546557244724697, "Episode Reward": 9076.2995716331, "Mean Reward": 51.86456898076057, "Episode": 2878, "Episode Step": 175}
{"Training Time": 9.547163908349143, "Episode Reward": 1564.4990474996252, "Mean Reward": 31.289980949992504, "Episode": 2879, "Episode Step": 50}
{"Training Time": 9.56018092446857, "Episode Reward": 63529.004103737374, "Mean Reward": 58.87766830744891, "Episode": 2880, "Episode Step": 1079}
{"Training Time": 9.568428720831871, "Episode Reward": 44930.17427813203, "Mean Reward": 63.55045866779636, "Episode": 2881, "Episode Step": 707}
{"Training Time": 9.570488332509994, "Episode Reward": 9100.762868509482, "Mean Reward": 52.00435924862561, "Episode": 2882, "Episode Step": 175}
{"Training Time": 9.62733530137274, "Episode Reward": 306074.0895568154, "Mean Reward": 63.160150548249156, "Episode": 2883, "Episode Step": 4846}
{"Training Time": 9.63028636581368, "Episode Reward": 17203.477948821772, "Mean Reward": 69.36886269686198, "Episode": 2884, "Episode Step": 248}
{"Training Time": 9.632316083047126, "Episode Reward": 8947.178097568065, "Mean Reward": 52.01847731144224, "Episode": 2885, "Episode Step": 172}
{"Training Time": 9.643038815524843, "Episode Reward": 55055.20152206065, "Mean Reward": 63.427651523111344, "Episode": 2886, "Episode Step": 868}
{"Training Time": 9.645080108642578, "Episode Reward": 9069.906901755157, "Mean Reward": 51.8280394386009, "Episode": 2887, "Episode Step": 175}
{"Training Time": 9.647112685574426, "Episode Reward": 8598.52007622053, "Mean Reward": 49.70242818624583, "Episode": 2888, "Episode Step": 173}
{"Training Time": 9.655827378895548, "Episode Reward": 43327.65761138049, "Mean Reward": 61.80835607900213, "Episode": 2889, "Episode Step": 701}
{"Training Time": 9.657908661696647, "Episode Reward": 9159.154058944221, "Mean Reward": 52.338023193966976, "Episode": 2890, "Episode Step": 175}
{"Training Time": 9.670452968610658, "Episode Reward": 65275.594774125006, "Mean Reward": 61.11947076228933, "Episode": 2891, "Episode Step": 1068}
{"Training Time": 9.673851443330447, "Episode Reward": 13241.41852906734, "Mean Reward": 53.392816649465075, "Episode": 2892, "Episode Step": 248}
{"Training Time": 9.686684041950437, "Episode Reward": 66563.36767707596, "Mean Reward": 61.861865870888444, "Episode": 2893, "Episode Step": 1076}
{"Training Time": 9.693593563636144, "Episode Reward": 34904.944539464304, "Mean Reward": 59.87125993047051, "Episode": 2894, "Episode Step": 583}
{"Training Time": 9.697188593347867, "Episode Reward": 17023.04881899828, "Mean Reward": 63.51883887685925, "Episode": 2895, "Episode Step": 268}
{"Training Time": 9.704640062782499, "Episode Reward": 39698.236139151486, "Mean Reward": 62.9132109970705, "Episode": 2896, "Episode Step": 631}
{"Training Time": 9.710487812492582, "Episode Reward": 31013.750035734167, "Mean Reward": 62.65404047623064, "Episode": 2897, "Episode Step": 495}
{"Training Time": 9.714024628599486, "Episode Reward": 15957.6984674549, "Mean Reward": 61.85154444749961, "Episode": 2898, "Episode Step": 258}
{"Training Time": 9.717184014452828, "Episode Reward": 8326.126221136037, "Mean Reward": 48.690796614830624, "Episode": 2899, "Episode Step": 171}
{"Training Time": 9.722432513303227, "Episode Reward": 24540.533357769385, "Mean Reward": 59.276650622631365, "Episode": 2900, "Episode Step": 414}
{"Training Time": 9.725157319439782, "Episode Reward": 8478.421204143882, "Mean Reward": 45.339150824298834, "Episode": 2901, "Episode Step": 187}
{"Training Time": 9.726678057246739, "Episode Reward": 6627.464475188435, "Mean Reward": 53.44729415474544, "Episode": 2902, "Episode Step": 124}
{"Training Time": 9.72966456386778, "Episode Reward": 16434.279011111055, "Mean Reward": 65.21539290123435, "Episode": 2903, "Episode Step": 252}
{"Training Time": 9.732297989990975, "Episode Reward": 8675.04081052234, "Mean Reward": 47.40459459301825, "Episode": 2904, "Episode Step": 183}
{"Training Time": 9.734404780864715, "Episode Reward": 8739.313410062465, "Mean Reward": 49.938933771785514, "Episode": 2905, "Episode Step": 175}
{"Training Time": 9.7372584397263, "Episode Reward": 16054.214688299653, "Mean Reward": 66.61499870663756, "Episode": 2906, "Episode Step": 241}
{"Training Time": 9.74081487417221, "Episode Reward": 16334.206349237396, "Mean Reward": 63.06643378083937, "Episode": 2907, "Episode Step": 259}
{"Training Time": 9.758904709153706, "Episode Reward": 99156.24808794886, "Mean Reward": 64.9353294616561, "Episode": 2908, "Episode Step": 1527}
{"Training Time": 9.76180173251364, "Episode Reward": 14812.912779444652, "Mean Reward": 61.21038338613493, "Episode": 2909, "Episode Step": 242}
{"Training Time": 9.77256219221486, "Episode Reward": 52248.49653965773, "Mean Reward": 59.8493660248084, "Episode": 2910, "Episode Step": 873}
{"Training Time": 9.779859883586566, "Episode Reward": 39805.60301850459, "Mean Reward": 64.41036087136665, "Episode": 2911, "Episode Step": 618}
{"Training Time": 9.7820466133621, "Episode Reward": 8677.307152290237, "Mean Reward": 46.65218899080773, "Episode": 2912, "Episode Step": 186}
{"Training Time": 9.796254748900731, "Episode Reward": 72957.60671562392, "Mean Reward": 62.038781220768634, "Episode": 2913, "Episode Step": 1176}
{"Training Time": 9.808715586927201, "Episode Reward": 70459.15964291098, "Mean Reward": 66.15883534545631, "Episode": 2914, "Episode Step": 1065}
{"Training Time": 9.831601048906645, "Episode Reward": 119949.18447122902, "Mean Reward": 61.5755567100765, "Episode": 2915, "Episode Step": 1948}
{"Training Time": 9.850244450569154, "Episode Reward": 93743.05049224239, "Mean Reward": 60.59667129427433, "Episode": 2916, "Episode Step": 1547}
{"Training Time": 9.852334375249015, "Episode Reward": 9135.024848961364, "Mean Reward": 51.61030988113765, "Episode": 2917, "Episode Step": 177}
{"Training Time": 9.865176085299916, "Episode Reward": 65204.7657720968, "Mean Reward": 60.04122078461952, "Episode": 2918, "Episode Step": 1086}
{"Training Time": 9.879345277746518, "Episode Reward": 72597.79099237373, "Mean Reward": 62.10247304736846, "Episode": 2919, "Episode Step": 1169}
{"Training Time": 9.886544971664746, "Episode Reward": 39556.379453563364, "Mean Reward": 64.21490171033014, "Episode": 2920, "Episode Step": 616}
{"Training Time": 9.89530891166793, "Episode Reward": 45895.48840077176, "Mean Reward": 61.19398453436235, "Episode": 2921, "Episode Step": 750}
{"Training Time": 9.898764236370722, "Episode Reward": 16688.06680041564, "Mean Reward": 64.93411206387408, "Episode": 2922, "Episode Step": 257}
{"Training Time": 9.909197684725125, "Episode Reward": 56865.341066129324, "Mean Reward": 65.0633192976308, "Episode": 2923, "Episode Step": 874}
{"Training Time": 9.921524425546329, "Episode Reward": 62424.8136781042, "Mean Reward": 60.197505957670394, "Episode": 2924, "Episode Step": 1037}
{"Training Time": 9.92957394944297, "Episode Reward": 37604.89523961981, "Mean Reward": 57.94282779602435, "Episode": 2925, "Episode Step": 649}
{"Training Time": 9.9325521783034, "Episode Reward": 16002.07413174224, "Mean Reward": 63.500294173580315, "Episode": 2926, "Episode Step": 252}
{"Training Time": 9.934640158083704, "Episode Reward": 8679.268057757981, "Mean Reward": 49.31402305544307, "Episode": 2927, "Episode Step": 176}
{"Training Time": 9.948096436129676, "Episode Reward": 65795.34867403643, "Mean Reward": 58.850937991088045, "Episode": 2928, "Episode Step": 1118}
{"Training Time": 9.953872678346103, "Episode Reward": 31072.982042107124, "Mean Reward": 62.773701095165904, "Episode": 2929, "Episode Step": 495}
{"Training Time": 9.961773359179496, "Episode Reward": 41881.49030284369, "Mean Reward": 61.49998576041658, "Episode": 2930, "Episode Step": 681}
{"Training Time": 9.968106115526624, "Episode Reward": 30854.805334010256, "Mean Reward": 61.46375564543876, "Episode": 2931, "Episode Step": 502}
{"Training Time": 9.975312555564775, "Episode Reward": 39682.77647269871, "Mean Reward": 64.21161241537008, "Episode": 2932, "Episode Step": 618}
{"Training Time": 9.976933115588293, "Episode Reward": 6697.910153382068, "Mean Reward": 49.614149284311615, "Episode": 2933, "Episode Step": 135}
{"Training Time": 9.980504867235819, "Episode Reward": 14894.897148476492, "Mean Reward": 56.420064956350345, "Episode": 2934, "Episode Step": 264}
{"Training Time": 9.982460571130117, "Episode Reward": 7422.01038928583, "Mean Reward": 44.44317598374748, "Episode": 2935, "Episode Step": 167}
{"Training Time": 9.999635046389368, "Episode Reward": 94399.92122162349, "Mean Reward": 64.52489488832774, "Episode": 2936, "Episode Step": 1463}
{"Training Time": 10.029990691145262, "Episode Reward": 163417.80224785733, "Mean Reward": 63.785246779023154, "Episode": 2937, "Episode Step": 2562}
{"Training Time": 10.042495668861601, "Episode Reward": 68768.17168626377, "Mean Reward": 63.79236705590331, "Episode": 2938, "Episode Step": 1078}
{"Training Time": 10.045317048629125, "Episode Reward": 15713.351565366838, "Mean Reward": 64.93120481556545, "Episode": 2939, "Episode Step": 242}
{"Training Time": 10.054142487777604, "Episode Reward": 42973.48987705963, "Mean Reward": 59.851657210389455, "Episode": 2940, "Episode Step": 718}
{"Training Time": 10.056234558025995, "Episode Reward": 8999.238898723, "Mean Reward": 50.843157619903955, "Episode": 2941, "Episode Step": 177}
{"Training Time": 10.062558711634741, "Episode Reward": 32963.546341061454, "Mean Reward": 60.48357126800267, "Episode": 2942, "Episode Step": 545}
{"Training Time": 10.066147429148357, "Episode Reward": 15724.009616944006, "Mean Reward": 58.891421786307134, "Episode": 2943, "Episode Step": 267}
{"Training Time": 10.068203931384616, "Episode Reward": 8893.870741852665, "Mean Reward": 50.53335648779923, "Episode": 2944, "Episode Step": 176}
{"Training Time": 10.075361867811944, "Episode Reward": 37305.06552076074, "Mean Reward": 60.95598941300775, "Episode": 2945, "Episode Step": 612}
{"Training Time": 10.08400635778904, "Episode Reward": 44163.025570475336, "Mean Reward": 62.64258946166714, "Episode": 2946, "Episode Step": 705}
{"Training Time": 10.086098232799106, "Episode Reward": 8893.578615790213, "Mean Reward": 49.68479673625817, "Episode": 2947, "Episode Step": 179}
{"Training Time": 10.092522095839183, "Episode Reward": 34473.462887336354, "Mean Reward": 62.22646730566129, "Episode": 2948, "Episode Step": 554}
{"Training Time": 10.136997683048248, "Episode Reward": 229734.5874324519, "Mean Reward": 62.14081347915929, "Episode": 2949, "Episode Step": 3697}
{"Training Time": 10.139357215033638, "Episode Reward": 8867.060999469972, "Mean Reward": 50.09638982751397, "Episode": 2950, "Episode Step": 177}
{"Training Time": 10.140669661959013, "Episode Reward": 6038.451248403487, "Mean Reward": 54.895011349122605, "Episode": 2951, "Episode Step": 110}
{"Training Time": 10.191867135829396, "Episode Reward": 276026.4962754949, "Mean Reward": 63.16395795777916, "Episode": 2952, "Episode Step": 4370}
{"Training Time": 10.201099662780761, "Episode Reward": 50420.27938651043, "Mean Reward": 63.58168901199298, "Episode": 2953, "Episode Step": 793}
{"Training Time": 10.205135640568203, "Episode Reward": 21444.139423626537, "Mean Reward": 62.519356920193985, "Episode": 2954, "Episode Step": 343}
{"Training Time": 10.230078848600387, "Episode Reward": 126151.77962063391, "Mean Reward": 60.737496206371645, "Episode": 2955, "Episode Step": 2077}
{"Training Time": 10.250564883351325, "Episode Reward": 117956.49777053825, "Mean Reward": 67.75215265395649, "Episode": 2956, "Episode Step": 1741}
{"Training Time": 10.260413730276955, "Episode Reward": 53862.46897373359, "Mean Reward": 63.89379474938741, "Episode": 2957, "Episode Step": 843}
{"Training Time": 10.26306099553903, "Episode Reward": 8894.091668690598, "Mean Reward": 47.561987533104805, "Episode": 2958, "Episode Step": 187}
{"Training Time": 10.27553482055664, "Episode Reward": 67412.59351554603, "Mean Reward": 63.29820987375214, "Episode": 2959, "Episode Step": 1065}
{"Training Time": 10.280264284147156, "Episode Reward": 25428.911427624887, "Mean Reward": 62.632786767548986, "Episode": 2960, "Episode Step": 406}
{"Training Time": 10.320112789736854, "Episode Reward": 211611.6223957128, "Mean Reward": 62.55146981841939, "Episode": 2961, "Episode Step": 3383}
{"Training Time": 10.32223549524943, "Episode Reward": 8463.816521784594, "Mean Reward": 47.0212028988033, "Episode": 2962, "Episode Step": 180}
{"Training Time": 10.323491044971679, "Episode Reward": 6007.42369478821, "Mean Reward": 57.21355899798295, "Episode": 2963, "Episode Step": 105}
{"Training Time": 10.332694441080093, "Episode Reward": 44686.10301033453, "Mean Reward": 59.34409430323311, "Episode": 2964, "Episode Step": 753}
{"Training Time": 10.340006691416106, "Episode Reward": 39445.94332100954, "Mean Reward": 63.31612090049685, "Episode": 2965, "Episode Step": 623}
{"Training Time": 10.342991530829005, "Episode Reward": 15294.37055012548, "Mean Reward": 60.9337472116553, "Episode": 2966, "Episode Step": 251}
{"Training Time": 10.345586593084866, "Episode Reward": 8268.100006981196, "Mean Reward": 46.190502832297184, "Episode": 2967, "Episode Step": 179}
{"Training Time": 10.347721338073413, "Episode Reward": 9340.054399104461, "Mean Reward": 52.76866892149413, "Episode": 2968, "Episode Step": 177}
{"Training Time": 10.356202653580242, "Episode Reward": 42132.715214545125, "Mean Reward": 58.926874425937235, "Episode": 2969, "Episode Step": 715}
{"Training Time": 10.363596665263175, "Episode Reward": 32960.123986458406, "Mean Reward": 56.342092284544286, "Episode": 2970, "Episode Step": 585}
{"Training Time": 10.371065151956346, "Episode Reward": 39485.14772656467, "Mean Reward": 62.77447969247165, "Episode": 2971, "Episode Step": 629}
{"Training Time": 10.40540991279814, "Episode Reward": 183185.32594670143, "Mean Reward": 62.52058906030766, "Episode": 2972, "Episode Step": 2930}
{"Training Time": 10.408004501395755, "Episode Reward": 9210.028439542466, "Mean Reward": 51.16682466412481, "Episode": 2973, "Episode Step": 180}
{"Training Time": 10.410200874474313, "Episode Reward": 9263.181634695422, "Mean Reward": 51.462120192752344, "Episode": 2974, "Episode Step": 180}
{"Training Time": 10.412330335577328, "Episode Reward": 9152.123864877452, "Mean Reward": 52.0007037777128, "Episode": 2975, "Episode Step": 176}
{"Training Time": 10.414969410830073, "Episode Reward": 9400.580453733097, "Mean Reward": 51.936908584160754, "Episode": 2976, "Episode Step": 181}
{"Training Time": 10.417314445575078, "Episode Reward": 9363.656592357247, "Mean Reward": 48.26627109462498, "Episode": 2977, "Episode Step": 194}
{"Training Time": 10.418986211948924, "Episode Reward": 6725.179935747435, "Mean Reward": 48.7331879401988, "Episode": 2978, "Episode Step": 138}
{"Training Time": 10.432878935270839, "Episode Reward": 72943.66066762827, "Mean Reward": 63.92958866575659, "Episode": 2979, "Episode Step": 1141}
{"Training Time": 10.434369385838508, "Episode Reward": 6398.860037947847, "Mean Reward": 51.60370998345038, "Episode": 2980, "Episode Step": 124}
{"Training Time": 10.439168373876148, "Episode Reward": 24304.759709076916, "Mean Reward": 59.57048948303166, "Episode": 2981, "Episode Step": 408}
{"Training Time": 10.447097311947081, "Episode Reward": 36693.37235510251, "Mean Reward": 58.428936871182344, "Episode": 2982, "Episode Step": 628}
{"Training Time": 10.458004588882128, "Episode Reward": 57272.821801885584, "Mean Reward": 61.849699570070825, "Episode": 2983, "Episode Step": 926}
{"Training Time": 10.459284179740482, "Episode Reward": 5997.809775912988, "Mean Reward": 55.53527570289803, "Episode": 2984, "Episode Step": 108}
{"Training Time": 10.470695476929347, "Episode Reward": 55416.73488849361, "Mean Reward": 59.2059133424077, "Episode": 2985, "Episode Step": 936}
{"Training Time": 10.473569871650803, "Episode Reward": 15261.118215004793, "Mean Reward": 62.290278428590995, "Episode": 2986, "Episode Step": 245}
{"Training Time": 10.476320733626684, "Episode Reward": 15638.283182773019, "Mean Reward": 66.8302700118505, "Episode": 2987, "Episode Step": 234}
{"Training Time": 10.494905148347218, "Episode Reward": 91845.2733766813, "Mean Reward": 59.29326880353861, "Episode": 2988, "Episode Step": 1549}
{"Training Time": 10.49639849834972, "Episode Reward": 6609.46939698028, "Mean Reward": 52.45610632524032, "Episode": 2989, "Episode Step": 126}
{"Training Time": 10.49848224805461, "Episode Reward": 9225.84510842159, "Mean Reward": 52.1234186916474, "Episode": 2990, "Episode Step": 177}
{"Training Time": 10.506644554138184, "Episode Reward": 37115.64586286951, "Mean Reward": 57.632990470294274, "Episode": 2991, "Episode Step": 644}
{"Training Time": 10.514135487476985, "Episode Reward": 38080.30143451691, "Mean Reward": 60.63742266642819, "Episode": 2992, "Episode Step": 628}
{"Training Time": 10.517083044979307, "Episode Reward": 16392.35847421982, "Mean Reward": 66.90758560906049, "Episode": 2993, "Episode Step": 245}
{"Training Time": 10.520534295307266, "Episode Reward": 15714.667268384579, "Mean Reward": 63.365593824131366, "Episode": 2994, "Episode Step": 248}
{"Training Time": 10.522715890275107, "Episode Reward": 9273.62676260199, "Mean Reward": 51.807970740793245, "Episode": 2995, "Episode Step": 179}
{"Training Time": 10.527614172763295, "Episode Reward": 25008.72626755395, "Mean Reward": 60.99689333549744, "Episode": 2996, "Episode Step": 410}
{"Training Time": 10.530208850304286, "Episode Reward": 7624.7887768208675, "Mean Reward": 42.835892004611615, "Episode": 2997, "Episode Step": 178}
{"Training Time": 10.532328920563062, "Episode Reward": 9151.980408985342, "Mean Reward": 51.70610400556691, "Episode": 2998, "Episode Step": 177}
{"Training Time": 10.536325868633059, "Episode Reward": 14585.239298465236, "Mean Reward": 61.80186143417473, "Episode": 2999, "Episode Step": 236}
{"Training Time": 10.539592492514187, "Episode Reward": 12744.19479975108, "Mean Reward": 54.6961150203909, "Episode": 3000, "Episode Step": 233}
{"Training Time": 10.54179068558746, "Episode Reward": 9521.501703834434, "Mean Reward": 52.03006395537942, "Episode": 3001, "Episode Step": 183}
{"Training Time": 10.544741456972227, "Episode Reward": 16396.584251363693, "Mean Reward": 65.84973594925178, "Episode": 3002, "Episode Step": 249}
{"Training Time": 10.557794023884668, "Episode Reward": 59531.374825768165, "Mean Reward": 56.427843436747075, "Episode": 3003, "Episode Step": 1055}
{"Training Time": 10.559985701110628, "Episode Reward": 9271.179197686126, "Mean Reward": 50.114482149654734, "Episode": 3004, "Episode Step": 185}
{"Training Time": 10.566823593907886, "Episode Reward": 33796.66742229752, "Mean Reward": 58.27011624534055, "Episode": 3005, "Episode Step": 580}
{"Training Time": 10.58547115166982, "Episode Reward": 91494.36861001753, "Mean Reward": 58.99056647970182, "Episode": 3006, "Episode Step": 1551}
{"Training Time": 10.586763892769813, "Episode Reward": 5921.139097465355, "Mean Reward": 54.32237704096656, "Episode": 3007, "Episode Step": 109}
{"Training Time": 10.58822831220097, "Episode Reward": 5948.021217947026, "Mean Reward": 47.96791304795989, "Episode": 3008, "Episode Step": 124}
{"Training Time": 10.594427541361915, "Episode Reward": 27864.65982731992, "Mean Reward": 57.334691002715886, "Episode": 3009, "Episode Step": 486}
{"Training Time": 10.595740587777561, "Episode Reward": 5515.554621618193, "Mean Reward": 50.14140565107448, "Episode": 3010, "Episode Step": 110}
{"Training Time": 10.596983325282732, "Episode Reward": 6002.280900617397, "Mean Reward": 57.16458000587997, "Episode": 3011, "Episode Step": 105}
{"Training Time": 10.60483555164602, "Episode Reward": 37455.051167849255, "Mean Reward": 58.984332547794104, "Episode": 3012, "Episode Step": 635}
{"Training Time": 10.606165325840314, "Episode Reward": 6093.363993720203, "Mean Reward": 54.4050356582161, "Episode": 3013, "Episode Step": 112}
{"Training Time": 10.608234230279923, "Episode Reward": 9103.148093950605, "Mean Reward": 51.43021522005992, "Episode": 3014, "Episode Step": 177}
{"Training Time": 10.610825550026364, "Episode Reward": 8255.852579295453, "Mean Reward": 45.86584766275252, "Episode": 3015, "Episode Step": 180}
{"Training Time": 10.612311569452286, "Episode Reward": 6190.081491821007, "Mean Reward": 49.52065193456806, "Episode": 3016, "Episode Step": 125}
{"Training Time": 10.61443117055628, "Episode Reward": 8576.939307914543, "Mean Reward": 47.91586205538851, "Episode": 3017, "Episode Step": 179}
{"Training Time": 10.622230956686868, "Episode Reward": 37504.725739651854, "Mean Reward": 59.62595507098864, "Episode": 3018, "Episode Step": 629}
{"Training Time": 10.62437414639526, "Episode Reward": 7716.374744578929, "Mean Reward": 42.631904666181924, "Episode": 3019, "Episode Step": 181}
{"Training Time": 10.62735638750924, "Episode Reward": 15817.466413225233, "Mean Reward": 62.76772386200489, "Episode": 3020, "Episode Step": 252}
{"Training Time": 10.62990126113097, "Episode Reward": 8417.197523174947, "Mean Reward": 46.762208462083045, "Episode": 3021, "Episode Step": 180}
{"Training Time": 10.6314224811395, "Episode Reward": 6435.404620656457, "Mean Reward": 51.07463984647982, "Episode": 3022, "Episode Step": 126}
{"Training Time": 10.63350326942073, "Episode Reward": 8992.184508959119, "Mean Reward": 51.09195743726772, "Episode": 3023, "Episode Step": 176}
{"Training Time": 10.657641627192497, "Episode Reward": 123676.92336374885, "Mean Reward": 61.86939638006446, "Episode": 3024, "Episode Step": 1999}
{"Training Time": 10.659237169159784, "Episode Reward": 5623.658151191295, "Mean Reward": 41.656727045861444, "Episode": 3025, "Episode Step": 135}
{"Training Time": 10.661334982249471, "Episode Reward": 8437.859960567246, "Mean Reward": 47.942386139586624, "Episode": 3026, "Episode Step": 176}
{"Training Time": 10.664013926916653, "Episode Reward": 8723.081042213396, "Mean Reward": 46.8982851731903, "Episode": 3027, "Episode Step": 186}
{"Training Time": 10.665329995552698, "Episode Reward": 5854.216158922983, "Mean Reward": 52.74068611642327, "Episode": 3028, "Episode Step": 111}
{"Training Time": 10.667486858632829, "Episode Reward": 8497.955488546066, "Mean Reward": 47.21086382525592, "Episode": 3029, "Episode Step": 180}
{"Training Time": 10.670106509990163, "Episode Reward": 8359.437206438895, "Mean Reward": 45.67998473463877, "Episode": 3030, "Episode Step": 183}
{"Training Time": 10.671413689189487, "Episode Reward": 6021.02113469637, "Mean Reward": 55.23872600638871, "Episode": 3031, "Episode Step": 109}
{"Training Time": 10.673011151949565, "Episode Reward": 6165.203833321323, "Mean Reward": 45.668176543120914, "Episode": 3032, "Episode Step": 135}
{"Training Time": 10.68632067196899, "Episode Reward": 65413.266671616744, "Mean Reward": 59.84745349644716, "Episode": 3033, "Episode Step": 1093}
{"Training Time": 10.687650665839513, "Episode Reward": 5721.838509226886, "Mean Reward": 51.548094677719696, "Episode": 3034, "Episode Step": 111}
{"Training Time": 10.691817925572396, "Episode Reward": 21916.594952847634, "Mean Reward": 62.263053843317145, "Episode": 3035, "Episode Step": 352}
{"Training Time": 10.699789678917991, "Episode Reward": 36088.56373584616, "Mean Reward": 57.011949029772765, "Episode": 3036, "Episode Step": 633}
{"Training Time": 10.701158176395628, "Episode Reward": 5830.873056125643, "Mean Reward": 51.60064651438623, "Episode": 3037, "Episode Step": 113}
{"Training Time": 10.702666706111696, "Episode Reward": 6525.299672823052, "Mean Reward": 52.202397382584415, "Episode": 3038, "Episode Step": 125}
{"Training Time": 10.716699467764961, "Episode Reward": 72288.38993234442, "Mean Reward": 62.69591494565865, "Episode": 3039, "Episode Step": 1153}
{"Training Time": 10.718246493604449, "Episode Reward": 6353.94337474856, "Mean Reward": 48.87648749806585, "Episode": 3040, "Episode Step": 130}
{"Training Time": 10.719825500249863, "Episode Reward": 6231.029255800947, "Mean Reward": 46.50021832687274, "Episode": 3041, "Episode Step": 134}
{"Training Time": 10.73306645307276, "Episode Reward": 63773.973450519465, "Mean Reward": 58.72373245904186, "Episode": 3042, "Episode Step": 1086}
{"Training Time": 10.734660826656553, "Episode Reward": 6249.707740385445, "Mean Reward": 46.29413141026255, "Episode": 3043, "Episode Step": 135}
{"Training Time": 10.735929939746857, "Episode Reward": 5375.638963521199, "Mean Reward": 50.23961648150653, "Episode": 3044, "Episode Step": 107}
{"Training Time": 10.738432576656342, "Episode Reward": 8812.553522907396, "Mean Reward": 50.646859327053996, "Episode": 3045, "Episode Step": 174}
{"Training Time": 10.739713102777799, "Episode Reward": 5947.450512686516, "Mean Reward": 55.58364965127585, "Episode": 3046, "Episode Step": 107}
{"Training Time": 10.741351788904932, "Episode Reward": 6449.7940524584665, "Mean Reward": 47.078788704076395, "Episode": 3047, "Episode Step": 137}
{"Training Time": 10.743938005566598, "Episode Reward": 8722.954448717406, "Mean Reward": 48.46085804843003, "Episode": 3048, "Episode Step": 180}
{"Training Time": 10.746621444159084, "Episode Reward": 6265.9408949542685, "Mean Reward": 48.199545345802065, "Episode": 3049, "Episode Step": 130}
{"Training Time": 10.748530000580681, "Episode Reward": 5885.237917722919, "Mean Reward": 43.27380821855087, "Episode": 3050, "Episode Step": 136}
{"Training Time": 10.751102002792889, "Episode Reward": 8626.31113750989, "Mean Reward": 48.19168233245749, "Episode": 3051, "Episode Step": 179}
{"Training Time": 10.752474798030324, "Episode Reward": 5501.609989167095, "Mean Reward": 47.42767232040599, "Episode": 3052, "Episode Step": 116}
{"Training Time": 10.754570249186623, "Episode Reward": 7983.410865339636, "Mean Reward": 44.600060700221434, "Episode": 3053, "Episode Step": 179}
{"Training Time": 10.758079020844566, "Episode Reward": 16278.11083625992, "Mean Reward": 64.08705053645637, "Episode": 3054, "Episode Step": 254}
{"Training Time": 10.759430272512965, "Episode Reward": 5574.280587891562, "Mean Reward": 49.77036239188895, "Episode": 3055, "Episode Step": 112}
{"Training Time": 10.762377324435446, "Episode Reward": 13984.13966506699, "Mean Reward": 56.16120347416462, "Episode": 3056, "Episode Step": 249}
{"Training Time": 10.77563797586494, "Episode Reward": 65320.53130666983, "Mean Reward": 60.65044689570086, "Episode": 3057, "Episode Step": 1077}
{"Training Time": 10.776973734431797, "Episode Reward": 5427.542794643259, "Mean Reward": 48.0313521649846, "Episode": 3058, "Episode Step": 113}
{"Training Time": 10.778245943321123, "Episode Reward": 5550.436038561358, "Mean Reward": 51.87323400524634, "Episode": 3059, "Episode Step": 107}
{"Training Time": 10.780768489970102, "Episode Reward": 9486.610946349405, "Mean Reward": 53.596672013273476, "Episode": 3060, "Episode Step": 177}
{"Training Time": 10.78227295835813, "Episode Reward": 6318.037794903356, "Mean Reward": 50.14315710240759, "Episode": 3061, "Episode Step": 126}
{"Training Time": 10.789707437488769, "Episode Reward": 33927.12994644687, "Mean Reward": 53.93820341247515, "Episode": 3062, "Episode Step": 629}
{"Training Time": 10.792355961932076, "Episode Reward": 8298.282360328361, "Mean Reward": 45.345805247695964, "Episode": 3063, "Episode Step": 183}
{"Training Time": 10.794521762530009, "Episode Reward": 8887.27337485375, "Mean Reward": 48.83117238930632, "Episode": 3064, "Episode Step": 182}
{"Training Time": 10.79575804915693, "Episode Reward": 5761.375597554549, "Mean Reward": 55.39784228417836, "Episode": 3065, "Episode Step": 104}
{"Training Time": 10.803621555831697, "Episode Reward": 37152.748784017196, "Mean Reward": 59.16042800002738, "Episode": 3066, "Episode Step": 628}
{"Training Time": 10.805227684444851, "Episode Reward": 6056.003873554444, "Mean Reward": 43.88408604024959, "Episode": 3067, "Episode Step": 138}
{"Training Time": 10.806498833894729, "Episode Reward": 4588.229148801941, "Mean Reward": 43.69742046478039, "Episode": 3068, "Episode Step": 105}
{"Training Time": 10.81508293390274, "Episode Reward": 43191.02785742024, "Mean Reward": 62.96068200790122, "Episode": 3069, "Episode Step": 686}
{"Training Time": 10.816483299467299, "Episode Reward": 5695.08669756252, "Mean Reward": 48.67595468002154, "Episode": 3070, "Episode Step": 117}
{"Training Time": 10.817773214446174, "Episode Reward": 5946.959283034917, "Mean Reward": 55.06443780587886, "Episode": 3071, "Episode Step": 108}
{"Training Time": 10.821217799981435, "Episode Reward": 16991.76601169311, "Mean Reward": 67.69627893104825, "Episode": 3072, "Episode Step": 251}
{"Training Time": 10.822838707764943, "Episode Reward": 6170.837476898669, "Mean Reward": 45.373804977196095, "Episode": 3073, "Episode Step": 136}
{"Training Time": 10.826936797499657, "Episode Reward": 21371.297975705234, "Mean Reward": 61.94579123392822, "Episode": 3074, "Episode Step": 345}
{"Training Time": 10.829481286936335, "Episode Reward": 8951.244883703866, "Mean Reward": 51.14997076402209, "Episode": 3075, "Episode Step": 175}
{"Training Time": 10.830885359181298, "Episode Reward": 4469.08007894113, "Mean Reward": 37.5552947810179, "Episode": 3076, "Episode Step": 119}
{"Training Time": 10.844119776089986, "Episode Reward": 68086.30690011824, "Mean Reward": 60.360201152587095, "Episode": 3077, "Episode Step": 1128}
{"Training Time": 10.847516978581746, "Episode Reward": 16044.46838438423, "Mean Reward": 63.922184798343544, "Episode": 3078, "Episode Step": 251}
{"Training Time": 10.848845330807897, "Episode Reward": 6120.978730289812, "Mean Reward": 54.16795336539657, "Episode": 3079, "Episode Step": 113}
{"Training Time": 10.86703184498681, "Episode Reward": 97892.8882502543, "Mean Reward": 62.711651665761885, "Episode": 3080, "Episode Step": 1561}
{"Training Time": 10.869546692238913, "Episode Reward": 8741.011621209764, "Mean Reward": 49.66483875687366, "Episode": 3081, "Episode Step": 176}
{"Training Time": 10.87096768114302, "Episode Reward": 5980.050145455561, "Mean Reward": 50.252522230718995, "Episode": 3082, "Episode Step": 119}
{"Training Time": 10.873022977511088, "Episode Reward": 8179.008591259365, "Mean Reward": 46.2090880862111, "Episode": 3083, "Episode Step": 177}
{"Training Time": 10.876157824463315, "Episode Reward": 12593.080771609551, "Mean Reward": 54.752525093954574, "Episode": 3084, "Episode Step": 230}
{"Training Time": 10.87767990860674, "Episode Reward": 6190.470455033214, "Mean Reward": 47.255499656742096, "Episode": 3085, "Episode Step": 131}
{"Training Time": 10.880636788076824, "Episode Reward": 15419.905397590404, "Mean Reward": 61.43388604617691, "Episode": 3086, "Episode Step": 251}
{"Training Time": 10.883174705836508, "Episode Reward": 7904.214362598385, "Mean Reward": 44.91030887839992, "Episode": 3087, "Episode Step": 176}
{"Training Time": 10.884466088083055, "Episode Reward": 5644.713703863679, "Mean Reward": 51.78636425563008, "Episode": 3088, "Episode Step": 109}
{"Training Time": 10.887147166397837, "Episode Reward": 13505.67198427663, "Mean Reward": 58.976733555793146, "Episode": 3089, "Episode Step": 229}
{"Training Time": 10.889686447514428, "Episode Reward": 8562.051165399038, "Mean Reward": 48.10141104156763, "Episode": 3090, "Episode Step": 178}
{"Training Time": 10.891205819447835, "Episode Reward": 6641.755396757546, "Mean Reward": 51.486475943856945, "Episode": 3091, "Episode Step": 129}
{"Training Time": 10.89912692613072, "Episode Reward": 43868.42018776499, "Mean Reward": 64.32319675625365, "Episode": 3092, "Episode Step": 682}
{"Training Time": 10.90164054526223, "Episode Reward": 8025.517896192361, "Mean Reward": 45.86010226395635, "Episode": 3093, "Episode Step": 175}
{"Training Time": 10.903202825850911, "Episode Reward": 5698.833549014464, "Mean Reward": 42.84837254898093, "Episode": 3094, "Episode Step": 133}
{"Training Time": 10.906037135587798, "Episode Reward": 15073.262078164986, "Mean Reward": 62.54465592599579, "Episode": 3095, "Episode Step": 241}
{"Training Time": 10.90859100997448, "Episode Reward": 8220.877377012042, "Mean Reward": 46.18470436523619, "Episode": 3096, "Episode Step": 178}
{"Training Time": 10.909981557793088, "Episode Reward": 6055.861538289919, "Mean Reward": 50.889592758738814, "Episode": 3097, "Episode Step": 119}
{"Training Time": 10.912066846092541, "Episode Reward": 9477.669770599945, "Mean Reward": 53.24533578988733, "Episode": 3098, "Episode Step": 178}
{"Training Time": 10.915721353888511, "Episode Reward": 8560.773962848887, "Mean Reward": 48.094235746342065, "Episode": 3099, "Episode Step": 178}
{"Training Time": 10.917381596101654, "Episode Reward": 5999.836483600822, "Mean Reward": 51.280653705989934, "Episode": 3100, "Episode Step": 117}
{"Training Time": 10.920819223059548, "Episode Reward": 19224.087761057886, "Mean Reward": 65.83591698992427, "Episode": 3101, "Episode Step": 292}
{"Training Time": 10.92698085890876, "Episode Reward": 29448.142389569675, "Mean Reward": 60.22115008091958, "Episode": 3102, "Episode Step": 489}
{"Training Time": 10.92830071998967, "Episode Reward": 5865.665566827726, "Mean Reward": 52.37201398953327, "Episode": 3103, "Episode Step": 112}
{"Training Time": 10.929888765017191, "Episode Reward": 6742.289250055957, "Mean Reward": 49.57565625041145, "Episode": 3104, "Episode Step": 136}
{"Training Time": 10.94288997636901, "Episode Reward": 67659.09100554272, "Mean Reward": 62.8801961018055, "Episode": 3105, "Episode Step": 1076}
{"Training Time": 10.944279706080755, "Episode Reward": 5961.787508360651, "Mean Reward": 51.394719899660785, "Episode": 3106, "Episode Step": 116}
{"Training Time": 10.945308442513149, "Episode Reward": 4214.540927649226, "Mean Reward": 49.582834442932075, "Episode": 3107, "Episode Step": 85}
{"Training Time": 10.947869892517726, "Episode Reward": 8264.026584547211, "Mean Reward": 46.427115643523656, "Episode": 3108, "Episode Step": 178}
{"Training Time": 10.949515702790684, "Episode Reward": 6480.0814831161115, "Mean Reward": 46.61929124543965, "Episode": 3109, "Episode Step": 139}
{"Training Time": 10.95115600168705, "Episode Reward": 6942.834145411797, "Mean Reward": 49.9484470892935, "Episode": 3110, "Episode Step": 139}
{"Training Time": 10.953756769167052, "Episode Reward": 8276.220318847805, "Mean Reward": 45.22524764397708, "Episode": 3111, "Episode Step": 183}
{"Training Time": 10.955177981389893, "Episode Reward": 6083.280847589937, "Mean Reward": 49.86295776713063, "Episode": 3112, "Episode Step": 122}
{"Training Time": 10.957822473314073, "Episode Reward": 14474.739425300122, "Mean Reward": 64.047519580974, "Episode": 3113, "Episode Step": 226}
{"Training Time": 10.960370879438189, "Episode Reward": 8790.512902512733, "Mean Reward": 49.38490394670075, "Episode": 3114, "Episode Step": 178}
{"Training Time": 10.961750596695476, "Episode Reward": 6051.659205649924, "Mean Reward": 52.623123527390646, "Episode": 3115, "Episode Step": 115}
{"Training Time": 10.967445106108983, "Episode Reward": 29880.555800886785, "Mean Reward": 60.486955062523855, "Episode": 3116, "Episode Step": 494}
{"Training Time": 10.970036089751456, "Episode Reward": 8836.36730353541, "Mean Reward": 48.28616012860879, "Episode": 3117, "Episode Step": 183}
{"Training Time": 10.971406293908755, "Episode Reward": 5929.748913935864, "Mean Reward": 51.11852512013676, "Episode": 3118, "Episode Step": 116}
{"Training Time": 10.978789018591245, "Episode Reward": 35816.40339712957, "Mean Reward": 57.03248948587512, "Episode": 3119, "Episode Step": 628}
{"Training Time": 10.982167075806194, "Episode Reward": 15219.63621069105, "Mean Reward": 61.36950084956068, "Episode": 3120, "Episode Step": 248}
{"Training Time": 10.9837503327926, "Episode Reward": 6602.013765684105, "Mean Reward": 49.639201245745156, "Episode": 3121, "Episode Step": 133}
{"Training Time": 10.99186233692699, "Episode Reward": 44846.645353609456, "Mean Reward": 64.62052644612314, "Episode": 3122, "Episode Step": 694}
{"Training Time": 10.995306713316175, "Episode Reward": 16461.589090118978, "Mean Reward": 64.80940586661015, "Episode": 3123, "Episode Step": 254}
{"Training Time": 10.99697661863433, "Episode Reward": 6814.777052488841, "Mean Reward": 48.67697894634887, "Episode": 3124, "Episode Step": 140}
{"Training Time": 11.004301312499576, "Episode Reward": 36841.13675788029, "Mean Reward": 58.851656162748064, "Episode": 3125, "Episode Step": 626}
{"Training Time": 11.007493803037537, "Episode Reward": 14397.238202555842, "Mean Reward": 61.00524662099933, "Episode": 3126, "Episode Step": 236}
{"Training Time": 11.009715721673436, "Episode Reward": 8866.40108362612, "Mean Reward": 47.413909538107596, "Episode": 3127, "Episode Step": 187}
{"Training Time": 11.016522476143308, "Episode Reward": 33451.23002141623, "Mean Reward": 58.07505212051429, "Episode": 3128, "Episode Step": 576}
{"Training Time": 11.024313604699241, "Episode Reward": 37718.45972937772, "Mean Reward": 59.96575473668954, "Episode": 3129, "Episode Step": 629}
{"Training Time": 11.027238198916118, "Episode Reward": 16342.323624538265, "Mean Reward": 65.89646622797687, "Episode": 3130, "Episode Step": 248}
{"Training Time": 11.028813922802607, "Episode Reward": 6460.753410480547, "Mean Reward": 48.21457769015334, "Episode": 3131, "Episode Step": 134}
{"Training Time": 11.032181225551499, "Episode Reward": 17540.2047439884, "Mean Reward": 70.44258933328675, "Episode": 3132, "Episode Step": 249}
{"Training Time": 11.03434376862314, "Episode Reward": 8780.282372542688, "Mean Reward": 47.718925937732, "Episode": 3133, "Episode Step": 184}
{"Training Time": 11.037147616081768, "Episode Reward": 14194.278528523162, "Mean Reward": 59.142827202179845, "Episode": 3134, "Episode Step": 240}
{"Training Time": 11.040554392470254, "Episode Reward": 15485.07423688109, "Mean Reward": 61.69352285609996, "Episode": 3135, "Episode Step": 251}
{"Training Time": 11.04267392443286, "Episode Reward": 8454.577909549414, "Mean Reward": 46.453724777744036, "Episode": 3136, "Episode Step": 182}
{"Training Time": 11.045547249449625, "Episode Reward": 16274.20258920738, "Mean Reward": 66.42531669064236, "Episode": 3137, "Episode Step": 245}
{"Training Time": 11.057907256947624, "Episode Reward": 63513.95333162748, "Mean Reward": 62.08597588624387, "Episode": 3138, "Episode Step": 1023}
{"Training Time": 11.060016784469287, "Episode Reward": 8597.47092092075, "Mean Reward": 46.98071541486749, "Episode": 3139, "Episode Step": 183}
{"Training Time": 11.07298954308033, "Episode Reward": 69084.03508651815, "Mean Reward": 62.12593083319978, "Episode": 3140, "Episode Step": 1112}
{"Training Time": 11.074447276128662, "Episode Reward": 4343.515030819314, "Mean Reward": 51.708512271658506, "Episode": 3141, "Episode Step": 84}
{"Training Time": 11.076697288089328, "Episode Reward": 8788.624446749434, "Mean Reward": 46.01374055889756, "Episode": 3142, "Episode Step": 191}
{"Training Time": 11.07942581752936, "Episode Reward": 14106.909854411047, "Mean Reward": 60.28593954876516, "Episode": 3143, "Episode Step": 234}
{"Training Time": 11.082846777505345, "Episode Reward": 14836.86982705798, "Mean Reward": 58.41287333487394, "Episode": 3144, "Episode Step": 254}
{"Training Time": 11.084947449432478, "Episode Reward": 8114.6816391815555, "Mean Reward": 44.83249524409699, "Episode": 3145, "Episode Step": 181}
{"Training Time": 11.08908050113254, "Episode Reward": 21251.04381064152, "Mean Reward": 60.20125725394198, "Episode": 3146, "Episode Step": 353}
{"Training Time": 11.091649326417182, "Episode Reward": 7951.92727753391, "Mean Reward": 44.673748750190505, "Episode": 3147, "Episode Step": 178}
{"Training Time": 11.098791066937977, "Episode Reward": 38675.41398773251, "Mean Reward": 62.784762967098224, "Episode": 3148, "Episode Step": 616}
{"Training Time": 11.102870324187808, "Episode Reward": 15927.83923014809, "Mean Reward": 63.45752681333901, "Episode": 3149, "Episode Step": 251}
{"Training Time": 11.10556306997935, "Episode Reward": 8385.60176107824, "Mean Reward": 46.07473495097934, "Episode": 3150, "Episode Step": 182}
{"Training Time": 11.107806213630571, "Episode Reward": 8466.220698753525, "Mean Reward": 46.26350108608484, "Episode": 3151, "Episode Step": 183}
{"Training Time": 11.112116152246793, "Episode Reward": 21380.113099421404, "Mean Reward": 60.05649747028484, "Episode": 3152, "Episode Step": 356}
{"Training Time": 11.114788973066542, "Episode Reward": 8423.329510039328, "Mean Reward": 46.02912300567939, "Episode": 3153, "Episode Step": 183}
{"Training Time": 11.117761015560891, "Episode Reward": 15462.364627541157, "Mean Reward": 62.34824446589177, "Episode": 3154, "Episode Step": 248}
{"Training Time": 11.120670887761646, "Episode Reward": 14891.501818986453, "Mean Reward": 61.28190048965619, "Episode": 3155, "Episode Step": 243}
{"Training Time": 11.128770871361096, "Episode Reward": 36956.02113840623, "Mean Reward": 58.10695147548149, "Episode": 3156, "Episode Step": 636}
{"Training Time": 11.137030201090706, "Episode Reward": 42792.41368090011, "Mean Reward": 61.395141579483656, "Episode": 3157, "Episode Step": 697}
{"Training Time": 11.145223505033387, "Episode Reward": 43402.145521169536, "Mean Reward": 62.53911458381778, "Episode": 3158, "Episode Step": 694}
{"Training Time": 11.153192222515742, "Episode Reward": 38311.842184646644, "Mean Reward": 60.90912906939053, "Episode": 3159, "Episode Step": 629}
{"Training Time": 11.161076466374928, "Episode Reward": 43143.47012865354, "Mean Reward": 64.48949197108153, "Episode": 3160, "Episode Step": 669}
{"Training Time": 11.166956598030197, "Episode Reward": 29154.036058194433, "Mean Reward": 59.256170849988685, "Episode": 3161, "Episode Step": 492}
{"Training Time": 11.186348540849156, "Episode Reward": 100336.1126286241, "Mean Reward": 62.39807999292544, "Episode": 3162, "Episode Step": 1608}
{"Training Time": 11.189752331972123, "Episode Reward": 19125.61930933691, "Mean Reward": 65.49869626485244, "Episode": 3163, "Episode Step": 292}
{"Training Time": 11.192746575805876, "Episode Reward": 16333.166432307393, "Mean Reward": 64.05163306787213, "Episode": 3164, "Episode Step": 255}
{"Training Time": 11.212154054178132, "Episode Reward": 99992.36850341354, "Mean Reward": 61.72368426136639, "Episode": 3165, "Episode Step": 1620}
{"Training Time": 11.219447844160928, "Episode Reward": 36221.989405270935, "Mean Reward": 58.048059944344445, "Episode": 3166, "Episode Step": 624}
{"Training Time": 11.223542309469646, "Episode Reward": 21412.514718739545, "Mean Reward": 61.178613482112986, "Episode": 3167, "Episode Step": 350}
{"Training Time": 11.242580448918872, "Episode Reward": 99311.20258412362, "Mean Reward": 62.26407685524992, "Episode": 3168, "Episode Step": 1595}
{"Training Time": 11.244650328887834, "Episode Reward": 9098.950708248793, "Mean Reward": 51.406501176546854, "Episode": 3169, "Episode Step": 177}
{"Training Time": 11.24625422332022, "Episode Reward": 6581.266353358394, "Mean Reward": 48.39166436292936, "Episode": 3170, "Episode Step": 136}
{"Training Time": 11.252349204156134, "Episode Reward": 28613.371266838898, "Mean Reward": 59.11853567528698, "Episode": 3171, "Episode Step": 484}
{"Training Time": 11.254423930843672, "Episode Reward": 8636.345112588137, "Mean Reward": 49.070142685159865, "Episode": 3172, "Episode Step": 176}
{"Training Time": 11.25733383834362, "Episode Reward": 16932.666558025092, "Mean Reward": 68.27688128235924, "Episode": 3173, "Episode Step": 248}
{"Training Time": 11.268844417797194, "Episode Reward": 54820.661528019555, "Mean Reward": 58.94694787959092, "Episode": 3174, "Episode Step": 930}
{"Training Time": 11.272979710565673, "Episode Reward": 21056.108106957006, "Mean Reward": 59.81848894021877, "Episode": 3175, "Episode Step": 352}
{"Training Time": 11.281070779164633, "Episode Reward": 44250.10926674047, "Mean Reward": 64.22367092415162, "Episode": 3176, "Episode Step": 689}
{"Training Time": 11.289075206385718, "Episode Reward": 38588.58894608615, "Mean Reward": 60.48368173367735, "Episode": 3177, "Episode Step": 638}
{"Training Time": 11.31275040474203, "Episode Reward": 133650.27126408348, "Mean Reward": 65.80515571840644, "Episode": 3178, "Episode Step": 2031}
{"Training Time": 11.315709095001221, "Episode Reward": 16191.70232394171, "Mean Reward": 64.50877419897095, "Episode": 3179, "Episode Step": 251}
{"Training Time": 11.35043385916286, "Episode Reward": 172734.0086655368, "Mean Reward": 59.277285060239116, "Episode": 3180, "Episode Step": 2914}
{"Training Time": 11.352653308908145, "Episode Reward": 9128.119598994524, "Mean Reward": 48.813473791414566, "Episode": 3181, "Episode Step": 187}
{"Training Time": 11.357488722205161, "Episode Reward": 24949.159897030437, "Mean Reward": 60.409588128402994, "Episode": 3182, "Episode Step": 413}
{"Training Time": 11.38227407111062, "Episode Reward": 133152.76255571813, "Mean Reward": 63.466521713879, "Episode": 3183, "Episode Step": 2098}
{"Training Time": 11.389561758041381, "Episode Reward": 39106.478515249146, "Mean Reward": 62.57036562439863, "Episode": 3184, "Episode Step": 625}
{"Training Time": 11.394752198590172, "Episode Reward": 25917.37161196296, "Mean Reward": 58.372458585502166, "Episode": 3185, "Episode Step": 444}
{"Training Time": 11.40891769223743, "Episode Reward": 73308.37939980494, "Mean Reward": 62.28409464724294, "Episode": 3186, "Episode Step": 1177}
{"Training Time": 11.410517229437827, "Episode Reward": 6604.291656704349, "Mean Reward": 48.20650844309744, "Episode": 3187, "Episode Step": 137}
{"Training Time": 11.414623110824161, "Episode Reward": 21758.66211177915, "Mean Reward": 62.167606033654714, "Episode": 3188, "Episode Step": 350}
{"Training Time": 11.433656237522762, "Episode Reward": 103055.85077037029, "Mean Reward": 64.61181866480896, "Episode": 3189, "Episode Step": 1595}
{"Training Time": 11.436585047509935, "Episode Reward": 16568.917597319654, "Mean Reward": 66.27567038927862, "Episode": 3190, "Episode Step": 250}
{"Training Time": 11.439540673361885, "Episode Reward": 15716.970286555166, "Mean Reward": 62.12241219982279, "Episode": 3191, "Episode Step": 253}
{"Training Time": 11.448116359710694, "Episode Reward": 42953.855092954385, "Mean Reward": 61.98247488160806, "Episode": 3192, "Episode Step": 693}
{"Training Time": 11.451565850575765, "Episode Reward": 19132.290273685496, "Mean Reward": 64.8552212667305, "Episode": 3193, "Episode Step": 295}
{"Training Time": 11.453016574713919, "Episode Reward": 6785.841227944104, "Mean Reward": 54.72452603180729, "Episode": 3194, "Episode Step": 124}
{"Training Time": 11.45636811223295, "Episode Reward": 14994.940159392732, "Mean Reward": 60.22064321041258, "Episode": 3195, "Episode Step": 249}
{"Training Time": 11.458547855549389, "Episode Reward": 9030.918516219042, "Mean Reward": 48.55332535601636, "Episode": 3196, "Episode Step": 186}
{"Training Time": 11.460676840278838, "Episode Reward": 9216.335718941535, "Mean Reward": 50.36249026744008, "Episode": 3197, "Episode Step": 183}
{"Training Time": 11.469440068072743, "Episode Reward": 44049.93052539005, "Mean Reward": 61.60829444110497, "Episode": 3198, "Episode Step": 715}
{"Training Time": 11.474646833870146, "Episode Reward": 22047.406055269334, "Mean Reward": 62.813122664584995, "Episode": 3199, "Episode Step": 351}
{"Training Time": 11.47795367691252, "Episode Reward": 15421.566507118052, "Mean Reward": 59.77351359348082, "Episode": 3200, "Episode Step": 258}
{"Training Time": 11.481221857468286, "Episode Reward": 14298.331015726988, "Mean Reward": 59.329174339116136, "Episode": 3201, "Episode Step": 241}
{"Training Time": 11.483511568639013, "Episode Reward": 8911.002941626992, "Mean Reward": 45.005065361752486, "Episode": 3202, "Episode Step": 198}
{"Training Time": 11.485119789441427, "Episode Reward": 6883.62594410665, "Mean Reward": 50.61489664784302, "Episode": 3203, "Episode Step": 136}
{"Training Time": 11.493593598074384, "Episode Reward": 44553.548868069214, "Mean Reward": 64.94686423916795, "Episode": 3204, "Episode Step": 686}
{"Training Time": 11.497147962782119, "Episode Reward": 17589.20791168663, "Mean Reward": 58.435906683344285, "Episode": 3205, "Episode Step": 301}
{"Training Time": 11.500114403631953, "Episode Reward": 16284.384821601452, "Mean Reward": 64.36515739763419, "Episode": 3206, "Episode Step": 253}
{"Training Time": 11.506129768623246, "Episode Reward": 29174.86822957285, "Mean Reward": 61.55035491471065, "Episode": 3207, "Episode Step": 474}
{"Training Time": 11.508296719458368, "Episode Reward": 9072.72446037899, "Mean Reward": 49.85013439768676, "Episode": 3208, "Episode Step": 182}
{"Training Time": 11.509755681951841, "Episode Reward": 6931.106967421205, "Mean Reward": 55.44885573936964, "Episode": 3209, "Episode Step": 125}
{"Training Time": 11.529489331377878, "Episode Reward": 104400.0974359507, "Mean Reward": 62.967489406484134, "Episode": 3210, "Episode Step": 1658}
{"Training Time": 11.537482001649009, "Episode Reward": 42461.25133561506, "Mean Reward": 61.62736042904943, "Episode": 3211, "Episode Step": 689}
{"Training Time": 11.540387166142464, "Episode Reward": 15256.508231242946, "Mean Reward": 61.27111739454998, "Episode": 3212, "Episode Step": 249}
{"Training Time": 11.543613986637856, "Episode Reward": 13343.31471016058, "Mean Reward": 56.780062596427996, "Episode": 3213, "Episode Step": 235}
{"Training Time": 11.545847257243262, "Episode Reward": 8623.919844475013, "Mean Reward": 46.365160454166734, "Episode": 3214, "Episode Step": 186}
{"Training Time": 11.548905053072506, "Episode Reward": 15961.857404072525, "Mean Reward": 62.3510054846583, "Episode": 3215, "Episode Step": 256}
{"Training Time": 11.551538171105914, "Episode Reward": 8570.141658990762, "Mean Reward": 47.08869043401518, "Episode": 3216, "Episode Step": 182}
{"Training Time": 11.559692554473877, "Episode Reward": 41584.02959091994, "Mean Reward": 60.00581470551218, "Episode": 3217, "Episode Step": 693}
{"Training Time": 11.56383764333195, "Episode Reward": 22513.4648097209, "Mean Reward": 64.14092538382023, "Episode": 3218, "Episode Step": 351}
{"Training Time": 11.56727292140325, "Episode Reward": 15216.785200050614, "Mean Reward": 60.867140800202456, "Episode": 3219, "Episode Step": 250}
{"Training Time": 11.577918393346998, "Episode Reward": 55340.76560979878, "Mean Reward": 60.48171104896041, "Episode": 3220, "Episode Step": 915}
{"Training Time": 11.579204122490353, "Episode Reward": 5961.094507666275, "Mean Reward": 54.68894043730527, "Episode": 3221, "Episode Step": 109}
{"Training Time": 11.582683458858066, "Episode Reward": 14327.861161169945, "Mean Reward": 55.1071583121921, "Episode": 3222, "Episode Step": 260}
{"Training Time": 11.585421292516921, "Episode Reward": 15106.314927534908, "Mean Reward": 64.55690139972182, "Episode": 3223, "Episode Step": 234}
{"Training Time": 11.587751348084874, "Episode Reward": 9678.351931745612, "Mean Reward": 48.880565311846524, "Episode": 3224, "Episode Step": 198}
{"Training Time": 11.591061037249036, "Episode Reward": 13558.802527890235, "Mean Reward": 56.028109619381134, "Episode": 3225, "Episode Step": 242}
{"Training Time": 11.598452357782257, "Episode Reward": 35685.65462290339, "Mean Reward": 56.64389622683078, "Episode": 3226, "Episode Step": 630}
{"Training Time": 11.601478669974538, "Episode Reward": 15675.283483645448, "Mean Reward": 62.451328620101386, "Episode": 3227, "Episode Step": 251}
{"Training Time": 11.604659846689966, "Episode Reward": 12706.265302902397, "Mean Reward": 55.4858746851633, "Episode": 3228, "Episode Step": 229}
{"Training Time": 11.612954706086052, "Episode Reward": 46325.89082226279, "Mean Reward": 66.17984403180398, "Episode": 3229, "Episode Step": 700}
{"Training Time": 11.615941814714008, "Episode Reward": 16257.270525384121, "Mean Reward": 64.77000209316382, "Episode": 3230, "Episode Step": 251}
{"Training Time": 11.62184996942679, "Episode Reward": 27927.465233616498, "Mean Reward": 60.71188094264456, "Episode": 3231, "Episode Step": 460}
{"Training Time": 11.624010628329383, "Episode Reward": 8796.205922088344, "Mean Reward": 48.867810678268576, "Episode": 3232, "Episode Step": 180}
{"Training Time": 11.627105304731263, "Episode Reward": 15817.49398695561, "Mean Reward": 61.54666920994401, "Episode": 3233, "Episode Step": 257}
{"Training Time": 11.630598939988348, "Episode Reward": 16430.019570117234, "Mean Reward": 65.19849035760807, "Episode": 3234, "Episode Step": 252}
{"Training Time": 11.637454670535194, "Episode Reward": 36386.140390673936, "Mean Reward": 63.2802441576938, "Episode": 3235, "Episode Step": 575}
{"Training Time": 11.63964924832185, "Episode Reward": 9349.907394353038, "Mean Reward": 50.540039969475885, "Episode": 3236, "Episode Step": 185}
{"Training Time": 11.664358656141493, "Episode Reward": 131449.9023703024, "Mean Reward": 63.59453428655173, "Episode": 3237, "Episode Step": 2067}
{"Training Time": 11.67176008330451, "Episode Reward": 36989.06728579909, "Mean Reward": 59.087966910222185, "Episode": 3238, "Episode Step": 626}
{"Training Time": 11.674802676969104, "Episode Reward": 15883.755716648033, "Mean Reward": 61.80449695193787, "Episode": 3239, "Episode Step": 257}
{"Training Time": 11.681013961964183, "Episode Reward": 29579.035674502215, "Mean Reward": 60.7372395780333, "Episode": 3240, "Episode Step": 487}
{"Training Time": 11.681356847484906, "Episode Reward": 244.64626354290436, "Mean Reward": 11.649822073471636, "Episode": 3241, "Episode Step": 21}
{"Training Time": 11.684400419725312, "Episode Reward": 16078.979293140124, "Mean Reward": 62.32162516720978, "Episode": 3242, "Episode Step": 258}
{"Training Time": 11.68785159614351, "Episode Reward": 16521.696739042338, "Mean Reward": 64.03758425985403, "Episode": 3243, "Episode Step": 258}
{"Training Time": 11.69518534918626, "Episode Reward": 37571.2614233523, "Mean Reward": 59.826849400242516, "Episode": 3244, "Episode Step": 628}
{"Training Time": 11.697343842784564, "Episode Reward": 9255.592927014468, "Mean Reward": 50.577010530133705, "Episode": 3245, "Episode Step": 183}
{"Training Time": 11.700834587746197, "Episode Reward": 17051.025495295737, "Mean Reward": 65.8340752714121, "Episode": 3246, "Episode Step": 259}
{"Training Time": 11.702957837250498, "Episode Reward": 8020.017810805561, "Mean Reward": 44.80456877545006, "Episode": 3247, "Episode Step": 179}
{"Training Time": 11.711146812240283, "Episode Reward": 43916.44277650976, "Mean Reward": 62.292826633347175, "Episode": 3248, "Episode Step": 705}
{"Training Time": 11.714897042512893, "Episode Reward": 14966.629141797346, "Mean Reward": 61.08828221141774, "Episode": 3249, "Episode Step": 245}
{"Training Time": 11.717224971652032, "Episode Reward": 9034.937600589017, "Mean Reward": 51.92492873901734, "Episode": 3250, "Episode Step": 174}
{"Training Time": 11.720294528603553, "Episode Reward": 17046.894114579838, "Mean Reward": 65.5649773637686, "Episode": 3251, "Episode Step": 260}
{"Training Time": 11.735456672244602, "Episode Reward": 75868.10746361114, "Mean Reward": 61.481448511840476, "Episode": 3252, "Episode Step": 1234}
{"Training Time": 11.743677742746142, "Episode Reward": 42269.16094035135, "Mean Reward": 62.06925248216057, "Episode": 3253, "Episode Step": 681}
{"Training Time": 11.752450076937675, "Episode Reward": 44242.403275349694, "Mean Reward": 61.362556553883074, "Episode": 3254, "Episode Step": 721}
{"Training Time": 11.755122743050258, "Episode Reward": 7980.718429184752, "Mean Reward": 44.092367012070454, "Episode": 3255, "Episode Step": 181}
{"Training Time": 11.758018912474315, "Episode Reward": 15034.718727382227, "Mean Reward": 62.906772917917266, "Episode": 3256, "Episode Step": 239}
{"Training Time": 11.760278383890787, "Episode Reward": 9274.45319808429, "Mean Reward": 50.404636946110266, "Episode": 3257, "Episode Step": 184}
{"Training Time": 11.766420576108827, "Episode Reward": 29138.75974612227, "Mean Reward": 61.60414322647414, "Episode": 3258, "Episode Step": 473}
{"Training Time": 11.76918624997139, "Episode Reward": 13896.829735857918, "Mean Reward": 60.42099885155617, "Episode": 3259, "Episode Step": 230}
{"Training Time": 11.771431742509206, "Episode Reward": 9567.722384479039, "Mean Reward": 51.71741829448129, "Episode": 3260, "Episode Step": 185}
{"Training Time": 11.780205153889126, "Episode Reward": 45650.41204506886, "Mean Reward": 65.40173645425338, "Episode": 3261, "Episode Step": 698}
{"Training Time": 11.782958760857582, "Episode Reward": 14905.909656494394, "Mean Reward": 64.2496105883379, "Episode": 3262, "Episode Step": 232}
{"Training Time": 11.797241382201513, "Episode Reward": 75392.01609594618, "Mean Reward": 62.46231656664969, "Episode": 3263, "Episode Step": 1207}
{"Training Time": 11.805135423077477, "Episode Reward": 37473.82791583018, "Mean Reward": 59.57683293454719, "Episode": 3264, "Episode Step": 629}
{"Training Time": 11.807820260855888, "Episode Reward": 13261.850156575827, "Mean Reward": 57.91200941736169, "Episode": 3265, "Episode Step": 229}
{"Training Time": 11.810591555833817, "Episode Reward": 14093.77841948806, "Mean Reward": 59.71940008257653, "Episode": 3266, "Episode Step": 236}
{"Training Time": 11.840363167524337, "Episode Reward": 162215.4529475033, "Mean Reward": 64.42234032863514, "Episode": 3267, "Episode Step": 2518}
{"Training Time": 11.848117803865009, "Episode Reward": 39334.96647502735, "Mean Reward": 59.59843405307174, "Episode": 3268, "Episode Step": 660}
{"Training Time": 11.861595173080762, "Episode Reward": 72647.05687864179, "Mean Reward": 62.78915892708884, "Episode": 3269, "Episode Step": 1157}
{"Training Time": 11.8700468369325, "Episode Reward": 41527.726134138895, "Mean Reward": 60.713049903711834, "Episode": 3270, "Episode Step": 684}
{"Training Time": 11.871849613918199, "Episode Reward": 7368.521523868984, "Mean Reward": 47.538848541090225, "Episode": 3271, "Episode Step": 155}
{"Training Time": 11.874796723922094, "Episode Reward": 17037.907890448932, "Mean Reward": 67.34350944841475, "Episode": 3272, "Episode Step": 253}
{"Training Time": 11.877350754472944, "Episode Reward": 9123.522762164697, "Mean Reward": 50.68623756758165, "Episode": 3273, "Episode Step": 180}
{"Training Time": 11.880041147801611, "Episode Reward": 13776.436102166637, "Mean Reward": 59.38119009554585, "Episode": 3274, "Episode Step": 232}
{"Training Time": 11.893172831137974, "Episode Reward": 70616.9073923002, "Mean Reward": 62.32736751306284, "Episode": 3275, "Episode Step": 1133}
{"Training Time": 11.89647566444344, "Episode Reward": 15312.579988962936, "Mean Reward": 63.27512392133445, "Episode": 3276, "Episode Step": 242}
{"Training Time": 11.898621589475209, "Episode Reward": 8937.217272404074, "Mean Reward": 49.10558940881359, "Episode": 3277, "Episode Step": 182}
{"Training Time": 11.916848741968472, "Episode Reward": 94158.8387258114, "Mean Reward": 60.396945943432584, "Episode": 3278, "Episode Step": 1559}
{"Training Time": 11.919467109441758, "Episode Reward": 9564.454201653212, "Mean Reward": 52.26477705821428, "Episode": 3279, "Episode Step": 183}
{"Training Time": 11.922464319467544, "Episode Reward": 15675.798527076868, "Mean Reward": 61.715742232586095, "Episode": 3280, "Episode Step": 254}
{"Training Time": 11.930410842763052, "Episode Reward": 43457.26603647727, "Mean Reward": 64.00186456034943, "Episode": 3281, "Episode Step": 679}
{"Training Time": 11.957852204971843, "Episode Reward": 147567.00505811325, "Mean Reward": 64.24336310758086, "Episode": 3282, "Episode Step": 2297}
{"Training Time": 11.96055834359593, "Episode Reward": 14623.396843739043, "Mean Reward": 63.85762813859844, "Episode": 3283, "Episode Step": 229}
{"Training Time": 11.96401531636715, "Episode Reward": 16834.362301969013, "Mean Reward": 57.25973572098304, "Episode": 3284, "Episode Step": 294}
{"Training Time": 11.997981722752254, "Episode Reward": 186829.5993623505, "Mean Reward": 64.84887169814318, "Episode": 3285, "Episode Step": 2881}
{"Training Time": 12.005970188909107, "Episode Reward": 44062.84053892141, "Mean Reward": 63.674625056244814, "Episode": 3286, "Episode Step": 692}
{"Training Time": 12.02956681225035, "Episode Reward": 127961.47439407496, "Mean Reward": 63.25332397136676, "Episode": 3287, "Episode Step": 2023}
{"Training Time": 12.03215696586503, "Episode Reward": 9488.618862801706, "Mean Reward": 53.30684754382981, "Episode": 3288, "Episode Step": 178}
{"Training Time": 12.035256138046583, "Episode Reward": 16306.099815529436, "Mean Reward": 62.9579143456735, "Episode": 3289, "Episode Step": 259}
{"Training Time": 12.038190853860643, "Episode Reward": 16109.50843832151, "Mean Reward": 65.7530956666184, "Episode": 3290, "Episode Step": 245}
{"Training Time": 12.040374158355926, "Episode Reward": 6741.5801126783745, "Mean Reward": 46.81652856026649, "Episode": 3291, "Episode Step": 144}
{"Training Time": 12.042618809739748, "Episode Reward": 8744.92573680616, "Mean Reward": 46.26944834288974, "Episode": 3292, "Episode Step": 189}
{"Training Time": 12.046167543596692, "Episode Reward": 18493.680297373005, "Mean Reward": 61.85177356980938, "Episode": 3293, "Episode Step": 299}
{"Training Time": 12.04935221195221, "Episode Reward": 14167.382648612132, "Mean Reward": 61.59731586353101, "Episode": 3294, "Episode Step": 230}
{"Training Time": 12.051726917227109, "Episode Reward": 10132.268775090008, "Mean Reward": 50.409297388507504, "Episode": 3295, "Episode Step": 201}
{"Training Time": 12.054648289746709, "Episode Reward": 16009.021324675641, "Mean Reward": 64.81385151690543, "Episode": 3296, "Episode Step": 247}
{"Training Time": 12.060594973365466, "Episode Reward": 28945.80006674898, "Mean Reward": 61.45605109713159, "Episode": 3297, "Episode Step": 471}
{"Training Time": 12.063496877219942, "Episode Reward": 14879.96968641125, "Mean Reward": 59.9998777677873, "Episode": 3298, "Episode Step": 248}
{"Training Time": 12.066008706688882, "Episode Reward": 6450.356062233527, "Mean Reward": 53.30872778705395, "Episode": 3299, "Episode Step": 121}
{"Training Time": 12.089283122486538, "Episode Reward": 128099.34040609079, "Mean Reward": 65.52395928700297, "Episode": 3300, "Episode Step": 1955}
{"Training Time": 12.090563655296961, "Episode Reward": 5921.848774762837, "Mean Reward": 54.8319330996559, "Episode": 3301, "Episode Step": 108}
{"Training Time": 12.093157346381082, "Episode Reward": 13371.733888774486, "Mean Reward": 60.78060858533858, "Episode": 3302, "Episode Step": 220}
{"Training Time": 12.114945251411863, "Episode Reward": 122837.18608882077, "Mean Reward": 66.72307772342248, "Episode": 3303, "Episode Step": 1841}
{"Training Time": 12.12217649863826, "Episode Reward": 38678.1438042403, "Mean Reward": 62.384102910065, "Episode": 3304, "Episode Step": 620}
{"Training Time": 12.124833034475644, "Episode Reward": 14708.421654591022, "Mean Reward": 64.51062129206589, "Episode": 3305, "Episode Step": 228}
{"Training Time": 12.133412302798694, "Episode Reward": 47394.40975039012, "Mean Reward": 67.32160475907688, "Episode": 3306, "Episode Step": 704}
{"Training Time": 12.136434918642044, "Episode Reward": 16426.3232780687, "Mean Reward": 63.422097598720846, "Episode": 3307, "Episode Step": 259}
{"Training Time": 12.139822268618477, "Episode Reward": 18639.058249846257, "Mean Reward": 64.49501124514276, "Episode": 3308, "Episode Step": 289}
{"Training Time": 12.147301899194717, "Episode Reward": 37635.34163638368, "Mean Reward": 62.310168272158414, "Episode": 3309, "Episode Step": 604}
{"Training Time": 12.15023462752501, "Episode Reward": 16345.445963135042, "Mean Reward": 65.12129865790854, "Episode": 3310, "Episode Step": 251}
{"Training Time": 12.152864706118901, "Episode Reward": 13797.223815043195, "Mean Reward": 62.43087699114568, "Episode": 3311, "Episode Step": 221}
{"Training Time": 12.165726119478544, "Episode Reward": 68268.6813026179, "Mean Reward": 64.77104487914411, "Episode": 3312, "Episode Step": 1054}
{"Training Time": 12.173067807753881, "Episode Reward": 38209.64438232058, "Mean Reward": 61.03777057878686, "Episode": 3313, "Episode Step": 626}
{"Training Time": 12.1757298741738, "Episode Reward": 12769.443923946903, "Mean Reward": 56.75308410643068, "Episode": 3314, "Episode Step": 225}
{"Training Time": 12.177903218600486, "Episode Reward": 7032.238021342241, "Mean Reward": 48.16601384480987, "Episode": 3315, "Episode Step": 146}
{"Training Time": 12.18498113334179, "Episode Reward": 34514.11329886676, "Mean Reward": 57.33241411771887, "Episode": 3316, "Episode Step": 602}
{"Training Time": 12.188515145248838, "Episode Reward": 18629.12828477915, "Mean Reward": 62.09709428259717, "Episode": 3317, "Episode Step": 300}
{"Training Time": 12.19068810330497, "Episode Reward": 6981.099226117243, "Mean Reward": 48.4798557369253, "Episode": 3318, "Episode Step": 144}
{"Training Time": 12.194298018084632, "Episode Reward": 17713.863838071604, "Mean Reward": 57.69988220870229, "Episode": 3319, "Episode Step": 307}
{"Training Time": 12.19636044608222, "Episode Reward": 8835.432124778867, "Mean Reward": 50.20131889078902, "Episode": 3320, "Episode Step": 176}
{"Training Time": 12.220716432200538, "Episode Reward": 137610.75534606556, "Mean Reward": 66.86625624201436, "Episode": 3321, "Episode Step": 2058}
{"Training Time": 12.225743384162586, "Episode Reward": 25939.875073679104, "Mean Reward": 60.325290869021174, "Episode": 3322, "Episode Step": 430}
{"Training Time": 12.234816506637467, "Episode Reward": 47499.076288276716, "Mean Reward": 60.585556490148875, "Episode": 3323, "Episode Step": 784}
{"Training Time": 12.2423013922241, "Episode Reward": 37348.850345211504, "Mean Reward": 63.1960242727775, "Episode": 3324, "Episode Step": 591}
{"Training Time": 12.248415154152447, "Episode Reward": 29327.798370568908, "Mean Reward": 57.16919760344816, "Episode": 3325, "Episode Step": 513}
{"Training Time": 12.251938882801268, "Episode Reward": 18651.63229363634, "Mean Reward": 62.800108732782284, "Episode": 3326, "Episode Step": 297}
{"Training Time": 12.254078228606119, "Episode Reward": 6697.485543919674, "Mean Reward": 46.83556324419352, "Episode": 3327, "Episode Step": 143}
{"Training Time": 12.257374442219735, "Episode Reward": 16296.200998024915, "Mean Reward": 57.58374910962868, "Episode": 3328, "Episode Step": 283}
{"Training Time": 12.260933382246229, "Episode Reward": 17546.217652113843, "Mean Reward": 57.90830908288397, "Episode": 3329, "Episode Step": 303}
{"Training Time": 12.263026285303964, "Episode Reward": 6772.864996440116, "Mean Reward": 49.43697077693515, "Episode": 3330, "Episode Step": 137}
{"Training Time": 12.268377321097585, "Episode Reward": 26239.820085509346, "Mean Reward": 57.66993425386669, "Episode": 3331, "Episode Step": 455}
{"Training Time": 12.27135398334927, "Episode Reward": 15099.474829951758, "Mean Reward": 59.68171869546149, "Episode": 3332, "Episode Step": 253}
{"Training Time": 12.27344379444917, "Episode Reward": 6310.959501843871, "Mean Reward": 45.402586344200515, "Episode": 3333, "Episode Step": 139}
{"Training Time": 12.278772053056294, "Episode Reward": 23789.098263969925, "Mean Reward": 52.28373244828555, "Episode": 3334, "Episode Step": 455}
{"Training Time": 12.282212034993702, "Episode Reward": 17463.32536774562, "Mean Reward": 60.42673137628242, "Episode": 3335, "Episode Step": 289}
{"Training Time": 12.28965045193831, "Episode Reward": 36527.921127268695, "Mean Reward": 62.44089081584392, "Episode": 3336, "Episode Step": 585}
{"Training Time": 12.29428668750657, "Episode Reward": 22181.73603063956, "Mean Reward": 55.873390505389324, "Episode": 3337, "Episode Step": 397}
{"Training Time": 12.297710984746615, "Episode Reward": 18047.418715063977, "Mean Reward": 62.23247832780682, "Episode": 3338, "Episode Step": 290}
{"Training Time": 12.299846418632402, "Episode Reward": 6977.802387640367, "Mean Reward": 49.13945343408709, "Episode": 3339, "Episode Step": 142}
{"Training Time": 12.301623868876034, "Episode Reward": 6338.185505942604, "Mean Reward": 42.25457003961736, "Episode": 3340, "Episode Step": 150}
{"Training Time": 12.310285508301522, "Episode Reward": 45087.55967836394, "Mean Reward": 60.929134700491815, "Episode": 3341, "Episode Step": 740}
{"Training Time": 12.31351803806093, "Episode Reward": 13539.719516093002, "Mean Reward": 57.371692864800856, "Episode": 3342, "Episode Step": 236}
{"Training Time": 12.318953838613298, "Episode Reward": 25404.72223829039, "Mean Reward": 55.10785734987069, "Episode": 3343, "Episode Step": 461}
{"Training Time": 12.322421310014194, "Episode Reward": 18346.824330413707, "Mean Reward": 62.40416438916227, "Episode": 3344, "Episode Step": 294}
{"Training Time": 12.324583543870185, "Episode Reward": 6898.868731499753, "Mean Reward": 47.90881063541495, "Episode": 3345, "Episode Step": 144}
{"Training Time": 12.329448459148407, "Episode Reward": 24935.011354882146, "Mean Reward": 59.653137212636715, "Episode": 3346, "Episode Step": 418}
{"Training Time": 12.331031513876384, "Episode Reward": 6523.934506026087, "Mean Reward": 49.05213914305328, "Episode": 3347, "Episode Step": 133}
{"Training Time": 12.365754278898239, "Episode Reward": 188341.70878682833, "Mean Reward": 64.76674992669474, "Episode": 3348, "Episode Step": 2908}
{"Training Time": 12.377906237509515, "Episode Reward": 58896.481661505626, "Mean Reward": 61.9962964857954, "Episode": 3349, "Episode Step": 950}
{"Training Time": 12.380937780009376, "Episode Reward": 15261.029835034993, "Mean Reward": 64.39253094951474, "Episode": 3350, "Episode Step": 237}
{"Training Time": 12.389588980542289, "Episode Reward": 47512.46000864829, "Mean Reward": 68.16708753034187, "Episode": 3351, "Episode Step": 697}
{"Training Time": 12.392818616694875, "Episode Reward": 16350.762751157286, "Mean Reward": 60.5583805598418, "Episode": 3352, "Episode Step": 270}
{"Training Time": 12.396391095585294, "Episode Reward": 18211.719477888564, "Mean Reward": 59.906971966738695, "Episode": 3353, "Episode Step": 304}
{"Training Time": 12.39983062585195, "Episode Reward": 16779.712399369113, "Mean Reward": 66.32297391054985, "Episode": 3354, "Episode Step": 253}
{"Training Time": 12.402070720261998, "Episode Reward": 9419.427699720927, "Mean Reward": 50.1033388283028, "Episode": 3355, "Episode Step": 188}
{"Training Time": 12.407639748321639, "Episode Reward": 29426.825038419454, "Mean Reward": 61.82106100508289, "Episode": 3356, "Episode Step": 476}
{"Training Time": 12.415350728631019, "Episode Reward": 38776.955554106105, "Mean Reward": 62.847577883478294, "Episode": 3357, "Episode Step": 617}
{"Training Time": 12.41815573308203, "Episode Reward": 15665.043757412539, "Mean Reward": 65.81951158576697, "Episode": 3358, "Episode Step": 238}
{"Training Time": 12.421596879164378, "Episode Reward": 17764.426545899718, "Mean Reward": 60.629442136176515, "Episode": 3359, "Episode Step": 293}
{"Training Time": 12.427809395260281, "Episode Reward": 32596.939399524486, "Mean Reward": 66.93416714481414, "Episode": 3360, "Episode Step": 487}
{"Training Time": 12.435380100806555, "Episode Reward": 37690.703525153964, "Mean Reward": 59.07633781372095, "Episode": 3361, "Episode Step": 638}
{"Training Time": 12.438273531132275, "Episode Reward": 15584.548383199359, "Mean Reward": 63.61040156407901, "Episode": 3362, "Episode Step": 245}
{"Training Time": 12.44614035056697, "Episode Reward": 39111.10576356392, "Mean Reward": 62.37815911254214, "Episode": 3363, "Episode Step": 627}
{"Training Time": 12.504462350540692, "Episode Reward": 336061.7922003127, "Mean Reward": 67.21235844006254, "Episode": 3364, "Episode Step": 5000}
{"Training Time": 12.508188032507896, "Episode Reward": 18292.2874895827, "Mean Reward": 62.64482016980377, "Episode": 3365, "Episode Step": 292}
{"Training Time": 12.521984533071517, "Episode Reward": 75634.78225861475, "Mean Reward": 65.71223480331429, "Episode": 3366, "Episode Step": 1151}
{"Training Time": 12.537269911964735, "Episode Reward": 89404.02046090942, "Mean Reward": 67.83309594909667, "Episode": 3367, "Episode Step": 1318}
{"Training Time": 12.54534403860569, "Episode Reward": 42590.742421976895, "Mean Reward": 61.90514886915246, "Episode": 3368, "Episode Step": 688}
{"Training Time": 12.547964577211275, "Episode Reward": 8456.328337887917, "Mean Reward": 45.95830618417346, "Episode": 3369, "Episode Step": 184}
{"Training Time": 12.550833540028997, "Episode Reward": 16070.180102459983, "Mean Reward": 66.13242840518511, "Episode": 3370, "Episode Step": 243}
{"Training Time": 12.562662787768575, "Episode Reward": 59838.5296776809, "Mean Reward": 58.95421643121271, "Episode": 3371, "Episode Step": 1015}
{"Training Time": 12.57648679388894, "Episode Reward": 75742.74458384352, "Mean Reward": 66.38277351782956, "Episode": 3372, "Episode Step": 1141}
{"Training Time": 12.634450677235922, "Episode Reward": 338992.3344578529, "Mean Reward": 67.79846689157057, "Episode": 3373, "Episode Step": 5000}
{"Training Time": 12.641123916639222, "Episode Reward": 32263.922847571444, "Mean Reward": 58.44913559342653, "Episode": 3374, "Episode Step": 552}
{"Training Time": 12.660085662470923, "Episode Reward": 104533.70002054672, "Mean Reward": 65.7444654217275, "Episode": 3375, "Episode Step": 1590}
{"Training Time": 12.682321761118041, "Episode Reward": 127415.32731501368, "Mean Reward": 66.39673127410822, "Episode": 3376, "Episode Step": 1919}
{"Training Time": 12.683551938070192, "Episode Reward": 5686.77270261386, "Mean Reward": 54.6805067559025, "Episode": 3377, "Episode Step": 104}
{"Training Time": 12.69189963195059, "Episode Reward": 44542.40789536596, "Mean Reward": 65.79380782181087, "Episode": 3378, "Episode Step": 677}
{"Training Time": 12.720304701394506, "Episode Reward": 164945.50979126297, "Mean Reward": 67.60061876691105, "Episode": 3379, "Episode Step": 2440}
{"Training Time": 12.721919634474649, "Episode Reward": 6142.639681190647, "Mean Reward": 45.840594635751096, "Episode": 3380, "Episode Step": 134}
{"Training Time": 12.766247662239605, "Episode Reward": 247300.7650328321, "Mean Reward": 65.73651383116217, "Episode": 3381, "Episode Step": 3762}
{"Training Time": 12.784800715843836, "Episode Reward": 106894.67238104479, "Mean Reward": 67.9991554586799, "Episode": 3382, "Episode Step": 1572}
{"Training Time": 12.790611063904233, "Episode Reward": 27348.765995678346, "Mean Reward": 55.8138081544456, "Episode": 3383, "Episode Step": 490}
{"Training Time": 12.799274894462691, "Episode Reward": 47159.23296810769, "Mean Reward": 68.34671444653289, "Episode": 3384, "Episode Step": 690}
{"Training Time": 12.80931215027968, "Episode Reward": 53676.219240414044, "Mean Reward": 63.297428349544866, "Episode": 3385, "Episode Step": 848}
{"Training Time": 12.817585529751248, "Episode Reward": 39226.79864818635, "Mean Reward": 56.36034288532521, "Episode": 3386, "Episode Step": 696}
{"Training Time": 12.82096422413985, "Episode Reward": 17685.50701114476, "Mean Reward": 71.60124296010025, "Episode": 3387, "Episode Step": 247}
{"Training Time": 12.830894438889292, "Episode Reward": 55871.19604517496, "Mean Reward": 66.19809957959119, "Episode": 3388, "Episode Step": 844}
{"Training Time": 12.832158460815748, "Episode Reward": 5476.072216208041, "Mean Reward": 51.66105864347209, "Episode": 3389, "Episode Step": 106}
{"Training Time": 12.833231683638362, "Episode Reward": 2508.421012334433, "Mean Reward": 50.168420246688655, "Episode": 3390, "Episode Step": 50}
{"Training Time": 12.835303998324607, "Episode Reward": 8727.207492188136, "Mean Reward": 49.30625701801207, "Episode": 3391, "Episode Step": 177}
{"Training Time": 12.836905612746875, "Episode Reward": 6178.566550141383, "Mean Reward": 46.455387595047995, "Episode": 3392, "Episode Step": 133}
{"Training Time": 12.839368126127455, "Episode Reward": 8269.882176682991, "Mean Reward": 48.93421406321297, "Episode": 3393, "Episode Step": 169}
{"Training Time": 12.845113973352644, "Episode Reward": 31249.952993126044, "Mean Reward": 64.69969563794211, "Episode": 3394, "Episode Step": 483}
{"Training Time": 12.85093942642212, "Episode Reward": 28156.34011685153, "Mean Reward": 58.41564339595753, "Episode": 3395, "Episode Step": 482}
{"Training Time": 12.854352249701817, "Episode Reward": 16970.24853405244, "Mean Reward": 67.61055192849578, "Episode": 3396, "Episode Step": 251}
{"Training Time": 12.857250538335906, "Episode Reward": 16840.237348379233, "Mean Reward": 69.0173661818821, "Episode": 3397, "Episode Step": 244}
{"Training Time": 12.86017664750417, "Episode Reward": 15010.932083336298, "Mean Reward": 61.020049119253244, "Episode": 3398, "Episode Step": 246}
{"Training Time": 12.862981058624056, "Episode Reward": 5040.830048256837, "Mean Reward": 49.419902433890556, "Episode": 3399, "Episode Step": 102}
{"Training Time": 12.871350189977221, "Episode Reward": 45017.54628860434, "Mean Reward": 64.96038425484032, "Episode": 3400, "Episode Step": 693}
{"Training Time": 12.88112440135744, "Episode Reward": 47180.50591054054, "Mean Reward": 56.234214434494085, "Episode": 3401, "Episode Step": 839}
{"Training Time": 12.883709996408886, "Episode Reward": 8984.505579435548, "Mean Reward": 50.47475044626712, "Episode": 3402, "Episode Step": 178}
{"Training Time": 12.891611339714792, "Episode Reward": 41707.53763820387, "Mean Reward": 61.78894464919092, "Episode": 3403, "Episode Step": 675}
{"Training Time": 12.900327072209782, "Episode Reward": 42573.2734229731, "Mean Reward": 57.60930097831272, "Episode": 3404, "Episode Step": 739}
{"Training Time": 12.902919683059057, "Episode Reward": 8891.705469372268, "Mean Reward": 48.85552455699048, "Episode": 3405, "Episode Step": 182}
{"Training Time": 12.904976890285809, "Episode Reward": 8756.767924163112, "Mean Reward": 50.91144141955298, "Episode": 3406, "Episode Step": 172}
{"Training Time": 12.91074866135915, "Episode Reward": 26336.773040949487, "Mean Reward": 54.41482033254026, "Episode": 3407, "Episode Step": 484}
{"Training Time": 12.913407720857196, "Episode Reward": 9211.418342683422, "Mean Reward": 51.46043766862247, "Episode": 3408, "Episode Step": 179}
{"Training Time": 12.936399328642421, "Episode Reward": 123758.8240917775, "Mean Reward": 63.826108350581485, "Episode": 3409, "Episode Step": 1939}
{"Training Time": 12.949026544160313, "Episode Reward": 59890.233106171676, "Mean Reward": 56.34076491643619, "Episode": 3410, "Episode Step": 1063}
{"Training Time": 12.951606042782466, "Episode Reward": 9012.051499314135, "Mean Reward": 50.91554519386517, "Episode": 3411, "Episode Step": 177}
{"Training Time": 12.954545481403668, "Episode Reward": 16253.317977970448, "Mean Reward": 65.53757249181632, "Episode": 3412, "Episode Step": 248}
{"Training Time": 12.95623509142134, "Episode Reward": 6384.929083956784, "Mean Reward": 44.649853733963525, "Episode": 3413, "Episode Step": 143}
{"Training Time": 12.958867337505023, "Episode Reward": 9438.438816237183, "Mean Reward": 51.01858819587667, "Episode": 3414, "Episode Step": 185}
{"Training Time": 12.96367787943946, "Episode Reward": 26008.942395437174, "Mean Reward": 63.90403536962451, "Episode": 3415, "Episode Step": 407}
{"Training Time": 12.965908575256666, "Episode Reward": 9046.170499401462, "Mean Reward": 47.86333597566911, "Episode": 3416, "Episode Step": 189}
{"Training Time": 12.968476700252957, "Episode Reward": 9309.577678714644, "Mean Reward": 52.00881384756784, "Episode": 3417, "Episode Step": 179}
{"Training Time": 12.97566286722819, "Episode Reward": 37514.30625572218, "Mean Reward": 61.197889487311876, "Episode": 3418, "Episode Step": 613}
{"Training Time": 13.00163069109122, "Episode Reward": 131151.4150160076, "Mean Reward": 59.317691097244506, "Episode": 3419, "Episode Step": 2211}
{"Training Time": 13.00421966916985, "Episode Reward": 9005.166149340435, "Mean Reward": 49.75229916762672, "Episode": 3420, "Episode Step": 181}
{"Training Time": 13.032994959155719, "Episode Reward": 167317.5602935037, "Mean Reward": 68.1815649117782, "Episode": 3421, "Episode Step": 2454}
{"Training Time": 13.034634631673494, "Episode Reward": 6493.006039536068, "Mean Reward": 47.39420466814648, "Episode": 3422, "Episode Step": 137}
{"Training Time": 13.035668553643756, "Episode Reward": 2639.9339968068043, "Mean Reward": 54.99862493347509, "Episode": 3423, "Episode Step": 48}
{"Training Time": 13.048993730809954, "Episode Reward": 76658.55973697215, "Mean Reward": 67.3625305245801, "Episode": 3424, "Episode Step": 1138}
{"Training Time": 13.051812874476115, "Episode Reward": 13540.557088491001, "Mean Reward": 56.18488418460996, "Episode": 3425, "Episode Step": 241}
{"Training Time": 13.052890534467167, "Episode Reward": 2653.9086476619063, "Mean Reward": 53.07817295323812, "Episode": 3426, "Episode Step": 50}
{"Training Time": 13.06610693944825, "Episode Reward": 76926.55554900775, "Mean Reward": 67.89634205561143, "Episode": 3427, "Episode Step": 1133}
{"Training Time": 13.068285610278448, "Episode Reward": 7952.920534973948, "Mean Reward": 42.75763728480617, "Episode": 3428, "Episode Step": 186}
{"Training Time": 13.070948053863313, "Episode Reward": 9146.314745215985, "Mean Reward": 48.91077403858815, "Episode": 3429, "Episode Step": 187}
{"Training Time": 13.073031125002437, "Episode Reward": 9087.125462812606, "Mean Reward": 51.631394675071625, "Episode": 3430, "Episode Step": 176}
{"Training Time": 13.074275380836593, "Episode Reward": 5449.644043119462, "Mean Reward": 50.45966706592095, "Episode": 3431, "Episode Step": 108}
{"Training Time": 13.079405571950806, "Episode Reward": 26343.05902383955, "Mean Reward": 65.69341402453753, "Episode": 3432, "Episode Step": 401}
{"Training Time": 13.102671242753665, "Episode Reward": 135294.81245638165, "Mean Reward": 67.78297217253589, "Episode": 3433, "Episode Step": 1996}
{"Training Time": 13.104375976920128, "Episode Reward": 6426.987045597261, "Mean Reward": 45.26047215209339, "Episode": 3434, "Episode Step": 142}
{"Training Time": 13.10542279581229, "Episode Reward": 2585.423660186859, "Mean Reward": 53.862992920559556, "Episode": 3435, "Episode Step": 48}
{"Training Time": 13.107520083056556, "Episode Reward": 9118.270476159047, "Mean Reward": 52.10440272090884, "Episode": 3436, "Episode Step": 175}
{"Training Time": 13.108827768630452, "Episode Reward": 5200.059097796036, "Mean Reward": 47.706964199963636, "Episode": 3437, "Episode Step": 109}
{"Training Time": 13.109865508344438, "Episode Reward": 2582.0777070348167, "Mean Reward": 53.793285563225346, "Episode": 3438, "Episode Step": 48}
{"Training Time": 13.121367863880263, "Episode Reward": 65763.02135921537, "Mean Reward": 66.96845352262258, "Episode": 3439, "Episode Step": 982}
{"Training Time": 13.124423350029522, "Episode Reward": 15344.534682950325, "Mean Reward": 58.791320624330744, "Episode": 3440, "Episode Step": 261}
{"Training Time": 13.126186648077436, "Episode Reward": 5387.8773221038155, "Mean Reward": 48.9807029282165, "Episode": 3441, "Episode Step": 110}
{"Training Time": 13.149924778607156, "Episode Reward": 138801.9521795876, "Mean Reward": 68.47654276250005, "Episode": 3442, "Episode Step": 2027}
{"Training Time": 13.160873821112844, "Episode Reward": 53390.08110999229, "Mean Reward": 57.04068494657296, "Episode": 3443, "Episode Step": 936}
{"Training Time": 13.168841527501742, "Episode Reward": 39977.72876164469, "Mean Reward": 62.957053167944395, "Episode": 3444, "Episode Step": 635}
{"Training Time": 13.187552503082488, "Episode Reward": 102438.39980670298, "Mean Reward": 64.38617209723631, "Episode": 3445, "Episode Step": 1591}
{"Training Time": 13.19047234667672, "Episode Reward": 12916.197106406682, "Mean Reward": 52.935234042650336, "Episode": 3446, "Episode Step": 244}
{"Training Time": 13.193873677783543, "Episode Reward": 16750.67861181424, "Mean Reward": 67.00271444725696, "Episode": 3447, "Episode Step": 250}
{"Training Time": 13.196671978036562, "Episode Reward": 15548.140174640746, "Mean Reward": 65.88194989254553, "Episode": 3448, "Episode Step": 236}
{"Training Time": 13.199329701662064, "Episode Reward": 8075.730837687003, "Mean Reward": 42.728734590936526, "Episode": 3449, "Episode Step": 189}
{"Training Time": 13.201946351395714, "Episode Reward": 9208.721905791374, "Mean Reward": 50.87691660658217, "Episode": 3450, "Episode Step": 181}
{"Training Time": 13.215025341974364, "Episode Reward": 73224.301538254, "Mean Reward": 65.90846223065166, "Episode": 3451, "Episode Step": 1111}
{"Training Time": 13.219224178062545, "Episode Reward": 21108.424827927316, "Mean Reward": 59.62831872295852, "Episode": 3452, "Episode Step": 354}
{"Training Time": 13.221931214729945, "Episode Reward": 8916.17404425895, "Mean Reward": 47.42645768222846, "Episode": 3453, "Episode Step": 188}
{"Training Time": 13.224648711416457, "Episode Reward": 15159.229973009338, "Mean Reward": 66.48785075881288, "Episode": 3454, "Episode Step": 228}
{"Training Time": 13.225942876670096, "Episode Reward": 5872.699806884129, "Mean Reward": 53.388180062583, "Episode": 3455, "Episode Step": 110}
{"Training Time": 13.233875247769886, "Episode Reward": 37811.10236068872, "Mean Reward": 59.17230416383211, "Episode": 3456, "Episode Step": 639}
{"Training Time": 13.236574193636576, "Episode Reward": 15596.470744050852, "Mean Reward": 66.93764267832984, "Episode": 3457, "Episode Step": 233}
{"Training Time": 13.23783891028828, "Episode Reward": 5888.3806170610505, "Mean Reward": 54.522042750565284, "Episode": 3458, "Episode Step": 108}
{"Training Time": 13.244317692253325, "Episode Reward": 31757.71528734364, "Mean Reward": 62.270029975183604, "Episode": 3459, "Episode Step": 510}
{"Training Time": 13.246982679168383, "Episode Reward": 15377.44422860882, "Mean Reward": 67.15041147864113, "Episode": 3460, "Episode Step": 229}
{"Training Time": 13.249914969735675, "Episode Reward": 15673.535283398207, "Mean Reward": 62.444363678877316, "Episode": 3461, "Episode Step": 251}
{"Training Time": 13.250992377532853, "Episode Reward": 2629.358584696201, "Mean Reward": 51.55605068031767, "Episode": 3462, "Episode Step": 51}
{"Training Time": 13.258804449968867, "Episode Reward": 45856.13613534774, "Mean Reward": 68.33999424045862, "Episode": 3463, "Episode Step": 671}
{"Training Time": 13.260983433590996, "Episode Reward": 8370.993340546038, "Mean Reward": 45.248612651600205, "Episode": 3464, "Episode Step": 185}
{"Training Time": 13.262722352809377, "Episode Reward": 5555.098890419433, "Mean Reward": 50.96421000384801, "Episode": 3465, "Episode Step": 109}
{"Training Time": 13.265647894740106, "Episode Reward": 16585.588594818037, "Mean Reward": 68.25345100748163, "Episode": 3466, "Episode Step": 243}
{"Training Time": 13.268335553341442, "Episode Reward": 12475.810037968133, "Mean Reward": 55.202699283044836, "Episode": 3467, "Episode Step": 226}
{"Training Time": 13.270971071918806, "Episode Reward": 9174.85958152657, "Mean Reward": 50.68983194213575, "Episode": 3468, "Episode Step": 181}
{"Training Time": 13.289564086662399, "Episode Reward": 109862.76002834612, "Mean Reward": 69.66566900973122, "Episode": 3469, "Episode Step": 1577}
{"Training Time": 13.2968555180894, "Episode Reward": 33661.36778349016, "Mean Reward": 54.46823265936919, "Episode": 3470, "Episode Step": 618}
{"Training Time": 13.30483704580201, "Episode Reward": 38660.64940662033, "Mean Reward": 61.659727921244546, "Episode": 3471, "Episode Step": 627}
{"Training Time": 13.3128785736031, "Episode Reward": 46976.59439312225, "Mean Reward": 69.49200354012167, "Episode": 3472, "Episode Step": 676}
{"Training Time": 13.315245600011613, "Episode Reward": 9005.742792952098, "Mean Reward": 45.71443042107664, "Episode": 3473, "Episode Step": 197}
{"Training Time": 13.318507302469678, "Episode Reward": 14051.385624697235, "Mean Reward": 60.048656515800154, "Episode": 3474, "Episode Step": 234}
{"Training Time": 13.321232447756662, "Episode Reward": 14769.366406591178, "Mean Reward": 64.21463655039642, "Episode": 3475, "Episode Step": 230}
{"Training Time": 13.324144092202186, "Episode Reward": 14760.880757368057, "Mean Reward": 59.28064561191991, "Episode": 3476, "Episode Step": 249}
{"Training Time": 13.325234644744132, "Episode Reward": 2540.456259468738, "Mean Reward": 50.80912518937476, "Episode": 3477, "Episode Step": 50}
{"Training Time": 13.328013095524575, "Episode Reward": 14295.102148652237, "Mean Reward": 62.42402685000977, "Episode": 3478, "Episode Step": 229}
{"Training Time": 13.330873500572311, "Episode Reward": 13958.80275491368, "Mean Reward": 59.147469300481696, "Episode": 3479, "Episode Step": 236}
{"Training Time": 13.33448578165637, "Episode Reward": 16590.58094676599, "Mean Reward": 63.32282804109156, "Episode": 3480, "Episode Step": 262}
{"Training Time": 13.342657264735964, "Episode Reward": 48039.176549433665, "Mean Reward": 69.82438451952568, "Episode": 3481, "Episode Step": 688}
{"Training Time": 13.350350598891577, "Episode Reward": 35846.31308435995, "Mean Reward": 54.97900779809808, "Episode": 3482, "Episode Step": 652}
{"Training Time": 13.353054437239965, "Episode Reward": 9103.8575883536, "Mean Reward": 48.424774406136166, "Episode": 3483, "Episode Step": 188}
{"Training Time": 13.361070599754651, "Episode Reward": 46044.88642045386, "Mean Reward": 68.41736466635047, "Episode": 3484, "Episode Step": 673}
{"Training Time": 13.377967496646775, "Episode Reward": 85806.38301790289, "Mean Reward": 60.51225882785817, "Episode": 3485, "Episode Step": 1418}
{"Training Time": 13.386010345286794, "Episode Reward": 40464.638188464676, "Mean Reward": 63.523764817056005, "Episode": 3486, "Episode Step": 637}
{"Training Time": 13.399289455016454, "Episode Reward": 77099.01990537335, "Mean Reward": 68.6545146085248, "Episode": 3487, "Episode Step": 1123}
{"Training Time": 13.401413730250464, "Episode Reward": 8783.895469641218, "Mean Reward": 49.90849698659783, "Episode": 3488, "Episode Step": 176}
{"Training Time": 13.407640096081627, "Episode Reward": 30120.7164438186, "Mean Reward": 62.232885214501245, "Episode": 3489, "Episode Step": 484}
{"Training Time": 13.410413368874126, "Episode Reward": 15648.57223771127, "Mean Reward": 67.16125423910417, "Episode": 3490, "Episode Step": 233}
{"Training Time": 13.411706635289722, "Episode Reward": 6024.311386407329, "Mean Reward": 55.78066098525305, "Episode": 3491, "Episode Step": 108}
{"Training Time": 13.414399986929364, "Episode Reward": 9294.392444425352, "Mean Reward": 49.43825768311357, "Episode": 3492, "Episode Step": 188}
{"Training Time": 13.41653403249052, "Episode Reward": 9614.119752284458, "Mean Reward": 54.317060747369815, "Episode": 3493, "Episode Step": 177}
{"Training Time": 13.418696245551109, "Episode Reward": 8876.692119981919, "Mean Reward": 48.77303362627428, "Episode": 3494, "Episode Step": 182}
{"Training Time": 13.421365670031971, "Episode Reward": 9223.133719117664, "Mean Reward": 50.12572673433513, "Episode": 3495, "Episode Step": 184}
{"Training Time": 13.423453885581758, "Episode Reward": 9392.294461105555, "Mean Reward": 53.67025406346032, "Episode": 3496, "Episode Step": 175}
{"Training Time": 13.43567459391223, "Episode Reward": 63780.10800807965, "Mean Reward": 62.285261726640286, "Episode": 3497, "Episode Step": 1024}
{"Training Time": 13.438485871420966, "Episode Reward": 9483.313178798178, "Mean Reward": 48.632375275888094, "Episode": 3498, "Episode Step": 195}
{"Training Time": 13.457476521929106, "Episode Reward": 107007.09228988785, "Mean Reward": 67.81184555759687, "Episode": 3499, "Episode Step": 1578}
{"Training Time": 13.459042750000954, "Episode Reward": 5231.4613166613, "Mean Reward": 48.892161837956074, "Episode": 3500, "Episode Step": 107}
{"Training Time": 13.466899829970465, "Episode Reward": 40414.22578263376, "Mean Reward": 64.35386271120025, "Episode": 3501, "Episode Step": 628}
{"Training Time": 13.471472283601761, "Episode Reward": 25761.12389551622, "Mean Reward": 66.91201011822395, "Episode": 3502, "Episode Step": 385}
{"Training Time": 13.472763876385159, "Episode Reward": 5783.85931451727, "Mean Reward": 53.062929490984125, "Episode": 3503, "Episode Step": 109}
{"Training Time": 13.475342038075128, "Episode Reward": 9502.701299112598, "Mean Reward": 53.08771675481898, "Episode": 3504, "Episode Step": 179}
{"Training Time": 13.502102188070616, "Episode Reward": 153451.82010290565, "Mean Reward": 68.50527683165431, "Episode": 3505, "Episode Step": 2240}
{"Training Time": 13.503388473060395, "Episode Reward": 5909.842808671293, "Mean Reward": 55.2321757819747, "Episode": 3506, "Episode Step": 107}
{"Training Time": 13.50688396361139, "Episode Reward": 16840.437515030706, "Mean Reward": 66.8271329961536, "Episode": 3507, "Episode Step": 252}
{"Training Time": 13.520248755812645, "Episode Reward": 77861.58214684676, "Mean Reward": 70.2721860531108, "Episode": 3508, "Episode Step": 1108}
{"Training Time": 13.5215877380636, "Episode Reward": 5687.1951158311695, "Mean Reward": 52.17610198010247, "Episode": 3509, "Episode Step": 109}
{"Training Time": 13.52332535220517, "Episode Reward": 6469.055037116904, "Mean Reward": 61.61004797254194, "Episode": 3510, "Episode Step": 105}
{"Training Time": 13.526170177194807, "Episode Reward": 14387.406202019038, "Mean Reward": 61.74852447218471, "Episode": 3511, "Episode Step": 233}
{"Training Time": 13.526809058917893, "Episode Reward": 2571.6005209819486, "Mean Reward": 50.423539627097036, "Episode": 3512, "Episode Step": 51}
{"Training Time": 13.529480182197359, "Episode Reward": 9573.987074551287, "Mean Reward": 53.18881708084049, "Episode": 3513, "Episode Step": 180}
{"Training Time": 13.532448947760795, "Episode Reward": 16956.208584264852, "Mean Reward": 70.35771196790395, "Episode": 3514, "Episode Step": 241}
{"Training Time": 13.537530398302607, "Episode Reward": 25257.03945771327, "Mean Reward": 59.99296783304814, "Episode": 3515, "Episode Step": 421}
{"Training Time": 13.539643792510033, "Episode Reward": 6628.130685928696, "Mean Reward": 47.684393423947455, "Episode": 3516, "Episode Step": 139}
{"Training Time": 13.542395320534705, "Episode Reward": 14028.278157767798, "Mean Reward": 62.072027246760165, "Episode": 3517, "Episode Step": 226}
{"Training Time": 13.550834519730675, "Episode Reward": 45010.9956265441, "Mean Reward": 64.2096941890786, "Episode": 3518, "Episode Step": 701}
{"Training Time": 13.553555299705929, "Episode Reward": 9080.19679596392, "Mean Reward": 48.55720211745412, "Episode": 3519, "Episode Step": 187}
{"Training Time": 13.571661847498682, "Episode Reward": 106267.2477919674, "Mean Reward": 69.4103512684307, "Episode": 3520, "Episode Step": 1531}
{"Training Time": 13.578950526383188, "Episode Reward": 37240.64110311612, "Mean Reward": 60.55388797254653, "Episode": 3521, "Episode Step": 615}
{"Training Time": 13.588312104145686, "Episode Reward": 50700.86048244741, "Mean Reward": 67.33182002981064, "Episode": 3522, "Episode Step": 753}
{"Training Time": 13.591206013361614, "Episode Reward": 16521.4775294678, "Mean Reward": 67.43460216109307, "Episode": 3523, "Episode Step": 245}
{"Training Time": 13.591821653644244, "Episode Reward": 2371.961397706152, "Mean Reward": 46.50904701384612, "Episode": 3524, "Episode Step": 51}
{"Training Time": 13.59452896806929, "Episode Reward": 9206.028749425403, "Mean Reward": 50.30616802964701, "Episode": 3525, "Episode Step": 183}
{"Training Time": 13.59724470085568, "Episode Reward": 12961.09545364279, "Mean Reward": 57.34997988337518, "Episode": 3526, "Episode Step": 226}
{"Training Time": 13.607795353068246, "Episode Reward": 53109.99231903109, "Mean Reward": 60.76658160072207, "Episode": 3527, "Episode Step": 874}
{"Training Time": 13.608895764748256, "Episode Reward": 2888.549628079791, "Mean Reward": 56.63822800156453, "Episode": 3528, "Episode Step": 51}
{"Training Time": 13.616905111670494, "Episode Reward": 46218.38889402639, "Mean Reward": 69.81629742300059, "Episode": 3529, "Episode Step": 662}
{"Training Time": 13.621785596940253, "Episode Reward": 23981.722495910064, "Mean Reward": 59.0682820096307, "Episode": 3530, "Episode Step": 406}
{"Training Time": 13.623587242232428, "Episode Reward": 6340.587006307764, "Mean Reward": 58.17052299364921, "Episode": 3531, "Episode Step": 109}
{"Training Time": 13.629937137232886, "Episode Reward": 35508.49301715791, "Mean Reward": 67.50664071703025, "Episode": 3532, "Episode Step": 526}
{"Training Time": 13.634806090858248, "Episode Reward": 24605.20558296514, "Mean Reward": 60.30687642883613, "Episode": 3533, "Episode Step": 408}
{"Training Time": 13.637426191700829, "Episode Reward": 9594.70301419703, "Mean Reward": 52.71814842965401, "Episode": 3534, "Episode Step": 182}
{"Training Time": 13.640293124980397, "Episode Reward": 18008.009568587306, "Mean Reward": 74.10703526167616, "Episode": 3535, "Episode Step": 243}
{"Training Time": 13.64245943526427, "Episode Reward": 8926.573340325138, "Mean Reward": 49.047106265522736, "Episode": 3536, "Episode Step": 182}
{"Training Time": 13.64596480389436, "Episode Reward": 17288.640446889167, "Mean Reward": 68.605716059084, "Episode": 3537, "Episode Step": 252}
{"Training Time": 13.659111515283584, "Episode Reward": 76495.41535933109, "Mean Reward": 69.35214447808802, "Episode": 3538, "Episode Step": 1103}
{"Training Time": 13.660369765030014, "Episode Reward": 5664.853355087515, "Mean Reward": 53.44201278384448, "Episode": 3539, "Episode Step": 106}
{"Training Time": 13.665646749999787, "Episode Reward": 25758.600214191818, "Mean Reward": 63.44482811377295, "Episode": 3540, "Episode Step": 406}
{"Training Time": 13.678992754750782, "Episode Reward": 75653.67662082451, "Mean Reward": 66.89096076111805, "Episode": 3541, "Episode Step": 1131}
{"Training Time": 13.69301838417848, "Episode Reward": 74786.15056272912, "Mean Reward": 62.687469038331194, "Episode": 3542, "Episode Step": 1193}
{"Training Time": 13.7045571855704, "Episode Reward": 61026.79336017268, "Mean Reward": 65.19956555574005, "Episode": 3543, "Episode Step": 936}
{"Training Time": 13.722743243310187, "Episode Reward": 105885.7883693308, "Mean Reward": 68.26936709821457, "Episode": 3544, "Episode Step": 1551}
{"Training Time": 13.725747421648768, "Episode Reward": 16138.423333563078, "Mean Reward": 63.28793464142384, "Episode": 3545, "Episode Step": 255}
{"Training Time": 13.729062935577499, "Episode Reward": 15204.91385059856, "Mean Reward": 62.830222523134545, "Episode": 3546, "Episode Step": 242}
{"Training Time": 13.736364578339789, "Episode Reward": 40184.48921348208, "Mean Reward": 64.50158782260365, "Episode": 3547, "Episode Step": 623}
{"Training Time": 13.743848359982172, "Episode Reward": 39517.3098068646, "Mean Reward": 61.55344206676729, "Episode": 3548, "Episode Step": 642}
{"Training Time": 13.74854174779521, "Episode Reward": 17381.618393442768, "Mean Reward": 67.11049572757825, "Episode": 3549, "Episode Step": 259}
{"Training Time": 13.792967924144532, "Episode Reward": 244507.17227256243, "Mean Reward": 65.28896455876166, "Episode": 3550, "Episode Step": 3745}
{"Training Time": 13.79592034889592, "Episode Reward": 15749.362196597876, "Mean Reward": 63.25045058874649, "Episode": 3551, "Episode Step": 249}
{"Training Time": 13.79803839524587, "Episode Reward": 7043.759211049538, "Mean Reward": 50.312565793210986, "Episode": 3552, "Episode Step": 140}
{"Training Time": 13.800991593599319, "Episode Reward": 16774.9979906808, "Mean Reward": 66.83266131745339, "Episode": 3553, "Episode Step": 251}
{"Training Time": 13.808331217235988, "Episode Reward": 38559.302306540296, "Mean Reward": 61.49808980309457, "Episode": 3554, "Episode Step": 627}
{"Training Time": 13.81052344057295, "Episode Reward": 7175.959783211741, "Mean Reward": 49.489377815253384, "Episode": 3555, "Episode Step": 145}
{"Training Time": 13.823767695559395, "Episode Reward": 72899.24470362018, "Mean Reward": 64.22840943050235, "Episode": 3556, "Episode Step": 1135}
{"Training Time": 13.831197991636063, "Episode Reward": 38251.97607733829, "Mean Reward": 60.71742234498141, "Episode": 3557, "Episode Step": 630}
{"Training Time": 13.837190280821588, "Episode Reward": 30567.35842438357, "Mean Reward": 64.08251242009133, "Episode": 3558, "Episode Step": 477}
{"Training Time": 13.854761326975293, "Episode Reward": 94613.93745299253, "Mean Reward": 62.69975974353382, "Episode": 3559, "Episode Step": 1509}
{"Training Time": 13.86222893887096, "Episode Reward": 39780.15500683704, "Mean Reward": 62.449222930670395, "Episode": 3560, "Episode Step": 637}
{"Training Time": 13.875611022512118, "Episode Reward": 70048.25583734881, "Mean Reward": 64.1467544298066, "Episode": 3561, "Episode Step": 1092}
{"Training Time": 13.893922858304448, "Episode Reward": 104214.34591293134, "Mean Reward": 66.29411317616497, "Episode": 3562, "Episode Step": 1572}
{"Training Time": 13.896028048329883, "Episode Reward": 9211.531647163867, "Mean Reward": 50.89244003957938, "Episode": 3563, "Episode Step": 181}
{"Training Time": 13.904775916139284, "Episode Reward": 45625.627776661255, "Mean Reward": 64.44297708567974, "Episode": 3564, "Episode Step": 708}
{"Training Time": 13.926813302238783, "Episode Reward": 116204.14968062783, "Mean Reward": 62.1080436561346, "Episode": 3565, "Episode Step": 1871}
{"Training Time": 13.928909823033544, "Episode Reward": 9321.530647286056, "Mean Reward": 53.26588941306318, "Episode": 3566, "Episode Step": 175}
{"Training Time": 13.931548440853755, "Episode Reward": 9776.478673754305, "Mean Reward": 54.013694330134285, "Episode": 3567, "Episode Step": 181}
{"Training Time": 13.933652406136195, "Episode Reward": 8268.074192925165, "Mean Reward": 47.51766777543198, "Episode": 3568, "Episode Step": 174}
{"Training Time": 13.936746038330925, "Episode Reward": 16293.905861750482, "Mean Reward": 63.154673882753805, "Episode": 3569, "Episode Step": 258}
{"Training Time": 13.939342746668391, "Episode Reward": 9362.100206665322, "Mean Reward": 52.011667814807346, "Episode": 3570, "Episode Step": 180}
{"Training Time": 13.950845908059014, "Episode Reward": 64429.34117103398, "Mean Reward": 65.74422568472855, "Episode": 3571, "Episode Step": 980}
{"Training Time": 13.95144439558188, "Episode Reward": 2605.664023828163, "Mean Reward": 52.11328047656326, "Episode": 3572, "Episode Step": 50}
{"Training Time": 13.95403215640121, "Episode Reward": 9465.958216551691, "Mean Reward": 52.88244813716029, "Episode": 3573, "Episode Step": 179}
{"Training Time": 13.96007062335809, "Episode Reward": 33339.313847130245, "Mean Reward": 64.86247830180982, "Episode": 3574, "Episode Step": 514}
{"Training Time": 13.966537656121783, "Episode Reward": 34966.85433371935, "Mean Reward": 64.5144913906261, "Episode": 3575, "Episode Step": 542}
{"Training Time": 13.969157637755076, "Episode Reward": 9532.909590148813, "Mean Reward": 52.96060883416007, "Episode": 3576, "Episode Step": 180}
{"Training Time": 13.9719122297234, "Episode Reward": 14191.74629535644, "Mean Reward": 60.90878238350404, "Episode": 3577, "Episode Step": 233}
{"Training Time": 13.97320016503334, "Episode Reward": 5896.637918143693, "Mean Reward": 56.15845636327327, "Episode": 3578, "Episode Step": 105}
{"Training Time": 13.978655295570691, "Episode Reward": 26017.121137081645, "Mean Reward": 62.69185816164252, "Episode": 3579, "Episode Step": 415}
{"Training Time": 13.981409948070844, "Episode Reward": 12679.760651912742, "Mean Reward": 54.89073875286901, "Episode": 3580, "Episode Step": 231}
{"Training Time": 13.982725734445784, "Episode Reward": 6082.571574088272, "Mean Reward": 56.320107167484004, "Episode": 3581, "Episode Step": 108}
{"Training Time": 13.991760989692477, "Episode Reward": 47269.21627011882, "Mean Reward": 66.01845847781958, "Episode": 3582, "Episode Step": 716}
{"Training Time": 13.99898347225454, "Episode Reward": 37015.76640406052, "Mean Reward": 60.48327843800739, "Episode": 3583, "Episode Step": 612}
{"Training Time": 14.001156926949818, "Episode Reward": 9162.306161096853, "Mean Reward": 50.90170089498251, "Episode": 3584, "Episode Step": 180}
{"Training Time": 14.009492056634691, "Episode Reward": 39190.865011841976, "Mean Reward": 59.20070243480661, "Episode": 3585, "Episode Step": 662}
{"Training Time": 14.02537326057752, "Episode Reward": 87877.07972541322, "Mean Reward": 65.72706037802035, "Episode": 3586, "Episode Step": 1337}
{"Training Time": 14.028350107471148, "Episode Reward": 16437.758869425816, "Mean Reward": 66.54963105030694, "Episode": 3587, "Episode Step": 247}
{"Training Time": 14.034649801916546, "Episode Reward": 31332.457232672525, "Mean Reward": 63.81355851868131, "Episode": 3588, "Episode Step": 491}
{"Training Time": 14.03734528667397, "Episode Reward": 14271.589325071784, "Mean Reward": 62.59469002224466, "Episode": 3589, "Episode Step": 228}
{"Training Time": 14.047469833890597, "Episode Reward": 54513.331766060786, "Mean Reward": 63.982783762982145, "Episode": 3590, "Episode Step": 852}
{"Training Time": 14.053582866390546, "Episode Reward": 30630.30209203713, "Mean Reward": 64.34937414293515, "Episode": 3591, "Episode Step": 476}
{"Training Time": 14.055634258058337, "Episode Reward": 8513.0362162136, "Mean Reward": 48.92549549548046, "Episode": 3592, "Episode Step": 174}
{"Training Time": 14.05961720387141, "Episode Reward": 22396.960349999285, "Mean Reward": 66.0677296460156, "Episode": 3593, "Episode Step": 339}
{"Training Time": 14.06820362581147, "Episode Reward": 42290.27151128154, "Mean Reward": 61.2015506675565, "Episode": 3594, "Episode Step": 691}
{"Training Time": 14.071105906698438, "Episode Reward": 14178.5721538256, "Mean Reward": 57.403126128848584, "Episode": 3595, "Episode Step": 247}
{"Training Time": 14.07308469997512, "Episode Reward": 8518.606337696558, "Mean Reward": 50.405954660926376, "Episode": 3596, "Episode Step": 169}
{"Training Time": 14.076301390859816, "Episode Reward": 14743.398704063813, "Mean Reward": 63.27638928782753, "Episode": 3597, "Episode Step": 233}
{"Training Time": 14.078380270004272, "Episode Reward": 8864.772591433431, "Mean Reward": 50.08346096855046, "Episode": 3598, "Episode Step": 177}
{"Training Time": 14.081569288306767, "Episode Reward": 8847.762250968859, "Mean Reward": 49.98735735010655, "Episode": 3599, "Episode Step": 177}
{"Training Time": 14.085609713594119, "Episode Reward": 18878.936833477368, "Mean Reward": 62.72072037700122, "Episode": 3600, "Episode Step": 301}
{"Training Time": 14.095456261965964, "Episode Reward": 50171.63154191888, "Mean Reward": 59.23451185586645, "Episode": 3601, "Episode Step": 847}
{"Training Time": 14.100227916638056, "Episode Reward": 24843.50833073015, "Mean Reward": 61.34199587834605, "Episode": 3602, "Episode Step": 405}
{"Training Time": 14.102251073916753, "Episode Reward": 6898.806159885644, "Mean Reward": 53.47911751849336, "Episode": 3603, "Episode Step": 129}
{"Training Time": 14.104313369724485, "Episode Reward": 8900.079608825663, "Mean Reward": 50.85759776471807, "Episode": 3604, "Episode Step": 175}
{"Training Time": 14.11068726585971, "Episode Reward": 35108.431262287646, "Mean Reward": 64.53755746744052, "Episode": 3605, "Episode Step": 544}
{"Training Time": 14.112797957791223, "Episode Reward": 7089.472686225815, "Mean Reward": 51.37299047989721, "Episode": 3606, "Episode Step": 138}
{"Training Time": 14.11565740969446, "Episode Reward": 14683.130434835499, "Mean Reward": 60.67409270593181, "Episode": 3607, "Episode Step": 242}
{"Training Time": 14.116912704971101, "Episode Reward": 5812.478137285791, "Mean Reward": 54.834699408356514, "Episode": 3608, "Episode Step": 106}
{"Training Time": 14.12308508720663, "Episode Reward": 30343.487855284144, "Mean Reward": 63.4801001156572, "Episode": 3609, "Episode Step": 478}
{"Training Time": 14.125965024696455, "Episode Reward": 11209.515129684087, "Mean Reward": 46.901736944284885, "Episode": 3610, "Episode Step": 239}
{"Training Time": 14.12722660197152, "Episode Reward": 5897.537243949032, "Mean Reward": 56.707088884125305, "Episode": 3611, "Episode Step": 104}
{"Training Time": 14.130428008900749, "Episode Reward": 15522.02540211306, "Mean Reward": 66.05117192388536, "Episode": 3612, "Episode Step": 235}
{"Training Time": 14.131839028861787, "Episode Reward": 5606.382943340177, "Mean Reward": 47.11246170874098, "Episode": 3613, "Episode Step": 119}
{"Training Time": 14.133998197250897, "Episode Reward": 8412.794105038867, "Mean Reward": 47.5299101979597, "Episode": 3614, "Episode Step": 177}
{"Training Time": 14.156040164166027, "Episode Reward": 115994.68346640201, "Mean Reward": 63.17793217124293, "Episode": 3615, "Episode Step": 1836}
{"Training Time": 14.156621220310528, "Episode Reward": 2113.0445265806147, "Mean Reward": 44.95839418256627, "Episode": 3616, "Episode Step": 47}
{"Training Time": 14.15868721557988, "Episode Reward": 8871.911132269688, "Mean Reward": 50.69663504154107, "Episode": 3617, "Episode Step": 175}
{"Training Time": 14.183034428622987, "Episode Reward": 131527.04724378607, "Mean Reward": 64.00342931571099, "Episode": 3618, "Episode Step": 2055}
{"Training Time": 14.184257456130451, "Episode Reward": 5349.071301265291, "Mean Reward": 51.43337789678165, "Episode": 3619, "Episode Step": 104}
{"Training Time": 14.186249025000466, "Episode Reward": 8585.23747245376, "Mean Reward": 51.10260400270096, "Episode": 3620, "Episode Step": 168}
{"Training Time": 14.188786699175834, "Episode Reward": 8619.734931606778, "Mean Reward": 48.69906741020778, "Episode": 3621, "Episode Step": 177}
{"Training Time": 14.19024936331643, "Episode Reward": 5599.384428505736, "Mean Reward": 46.275904367816, "Episode": 3622, "Episode Step": 121}
{"Training Time": 14.195010390811497, "Episode Reward": 25328.313843299507, "Mean Reward": 63.32078460824877, "Episode": 3623, "Episode Step": 400}
{"Training Time": 14.197170436647204, "Episode Reward": 6869.103699781001, "Mean Reward": 48.37396971676761, "Episode": 3624, "Episode Step": 142}
{"Training Time": 14.199263323346774, "Episode Reward": 8569.411490610984, "Mean Reward": 49.24949132535048, "Episode": 3625, "Episode Step": 174}
{"Training Time": 14.201257701913516, "Episode Reward": 8502.036955789024, "Mean Reward": 50.30791098100014, "Episode": 3626, "Episode Step": 169}
{"Training Time": 14.209943221145206, "Episode Reward": 46478.79405874611, "Mean Reward": 67.06896689573753, "Episode": 3627, "Episode Step": 693}
{"Training Time": 14.212923308875826, "Episode Reward": 14341.996869430692, "Mean Reward": 57.367987477722764, "Episode": 3628, "Episode Step": 250}
{"Training Time": 14.21876255525483, "Episode Reward": 30676.17523636761, "Mean Reward": 62.34994966741384, "Episode": 3629, "Episode Step": 492}
{"Training Time": 14.238483908904923, "Episode Reward": 103752.52518161657, "Mean Reward": 63.3023338508948, "Episode": 3630, "Episode Step": 1639}
{"Training Time": 14.24049044860734, "Episode Reward": 6455.639484055603, "Mean Reward": 37.97434990620943, "Episode": 3631, "Episode Step": 170}
{"Training Time": 14.243500834703445, "Episode Reward": 16212.062669448447, "Mean Reward": 63.57671635077823, "Episode": 3632, "Episode Step": 255}
{"Training Time": 14.25291377696726, "Episode Reward": 46480.17415086949, "Mean Reward": 60.99760387253214, "Episode": 3633, "Episode Step": 762}
{"Training Time": 14.256393954753875, "Episode Reward": 16552.89188458616, "Mean Reward": 55.733642709044304, "Episode": 3634, "Episode Step": 297}
{"Training Time": 14.259264617760977, "Episode Reward": 15654.2500389176, "Mean Reward": 63.89489811803102, "Episode": 3635, "Episode Step": 245}
{"Training Time": 14.273542513052622, "Episode Reward": 72693.3177475232, "Mean Reward": 61.03553127415885, "Episode": 3636, "Episode Step": 1191}
{"Training Time": 14.28217931860023, "Episode Reward": 43220.13786432624, "Mean Reward": 59.04390418623804, "Episode": 3637, "Episode Step": 732}
{"Training Time": 14.286197346382671, "Episode Reward": 21222.86844184824, "Mean Reward": 62.055170882597196, "Episode": 3638, "Episode Step": 342}
{"Training Time": 14.298837113049295, "Episode Reward": 62050.48093535099, "Mean Reward": 59.95215549309275, "Episode": 3639, "Episode Step": 1035}
{"Training Time": 14.301595106389787, "Episode Reward": 14478.690006476329, "Mean Reward": 61.87474361742021, "Episode": 3640, "Episode Step": 234}
{"Training Time": 14.3044900816679, "Episode Reward": 16577.167050602795, "Mean Reward": 67.93920922378194, "Episode": 3641, "Episode Step": 244}
{"Training Time": 14.313824082215627, "Episode Reward": 46578.768484990884, "Mean Reward": 61.36860142950051, "Episode": 3642, "Episode Step": 759}
{"Training Time": 14.31916102806727, "Episode Reward": 27706.908801126967, "Mean Reward": 59.971664071703394, "Episode": 3643, "Episode Step": 462}
{"Training Time": 14.319774203631614, "Episode Reward": 2660.064507495536, "Mean Reward": 53.20129014991072, "Episode": 3644, "Episode Step": 50}
{"Training Time": 14.33300064696206, "Episode Reward": 63432.04343266543, "Mean Reward": 57.875952037103495, "Episode": 3645, "Episode Step": 1096}
{"Training Time": 14.335874530275662, "Episode Reward": 14578.74194070712, "Mean Reward": 59.74894237994721, "Episode": 3646, "Episode Step": 244}
{"Training Time": 14.34238321642081, "Episode Reward": 36136.7063795896, "Mean Reward": 64.99407622228345, "Episode": 3647, "Episode Step": 556}
{"Training Time": 14.345060584147772, "Episode Reward": 8369.349033727114, "Mean Reward": 44.04920544066902, "Episode": 3648, "Episode Step": 190}
{"Training Time": 14.349059638579687, "Episode Reward": 14142.888152595784, "Mean Reward": 58.201185813151376, "Episode": 3649, "Episode Step": 243}
{"Training Time": 14.350570890307427, "Episode Reward": 5952.523496610739, "Mean Reward": 56.69069996772132, "Episode": 3650, "Episode Step": 105}
{"Training Time": 14.353210681411955, "Episode Reward": 8476.12284492387, "Mean Reward": 46.57210354353774, "Episode": 3651, "Episode Step": 182}
{"Training Time": 14.355881792770491, "Episode Reward": 12003.523580015288, "Mean Reward": 53.827460000068555, "Episode": 3652, "Episode Step": 223}
{"Training Time": 14.35855708360672, "Episode Reward": 13492.995232826928, "Mean Reward": 59.968867701453014, "Episode": 3653, "Episode Step": 225}
{"Training Time": 14.36802299691571, "Episode Reward": 48147.14485510567, "Mean Reward": 62.93744425504009, "Episode": 3654, "Episode Step": 765}
{"Training Time": 14.370859613352351, "Episode Reward": 15283.41758022483, "Mean Reward": 62.89472255236556, "Episode": 3655, "Episode Step": 243}
{"Training Time": 14.372949751085706, "Episode Reward": 8645.899118939544, "Mean Reward": 49.1244268121565, "Episode": 3656, "Episode Step": 176}
{"Training Time": 14.382564042210578, "Episode Reward": 47614.83346901234, "Mean Reward": 60.88853384784186, "Episode": 3657, "Episode Step": 782}
{"Training Time": 14.388326295283106, "Episode Reward": 27423.980376752774, "Mean Reward": 56.08175946166212, "Episode": 3658, "Episode Step": 489}
{"Training Time": 14.39040473030673, "Episode Reward": 8817.928172433494, "Mean Reward": 50.1018646160994, "Episode": 3659, "Episode Step": 176}
{"Training Time": 14.395017043881946, "Episode Reward": 21205.993463835923, "Mean Reward": 60.0736358748893, "Episode": 3660, "Episode Step": 353}
{"Training Time": 14.40929478943348, "Episode Reward": 73184.74158182195, "Mean Reward": 60.583395349190354, "Episode": 3661, "Episode Step": 1208}
{"Training Time": 14.411398543914158, "Episode Reward": 8283.960285715108, "Mean Reward": 46.53910272873656, "Episode": 3662, "Episode Step": 178}
{"Training Time": 14.470475894146496, "Episode Reward": 302763.80257171096, "Mean Reward": 60.55276051434219, "Episode": 3663, "Episode Step": 5000}
{"Training Time": 14.473534689744314, "Episode Reward": 12668.747221536174, "Mean Reward": 53.909562644834786, "Episode": 3664, "Episode Step": 235}
{"Training Time": 14.481483097804917, "Episode Reward": 43214.8715661352, "Mean Reward": 64.3078445924631, "Episode": 3665, "Episode Step": 672}
{"Training Time": 14.500737956364949, "Episode Reward": 93570.68726263985, "Mean Reward": 59.14708423681407, "Episode": 3666, "Episode Step": 1582}
{"Training Time": 14.502400311960114, "Episode Reward": 5343.653337125781, "Mean Reward": 38.16895240804129, "Episode": 3667, "Episode Step": 140}
{"Training Time": 14.503655463324653, "Episode Reward": 5581.973481212098, "Mean Reward": 53.16165220201998, "Episode": 3668, "Episode Step": 105}
{"Training Time": 14.505760732491812, "Episode Reward": 5989.650473903475, "Mean Reward": 44.04154760223144, "Episode": 3669, "Episode Step": 136}
{"Training Time": 14.50748362057739, "Episode Reward": 5811.157173151431, "Mean Reward": 40.63746274931071, "Episode": 3670, "Episode Step": 143}
{"Training Time": 14.513289914462302, "Episode Reward": 30234.990751644524, "Mean Reward": 61.956948261566644, "Episode": 3671, "Episode Step": 488}
{"Training Time": 14.516007596386803, "Episode Reward": 8211.137461102204, "Mean Reward": 43.44517175186351, "Episode": 3672, "Episode Step": 189}
{"Training Time": 14.517737749152714, "Episode Reward": 6016.717457948305, "Mean Reward": 42.97655327105932, "Episode": 3673, "Episode Step": 140}
{"Training Time": 14.520750347243416, "Episode Reward": 15612.484809320176, "Mean Reward": 62.700742206105126, "Episode": 3674, "Episode Step": 249}
{"Training Time": 14.522848337491354, "Episode Reward": 6146.13126613445, "Mean Reward": 45.19214166275331, "Episode": 3675, "Episode Step": 136}
{"Training Time": 14.526416444977125, "Episode Reward": 17522.204500378724, "Mean Reward": 58.213303987969184, "Episode": 3676, "Episode Step": 301}
{"Training Time": 14.529263309968842, "Episode Reward": 15626.809075474288, "Mean Reward": 64.84153143350326, "Episode": 3677, "Episode Step": 241}
{"Training Time": 14.531336785554887, "Episode Reward": 6137.478527852348, "Mean Reward": 47.2113732911719, "Episode": 3678, "Episode Step": 130}
{"Training Time": 14.534435739980804, "Episode Reward": 15229.492180785071, "Mean Reward": 60.43449278089314, "Episode": 3679, "Episode Step": 252}
{"Training Time": 14.537332151399719, "Episode Reward": 16519.909477340712, "Mean Reward": 68.8329561555863, "Episode": 3680, "Episode Step": 240}
{"Training Time": 14.539342461360825, "Episode Reward": 6274.882106821163, "Mean Reward": 49.022516459540334, "Episode": 3681, "Episode Step": 128}
{"Training Time": 14.54780341943105, "Episode Reward": 42217.23481767375, "Mean Reward": 60.13851113628739, "Episode": 3682, "Episode Step": 702}
{"Training Time": 14.549156609707408, "Episode Reward": 6120.115404726726, "Mean Reward": 55.63741277024297, "Episode": 3683, "Episode Step": 110}
{"Training Time": 14.551227881113688, "Episode Reward": 6365.125822416834, "Mean Reward": 47.858088890352136, "Episode": 3684, "Episode Step": 133}
{"Training Time": 14.552893036670156, "Episode Reward": 5728.528219202514, "Mean Reward": 41.21243323167276, "Episode": 3685, "Episode Step": 139}
{"Training Time": 14.555819958912002, "Episode Reward": 16329.530593724448, "Mean Reward": 66.65114528050795, "Episode": 3686, "Episode Step": 245}
{"Training Time": 14.578847046362029, "Episode Reward": 114324.58083143712, "Mean Reward": 60.81094725076443, "Episode": 3687, "Episode Step": 1880}
{"Training Time": 14.581803780529235, "Episode Reward": 15782.6449791707, "Mean Reward": 63.1305799166828, "Episode": 3688, "Episode Step": 250}
{"Training Time": 14.58477949725257, "Episode Reward": 16436.68240342329, "Mean Reward": 66.5452728883534, "Episode": 3689, "Episode Step": 247}
{"Training Time": 14.58840710832013, "Episode Reward": 15494.116922196665, "Mean Reward": 58.46836574413836, "Episode": 3690, "Episode Step": 265}
{"Training Time": 14.591312559975519, "Episode Reward": 15568.070719507063, "Mean Reward": 63.80356852256993, "Episode": 3691, "Episode Step": 244}
{"Training Time": 14.593372866113981, "Episode Reward": 8008.993365508222, "Mean Reward": 46.56391491574548, "Episode": 3692, "Episode Step": 172}
{"Training Time": 14.61051257305675, "Episode Reward": 86153.12865266521, "Mean Reward": 60.50079259316377, "Episode": 3693, "Episode Step": 1424}
{"Training Time": 14.612178260551559, "Episode Reward": 5585.7737052565335, "Mean Reward": 40.18542233997506, "Episode": 3694, "Episode Step": 139}
{"Training Time": 14.613475881682502, "Episode Reward": 5750.563904232431, "Mean Reward": 53.24596207622621, "Episode": 3695, "Episode Step": 108}
{"Training Time": 14.617546380294694, "Episode Reward": 19349.608729756957, "Mean Reward": 62.41809267663535, "Episode": 3696, "Episode Step": 310}
{"Training Time": 14.623427151640255, "Episode Reward": 31059.56193297366, "Mean Reward": 62.243611088123565, "Episode": 3697, "Episode Step": 499}
{"Training Time": 14.624641955826018, "Episode Reward": 5830.360176508156, "Mean Reward": 57.16039388733486, "Episode": 3698, "Episode Step": 102}
{"Training Time": 14.639715553919475, "Episode Reward": 73780.32267777021, "Mean Reward": 60.92512194696136, "Episode": 3699, "Episode Step": 1211}
{"Training Time": 14.641615882515907, "Episode Reward": 6803.918411361035, "Mean Reward": 49.66363803913165, "Episode": 3700, "Episode Step": 137}
{"Training Time": 14.64372836192449, "Episode Reward": 8424.782811869814, "Mean Reward": 47.597643004914204, "Episode": 3701, "Episode Step": 177}
{"Training Time": 14.651716374754905, "Episode Reward": 38331.26248031999, "Mean Reward": 59.42831392297673, "Episode": 3702, "Episode Step": 645}
{"Training Time": 14.654558032751083, "Episode Reward": 16568.800768673118, "Mean Reward": 67.90492118308654, "Episode": 3703, "Episode Step": 244}
{"Training Time": 14.65737377749549, "Episode Reward": 15822.39118068817, "Mean Reward": 65.92662991953404, "Episode": 3704, "Episode Step": 240}
{"Training Time": 14.659350989196035, "Episode Reward": 6550.64072162311, "Mean Reward": 52.40512577298488, "Episode": 3705, "Episode Step": 125}
{"Training Time": 14.662312328351868, "Episode Reward": 15202.942526998748, "Mean Reward": 62.05282664081122, "Episode": 3706, "Episode Step": 245}
{"Training Time": 14.664344786405563, "Episode Reward": 8027.016893464799, "Mean Reward": 46.398941580721385, "Episode": 3707, "Episode Step": 173}
{"Training Time": 14.666904699140124, "Episode Reward": 9166.455915825481, "Mean Reward": 51.49694334733417, "Episode": 3708, "Episode Step": 178}
{"Training Time": 14.668585299717055, "Episode Reward": 6457.736587556969, "Mean Reward": 45.799550266361486, "Episode": 3709, "Episode Step": 141}
{"Training Time": 14.669806188080045, "Episode Reward": 5555.5011321997035, "Mean Reward": 54.465697374506895, "Episode": 3710, "Episode Step": 102}
{"Training Time": 14.672527820865314, "Episode Reward": 9464.214253475491, "Mean Reward": 49.55085996584027, "Episode": 3711, "Episode Step": 191}
{"Training Time": 14.675473965009054, "Episode Reward": 15865.87559111002, "Mean Reward": 63.718375867911725, "Episode": 3712, "Episode Step": 249}
{"Training Time": 14.677512298623721, "Episode Reward": 8251.68298980764, "Mean Reward": 48.25545608074643, "Episode": 3713, "Episode Step": 171}
{"Training Time": 14.685278058581883, "Episode Reward": 37716.09489559527, "Mean Reward": 60.44245976858216, "Episode": 3714, "Episode Step": 624}
{"Training Time": 14.698745633363723, "Episode Reward": 71559.80796799847, "Mean Reward": 61.689489627584884, "Episode": 3715, "Episode Step": 1160}
{"Training Time": 14.700754163596365, "Episode Reward": 8318.212058913308, "Mean Reward": 48.36169801693784, "Episode": 3716, "Episode Step": 172}
{"Training Time": 14.702424112492137, "Episode Reward": 5796.723688165386, "Mean Reward": 56.278870758887244, "Episode": 3717, "Episode Step": 103}
{"Training Time": 14.705291598306761, "Episode Reward": 15870.644736759408, "Mean Reward": 65.31129521300169, "Episode": 3718, "Episode Step": 243}
{"Training Time": 14.707351967228783, "Episode Reward": 8321.484807011564, "Mean Reward": 47.82462532765267, "Episode": 3719, "Episode Step": 174}
{"Training Time": 14.709883331921365, "Episode Reward": 8469.506507406544, "Mean Reward": 47.85031925088443, "Episode": 3720, "Episode Step": 177}
{"Training Time": 14.713351442482736, "Episode Reward": 17920.96817488115, "Mean Reward": 59.93634841097374, "Episode": 3721, "Episode Step": 299}
{"Training Time": 14.71603008084827, "Episode Reward": 13591.378439371256, "Mean Reward": 59.61130894461077, "Episode": 3722, "Episode Step": 228}
{"Training Time": 14.717766312493218, "Episode Reward": 5467.441459472327, "Mean Reward": 50.6244579580771, "Episode": 3723, "Episode Step": 108}
{"Training Time": 14.720663424200481, "Episode Reward": 15771.06912216032, "Mean Reward": 63.85048227595271, "Episode": 3724, "Episode Step": 247}
{"Training Time": 14.723591742515564, "Episode Reward": 15235.962613346339, "Mean Reward": 61.93480737132658, "Episode": 3725, "Episode Step": 246}
{"Training Time": 14.725272955033514, "Episode Reward": 5836.9283374979, "Mean Reward": 57.22478762252844, "Episode": 3726, "Episode Step": 102}
{"Training Time": 14.734013062516848, "Episode Reward": 46797.28646989027, "Mean Reward": 63.66977751005479, "Episode": 3727, "Episode Step": 735}
{"Training Time": 14.736706486675475, "Episode Reward": 13480.576315045124, "Mean Reward": 59.385798744692174, "Episode": 3728, "Episode Step": 227}
{"Training Time": 14.740081941948997, "Episode Reward": 16660.21793513123, "Mean Reward": 67.45027504101712, "Episode": 3729, "Episode Step": 247}
{"Training Time": 14.74171035832829, "Episode Reward": 6467.977929510675, "Mean Reward": 46.86940528630924, "Episode": 3730, "Episode Step": 138}
{"Training Time": 14.745286651121246, "Episode Reward": 19100.531014236138, "Mean Reward": 64.31155223648531, "Episode": 3731, "Episode Step": 297}
{"Training Time": 14.752534985277387, "Episode Reward": 33506.17695135575, "Mean Reward": 58.679819529519705, "Episode": 3732, "Episode Step": 571}
{"Training Time": 14.755072418053945, "Episode Reward": 11384.518231694243, "Mean Reward": 52.951247589275546, "Episode": 3733, "Episode Step": 215}
{"Training Time": 14.75810784108109, "Episode Reward": 16418.437623281046, "Mean Reward": 64.89501036869979, "Episode": 3734, "Episode Step": 253}
{"Training Time": 14.772131558060646, "Episode Reward": 74142.03272387899, "Mean Reward": 64.02593499471415, "Episode": 3735, "Episode Step": 1158}
{"Training Time": 14.779228526088927, "Episode Reward": 35900.78186683071, "Mean Reward": 58.950380733712166, "Episode": 3736, "Episode Step": 609}
{"Training Time": 14.781271638075511, "Episode Reward": 8877.10753040086, "Mean Reward": 51.31276029133445, "Episode": 3737, "Episode Step": 173}
{"Training Time": 14.783191851377488, "Episode Reward": 6402.263689662562, "Mean Reward": 51.2181095173005, "Episode": 3738, "Episode Step": 125}
{"Training Time": 14.791807198590703, "Episode Reward": 45454.02654512195, "Mean Reward": 62.09566467912835, "Episode": 3739, "Episode Step": 732}
{"Training Time": 14.793817468881606, "Episode Reward": 8853.276733789207, "Mean Reward": 52.07809843405416, "Episode": 3740, "Episode Step": 170}
{"Training Time": 14.796457182765007, "Episode Reward": 8709.146522359328, "Mean Reward": 47.33231805630069, "Episode": 3741, "Episode Step": 184}
{"Training Time": 14.800857568581899, "Episode Reward": 23462.653736379496, "Mean Reward": 63.07164982897714, "Episode": 3742, "Episode Step": 372}
{"Training Time": 14.802912049425974, "Episode Reward": 9013.325607801116, "Mean Reward": 52.10014802197177, "Episode": 3743, "Episode Step": 173}
{"Training Time": 14.815911532772912, "Episode Reward": 64527.15141463656, "Mean Reward": 60.13714018139474, "Episode": 3744, "Episode Step": 1073}
{"Training Time": 14.82377070552773, "Episode Reward": 44642.22288610748, "Mean Reward": 66.03879125163827, "Episode": 3745, "Episode Step": 676}
{"Training Time": 14.825824275281693, "Episode Reward": 8344.808687615194, "Mean Reward": 48.235888367717884, "Episode": 3746, "Episode Step": 173}
{"Training Time": 14.838964064717294, "Episode Reward": 65942.89722281399, "Mean Reward": 60.83293101735608, "Episode": 3747, "Episode Step": 1084}
{"Training Time": 14.84237581193447, "Episode Reward": 18352.922681191252, "Mean Reward": 63.06846282196307, "Episode": 3748, "Episode Step": 291}
{"Training Time": 14.84570914109548, "Episode Reward": 9036.922062800497, "Mean Reward": 47.562747698949984, "Episode": 3749, "Episode Step": 190}
{"Training Time": 14.890375145276387, "Episode Reward": 240678.24797351545, "Mean Reward": 62.98828787582189, "Episode": 3750, "Episode Step": 3821}
{"Training Time": 14.91182309554683, "Episode Reward": 117131.55958919866, "Mean Reward": 63.31435653470198, "Episode": 3751, "Episode Step": 1850}
{"Training Time": 14.913882908622424, "Episode Reward": 8656.467895775457, "Mean Reward": 50.03738668078299, "Episode": 3752, "Episode Step": 173}
{"Training Time": 14.933926313320796, "Episode Reward": 109662.78688972195, "Mean Reward": 65.74507607297478, "Episode": 3753, "Episode Step": 1668}
{"Training Time": 14.937486052778032, "Episode Reward": 18169.96452140675, "Mean Reward": 61.3850152750228, "Episode": 3754, "Episode Step": 296}
{"Training Time": 14.941065506140392, "Episode Reward": 18357.22981927172, "Mean Reward": 62.22789769244651, "Episode": 3755, "Episode Step": 295}
{"Training Time": 14.951152221957843, "Episode Reward": 51295.57905179169, "Mean Reward": 64.44168222586896, "Episode": 3756, "Episode Step": 796}
{"Training Time": 14.960165927211444, "Episode Reward": 48210.29027510504, "Mean Reward": 64.02428987397748, "Episode": 3757, "Episode Step": 753}
{"Training Time": 14.963217948344019, "Episode Reward": 16757.162636537596, "Mean Reward": 67.29784191380561, "Episode": 3758, "Episode Step": 249}
{"Training Time": 14.984788095023896, "Episode Reward": 111925.65818995914, "Mean Reward": 63.77530381194253, "Episode": 3759, "Episode Step": 1755}
{"Training Time": 14.986451471977764, "Episode Reward": 6928.595822983256, "Mean Reward": 50.57369213856391, "Episode": 3760, "Episode Step": 137}
{"Training Time": 14.989508312808143, "Episode Reward": 15456.931748677513, "Mean Reward": 61.33703074872029, "Episode": 3761, "Episode Step": 252}
{"Training Time": 15.049242705305417, "Episode Reward": 325767.10039350827, "Mean Reward": 65.15342007870166, "Episode": 3762, "Episode Step": 5000}
{"Training Time": 15.062213282783826, "Episode Reward": 62524.47659085198, "Mean Reward": 58.270714436954314, "Episode": 3763, "Episode Step": 1073}
{"Training Time": 15.06676302585337, "Episode Reward": 23552.19252157055, "Mean Reward": 61.17452603005337, "Episode": 3764, "Episode Step": 385}
{"Training Time": 15.082236745026377, "Episode Reward": 80562.5806694831, "Mean Reward": 63.73621888408473, "Episode": 3765, "Episode Step": 1264}
{"Training Time": 15.083976043595207, "Episode Reward": 6524.9312627791305, "Mean Reward": 45.312022658188404, "Episode": 3766, "Episode Step": 144}
{"Training Time": 15.086982312533591, "Episode Reward": 15637.686491667817, "Mean Reward": 62.054311474872286, "Episode": 3767, "Episode Step": 252}
{"Training Time": 15.117545812792248, "Episode Reward": 166662.90178584575, "Mean Reward": 65.90071244991924, "Episode": 3768, "Episode Step": 2529}
{"Training Time": 15.119257343345218, "Episode Reward": 6787.097335014367, "Mean Reward": 48.13544209230047, "Episode": 3769, "Episode Step": 141}
{"Training Time": 15.122238308058845, "Episode Reward": 15372.974593601417, "Mean Reward": 61.738853789563926, "Episode": 3770, "Episode Step": 249}
{"Training Time": 15.15207061390082, "Episode Reward": 158443.30603368464, "Mean Reward": 63.91420170781954, "Episode": 3771, "Episode Step": 2479}
{"Training Time": 15.153688105013636, "Episode Reward": 6427.578080957516, "Mean Reward": 47.26160353645233, "Episode": 3772, "Episode Step": 136}
{"Training Time": 15.166881281137467, "Episode Reward": 75887.24642614347, "Mean Reward": 67.69602714196563, "Episode": 3773, "Episode Step": 1121}
{"Training Time": 15.181252408623696, "Episode Reward": 76434.84503239696, "Mean Reward": 64.99561652414707, "Episode": 3774, "Episode Step": 1176}
{"Training Time": 15.183001080022917, "Episode Reward": 6786.805995765767, "Mean Reward": 47.460181788571795, "Episode": 3775, "Episode Step": 143}
{"Training Time": 15.186934365034103, "Episode Reward": 20596.26982841846, "Mean Reward": 63.178741804964595, "Episode": 3776, "Episode Step": 326}
{"Training Time": 15.233922494451205, "Episode Reward": 253666.78939203065, "Mean Reward": 64.46424126862279, "Episode": 3777, "Episode Step": 3935}
{"Training Time": 15.235702725251516, "Episode Reward": 6906.691711156805, "Mean Reward": 45.43876125761056, "Episode": 3778, "Episode Step": 152}
{"Training Time": 15.238530825840103, "Episode Reward": 16671.817405911497, "Mean Reward": 70.04965296601469, "Episode": 3779, "Episode Step": 238}
{"Training Time": 15.246573997802205, "Episode Reward": 38253.28325706234, "Mean Reward": 59.86429304704592, "Episode": 3780, "Episode Step": 639}
{"Training Time": 15.248327829440434, "Episode Reward": 6395.814884583738, "Mean Reward": 43.80695126427218, "Episode": 3781, "Episode Step": 146}
{"Training Time": 15.251267043087218, "Episode Reward": 16104.724164676965, "Mean Reward": 66.54844696147507, "Episode": 3782, "Episode Step": 242}
{"Training Time": 15.257306871679095, "Episode Reward": 30090.972572940685, "Mean Reward": 65.8445789342247, "Episode": 3783, "Episode Step": 457}
{"Training Time": 15.258952199419339, "Episode Reward": 6604.760733892718, "Mean Reward": 47.86058502820811, "Episode": 3784, "Episode Step": 138}
{"Training Time": 15.261101244158215, "Episode Reward": 8977.58136531222, "Mean Reward": 50.72079867408034, "Episode": 3785, "Episode Step": 177}
{"Training Time": 15.263741149173843, "Episode Reward": 9039.036543894905, "Mean Reward": 50.49741085974807, "Episode": 3786, "Episode Step": 179}
{"Training Time": 15.265436431103282, "Episode Reward": 6676.123599887721, "Mean Reward": 47.014954928786764, "Episode": 3787, "Episode Step": 142}
{"Training Time": 15.268451453579797, "Episode Reward": 16704.879247598565, "Mean Reward": 67.08786846425126, "Episode": 3788, "Episode Step": 249}
{"Training Time": 15.271979241106246, "Episode Reward": 16866.790205664554, "Mean Reward": 65.37515583590913, "Episode": 3789, "Episode Step": 258}
{"Training Time": 15.273703782757122, "Episode Reward": 6665.479612714037, "Mean Reward": 46.6117455434548, "Episode": 3790, "Episode Step": 143}
{"Training Time": 15.275702404446072, "Episode Reward": 8851.21089740826, "Mean Reward": 53.32054757474856, "Episode": 3791, "Episode Step": 166}
{"Training Time": 15.299808351927334, "Episode Reward": 126124.36692130408, "Mean Reward": 63.570749456302465, "Episode": 3792, "Episode Step": 1984}
{"Training Time": 15.301577407783933, "Episode Reward": 6541.588411058112, "Mean Reward": 45.11440283488353, "Episode": 3793, "Episode Step": 145}
{"Training Time": 15.304480959177017, "Episode Reward": 16447.531039392066, "Mean Reward": 67.13277975262068, "Episode": 3794, "Episode Step": 245}
{"Training Time": 15.307137291961245, "Episode Reward": 8792.797334872283, "Mean Reward": 47.528634242552876, "Episode": 3795, "Episode Step": 185}
{"Training Time": 15.325512652198473, "Episode Reward": 95746.63523149285, "Mean Reward": 62.05225873719563, "Episode": 3796, "Episode Step": 1543}
{"Training Time": 15.326526966691016, "Episode Reward": 3998.8918767662935, "Mean Reward": 47.60585567578921, "Episode": 3797, "Episode Step": 84}
{"Training Time": 15.370944732493825, "Episode Reward": 229391.21902928743, "Mean Reward": 62.84690932309245, "Episode": 3798, "Episode Step": 3650}
{"Training Time": 15.378734555840492, "Episode Reward": 34498.94102351013, "Mean Reward": 61.60525182769666, "Episode": 3799, "Episode Step": 560}
{"Training Time": 15.380002989172935, "Episode Reward": 4521.632267505347, "Mean Reward": 55.14185692079692, "Episode": 3800, "Episode Step": 82}
{"Training Time": 15.415669390559197, "Episode Reward": 185186.0738127694, "Mean Reward": 63.03133894239939, "Episode": 3801, "Episode Step": 2938}
{"Training Time": 15.417548223336537, "Episode Reward": 7146.158122893063, "Mean Reward": 46.104245954148794, "Episode": 3802, "Episode Step": 155}
{"Training Time": 15.420994494756062, "Episode Reward": 18030.55251914653, "Mean Reward": 62.606085135925454, "Episode": 3803, "Episode Step": 288}
{"Training Time": 15.439881216949887, "Episode Reward": 99909.44733483178, "Mean Reward": 64.2917936517579, "Episode": 3804, "Episode Step": 1554}
{"Training Time": 15.448151350286272, "Episode Reward": 39493.21916204778, "Mean Reward": 57.236549510214175, "Episode": 3805, "Episode Step": 690}
{"Training Time": 15.449461106657981, "Episode Reward": 5779.619980667734, "Mean Reward": 54.52471679875221, "Episode": 3806, "Episode Step": 106}
{"Training Time": 15.457438908881612, "Episode Reward": 38141.13962811126, "Mean Reward": 59.970345327218965, "Episode": 3807, "Episode Step": 636}
{"Training Time": 15.463786019417975, "Episode Reward": 36056.31936419989, "Mean Reward": 67.64787873208235, "Episode": 3808, "Episode Step": 533}
{"Training Time": 15.466698491374652, "Episode Reward": 16534.119524140013, "Mean Reward": 67.48620213934699, "Episode": 3809, "Episode Step": 245}
{"Training Time": 15.470172668894133, "Episode Reward": 16540.92654004482, "Mean Reward": 65.90010573723036, "Episode": 3810, "Episode Step": 251}
{"Training Time": 15.471949671639337, "Episode Reward": 6969.1339607163, "Mean Reward": 46.77271114574698, "Episode": 3811, "Episode Step": 149}
{"Training Time": 15.474882091085115, "Episode Reward": 15870.901164638075, "Mean Reward": 65.31235047176162, "Episode": 3812, "Episode Step": 243}
{"Training Time": 15.511467722521887, "Episode Reward": 199599.48212013734, "Mean Reward": 65.37814678026116, "Episode": 3813, "Episode Step": 3053}
{"Training Time": 15.52972119278378, "Episode Reward": 93268.86113405386, "Mean Reward": 60.29014940792105, "Episode": 3814, "Episode Step": 1547}
{"Training Time": 15.532748659981621, "Episode Reward": 15805.246182225526, "Mean Reward": 62.96910829571923, "Episode": 3815, "Episode Step": 251}
{"Training Time": 15.560164194703102, "Episode Reward": 152380.6604033462, "Mean Reward": 66.80432284232626, "Episode": 3816, "Episode Step": 2281}
{"Training Time": 15.568847771419419, "Episode Reward": 45426.29504713159, "Mean Reward": 61.63676397168466, "Episode": 3817, "Episode Step": 737}
{"Training Time": 15.571724269721242, "Episode Reward": 16058.331670480651, "Mean Reward": 65.54421089992103, "Episode": 3818, "Episode Step": 245}
{"Training Time": 15.576391165256501, "Episode Reward": 20118.730636402845, "Mean Reward": 56.19757161006381, "Episode": 3819, "Episode Step": 358}
{"Training Time": 15.58374969025453, "Episode Reward": 35615.18075863614, "Mean Reward": 56.7120712717136, "Episode": 3820, "Episode Step": 628}
{"Training Time": 15.586696657207277, "Episode Reward": 16329.754347510376, "Mean Reward": 66.11236577939424, "Episode": 3821, "Episode Step": 247}
{"Training Time": 15.605889278319147, "Episode Reward": 103243.35455371415, "Mean Reward": 64.76998403620712, "Episode": 3822, "Episode Step": 1594}
{"Training Time": 15.632503456407123, "Episode Reward": 150296.57977405482, "Mean Reward": 66.23912726930578, "Episode": 3823, "Episode Step": 2269}
{"Training Time": 15.633778753611777, "Episode Reward": 5786.185879965592, "Mean Reward": 54.0765035510803, "Episode": 3824, "Episode Step": 107}
{"Training Time": 15.647611326641506, "Episode Reward": 69482.15502498523, "Mean Reward": 61.21775773126452, "Episode": 3825, "Episode Step": 1135}
{"Training Time": 15.648954465587934, "Episode Reward": 6266.929111287983, "Mean Reward": 55.45954965741578, "Episode": 3826, "Episode Step": 113}
{"Training Time": 15.65247175971667, "Episode Reward": 18776.853197891127, "Mean Reward": 62.798840126726176, "Episode": 3827, "Episode Step": 299}
{"Training Time": 15.66636479669147, "Episode Reward": 75180.42686982956, "Mean Reward": 65.5452719004617, "Episode": 3828, "Episode Step": 1147}
{"Training Time": 15.672900039752324, "Episode Reward": 35936.1043055558, "Mean Reward": 66.30277547150516, "Episode": 3829, "Episode Step": 542}
{"Training Time": 15.675088077783585, "Episode Reward": 8624.66601750075, "Mean Reward": 46.61981631081486, "Episode": 3830, "Episode Step": 185}
{"Training Time": 15.677690128352907, "Episode Reward": 7804.5761135294, "Mean Reward": 43.84593322207528, "Episode": 3831, "Episode Step": 178}
{"Training Time": 15.68070918891165, "Episode Reward": 13542.414929001472, "Mean Reward": 53.31659420866721, "Episode": 3832, "Episode Step": 254}
{"Training Time": 15.684285021689202, "Episode Reward": 17837.674333328567, "Mean Reward": 59.45891444442856, "Episode": 3833, "Episode Step": 300}
{"Training Time": 15.70910581085417, "Episode Reward": 131307.75717849648, "Mean Reward": 63.495046991536015, "Episode": 3834, "Episode Step": 2068}
{"Training Time": 15.743753592504396, "Episode Reward": 190516.08569733283, "Mean Reward": 65.06696915892515, "Episode": 3835, "Episode Step": 2928}
{"Training Time": 15.745073099136352, "Episode Reward": 5985.024946960818, "Mean Reward": 54.4093176996438, "Episode": 3836, "Episode Step": 110}
{"Training Time": 15.769979950851864, "Episode Reward": 129615.50585005652, "Mean Reward": 62.737418126842456, "Episode": 3837, "Episode Step": 2066}
{"Training Time": 15.777425220542483, "Episode Reward": 40221.48672411513, "Mean Reward": 64.66476965291821, "Episode": 3838, "Episode Step": 622}
{"Training Time": 15.786310223870807, "Episode Reward": 46386.40670444268, "Mean Reward": 62.096929992560476, "Episode": 3839, "Episode Step": 747}
{"Training Time": 15.811406612197558, "Episode Reward": 136779.66225961744, "Mean Reward": 65.9179095227072, "Episode": 3840, "Episode Step": 2075}
{"Training Time": 15.813543274733755, "Episode Reward": 9504.287545392925, "Mean Reward": 53.394873850522046, "Episode": 3841, "Episode Step": 178}
{"Training Time": 15.816606202522914, "Episode Reward": 14404.490421208991, "Mean Reward": 56.26754070784762, "Episode": 3842, "Episode Step": 256}
{"Training Time": 15.841264313922988, "Episode Reward": 128181.6938071512, "Mean Reward": 63.081542227928736, "Episode": 3843, "Episode Step": 2032}
{"Training Time": 15.844763750301468, "Episode Reward": 19651.486990561283, "Mean Reward": 67.53088312907657, "Episode": 3844, "Episode Step": 291}
{"Training Time": 15.851011971963777, "Episode Reward": 34616.012090974684, "Mean Reward": 65.93526112566606, "Episode": 3845, "Episode Step": 525}
{"Training Time": 15.91063915749391, "Episode Reward": 321266.43521090184, "Mean Reward": 64.25328704218036, "Episode": 3846, "Episode Step": 5000}
{"Training Time": 15.913005628055997, "Episode Reward": 9414.104600366709, "Mean Reward": 53.48923068390175, "Episode": 3847, "Episode Step": 176}
{"Training Time": 15.91585731446743, "Episode Reward": 13925.617617843689, "Mean Reward": 58.26618250143803, "Episode": 3848, "Episode Step": 239}
{"Training Time": 15.931071298321088, "Episode Reward": 75306.58484873715, "Mean Reward": 65.42709370003229, "Episode": 3849, "Episode Step": 1151}
{"Training Time": 15.932998176415762, "Episode Reward": 7371.69894641872, "Mean Reward": 53.808021506705984, "Episode": 3850, "Episode Step": 137}
{"Training Time": 15.93655407389005, "Episode Reward": 18941.077525238186, "Mean Reward": 63.99012677445333, "Episode": 3851, "Episode Step": 296}
{"Training Time": 15.961283102499115, "Episode Reward": 135052.23241206296, "Mean Reward": 65.87913776198194, "Episode": 3852, "Episode Step": 2050}
{"Training Time": 15.967761184970538, "Episode Reward": 36563.614598782384, "Mean Reward": 67.5852395541264, "Episode": 3853, "Episode Step": 541}
{"Training Time": 15.971416379743152, "Episode Reward": 18810.297117115097, "Mean Reward": 62.080188505330355, "Episode": 3854, "Episode Step": 303}
{"Training Time": 15.97464396999942, "Episode Reward": 14476.465802100516, "Mean Reward": 62.66868312597626, "Episode": 3855, "Episode Step": 231}
{"Training Time": 15.981911011404462, "Episode Reward": 39369.955003435076, "Mean Reward": 65.18204470767397, "Episode": 3856, "Episode Step": 604}
{"Training Time": 15.99562323278851, "Episode Reward": 74900.91814077529, "Mean Reward": 65.35856731306744, "Episode": 3857, "Episode Step": 1146}
{"Training Time": 16.02078553557396, "Episode Reward": 132895.9561004554, "Mean Reward": 64.4812984475766, "Episode": 3858, "Episode Step": 2061}
{"Training Time": 16.025593949755034, "Episode Reward": 26222.94987484998, "Mean Reward": 65.72167888433579, "Episode": 3859, "Episode Step": 399}
{"Training Time": 16.033370619416235, "Episode Reward": 38700.63079603154, "Mean Reward": 59.81550354873499, "Episode": 3860, "Episode Step": 647}
{"Training Time": 16.042149091098043, "Episode Reward": 43259.54191024282, "Mean Reward": 62.69498827571423, "Episode": 3861, "Episode Step": 690}
{"Training Time": 16.044243581692378, "Episode Reward": 9183.151078597153, "Mean Reward": 52.77673033676525, "Episode": 3862, "Episode Step": 174}
{"Training Time": 16.05725325723489, "Episode Reward": 66308.9460195064, "Mean Reward": 61.17061440913875, "Episode": 3863, "Episode Step": 1084}
{"Training Time": 16.10853435748153, "Episode Reward": 264201.1593093387, "Mean Reward": 61.68600497533008, "Episode": 3864, "Episode Step": 4283}
{"Training Time": 16.126918121973674, "Episode Reward": 105514.24986989856, "Mean Reward": 67.81121456934355, "Episode": 3865, "Episode Step": 1556}
{"Training Time": 16.129866249428854, "Episode Reward": 16627.964334900513, "Mean Reward": 66.77897323253218, "Episode": 3866, "Episode Step": 249}
{"Training Time": 16.133242127233082, "Episode Reward": 16270.049701454613, "Mean Reward": 65.87064656459357, "Episode": 3867, "Episode Step": 247}
{"Training Time": 16.151104653345215, "Episode Reward": 97927.79451454314, "Mean Reward": 65.94464277073612, "Episode": 3868, "Episode Step": 1485}
{"Training Time": 16.159721318350897, "Episode Reward": 43758.65819730541, "Mean Reward": 60.69162024591597, "Episode": 3869, "Episode Step": 721}
{"Training Time": 16.192399401664733, "Episode Reward": 171890.31688354947, "Mean Reward": 63.35802317860283, "Episode": 3870, "Episode Step": 2713}
{"Training Time": 16.201084351936977, "Episode Reward": 47838.911140968616, "Mean Reward": 65.80317901096096, "Episode": 3871, "Episode Step": 727}
{"Training Time": 16.20543173001872, "Episode Reward": 21562.708337925866, "Mean Reward": 59.40140037996106, "Episode": 3872, "Episode Step": 363}
{"Training Time": 16.214161186946765, "Episode Reward": 40411.25993082493, "Mean Reward": 59.1672912603586, "Episode": 3873, "Episode Step": 683}
{"Training Time": 16.216266285843318, "Episode Reward": 9137.568565958116, "Mean Reward": 52.514761873322506, "Episode": 3874, "Episode Step": 174}
{"Training Time": 16.23483207192686, "Episode Reward": 94608.73066594888, "Mean Reward": 61.03789075222509, "Episode": 3875, "Episode Step": 1550}
{"Training Time": 16.243474138908915, "Episode Reward": 40515.64629451246, "Mean Reward": 60.38099298735091, "Episode": 3876, "Episode Step": 671}
{"Training Time": 16.247039816644456, "Episode Reward": 17183.840223373198, "Mean Reward": 58.44843613392244, "Episode": 3877, "Episode Step": 294}
{"Training Time": 16.272946799198788, "Episode Reward": 136042.7299403914, "Mean Reward": 62.46222678622195, "Episode": 3878, "Episode Step": 2178}
{"Training Time": 16.276260892748834, "Episode Reward": 15951.886371929128, "Mean Reward": 65.64562292974949, "Episode": 3879, "Episode Step": 243}
{"Training Time": 16.293103568024105, "Episode Reward": 94563.43151143972, "Mean Reward": 66.5471016970019, "Episode": 3880, "Episode Step": 1421}
{"Training Time": 16.296590634187062, "Episode Reward": 19065.750797417437, "Mean Reward": 64.62966372005911, "Episode": 3881, "Episode Step": 295}
{"Training Time": 16.299788217809464, "Episode Reward": 13937.966495824854, "Mean Reward": 60.337517297943094, "Episode": 3882, "Episode Step": 231}
{"Training Time": 16.301900009181765, "Episode Reward": 8535.583419532037, "Mean Reward": 48.49763306552293, "Episode": 3883, "Episode Step": 176}
{"Training Time": 16.314829599459966, "Episode Reward": 63493.08486949084, "Mean Reward": 58.57295652167052, "Episode": 3884, "Episode Step": 1084}
{"Training Time": 16.318073453042242, "Episode Reward": 13956.088610149534, "Mean Reward": 60.94361838493246, "Episode": 3885, "Episode Step": 229}
{"Training Time": 16.326022316945924, "Episode Reward": 42278.377494829554, "Mean Reward": 63.38587330559154, "Episode": 3886, "Episode Step": 667}
{"Training Time": 16.32912892891301, "Episode Reward": 16204.386627203481, "Mean Reward": 63.79679774489559, "Episode": 3887, "Episode Step": 254}
{"Training Time": 16.330956264999177, "Episode Reward": 5840.955047046873, "Mean Reward": 52.62121664006192, "Episode": 3888, "Episode Step": 111}
{"Training Time": 16.333813815249336, "Episode Reward": 12976.642752093681, "Mean Reward": 55.455738256810605, "Episode": 3889, "Episode Step": 234}
{"Training Time": 16.336832068032688, "Episode Reward": 16395.22364640815, "Mean Reward": 65.06041129527044, "Episode": 3890, "Episode Step": 252}
{"Training Time": 16.340007860859235, "Episode Reward": 14937.260164210848, "Mean Reward": 64.94460940961238, "Episode": 3891, "Episode Step": 230}
{"Training Time": 16.349857419729233, "Episode Reward": 53449.47211111022, "Mean Reward": 64.63055878006072, "Episode": 3892, "Episode Step": 827}
{"Training Time": 16.352842779159545, "Episode Reward": 14542.121189040616, "Mean Reward": 59.11431377658787, "Episode": 3893, "Episode Step": 246}
{"Training Time": 16.359883762200674, "Episode Reward": 33514.18133583809, "Mean Reward": 60.60430621308877, "Episode": 3894, "Episode Step": 553}
{"Training Time": 16.369967717528343, "Episode Reward": 55881.922268825125, "Mean Reward": 66.28935025957904, "Episode": 3895, "Episode Step": 843}
{"Training Time": 16.373637309471768, "Episode Reward": 17586.960097527124, "Mean Reward": 57.47372580891217, "Episode": 3896, "Episode Step": 306}
{"Training Time": 16.376786753601497, "Episode Reward": 13861.99836017704, "Mean Reward": 60.532743930904104, "Episode": 3897, "Episode Step": 229}
{"Training Time": 16.37892336918248, "Episode Reward": 9201.00327062932, "Mean Reward": 51.98306932558938, "Episode": 3898, "Episode Step": 177}
{"Training Time": 16.39442115028699, "Episode Reward": 73033.56425489656, "Mean Reward": 60.7600368177176, "Episode": 3899, "Episode Step": 1202}
{"Training Time": 16.397600146664512, "Episode Reward": 12544.777121011586, "Mean Reward": 54.780686117954524, "Episode": 3900, "Episode Step": 229}
{"Training Time": 16.40495353970263, "Episode Reward": 38324.67071917611, "Mean Reward": 62.3165377547579, "Episode": 3901, "Episode Step": 615}
{"Training Time": 16.41326195054584, "Episode Reward": 43417.86686206835, "Mean Reward": 62.203247653393056, "Episode": 3902, "Episode Step": 698}
{"Training Time": 16.415013676948018, "Episode Reward": 5479.562522492103, "Mean Reward": 50.73669002307503, "Episode": 3903, "Episode Step": 108}
{"Training Time": 16.416349841422505, "Episode Reward": 5675.136115960599, "Mean Reward": 51.592146508732725, "Episode": 3904, "Episode Step": 110}
{"Training Time": 16.42678684055805, "Episode Reward": 52485.736309354215, "Mean Reward": 60.19006457494749, "Episode": 3905, "Episode Step": 872}
{"Training Time": 16.428539466659227, "Episode Reward": 5458.856826470651, "Mean Reward": 51.0173535184173, "Episode": 3906, "Episode Step": 107}
{"Training Time": 16.4298565010892, "Episode Reward": 5862.331706544602, "Mean Reward": 53.78285969306974, "Episode": 3907, "Episode Step": 109}
{"Training Time": 16.432606907222006, "Episode Reward": 12432.4625734849, "Mean Reward": 53.820184300800435, "Episode": 3908, "Episode Step": 231}
{"Training Time": 16.43603664888276, "Episode Reward": 14996.085203918476, "Mean Reward": 62.22441993327168, "Episode": 3909, "Episode Step": 241}
{"Training Time": 16.453806046115027, "Episode Reward": 96086.9931146239, "Mean Reward": 65.14372414550773, "Episode": 3910, "Episode Step": 1475}
{"Training Time": 16.456567709975772, "Episode Reward": 12451.956537531622, "Mean Reward": 54.13894146752879, "Episode": 3911, "Episode Step": 230}
{"Training Time": 16.470551762249734, "Episode Reward": 70782.4784807503, "Mean Reward": 63.08598795075785, "Episode": 3912, "Episode Step": 1122}
{"Training Time": 16.487110644976298, "Episode Reward": 86056.9965170146, "Mean Reward": 62.907161196648104, "Episode": 3913, "Episode Step": 1368}
{"Training Time": 16.49018698414167, "Episode Reward": 14639.32405901488, "Mean Reward": 57.862940944722844, "Episode": 3914, "Episode Step": 253}
{"Training Time": 16.5099274219407, "Episode Reward": 101076.80682747549, "Mean Reward": 63.57031875941855, "Episode": 3915, "Episode Step": 1590}
{"Training Time": 16.52247743666172, "Episode Reward": 66114.23009046682, "Mean Reward": 63.38852357667001, "Episode": 3916, "Episode Step": 1043}
{"Training Time": 16.52619370109505, "Episode Reward": 17689.9926407375, "Mean Reward": 57.622125865594455, "Episode": 3917, "Episode Step": 307}
{"Training Time": 16.5297628105349, "Episode Reward": 16158.58117619836, "Mean Reward": 63.8679097873453, "Episode": 3918, "Episode Step": 253}
{"Training Time": 16.537228104141022, "Episode Reward": 34387.376883765275, "Mean Reward": 55.46351110284722, "Episode": 3919, "Episode Step": 620}
{"Training Time": 16.540935843057103, "Episode Reward": 18541.96923248934, "Mean Reward": 60.59467069440961, "Episode": 3920, "Episode Step": 306}
{"Training Time": 16.54411003112793, "Episode Reward": 12874.261791453539, "Mean Reward": 56.46606048883131, "Episode": 3921, "Episode Step": 228}
{"Training Time": 16.55428254114257, "Episode Reward": 51495.72513263142, "Mean Reward": 61.01389233724102, "Episode": 3922, "Episode Step": 844}
{"Training Time": 16.562432752516536, "Episode Reward": 41956.03369516202, "Mean Reward": 61.70004955170885, "Episode": 3923, "Episode Step": 680}
{"Training Time": 16.565683587789536, "Episode Reward": 15317.318182929634, "Mean Reward": 65.4586247133745, "Episode": 3924, "Episode Step": 234}
{"Training Time": 16.573037826948696, "Episode Reward": 34908.86423095096, "Mean Reward": 57.22764628024748, "Episode": 3925, "Episode Step": 610}
{"Training Time": 16.57517954164081, "Episode Reward": 8540.280364643442, "Mean Reward": 47.97910317215417, "Episode": 3926, "Episode Step": 178}
{"Training Time": 16.589377382530106, "Episode Reward": 71238.54560933827, "Mean Reward": 62.32593666608772, "Episode": 3927, "Episode Step": 1143}
{"Training Time": 16.59146651585897, "Episode Reward": 8453.222556710074, "Mean Reward": 48.30412889548614, "Episode": 3928, "Episode Step": 175}
{"Training Time": 16.594479953315524, "Episode Reward": 15218.623193925698, "Mean Reward": 60.87449277570279, "Episode": 3929, "Episode Step": 250}
{"Training Time": 16.597062798606025, "Episode Reward": 7847.172305714401, "Mean Reward": 45.09869141215173, "Episode": 3930, "Episode Step": 174}
{"Training Time": 16.603550351924365, "Episode Reward": 32406.684702486647, "Mean Reward": 60.23547342469637, "Episode": 3931, "Episode Step": 538}
{"Training Time": 16.61768989112642, "Episode Reward": 70889.07451539532, "Mean Reward": 60.126441488884915, "Episode": 3932, "Episode Step": 1179}
{"Training Time": 16.63116033554077, "Episode Reward": 63378.10471027719, "Mean Reward": 58.52087230865853, "Episode": 3933, "Episode Step": 1083}
{"Training Time": 16.633199979199304, "Episode Reward": 8230.48332091933, "Mean Reward": 47.851647214647265, "Episode": 3934, "Episode Step": 172}
{"Training Time": 16.63625093638897, "Episode Reward": 15385.22182303505, "Mean Reward": 59.17393008859634, "Episode": 3935, "Episode Step": 260}
{"Training Time": 16.644265624748336, "Episode Reward": 36680.74496531923, "Mean Reward": 56.95767851757645, "Episode": 3936, "Episode Step": 644}
{"Training Time": 16.645519366926617, "Episode Reward": 5024.322939819103, "Mean Reward": 47.39927301716135, "Episode": 3937, "Episode Step": 106}
{"Training Time": 16.64915039969815, "Episode Reward": 17304.862453283753, "Mean Reward": 56.00279111095066, "Episode": 3938, "Episode Step": 309}
{"Training Time": 16.655239884985818, "Episode Reward": 27714.3973894005, "Mean Reward": 57.85886720125365, "Episode": 3939, "Episode Step": 479}
{"Training Time": 16.658006342781913, "Episode Reward": 13424.220495790601, "Mean Reward": 57.124342535279155, "Episode": 3940, "Episode Step": 235}
{"Training Time": 16.659564212229515, "Episode Reward": 5467.666371353751, "Mean Reward": 41.737911231708026, "Episode": 3941, "Episode Step": 131}
{"Training Time": 16.66276999168926, "Episode Reward": 14158.76747145566, "Mean Reward": 60.50755329681906, "Episode": 3942, "Episode Step": 234}
{"Training Time": 16.66982645081149, "Episode Reward": 34997.22612585417, "Mean Reward": 57.94242736068571, "Episode": 3943, "Episode Step": 604}
{"Training Time": 16.676863703595266, "Episode Reward": 32385.539112923238, "Mean Reward": 53.618442239939135, "Episode": 3944, "Episode Step": 604}
{"Training Time": 16.685305629703734, "Episode Reward": 39156.39207174713, "Mean Reward": 57.667735009936855, "Episode": 3945, "Episode Step": 679}
{"Training Time": 16.691762335300446, "Episode Reward": 32151.000432478682, "Mean Reward": 59.20994554784288, "Episode": 3946, "Episode Step": 543}
{"Training Time": 16.693114480839835, "Episode Reward": 4978.407401759311, "Mean Reward": 44.05670267043638, "Episode": 3947, "Episode Step": 113}
{"Training Time": 16.69566097140312, "Episode Reward": 7684.805752260919, "Mean Reward": 43.66366904693704, "Episode": 3948, "Episode Step": 176}
{"Training Time": 16.69831161889765, "Episode Reward": 6239.756739961966, "Mean Reward": 47.63173083940432, "Episode": 3949, "Episode Step": 131}
{"Training Time": 16.70097259501616, "Episode Reward": 7592.7891168004235, "Mean Reward": 37.775070232837926, "Episode": 3950, "Episode Step": 201}
{"Training Time": 16.720095326105753, "Episode Reward": 90946.79831798308, "Mean Reward": 57.199244225146586, "Episode": 3951, "Episode Step": 1590}
{"Training Time": 16.723524206413163, "Episode Reward": 16109.258386478787, "Mean Reward": 55.54916684992685, "Episode": 3952, "Episode Step": 290}
{"Training Time": 16.72663047777282, "Episode Reward": 14658.777606165568, "Mean Reward": 56.16389887419758, "Episode": 3953, "Episode Step": 261}
{"Training Time": 16.733707031408947, "Episode Reward": 34327.40318193723, "Mean Reward": 61.629090093244585, "Episode": 3954, "Episode Step": 557}
{"Training Time": 16.744261433084805, "Episode Reward": 51989.840817220815, "Mean Reward": 57.89514567619244, "Episode": 3955, "Episode Step": 898}
{"Training Time": 16.751983651916188, "Episode Reward": 33311.20492705836, "Mean Reward": 50.85680141535627, "Episode": 3956, "Episode Step": 655}
{"Training Time": 16.753653461933137, "Episode Reward": 5291.892194097426, "Mean Reward": 51.37759411745074, "Episode": 3957, "Episode Step": 103}
{"Training Time": 16.756687549153963, "Episode Reward": 15576.237096430374, "Mean Reward": 61.0832827310995, "Episode": 3958, "Episode Step": 255}
{"Training Time": 16.758378369145923, "Episode Reward": 5407.137110601867, "Mean Reward": 38.34849014611253, "Episode": 3959, "Episode Step": 141}
{"Training Time": 16.76187751001782, "Episode Reward": 14391.335308308018, "Mean Reward": 55.78036941204658, "Episode": 3960, "Episode Step": 258}
{"Training Time": 16.769051206641727, "Episode Reward": 36216.83828396575, "Mean Reward": 58.79356864280154, "Episode": 3961, "Episode Step": 616}
{"Training Time": 16.77038274447123, "Episode Reward": 4983.385915980809, "Mean Reward": 44.49451710697151, "Episode": 3962, "Episode Step": 112}
{"Training Time": 16.778986211419106, "Episode Reward": 40054.869355040144, "Mean Reward": 57.46753135586821, "Episode": 3963, "Episode Step": 697}
{"Training Time": 16.784584992792873, "Episode Reward": 29379.8412466728, "Mean Reward": 61.464103026512134, "Episode": 3964, "Episode Step": 478}
{"Training Time": 16.79517661584748, "Episode Reward": 49382.37467153802, "Mean Reward": 54.20677790509113, "Episode": 3965, "Episode Step": 911}
{"Training Time": 16.803663946125244, "Episode Reward": 41477.971845316075, "Mean Reward": 60.20024941265033, "Episode": 3966, "Episode Step": 689}
{"Training Time": 16.80527443832821, "Episode Reward": 5780.46926418339, "Mean Reward": 42.818290845802885, "Episode": 3967, "Episode Step": 135}
{"Training Time": 16.806923778918055, "Episode Reward": 6177.383143214029, "Mean Reward": 44.124165308671635, "Episode": 3968, "Episode Step": 140}
{"Training Time": 16.809506150285404, "Episode Reward": 8594.979600938459, "Mean Reward": 47.749886671880326, "Episode": 3969, "Episode Step": 180}
{"Training Time": 16.819807352489896, "Episode Reward": 54639.53329016675, "Mean Reward": 61.60037574990614, "Episode": 3970, "Episode Step": 887}
{"Training Time": 16.821433606942495, "Episode Reward": 5727.935362868834, "Mean Reward": 41.208168078193054, "Episode": 3971, "Episode Step": 139}
{"Training Time": 16.84592333945963, "Episode Reward": 127315.27618346567, "Mean Reward": 62.28731711519847, "Episode": 3972, "Episode Step": 2044}
{"Training Time": 16.85800115916464, "Episode Reward": 65105.71498730769, "Mean Reward": 62.964908111516145, "Episode": 3973, "Episode Step": 1034}
{"Training Time": 16.859646759165656, "Episode Reward": 5708.932732042189, "Mean Reward": 41.07145850390064, "Episode": 3974, "Episode Step": 139}
{"Training Time": 16.862260409196217, "Episode Reward": 8251.620480356132, "Mean Reward": 45.33857406789084, "Episode": 3975, "Episode Step": 182}
{"Training Time": 16.863824198908276, "Episode Reward": 6601.896325294847, "Mean Reward": 48.90293574292479, "Episode": 3976, "Episode Step": 135}
{"Training Time": 16.86687613778644, "Episode Reward": 14959.407964302605, "Mean Reward": 57.315739326829906, "Episode": 3977, "Episode Step": 261}
{"Training Time": 16.87787570807669, "Episode Reward": 54379.01041255109, "Mean Reward": 60.826633571086234, "Episode": 3978, "Episode Step": 894}
{"Training Time": 16.879575861361293, "Episode Reward": 6846.21216906733, "Mean Reward": 48.21276175399528, "Episode": 3979, "Episode Step": 142}
{"Training Time": 16.881251910527546, "Episode Reward": 5984.917707266891, "Mean Reward": 42.446224874233266, "Episode": 3980, "Episode Step": 141}
{"Training Time": 16.88723139444987, "Episode Reward": 27397.055263929557, "Mean Reward": 58.415896085137646, "Episode": 3981, "Episode Step": 469}
{"Training Time": 16.88939448946052, "Episode Reward": 9168.356201082432, "Mean Reward": 50.65390166343885, "Episode": 3982, "Episode Step": 181}
{"Training Time": 16.907596746087073, "Episode Reward": 89941.2505239648, "Mean Reward": 57.98920085362012, "Episode": 3983, "Episode Step": 1551}
{"Training Time": 16.913775460852516, "Episode Reward": 30525.426208054865, "Mean Reward": 63.33075976774868, "Episode": 3984, "Episode Step": 482}
{"Training Time": 16.915425662199656, "Episode Reward": 6432.931587852148, "Mean Reward": 46.9557050208186, "Episode": 3985, "Episode Step": 137}
{"Training Time": 16.916791734695433, "Episode Reward": 5512.2463265745055, "Mean Reward": 48.78094094313722, "Episode": 3986, "Episode Step": 113}
{"Training Time": 16.93338646915224, "Episode Reward": 86786.13429431408, "Mean Reward": 63.16312539615289, "Episode": 3987, "Episode Step": 1374}
{"Training Time": 16.93497684114509, "Episode Reward": 7094.838260272502, "Mean Reward": 53.344648573477464, "Episode": 3988, "Episode Step": 133}
{"Training Time": 16.947459583083788, "Episode Reward": 62066.5338572548, "Mean Reward": 58.83083777938843, "Episode": 3989, "Episode Step": 1055}
{"Training Time": 16.95331450998783, "Episode Reward": 25464.43566768115, "Mean Reward": 56.33724705239193, "Episode": 3990, "Episode Step": 452}
{"Training Time": 16.96013799197144, "Episode Reward": 35813.149150680365, "Mean Reward": 62.17560616437564, "Episode": 3991, "Episode Step": 576}
{"Training Time": 16.96188070250882, "Episode Reward": 6106.961531698563, "Mean Reward": 42.706024697192746, "Episode": 3992, "Episode Step": 143}
{"Training Time": 16.967963773078388, "Episode Reward": 27514.408687730305, "Mean Reward": 58.16999722564547, "Episode": 3993, "Episode Step": 473}
{"Training Time": 16.973656803038384, "Episode Reward": 27487.33501124474, "Mean Reward": 57.265281273426545, "Episode": 3994, "Episode Step": 480}
{"Training Time": 16.99179488056236, "Episode Reward": 87788.16739203977, "Mean Reward": 57.45298913091608, "Episode": 3995, "Episode Step": 1528}
{"Training Time": 16.994487009975646, "Episode Reward": 8230.46741856246, "Mean Reward": 45.222348453639896, "Episode": 3996, "Episode Step": 182}
{"Training Time": 17.016565335856544, "Episode Reward": 110984.34106666564, "Mean Reward": 59.862104135202614, "Episode": 3997, "Episode Step": 1854}
{"Training Time": 17.017954292496047, "Episode Reward": 5500.485590924229, "Mean Reward": 47.01269735832674, "Episode": 3998, "Episode Step": 117}
{"Training Time": 17.021689041389358, "Episode Reward": 8872.618385883816, "Mean Reward": 48.22075209719465, "Episode": 3999, "Episode Step": 184}
{"Training Time": 17.02402938114272, "Episode Reward": 8781.589632569965, "Mean Reward": 50.180512186114086, "Episode": 4000, "Episode Step": 175}
{"Training Time": 17.025361454751756, "Episode Reward": 5511.116201159592, "Mean Reward": 48.770939833270724, "Episode": 4001, "Episode Step": 113}
{"Training Time": 17.02746222999361, "Episode Reward": 6290.329517510351, "Mean Reward": 45.58209795297356, "Episode": 4002, "Episode Step": 138}
{"Training Time": 17.033167760305936, "Episode Reward": 30426.332397642378, "Mean Reward": 64.32628413877882, "Episode": 4003, "Episode Step": 473}
{"Training Time": 17.04678003999922, "Episode Reward": 65375.20588345274, "Mean Reward": 57.09624967987139, "Episode": 4004, "Episode Step": 1145}
{"Training Time": 17.053005033863915, "Episode Reward": 29078.588570883723, "Mean Reward": 59.83248677136569, "Episode": 4005, "Episode Step": 486}
{"Training Time": 17.055909485552046, "Episode Reward": 14818.543935602152, "Mean Reward": 61.74393306500897, "Episode": 4006, "Episode Step": 240}
{"Training Time": 17.056442901359663, "Episode Reward": 1559.721890015644, "Mean Reward": 44.56348257187555, "Episode": 4007, "Episode Step": 35}
{"Training Time": 17.05905687080489, "Episode Reward": 8721.325900752396, "Mean Reward": 48.451810559735534, "Episode": 4008, "Episode Step": 180}
{"Training Time": 17.072500326368544, "Episode Reward": 75051.1937146052, "Mean Reward": 66.18271050670651, "Episode": 4009, "Episode Step": 1134}
{"Training Time": 17.075514199733735, "Episode Reward": 15716.213737380896, "Mean Reward": 62.61439736008325, "Episode": 4010, "Episode Step": 251}
{"Training Time": 17.097388177514077, "Episode Reward": 111920.09083837701, "Mean Reward": 61.39335756356392, "Episode": 4011, "Episode Step": 1823}
{"Training Time": 17.10022436334027, "Episode Reward": 14255.066232765304, "Mean Reward": 59.89523627212313, "Episode": 4012, "Episode Step": 238}
{"Training Time": 17.108484671380786, "Episode Reward": 44284.7347868411, "Mean Reward": 62.7262532391517, "Episode": 4013, "Episode Step": 706}
{"Training Time": 17.121935107509294, "Episode Reward": 70048.9965941328, "Mean Reward": 62.824212192047355, "Episode": 4014, "Episode Step": 1115}
{"Training Time": 17.1246246897512, "Episode Reward": 13719.76819280996, "Mean Reward": 60.174421898289296, "Episode": 4015, "Episode Step": 228}
{"Training Time": 17.129337623582945, "Episode Reward": 24573.328138014294, "Mean Reward": 60.525438763582, "Episode": 4016, "Episode Step": 406}
{"Training Time": 17.13798795196745, "Episode Reward": 42637.46658951646, "Mean Reward": 60.910666556452085, "Episode": 4017, "Episode Step": 700}
{"Training Time": 17.1511427205801, "Episode Reward": 72804.22982027453, "Mean Reward": 64.08823047559378, "Episode": 4018, "Episode Step": 1136}
{"Training Time": 17.174104523592526, "Episode Reward": 120319.19575531961, "Mean Reward": 61.48144903184446, "Episode": 4019, "Episode Step": 1957}
{"Training Time": 17.17826948636108, "Episode Reward": 18101.48826320232, "Mean Reward": 56.922919066673956, "Episode": 4020, "Episode Step": 318}
{"Training Time": 17.181221497191324, "Episode Reward": 15156.041282737455, "Mean Reward": 60.86763567364439, "Episode": 4021, "Episode Step": 249}
{"Training Time": 17.184703687495656, "Episode Reward": 16603.55315207641, "Mean Reward": 55.90421936726064, "Episode": 4022, "Episode Step": 297}
{"Training Time": 17.186831241117584, "Episode Reward": 5315.775174707257, "Mean Reward": 37.4350364416004, "Episode": 4023, "Episode Step": 142}
{"Training Time": 17.18887599527836, "Episode Reward": 9461.567636772092, "Mean Reward": 54.37682549869018, "Episode": 4024, "Episode Step": 174}
{"Training Time": 17.191587572760053, "Episode Reward": 13518.537436647319, "Mean Reward": 58.77624972455356, "Episode": 4025, "Episode Step": 230}
{"Training Time": 17.197680075565973, "Episode Reward": 28900.08577861168, "Mean Reward": 60.0833384170721, "Episode": 4026, "Episode Step": 481}
{"Training Time": 17.200618422494994, "Episode Reward": 16823.262273891472, "Mean Reward": 66.49510780194258, "Episode": 4027, "Episode Step": 253}
{"Training Time": 17.20407539665699, "Episode Reward": 17808.14779466399, "Mean Reward": 60.162661468459426, "Episode": 4028, "Episode Step": 296}
{"Training Time": 17.218504943052928, "Episode Reward": 76041.30136240658, "Mean Reward": 64.00782942963517, "Episode": 4029, "Episode Step": 1188}
{"Training Time": 17.231563637190394, "Episode Reward": 75525.94138743493, "Mean Reward": 67.5545092910867, "Episode": 4030, "Episode Step": 1118}
{"Training Time": 17.232604148586592, "Episode Reward": 4566.748746703033, "Mean Reward": 52.49136490463257, "Episode": 4031, "Episode Step": 87}
{"Training Time": 17.238716899752617, "Episode Reward": 27245.135153396604, "Mean Reward": 56.76069823624292, "Episode": 4032, "Episode Step": 480}
{"Training Time": 17.24596733086639, "Episode Reward": 38891.77231844036, "Mean Reward": 63.03366664252894, "Episode": 4033, "Episode Step": 617}
{"Training Time": 17.24703035136064, "Episode Reward": 4151.7290183175455, "Mean Reward": 47.72102319905225, "Episode": 4034, "Episode Step": 87}
{"Training Time": 17.25436317582925, "Episode Reward": 35352.48159849511, "Mean Reward": 61.05782659498292, "Episode": 4035, "Episode Step": 579}
{"Training Time": 17.273179330825805, "Episode Reward": 104386.8587845978, "Mean Reward": 65.4052999903495, "Episode": 4036, "Episode Step": 1596}
{"Training Time": 17.28648965557416, "Episode Reward": 69754.77397291535, "Mean Reward": 62.225489717141265, "Episode": 4037, "Episode Step": 1121}
{"Training Time": 17.30938048640887, "Episode Reward": 121720.0166889624, "Mean Reward": 64.06316667840126, "Episode": 4038, "Episode Step": 1900}
{"Training Time": 17.312760488059787, "Episode Reward": 17031.933438310713, "Mean Reward": 58.93402573809935, "Episode": 4039, "Episode Step": 289}
{"Training Time": 17.320866821408273, "Episode Reward": 44465.24596483669, "Mean Reward": 64.53591576899375, "Episode": 4040, "Episode Step": 689}
{"Training Time": 17.35080306808154, "Episode Reward": 160713.99461713654, "Mean Reward": 63.85140827061444, "Episode": 4041, "Episode Step": 2517}
{"Training Time": 17.35285589913527, "Episode Reward": 8889.790865165383, "Mean Reward": 51.68483061142665, "Episode": 4042, "Episode Step": 172}
{"Training Time": 17.354989273084534, "Episode Reward": 8112.927256439693, "Mean Reward": 45.07181809133163, "Episode": 4043, "Episode Step": 180}
{"Training Time": 17.358298666675886, "Episode Reward": 15188.962386752404, "Mean Reward": 63.02474019399338, "Episode": 4044, "Episode Step": 241}
{"Training Time": 17.36094179974662, "Episode Reward": 14133.507658920891, "Mean Reward": 62.81558959520396, "Episode": 4045, "Episode Step": 225}
{"Training Time": 17.362601186699337, "Episode Reward": 6448.958242272098, "Mean Reward": 46.731581465739836, "Episode": 4046, "Episode Step": 138}
{"Training Time": 17.3916135278013, "Episode Reward": 151225.7174407307, "Mean Reward": 62.567528937000695, "Episode": 4047, "Episode Step": 2417}
{"Training Time": 17.395117607778975, "Episode Reward": 19059.015304277447, "Mean Reward": 64.38856521715354, "Episode": 4048, "Episode Step": 296}
{"Training Time": 17.40412838637829, "Episode Reward": 41471.15454468088, "Mean Reward": 61.4387474736013, "Episode": 4049, "Episode Step": 675}
{"Training Time": 17.433464900255203, "Episode Reward": 155929.27760204114, "Mean Reward": 63.59269070230063, "Episode": 4050, "Episode Step": 2452}
{"Training Time": 17.446752304699686, "Episode Reward": 72906.26564704128, "Mean Reward": 64.23459528373681, "Episode": 4051, "Episode Step": 1135}
{"Training Time": 17.47033146997293, "Episode Reward": 123143.98292442101, "Mean Reward": 62.037270994670536, "Episode": 4052, "Episode Step": 1985}
{"Training Time": 17.481937842501534, "Episode Reward": 56999.05937540995, "Mean Reward": 61.22347945801283, "Episode": 4053, "Episode Step": 931}
{"Training Time": 17.485532492200534, "Episode Reward": 18459.171675895745, "Mean Reward": 61.53057225298581, "Episode": 4054, "Episode Step": 300}
{"Training Time": 17.48851776553525, "Episode Reward": 16241.193977668374, "Mean Reward": 64.70595210226443, "Episode": 4055, "Episode Step": 251}
{"Training Time": 17.51191617747148, "Episode Reward": 121091.75446274495, "Mean Reward": 62.386272263134956, "Episode": 4056, "Episode Step": 1941}
{"Training Time": 17.52455705973837, "Episode Reward": 69642.0503770034, "Mean Reward": 64.54314214736182, "Episode": 4057, "Episode Step": 1079}
{"Training Time": 17.531840434736676, "Episode Reward": 37336.3746229932, "Mean Reward": 60.610997764599354, "Episode": 4058, "Episode Step": 616}
{"Training Time": 17.535178894466824, "Episode Reward": 14326.951794390341, "Mean Reward": 58.95864935963103, "Episode": 4059, "Episode Step": 243}
{"Training Time": 17.54668907529778, "Episode Reward": 64028.4962391051, "Mean Reward": 65.53582010143818, "Episode": 4060, "Episode Step": 977}
{"Training Time": 17.54877003053824, "Episode Reward": 9036.40659914362, "Mean Reward": 51.05314462793006, "Episode": 4061, "Episode Step": 177}
{"Training Time": 17.55751345442401, "Episode Reward": 41744.070937145036, "Mean Reward": 59.97711341543827, "Episode": 4062, "Episode Step": 696}
{"Training Time": 17.56017821080155, "Episode Reward": 13798.138699538074, "Mean Reward": 60.78475198034394, "Episode": 4063, "Episode Step": 227}
{"Training Time": 17.56284768614504, "Episode Reward": 12846.81107442078, "Mean Reward": 57.3518351536642, "Episode": 4064, "Episode Step": 224}
{"Training Time": 17.622407422794236, "Episode Reward": 311884.1089110334, "Mean Reward": 62.37682178220668, "Episode": 4065, "Episode Step": 5000}
{"Training Time": 17.62333764195442, "Episode Reward": 2589.009014439843, "Mean Reward": 48.84922668754421, "Episode": 4066, "Episode Step": 53}
{"Training Time": 17.630728353857993, "Episode Reward": 36311.0993272902, "Mean Reward": 58.19086430655481, "Episode": 4067, "Episode Step": 624}
{"Training Time": 17.650105136699146, "Episode Reward": 99058.54305442699, "Mean Reward": 62.144631778185065, "Episode": 4068, "Episode Step": 1594}
{"Training Time": 17.652773549755413, "Episode Reward": 14261.758469554372, "Mean Reward": 63.105125971479524, "Episode": 4069, "Episode Step": 226}
{"Training Time": 17.655478890538216, "Episode Reward": 12401.51764995198, "Mean Reward": 54.392621271719214, "Episode": 4070, "Episode Step": 228}
{"Training Time": 17.680778725014793, "Episode Reward": 134149.12736909883, "Mean Reward": 63.638105962570606, "Episode": 4071, "Episode Step": 2108}
{"Training Time": 17.6842269808054, "Episode Reward": 17665.306966065644, "Mean Reward": 60.29115005483155, "Episode": 4072, "Episode Step": 293}
{"Training Time": 17.68715392609437, "Episode Reward": 14855.931861264618, "Mean Reward": 60.389966915709834, "Episode": 4073, "Episode Step": 246}
{"Training Time": 17.69315689139896, "Episode Reward": 29529.047083148154, "Mean Reward": 62.03581319989108, "Episode": 4074, "Episode Step": 476}
{"Training Time": 17.701017502480084, "Episode Reward": 44812.96490861334, "Mean Reward": 66.09581844928222, "Episode": 4075, "Episode Step": 678}
{"Training Time": 17.70310035030047, "Episode Reward": 8379.775983499301, "Mean Reward": 47.612363542609664, "Episode": 4076, "Episode Step": 176}
{"Training Time": 17.70488642666075, "Episode Reward": 5778.197419106371, "Mean Reward": 51.59104838487831, "Episode": 4077, "Episode Step": 112}
{"Training Time": 17.71700879249308, "Episode Reward": 64967.43727330619, "Mean Reward": 62.40868133843054, "Episode": 4078, "Episode Step": 1041}
{"Training Time": 17.719155418607922, "Episode Reward": 7644.288621347575, "Mean Reward": 42.46827011859764, "Episode": 4079, "Episode Step": 180}
{"Training Time": 17.738970031407145, "Episode Reward": 106387.16507183661, "Mean Reward": 64.59451431198337, "Episode": 4080, "Episode Step": 1647}
{"Training Time": 17.755965827239883, "Episode Reward": 95739.47172582663, "Mean Reward": 65.21762379143503, "Episode": 4081, "Episode Step": 1468}
{"Training Time": 17.75802322136031, "Episode Reward": 8763.8616708254, "Mean Reward": 50.07920954757371, "Episode": 4082, "Episode Step": 175}
{"Training Time": 17.766643734971684, "Episode Reward": 44335.90113012952, "Mean Reward": 63.427612489455676, "Episode": 4083, "Episode Step": 699}
{"Training Time": 17.768701909184458, "Episode Reward": 9121.684023418358, "Mean Reward": 52.123908705247764, "Episode": 4084, "Episode Step": 175}
{"Training Time": 17.772133954697185, "Episode Reward": 18763.520892526765, "Mean Reward": 63.60515556788734, "Episode": 4085, "Episode Step": 295}
{"Training Time": 17.78937397804525, "Episode Reward": 95486.3306697489, "Mean Reward": 66.35603243207012, "Episode": 4086, "Episode Step": 1439}
{"Training Time": 17.79991714808676, "Episode Reward": 59652.67981101347, "Mean Reward": 66.13379136475994, "Episode": 4087, "Episode Step": 902}
{"Training Time": 17.80807125919395, "Episode Reward": 44415.86395935933, "Mean Reward": 64.46424377265505, "Episode": 4088, "Episode Step": 689}
{"Training Time": 17.8106457477808, "Episode Reward": 8898.620208052378, "Mean Reward": 49.436778933624325, "Episode": 4089, "Episode Step": 180}
{"Training Time": 17.843115852210257, "Episode Reward": 191948.64996058642, "Mean Reward": 68.77414903639786, "Episode": 4090, "Episode Step": 2791}
{"Training Time": 17.84790835969978, "Episode Reward": 25253.375189950282, "Mean Reward": 62.04760488931273, "Episode": 4091, "Episode Step": 407}
{"Training Time": 17.849654980566765, "Episode Reward": 6036.375976487177, "Mean Reward": 55.89237015265904, "Episode": 4092, "Episode Step": 108}
{"Training Time": 17.8524162716998, "Episode Reward": 15240.195723893752, "Mean Reward": 64.30462330756858, "Episode": 4093, "Episode Step": 237}
{"Training Time": 17.85447038723363, "Episode Reward": 8639.849086278047, "Mean Reward": 49.090051626579815, "Episode": 4094, "Episode Step": 176}
{"Training Time": 17.86159094472726, "Episode Reward": 35898.199358805316, "Mean Reward": 62.86900062838059, "Episode": 4095, "Episode Step": 571}
{"Training Time": 17.879686235586803, "Episode Reward": 100392.65881291898, "Mean Reward": 64.51970360727441, "Episode": 4096, "Episode Step": 1556}
{"Training Time": 17.882641628318364, "Episode Reward": 16628.972966788588, "Mean Reward": 67.59745108450646, "Episode": 4097, "Episode Step": 246}
{"Training Time": 17.88442637834284, "Episode Reward": 5929.55719114101, "Mean Reward": 55.41642234711224, "Episode": 4098, "Episode Step": 107}
{"Training Time": 17.91583946638637, "Episode Reward": 173501.93823968715, "Mean Reward": 66.4503784908798, "Episode": 4099, "Episode Step": 2611}
{"Training Time": 17.917422713902262, "Episode Reward": 5678.454831730956, "Mean Reward": 53.06967132458838, "Episode": 4100, "Episode Step": 107}
{"Training Time": 17.93617632501655, "Episode Reward": 95031.42697317222, "Mean Reward": 61.950082772602485, "Episode": 4101, "Episode Step": 1534}
{"Training Time": 17.938300480246543, "Episode Reward": 9100.727248890615, "Mean Reward": 52.00415570794637, "Episode": 4102, "Episode Step": 175}
{"Training Time": 17.939641600847246, "Episode Reward": 5279.752541596728, "Mean Reward": 49.343481697165686, "Episode": 4103, "Episode Step": 107}
{"Training Time": 17.94981642252869, "Episode Reward": 49419.323060211034, "Mean Reward": 61.390463428833584, "Episode": 4104, "Episode Step": 805}
{"Training Time": 17.95194646610154, "Episode Reward": 9556.507985855456, "Mean Reward": 54.60861706203118, "Episode": 4105, "Episode Step": 175}
{"Training Time": 17.953212227755124, "Episode Reward": 5690.248607904362, "Mean Reward": 53.68159064060719, "Episode": 4106, "Episode Step": 106}
{"Training Time": 17.960358164178, "Episode Reward": 33190.411982191334, "Mean Reward": 59.80254411205646, "Episode": 4107, "Episode Step": 555}
{"Training Time": 17.962034262220065, "Episode Reward": 6726.289389158863, "Mean Reward": 48.74122745767292, "Episode": 4108, "Episode Step": 138}
{"Training Time": 17.967889632251527, "Episode Reward": 31478.004298946325, "Mean Reward": 65.30706286088449, "Episode": 4109, "Episode Step": 482}
{"Training Time": 17.969611183338696, "Episode Reward": 5922.180636354088, "Mean Reward": 55.34748258274849, "Episode": 4110, "Episode Step": 107}
{"Training Time": 17.971734527217016, "Episode Reward": 9255.439322488543, "Mean Reward": 52.58772342323036, "Episode": 4111, "Episode Step": 176}
{"Training Time": 17.974722398055924, "Episode Reward": 16535.606044106808, "Mean Reward": 67.21791074840165, "Episode": 4112, "Episode Step": 246}
{"Training Time": 17.979497009714443, "Episode Reward": 21959.795475572504, "Mean Reward": 61.684818751608155, "Episode": 4113, "Episode Step": 356}
{"Training Time": 17.98292167941729, "Episode Reward": 17787.072783762414, "Mean Reward": 61.9758633580572, "Episode": 4114, "Episode Step": 287}
{"Training Time": 17.985891546408336, "Episode Reward": 16367.646498562379, "Mean Reward": 66.80672040229543, "Episode": 4115, "Episode Step": 245}
{"Training Time": 17.98998840219445, "Episode Reward": 18233.216800179584, "Mean Reward": 61.18529127577042, "Episode": 4116, "Episode Step": 298}
{"Training Time": 17.99230675081412, "Episode Reward": 9697.697815501378, "Mean Reward": 50.773286992153814, "Episode": 4117, "Episode Step": 191}
{"Training Time": 17.995265621410475, "Episode Reward": 17108.807439151766, "Mean Reward": 69.54799772012913, "Episode": 4118, "Episode Step": 246}
{"Training Time": 17.99702009472582, "Episode Reward": 5767.661399226468, "Mean Reward": 53.90337756286419, "Episode": 4119, "Episode Step": 107}
{"Training Time": 18.010257044699458, "Episode Reward": 78596.54044531415, "Mean Reward": 70.30102007630961, "Episode": 4120, "Episode Step": 1118}
{"Training Time": 18.012350057760873, "Episode Reward": 8982.93422206398, "Mean Reward": 51.331052697508454, "Episode": 4121, "Episode Step": 175}
{"Training Time": 18.014941312472025, "Episode Reward": 8389.116583998302, "Mean Reward": 46.86657309496258, "Episode": 4122, "Episode Step": 179}
{"Training Time": 18.017888046105703, "Episode Reward": 15394.359964700912, "Mean Reward": 62.32534398664337, "Episode": 4123, "Episode Step": 247}
{"Training Time": 18.022718847195307, "Episode Reward": 25864.773197494083, "Mean Reward": 64.0217158353814, "Episode": 4124, "Episode Step": 404}
{"Training Time": 18.02449776530266, "Episode Reward": 5293.55739668459, "Mean Reward": 48.564746758574216, "Episode": 4125, "Episode Step": 109}
{"Training Time": 18.032683260573283, "Episode Reward": 47126.73306844746, "Mean Reward": 68.7981504648868, "Episode": 4126, "Episode Step": 685}
{"Training Time": 18.03396829611725, "Episode Reward": 5375.181299603155, "Mean Reward": 50.70925754342599, "Episode": 4127, "Episode Step": 106}
{"Training Time": 18.03867812361982, "Episode Reward": 20614.420592300496, "Mean Reward": 57.103658150416884, "Episode": 4128, "Episode Step": 361}
{"Training Time": 18.051159287492435, "Episode Reward": 68929.17692775984, "Mean Reward": 65.83493498353376, "Episode": 4129, "Episode Step": 1047}
{"Training Time": 18.05326647553179, "Episode Reward": 8843.206811279386, "Mean Reward": 49.68093714201902, "Episode": 4130, "Episode Step": 178}
{"Training Time": 18.073746729162004, "Episode Reward": 110794.7659768352, "Mean Reward": 66.02787006962765, "Episode": 4131, "Episode Step": 1678}
{"Training Time": 18.102640842530462, "Episode Reward": 168184.42942403498, "Mean Reward": 68.39545726882268, "Episode": 4132, "Episode Step": 2459}
{"Training Time": 18.103866686092484, "Episode Reward": 5922.86163620946, "Mean Reward": 56.40820605913771, "Episode": 4133, "Episode Step": 105}
{"Training Time": 18.107297204467987, "Episode Reward": 15902.521120476624, "Mean Reward": 62.8558147054412, "Episode": 4134, "Episode Step": 253}
{"Training Time": 18.109382858872415, "Episode Reward": 8573.92989963239, "Mean Reward": 48.99388514075652, "Episode": 4135, "Episode Step": 175}
{"Training Time": 18.11063599917624, "Episode Reward": 5688.906028977375, "Mean Reward": 53.66892480167335, "Episode": 4136, "Episode Step": 106}
{"Training Time": 18.139953915278117, "Episode Reward": 162718.67787550006, "Mean Reward": 66.28052051955196, "Episode": 4137, "Episode Step": 2455}
{"Training Time": 18.142032980587746, "Episode Reward": 8725.443976683988, "Mean Reward": 49.57638623115902, "Episode": 4138, "Episode Step": 176}
{"Training Time": 18.144111619724168, "Episode Reward": 8749.939738625568, "Mean Reward": 49.71556669673618, "Episode": 4139, "Episode Step": 176}
{"Training Time": 18.173060026102597, "Episode Reward": 151432.51488006258, "Mean Reward": 63.573683828741636, "Episode": 4140, "Episode Step": 2382}
{"Training Time": 18.18039165635904, "Episode Reward": 40198.025649819545, "Mean Reward": 65.15077090732503, "Episode": 4141, "Episode Step": 617}
{"Training Time": 18.18248815556367, "Episode Reward": 8312.992192620812, "Mean Reward": 47.77581719897018, "Episode": 4142, "Episode Step": 174}
{"Training Time": 18.194550371103816, "Episode Reward": 63839.22501852699, "Mean Reward": 65.20860573904697, "Episode": 4143, "Episode Step": 979}
{"Training Time": 18.201826746927367, "Episode Reward": 38502.522891728986, "Mean Reward": 62.80998840412559, "Episode": 4144, "Episode Step": 613}
{"Training Time": 18.204808456963963, "Episode Reward": 16636.39687790838, "Mean Reward": 66.54558751163353, "Episode": 4145, "Episode Step": 250}
{"Training Time": 18.21179963608583, "Episode Reward": 33650.5756041821, "Mean Reward": 61.40615986164617, "Episode": 4146, "Episode Step": 548}
{"Training Time": 18.21457904027568, "Episode Reward": 14946.857732772516, "Mean Reward": 63.06691026486294, "Episode": 4147, "Episode Step": 237}
{"Training Time": 18.21585560553604, "Episode Reward": 5343.042241687349, "Mean Reward": 50.40605888384292, "Episode": 4148, "Episode Step": 106}
{"Training Time": 18.233866959412893, "Episode Reward": 88475.07935572595, "Mean Reward": 63.016438287554095, "Episode": 4149, "Episode Step": 1404}
{"Training Time": 18.242567970289123, "Episode Reward": 47220.48836762997, "Mean Reward": 67.26565294534184, "Episode": 4150, "Episode Step": 702}
{"Training Time": 18.243859859175153, "Episode Reward": 5588.650099353186, "Mean Reward": 52.72311414484138, "Episode": 4151, "Episode Step": 106}
{"Training Time": 18.245944461358917, "Episode Reward": 5394.395438850893, "Mean Reward": 39.95848473222883, "Episode": 4152, "Episode Step": 135}
{"Training Time": 18.248868391381368, "Episode Reward": 16864.006925136684, "Mean Reward": 68.55287367941742, "Episode": 4153, "Episode Step": 246}
{"Training Time": 18.25099503000577, "Episode Reward": 8443.30733188798, "Mean Reward": 47.973337112999886, "Episode": 4154, "Episode Step": 176}
{"Training Time": 18.25305200530423, "Episode Reward": 6072.044461998562, "Mean Reward": 45.31376464178031, "Episode": 4155, "Episode Step": 134}
{"Training Time": 18.268561629984113, "Episode Reward": 83611.84211953932, "Mean Reward": 64.218004700107, "Episode": 4156, "Episode Step": 1302}
{"Training Time": 18.275943997237416, "Episode Reward": 37889.2932952951, "Mean Reward": 60.91526253262878, "Episode": 4157, "Episode Step": 622}
{"Training Time": 18.278039990266166, "Episode Reward": 5771.759517185829, "Mean Reward": 42.753774201376515, "Episode": 4158, "Episode Step": 135}
{"Training Time": 18.283011545273993, "Episode Reward": 23886.911618336962, "Mean Reward": 57.97794082120622, "Episode": 4159, "Episode Step": 412}
{"Training Time": 18.28511020640532, "Episode Reward": 8072.07421268347, "Mean Reward": 46.126138358191255, "Episode": 4160, "Episode Step": 175}
{"Training Time": 18.302465064989196, "Episode Reward": 91120.5437941207, "Mean Reward": 63.41026012116959, "Episode": 4161, "Episode Step": 1437}
{"Training Time": 18.309807234141562, "Episode Reward": 35982.13063058048, "Mean Reward": 57.75622894154171, "Episode": 4162, "Episode Step": 623}
{"Training Time": 18.31081122557322, "Episode Reward": 4514.918414421506, "Mean Reward": 53.1166872284883, "Episode": 4163, "Episode Step": 85}
{"Training Time": 18.312611473600068, "Episode Reward": 5627.382131555526, "Mean Reward": 52.105390106995614, "Episode": 4164, "Episode Step": 108}
{"Training Time": 18.320174864464335, "Episode Reward": 39219.43589404425, "Mean Reward": 62.056069452601655, "Episode": 4165, "Episode Step": 632}
{"Training Time": 18.32147454082966, "Episode Reward": 5417.166632232283, "Mean Reward": 50.627725534881144, "Episode": 4166, "Episode Step": 107}
{"Training Time": 18.32321665638023, "Episode Reward": 5606.814474354406, "Mean Reward": 51.914948836614876, "Episode": 4167, "Episode Step": 108}
{"Training Time": 18.33079970194234, "Episode Reward": 37910.28539949482, "Mean Reward": 59.42051003055614, "Episode": 4168, "Episode Step": 638}
{"Training Time": 18.333754614724054, "Episode Reward": 15793.877637421689, "Mean Reward": 63.68499047347455, "Episode": 4169, "Episode Step": 248}
{"Training Time": 18.34155272636149, "Episode Reward": 35041.82728217186, "Mean Reward": 56.24691377555675, "Episode": 4170, "Episode Step": 623}
{"Training Time": 18.355130326946576, "Episode Reward": 76503.71369065376, "Mean Reward": 66.29437928132909, "Episode": 4171, "Episode Step": 1154}
{"Training Time": 18.35720684780015, "Episode Reward": 8323.39474647455, "Mean Reward": 47.56225569414029, "Episode": 4172, "Episode Step": 175}
{"Training Time": 18.358931418326165, "Episode Reward": 5161.373732157102, "Mean Reward": 48.692205020350016, "Episode": 4173, "Episode Step": 106}
{"Training Time": 18.363092295858596, "Episode Reward": 21658.618629916582, "Mean Reward": 61.705466182098526, "Episode": 4174, "Episode Step": 351}
{"Training Time": 18.36603127612008, "Episode Reward": 15751.777741702263, "Mean Reward": 63.00711096680905, "Episode": 4175, "Episode Step": 250}
{"Training Time": 18.369440270264942, "Episode Reward": 16047.803129192285, "Mean Reward": 64.44900855097303, "Episode": 4176, "Episode Step": 249}
{"Training Time": 18.373697080545956, "Episode Reward": 22007.698986387182, "Mean Reward": 61.13249718440884, "Episode": 4177, "Episode Step": 360}
{"Training Time": 18.375757081376182, "Episode Reward": 8490.567064824043, "Mean Reward": 48.79636244151749, "Episode": 4178, "Episode Step": 174}
{"Training Time": 18.403046036693784, "Episode Reward": 147150.9845740325, "Mean Reward": 64.25807186638974, "Episode": 4179, "Episode Step": 2290}
{"Training Time": 18.42336880558067, "Episode Reward": 109459.56425779789, "Mean Reward": 63.86205615974206, "Episode": 4180, "Episode Step": 1714}
{"Training Time": 18.425515815549428, "Episode Reward": 8112.000980480244, "Mean Reward": 45.066672113779134, "Episode": 4181, "Episode Step": 180}
{"Training Time": 18.428427383038734, "Episode Reward": 9203.638780831498, "Mean Reward": 44.6778581593762, "Episode": 4182, "Episode Step": 206}
{"Training Time": 18.430199408862325, "Episode Reward": 6860.505442864021, "Mean Reward": 46.67010505349674, "Episode": 4183, "Episode Step": 147}
{"Training Time": 18.432379734979737, "Episode Reward": 8597.616688381684, "Mean Reward": 47.2396521339653, "Episode": 4184, "Episode Step": 182}
{"Training Time": 18.437402016917865, "Episode Reward": 23905.395925007564, "Mean Reward": 61.295886987198884, "Episode": 4185, "Episode Step": 390}
{"Training Time": 18.440482183893522, "Episode Reward": 16487.695440379834, "Mean Reward": 62.93013526862532, "Episode": 4186, "Episode Step": 262}
{"Training Time": 18.442628130581642, "Episode Reward": 8690.999157294735, "Mean Reward": 48.016569929805165, "Episode": 4187, "Episode Step": 181}
{"Training Time": 18.448811921079955, "Episode Reward": 31841.310072143664, "Mean Reward": 65.24858621340914, "Episode": 4188, "Episode Step": 488}
{"Training Time": 18.451671071648597, "Episode Reward": 13249.007608756207, "Mean Reward": 54.975135306042354, "Episode": 4189, "Episode Step": 241}
{"Training Time": 18.454625045259792, "Episode Reward": 16180.695996716418, "Mean Reward": 64.72278398686568, "Episode": 4190, "Episode Step": 250}
{"Training Time": 18.458535602225197, "Episode Reward": 17921.525457454147, "Mean Reward": 60.750933754081856, "Episode": 4191, "Episode Step": 295}
{"Training Time": 18.467366140286128, "Episode Reward": 49487.598862455205, "Mean Reward": 65.7205828186656, "Episode": 4192, "Episode Step": 753}
{"Training Time": 18.47466436194049, "Episode Reward": 38140.81442915417, "Mean Reward": 61.319637345907026, "Episode": 4193, "Episode Step": 622}
{"Training Time": 18.493513373070293, "Episode Reward": 102901.84252749667, "Mean Reward": 65.45918735845844, "Episode": 4194, "Episode Step": 1572}
{"Training Time": 18.497609799173144, "Episode Reward": 21858.795462291, "Mean Reward": 62.09885074514489, "Episode": 4195, "Episode Step": 352}
{"Training Time": 18.499724065528977, "Episode Reward": 8723.330102246886, "Mean Reward": 49.00747248453307, "Episode": 4196, "Episode Step": 178}
{"Training Time": 18.502910671366585, "Episode Reward": 12838.719974687525, "Mean Reward": 54.86632467815181, "Episode": 4197, "Episode Step": 234}
{"Training Time": 18.516207781963878, "Episode Reward": 75591.43158260769, "Mean Reward": 66.25015914338974, "Episode": 4198, "Episode Step": 1141}
{"Training Time": 18.519453060030937, "Episode Reward": 8706.595665853984, "Mean Reward": 47.31845470572817, "Episode": 4199, "Episode Step": 184}
{"Training Time": 18.54783113890224, "Episode Reward": 152660.65592759766, "Mean Reward": 63.58211408896196, "Episode": 4200, "Episode Step": 2401}
{"Training Time": 18.559963613351186, "Episode Reward": 65502.922542253626, "Mean Reward": 62.98357936755156, "Episode": 4201, "Episode Step": 1040}
{"Training Time": 18.562117805017365, "Episode Reward": 8494.66273321096, "Mean Reward": 46.673971061598685, "Episode": 4202, "Episode Step": 182}
{"Training Time": 18.619074394173094, "Episode Reward": 300859.1592988909, "Mean Reward": 63.338770378713875, "Episode": 4203, "Episode Step": 4750}
{"Training Time": 18.620466575556332, "Episode Reward": 5983.304025514856, "Mean Reward": 51.13935064542612, "Episode": 4204, "Episode Step": 117}
{"Training Time": 18.622518336375553, "Episode Reward": 8198.365245553698, "Mean Reward": 48.22567791502175, "Episode": 4205, "Episode Step": 170}
{"Training Time": 18.640362698899374, "Episode Reward": 93999.37312565574, "Mean Reward": 64.20722208036594, "Episode": 4206, "Episode Step": 1464}
{"Training Time": 18.64466259724564, "Episode Reward": 22901.48015958154, "Mean Reward": 63.61522266550428, "Episode": 4207, "Episode Step": 360}
{"Training Time": 18.64820966747072, "Episode Reward": 18245.346793375033, "Mean Reward": 61.63968511275349, "Episode": 4208, "Episode Step": 296}
{"Training Time": 18.65039579808712, "Episode Reward": 6466.3837300461, "Mean Reward": 45.537913591873945, "Episode": 4209, "Episode Step": 142}
{"Training Time": 18.654801517791217, "Episode Reward": 22128.097225924208, "Mean Reward": 60.29454284992972, "Episode": 4210, "Episode Step": 367}
{"Training Time": 18.66838848332564, "Episode Reward": 73912.23592847637, "Mean Reward": 64.6651232970047, "Episode": 4211, "Episode Step": 1143}
{"Training Time": 18.680831210282115, "Episode Reward": 63601.42940581317, "Mean Reward": 63.60142940581317, "Episode": 4212, "Episode Step": 1000}
{"Training Time": 18.68726683166292, "Episode Reward": 35039.48770233793, "Mean Reward": 64.76799944979285, "Episode": 4213, "Episode Step": 541}
{"Training Time": 18.694662481678858, "Episode Reward": 37804.359176905156, "Mean Reward": 61.370712949521355, "Episode": 4214, "Episode Step": 616}
{"Training Time": 18.696848835282857, "Episode Reward": 6117.04509455718, "Mean Reward": 43.38329854295873, "Episode": 4215, "Episode Step": 141}
{"Training Time": 18.69822333859073, "Episode Reward": 6307.775970392483, "Mean Reward": 55.82102628665914, "Episode": 4216, "Episode Step": 113}
{"Training Time": 18.70644986609618, "Episode Reward": 45127.53848998751, "Mean Reward": 65.97593346489403, "Episode": 4217, "Episode Step": 684}
{"Training Time": 18.7090434369776, "Episode Reward": 7860.898692046326, "Mean Reward": 43.915635151096794, "Episode": 4218, "Episode Step": 179}
{"Training Time": 18.715748546653323, "Episode Reward": 35935.30949650374, "Mean Reward": 63.9418318443127, "Episode": 4219, "Episode Step": 562}
{"Training Time": 18.718758904735246, "Episode Reward": 16471.57520304713, "Mean Reward": 64.8487212718391, "Episode": 4220, "Episode Step": 254}
{"Training Time": 18.754553683598836, "Episode Reward": 186413.33515481625, "Mean Reward": 62.82889624361855, "Episode": 4221, "Episode Step": 2967}
{"Training Time": 18.7559146296978, "Episode Reward": 6146.266929268519, "Mean Reward": 55.37177413755422, "Episode": 4222, "Episode Step": 111}
{"Training Time": 18.763203830255403, "Episode Reward": 37327.86227531232, "Mean Reward": 60.695711016768, "Episode": 4223, "Episode Step": 615}
{"Training Time": 18.76523508058654, "Episode Reward": 5790.574698902739, "Mean Reward": 44.54288229925184, "Episode": 4224, "Episode Step": 130}
{"Training Time": 18.77235329164399, "Episode Reward": 37619.1335987613, "Mean Reward": 63.22543461976689, "Episode": 4225, "Episode Step": 595}
{"Training Time": 18.778594348894224, "Episode Reward": 34235.116817023016, "Mean Reward": 65.33419239889888, "Episode": 4226, "Episode Step": 524}
{"Training Time": 18.785504458083047, "Episode Reward": 34160.04078856422, "Mean Reward": 63.25933479363744, "Episode": 4227, "Episode Step": 540}
{"Training Time": 18.816491971082158, "Episode Reward": 164873.76577773227, "Mean Reward": 63.242717981485335, "Episode": 4228, "Episode Step": 2607}
{"Training Time": 18.829998314711784, "Episode Reward": 72710.01090461173, "Mean Reward": 63.446780894076554, "Episode": 4229, "Episode Step": 1146}
{"Training Time": 18.860617882476912, "Episode Reward": 162179.20454177572, "Mean Reward": 63.87522825591797, "Episode": 4230, "Episode Step": 2539}
{"Training Time": 18.86401947359244, "Episode Reward": 18529.116248041842, "Mean Reward": 63.67393899670736, "Episode": 4231, "Episode Step": 291}
{"Training Time": 18.877356459697086, "Episode Reward": 74422.16814651071, "Mean Reward": 65.05434278541146, "Episode": 4232, "Episode Step": 1144}
{"Training Time": 18.89630804611577, "Episode Reward": 104430.84811663635, "Mean Reward": 66.6013061968344, "Episode": 4233, "Episode Step": 1568}
{"Training Time": 18.9148002083434, "Episode Reward": 104181.99716291415, "Mean Reward": 65.85461261878265, "Episode": 4234, "Episode Step": 1582}
{"Training Time": 18.922923308875827, "Episode Reward": 45576.90311715468, "Mean Reward": 65.95789163119346, "Episode": 4235, "Episode Step": 691}
{"Training Time": 18.925470074746343, "Episode Reward": 8821.661158336176, "Mean Reward": 50.409492333349576, "Episode": 4236, "Episode Step": 175}
{"Training Time": 18.93920406944222, "Episode Reward": 79337.94747656699, "Mean Reward": 67.52165742686552, "Episode": 4237, "Episode Step": 1175}
{"Training Time": 18.94737392498387, "Episode Reward": 43188.3450384808, "Mean Reward": 62.320844211372005, "Episode": 4238, "Episode Step": 693}
{"Training Time": 18.984327378869057, "Episode Reward": 203676.06439531528, "Mean Reward": 66.53906056691123, "Episode": 4239, "Episode Step": 3061}
{"Training Time": 18.98795052998596, "Episode Reward": 19036.975743782798, "Mean Reward": 63.036343522459596, "Episode": 4240, "Episode Step": 302}
{"Training Time": 18.99103098862701, "Episode Reward": 16895.08910203038, "Mean Reward": 66.2552513805113, "Episode": 4241, "Episode Step": 255}
{"Training Time": 18.99912101308505, "Episode Reward": 37543.55145925793, "Mean Reward": 59.4043535747752, "Episode": 4242, "Episode Step": 632}
{"Training Time": 19.00016568667359, "Episode Reward": 4698.537648956973, "Mean Reward": 54.634158708802005, "Episode": 4243, "Episode Step": 86}
{"Training Time": 19.003306131098004, "Episode Reward": 17039.373553912883, "Mean Reward": 65.78908708074472, "Episode": 4244, "Episode Step": 259}
{"Training Time": 19.011046816375522, "Episode Reward": 37517.658925140815, "Mean Reward": 60.708185963011026, "Episode": 4245, "Episode Step": 618}
{"Training Time": 19.01399492694272, "Episode Reward": 14550.303194737608, "Mean Reward": 58.90811010015226, "Episode": 4246, "Episode Step": 247}
{"Training Time": 19.038303160534966, "Episode Reward": 133801.80084213582, "Mean Reward": 65.49280511117759, "Episode": 4247, "Episode Step": 2043}
{"Training Time": 19.050424786143832, "Episode Reward": 62894.3074972261, "Mean Reward": 64.04715631082088, "Episode": 4248, "Episode Step": 982}
{"Training Time": 19.05928606192271, "Episode Reward": 43523.9665323497, "Mean Reward": 66.14584579384453, "Episode": 4249, "Episode Step": 658}
{"Training Time": 19.08382178975476, "Episode Reward": 131561.65802459113, "Mean Reward": 64.90461668702079, "Episode": 4250, "Episode Step": 2027}
{"Training Time": 19.10068418416712, "Episode Reward": 91707.05842961228, "Mean Reward": 66.59917097284843, "Episode": 4251, "Episode Step": 1377}
{"Training Time": 19.104234466685188, "Episode Reward": 18003.768267811447, "Mean Reward": 60.012560892704826, "Episode": 4252, "Episode Step": 300}
{"Training Time": 19.10713607887427, "Episode Reward": 13749.360529028205, "Mean Reward": 56.81553937614961, "Episode": 4253, "Episode Step": 242}
{"Training Time": 19.163974771102268, "Episode Reward": 312793.9375302292, "Mean Reward": 65.50658377596423, "Episode": 4254, "Episode Step": 4775}
{"Training Time": 19.18281934890482, "Episode Reward": 108398.83542148118, "Mean Reward": 67.53821521587612, "Episode": 4255, "Episode Step": 1605}
{"Training Time": 19.201396053036053, "Episode Reward": 100526.28264240385, "Mean Reward": 63.988722242141215, "Episode": 4256, "Episode Step": 1571}
{"Training Time": 19.21519390192297, "Episode Reward": 75033.44962605846, "Mean Reward": 66.51901562593835, "Episode": 4257, "Episode Step": 1128}
{"Training Time": 19.218659478624662, "Episode Reward": 18297.20824204331, "Mean Reward": 62.44780969980652, "Episode": 4258, "Episode Step": 293}
{"Training Time": 19.22212162276109, "Episode Reward": 18414.354547126284, "Mean Reward": 62.421540837716215, "Episode": 4259, "Episode Step": 295}
{"Training Time": 19.2247106808424, "Episode Reward": 8642.060805446361, "Mean Reward": 47.74619229528376, "Episode": 4260, "Episode Step": 181}
{"Training Time": 19.228134556677606, "Episode Reward": 19260.562506771035, "Mean Reward": 66.41573278196908, "Episode": 4261, "Episode Step": 290}
{"Training Time": 19.241768585311043, "Episode Reward": 71093.70168676105, "Mean Reward": 62.47249708854223, "Episode": 4262, "Episode Step": 1138}
{"Training Time": 19.25116924862067, "Episode Reward": 49633.0998707434, "Mean Reward": 66.35441159190293, "Episode": 4263, "Episode Step": 748}
{"Training Time": 19.253358175555864, "Episode Reward": 8641.542319567357, "Mean Reward": 47.74332773241634, "Episode": 4264, "Episode Step": 181}
{"Training Time": 19.256800311406455, "Episode Reward": 17358.76662727677, "Mean Reward": 59.8578159561268, "Episode": 4265, "Episode Step": 290}
{"Training Time": 19.265414773888057, "Episode Reward": 44174.88834211913, "Mean Reward": 64.86767744804571, "Episode": 4266, "Episode Step": 681}
{"Training Time": 19.26893723057376, "Episode Reward": 19355.37698166662, "Mean Reward": 66.28553760844733, "Episode": 4267, "Episode Step": 292}
{"Training Time": 19.275127506388557, "Episode Reward": 33486.88821401797, "Mean Reward": 63.78454897908185, "Episode": 4268, "Episode Step": 525}
{"Training Time": 19.278316141698095, "Episode Reward": 13834.823247355363, "Mean Reward": 59.6328588248076, "Episode": 4269, "Episode Step": 232}
{"Training Time": 19.27933702475495, "Episode Reward": 4829.614831242808, "Mean Reward": 57.495414657652475, "Episode": 4270, "Episode Step": 84}
{"Training Time": 19.29819501446353, "Episode Reward": 106788.02445446972, "Mean Reward": 65.9185336138702, "Episode": 4271, "Episode Step": 1620}
{"Training Time": 19.333638594150543, "Episode Reward": 193700.18893579955, "Mean Reward": 65.02188282504181, "Episode": 4272, "Episode Step": 2979}
{"Training Time": 19.3370225855377, "Episode Reward": 19192.759566385557, "Mean Reward": 66.41093275565937, "Episode": 4273, "Episode Step": 289}
{"Training Time": 19.355306942529147, "Episode Reward": 98231.22838052662, "Mean Reward": 63.090063185951585, "Episode": 4274, "Episode Step": 1557}
{"Training Time": 19.412695425020324, "Episode Reward": 309923.18050977576, "Mean Reward": 63.4698301269252, "Episode": 4275, "Episode Step": 4883}
{"Training Time": 19.413696301380792, "Episode Reward": 4388.12998130871, "Mean Reward": 52.86903591938204, "Episode": 4276, "Episode Step": 83}
{"Training Time": 19.416454544994565, "Episode Reward": 13526.113828315898, "Mean Reward": 58.302214777223696, "Episode": 4277, "Episode Step": 232}
{"Training Time": 19.43595906164911, "Episode Reward": 105374.18971374001, "Mean Reward": 64.56751820694853, "Episode": 4278, "Episode Step": 1632}
{"Training Time": 19.436967070831194, "Episode Reward": 4359.981341958202, "Mean Reward": 51.9045397852167, "Episode": 4279, "Episode Step": 84}
{"Training Time": 19.440007938345275, "Episode Reward": 15070.99377179575, "Mean Reward": 58.871069421077145, "Episode": 4280, "Episode Step": 256}
{"Training Time": 19.443343931105403, "Episode Reward": 14997.687630290005, "Mean Reward": 61.97391582764465, "Episode": 4281, "Episode Step": 242}
{"Training Time": 19.44685705165068, "Episode Reward": 19022.5826286448, "Mean Reward": 65.36969975479312, "Episode": 4282, "Episode Step": 291}
{"Training Time": 19.45036780609025, "Episode Reward": 19049.448175135152, "Mean Reward": 66.60646215082221, "Episode": 4283, "Episode Step": 286}
{"Training Time": 19.453717449969716, "Episode Reward": 14702.683218680255, "Mean Reward": 61.261180077834396, "Episode": 4284, "Episode Step": 240}
{"Training Time": 19.48797110941675, "Episode Reward": 194570.1877234926, "Mean Reward": 67.84176698866548, "Episode": 4285, "Episode Step": 2868}
{"Training Time": 19.543465598026913, "Episode Reward": 307096.2137462507, "Mean Reward": 65.46497841531672, "Episode": 4286, "Episode Step": 4691}
{"Training Time": 19.603394420544305, "Episode Reward": 331942.3107385537, "Mean Reward": 66.38846214771074, "Episode": 4287, "Episode Step": 5000}
{"Training Time": 19.622730750574007, "Episode Reward": 112492.54402514132, "Mean Reward": 68.92925491736601, "Episode": 4288, "Episode Step": 1632}
{"Training Time": 19.63781185719702, "Episode Reward": 80849.19081899917, "Mean Reward": 62.77111088431612, "Episode": 4289, "Episode Step": 1288}
{"Training Time": 19.643897575802274, "Episode Reward": 29355.29868019108, "Mean Reward": 61.54150666706725, "Episode": 4290, "Episode Step": 477}
{"Training Time": 19.64743255191379, "Episode Reward": 19908.869583221356, "Mean Reward": 67.71724348034475, "Episode": 4291, "Episode Step": 294}
{"Training Time": 19.66874575138092, "Episode Reward": 111558.7254111925, "Mean Reward": 62.08053723494296, "Episode": 4292, "Episode Step": 1797}
{"Training Time": 19.7065603622463, "Episode Reward": 199688.90204709288, "Mean Reward": 63.94137113259458, "Episode": 4293, "Episode Step": 3123}
{"Training Time": 19.741027345259983, "Episode Reward": 196265.63009909922, "Mean Reward": 67.65447435336064, "Episode": 4294, "Episode Step": 2901}
{"Training Time": 19.744025992221303, "Episode Reward": 14272.891225782712, "Mean Reward": 56.864108469253836, "Episode": 4295, "Episode Step": 251}
{"Training Time": 19.74666065666411, "Episode Reward": 8381.377152709149, "Mean Reward": 46.82333604865446, "Episode": 4296, "Episode Step": 179}
{"Training Time": 19.758622489439116, "Episode Reward": 65734.34748015307, "Mean Reward": 65.60314119775755, "Episode": 4297, "Episode Step": 1002}
{"Training Time": 19.777188058363066, "Episode Reward": 97822.35926981733, "Mean Reward": 62.506299852918424, "Episode": 4298, "Episode Step": 1565}
{"Training Time": 19.786656778057417, "Episode Reward": 43776.52361396814, "Mean Reward": 64.4720524506158, "Episode": 4299, "Episode Step": 679}
{"Training Time": 19.79482231080532, "Episode Reward": 45002.40257927935, "Mean Reward": 67.36886613664574, "Episode": 4300, "Episode Step": 668}
{"Training Time": 19.796955886946783, "Episode Reward": 8026.604210559336, "Mean Reward": 44.84136430480076, "Episode": 4301, "Episode Step": 179}
{"Training Time": 19.80201483388742, "Episode Reward": 23377.034012956916, "Mean Reward": 60.25008766226009, "Episode": 4302, "Episode Step": 388}
{"Training Time": 19.84164697137144, "Episode Reward": 225075.14955723492, "Mean Reward": 66.6297067961027, "Episode": 4303, "Episode Step": 3378}
{"Training Time": 19.899934798346624, "Episode Reward": 322069.8975610757, "Mean Reward": 64.41397951221514, "Episode": 4304, "Episode Step": 5000}
{"Training Time": 19.902544484469626, "Episode Reward": 9023.292143034305, "Mean Reward": 49.57852825843025, "Episode": 4305, "Episode Step": 182}
{"Training Time": 19.939711424443455, "Episode Reward": 218719.36261992765, "Mean Reward": 68.26447023093871, "Episode": 4306, "Episode Step": 3204}
{"Training Time": 19.94531652635998, "Episode Reward": 29458.52999013887, "Mean Reward": 62.81136458451785, "Episode": 4307, "Episode Step": 469}
{"Training Time": 19.94862104581462, "Episode Reward": 15054.0173314453, "Mean Reward": 62.464802205167224, "Episode": 4308, "Episode Step": 241}
{"Training Time": 19.95851423607932, "Episode Reward": 58052.84592789196, "Mean Reward": 69.11053086653806, "Episode": 4309, "Episode Step": 840}
{"Training Time": 19.961371289690337, "Episode Reward": 15250.638137430857, "Mean Reward": 64.07831150181032, "Episode": 4310, "Episode Step": 238}
{"Training Time": 19.995552718639374, "Episode Reward": 179373.1329612272, "Mean Reward": 63.72047352086224, "Episode": 4311, "Episode Step": 2815}
{"Training Time": 19.99719554417663, "Episode Reward": 6881.717969199403, "Mean Reward": 49.8675215159377, "Episode": 4312, "Episode Step": 138}
{"Training Time": 20.034124457505015, "Episode Reward": 204250.6063109719, "Mean Reward": 65.44396229124379, "Episode": 4313, "Episode Step": 3121}
{"Training Time": 20.062923412190543, "Episode Reward": 151837.28715798556, "Mean Reward": 64.03934506874127, "Episode": 4314, "Episode Step": 2371}
{"Training Time": 20.06772957669364, "Episode Reward": 25196.06261248424, "Mean Reward": 61.90678774566152, "Episode": 4315, "Episode Step": 407}
{"Training Time": 20.082164994743135, "Episode Reward": 82011.72513576024, "Mean Reward": 66.62203504123497, "Episode": 4316, "Episode Step": 1231}
{"Training Time": 20.09716399219301, "Episode Reward": 81515.5432290796, "Mean Reward": 66.16521365996721, "Episode": 4317, "Episode Step": 1232}
{"Training Time": 20.098652616143227, "Episode Reward": 6192.4102562135295, "Mean Reward": 48.75913587569708, "Episode": 4318, "Episode Step": 127}
{"Training Time": 20.127057209478483, "Episode Reward": 162989.33219564258, "Mean Reward": 66.6895794581189, "Episode": 4319, "Episode Step": 2444}
{"Training Time": 20.13045341471831, "Episode Reward": 16104.212074372736, "Mean Reward": 63.65301215167089, "Episode": 4320, "Episode Step": 253}
{"Training Time": 20.131699718634287, "Episode Reward": 6048.234486590558, "Mean Reward": 57.058815911231676, "Episode": 4321, "Episode Step": 106}
{"Training Time": 20.138824590245882, "Episode Reward": 36424.37200854276, "Mean Reward": 59.614356806125635, "Episode": 4322, "Episode Step": 611}
{"Training Time": 20.15242672085762, "Episode Reward": 75210.18583269957, "Mean Reward": 66.85349851795517, "Episode": 4323, "Episode Step": 1125}
{"Training Time": 20.153661315838495, "Episode Reward": 5786.048705234126, "Mean Reward": 56.17523014790414, "Episode": 4324, "Episode Step": 103}
{"Training Time": 20.171951433089045, "Episode Reward": 99779.44326231832, "Mean Reward": 64.12560620971615, "Episode": 4325, "Episode Step": 1556}
{"Training Time": 20.181007178624473, "Episode Reward": 47792.78351519166, "Mean Reward": 65.73972973203804, "Episode": 4326, "Episode Step": 727}
{"Training Time": 20.19340742389361, "Episode Reward": 67189.44657207098, "Mean Reward": 63.32652834313948, "Episode": 4327, "Episode Step": 1061}
{"Training Time": 20.195500345826147, "Episode Reward": 8325.83533614119, "Mean Reward": 47.038617718311805, "Episode": 4328, "Episode Step": 177}
{"Training Time": 20.197994593580564, "Episode Reward": 8856.683492545333, "Mean Reward": 50.609619957401904, "Episode": 4329, "Episode Step": 175}
{"Training Time": 20.208005898859767, "Episode Reward": 56641.17769992281, "Mean Reward": 66.16960011673225, "Episode": 4330, "Episode Step": 856}
{"Training Time": 20.2332240263621, "Episode Reward": 136029.1028956531, "Mean Reward": 63.00560578770408, "Episode": 4331, "Episode Step": 2159}
{"Training Time": 20.252332490815057, "Episode Reward": 103848.59990363839, "Mean Reward": 64.98660820002402, "Episode": 4332, "Episode Step": 1598}
{"Training Time": 20.25801234556569, "Episode Reward": 33117.5732429587, "Mean Reward": 67.86387959622685, "Episode": 4333, "Episode Step": 488}
{"Training Time": 20.278907332221667, "Episode Reward": 118703.9090398144, "Mean Reward": 66.20407643045979, "Episode": 4334, "Episode Step": 1793}
{"Training Time": 20.287278397811782, "Episode Reward": 45388.28965676289, "Mean Reward": 66.64947086161952, "Episode": 4335, "Episode Step": 681}
{"Training Time": 20.309161339998244, "Episode Reward": 128576.10362876374, "Mean Reward": 68.24633950571324, "Episode": 4336, "Episode Step": 1884}
{"Training Time": 20.31040103197098, "Episode Reward": 5293.506475551743, "Mean Reward": 50.89910072645907, "Episode": 4337, "Episode Step": 104}
{"Training Time": 20.313653111656507, "Episode Reward": 13710.600982863592, "Mean Reward": 58.095766876540644, "Episode": 4338, "Episode Step": 236}
{"Training Time": 20.33731809947226, "Episode Reward": 138650.0811382998, "Mean Reward": 67.99905892020588, "Episode": 4339, "Episode Step": 2039}
{"Training Time": 20.341330211692387, "Episode Reward": 21265.28481969921, "Mean Reward": 61.63850672376582, "Episode": 4340, "Episode Step": 345}
{"Training Time": 20.343899412486287, "Episode Reward": 9096.073086950366, "Mean Reward": 51.10153419635037, "Episode": 4341, "Episode Step": 178}
{"Training Time": 20.347925262252488, "Episode Reward": 21564.459394342146, "Mean Reward": 62.50567940389028, "Episode": 4342, "Episode Step": 345}
{"Training Time": 20.349393962224326, "Episode Reward": 5366.754624891523, "Mean Reward": 43.28027923299616, "Episode": 4343, "Episode Step": 124}
{"Training Time": 20.36317233529356, "Episode Reward": 72143.45005007385, "Mean Reward": 63.45070365002098, "Episode": 4344, "Episode Step": 1137}
{"Training Time": 20.374786466956138, "Episode Reward": 66494.36761980885, "Mean Reward": 67.23394097048417, "Episode": 4345, "Episode Step": 989}
{"Training Time": 20.39309728331036, "Episode Reward": 99721.63561635913, "Mean Reward": 63.63856771943786, "Episode": 4346, "Episode Step": 1567}
{"Training Time": 20.40164654692014, "Episode Reward": 43647.77702273315, "Mean Reward": 62.893050465033355, "Episode": 4347, "Episode Step": 694}
{"Training Time": 20.40505232830842, "Episode Reward": 19423.181791474726, "Mean Reward": 66.97648893611975, "Episode": 4348, "Episode Step": 290}
{"Training Time": 20.429745424985885, "Episode Reward": 129176.75471924494, "Mean Reward": 63.6966246150123, "Episode": 4349, "Episode Step": 2028}
{"Training Time": 20.455797282192442, "Episode Reward": 138479.50972662357, "Mean Reward": 64.25963328381604, "Episode": 4350, "Episode Step": 2155}
{"Training Time": 20.461539352469973, "Episode Reward": 32447.789491210024, "Mean Reward": 67.31906533446063, "Episode": 4351, "Episode Step": 482}
{"Training Time": 20.46847366001871, "Episode Reward": 31926.13468667613, "Mean Reward": 55.04505980461402, "Episode": 4352, "Episode Step": 580}
{"Training Time": 20.480571440855663, "Episode Reward": 63707.391571597815, "Mean Reward": 64.48116555829738, "Episode": 4353, "Episode Step": 988}
{"Training Time": 20.498041305277084, "Episode Reward": 99118.35475010546, "Mean Reward": 66.70145003371834, "Episode": 4354, "Episode Step": 1486}
{"Training Time": 20.500185886687703, "Episode Reward": 7723.279654154657, "Mean Reward": 42.67005333787103, "Episode": 4355, "Episode Step": 181}
{"Training Time": 20.50594462249014, "Episode Reward": 27908.267249481767, "Mean Reward": 62.29523939616466, "Episode": 4356, "Episode Step": 448}
{"Training Time": 20.509397224452762, "Episode Reward": 19100.857984874674, "Mean Reward": 65.6386872332463, "Episode": 4357, "Episode Step": 291}
{"Training Time": 20.51338022583061, "Episode Reward": 19956.38123416828, "Mean Reward": 59.21774846934208, "Episode": 4358, "Episode Step": 337}
{"Training Time": 20.51533866054482, "Episode Reward": 6625.26822670625, "Mean Reward": 53.00214581365, "Episode": 4359, "Episode Step": 125}
{"Training Time": 20.51696573747529, "Episode Reward": 6094.3837320212215, "Mean Reward": 45.82243407534753, "Episode": 4360, "Episode Step": 133}
{"Training Time": 20.52182491030958, "Episode Reward": 23347.188187670858, "Mean Reward": 57.364098741206035, "Episode": 4361, "Episode Step": 407}
{"Training Time": 20.525293500290978, "Episode Reward": 15281.677666874652, "Mean Reward": 61.12671066749861, "Episode": 4362, "Episode Step": 250}
{"Training Time": 20.528236573868327, "Episode Reward": 16994.96816322359, "Mean Reward": 68.80553912236272, "Episode": 4363, "Episode Step": 247}
{"Training Time": 20.54510048833158, "Episode Reward": 89729.41416360725, "Mean Reward": 62.74784207245262, "Episode": 4364, "Episode Step": 1430}
{"Training Time": 20.547678334183164, "Episode Reward": 8940.567578841838, "Mean Reward": 50.227907746302456, "Episode": 4365, "Episode Step": 178}
{"Training Time": 20.55123730248875, "Episode Reward": 18817.83533538617, "Mean Reward": 62.10506711348572, "Episode": 4366, "Episode Step": 303}
{"Training Time": 20.556936393313936, "Episode Reward": 30244.35881787662, "Mean Reward": 62.231190983285224, "Episode": 4367, "Episode Step": 486}
{"Training Time": 20.55872652053833, "Episode Reward": 6098.013569858822, "Mean Reward": 55.945078622558, "Episode": 4368, "Episode Step": 109}
{"Training Time": 20.56453830752108, "Episode Reward": 30591.248890019917, "Mean Reward": 62.431120183714114, "Episode": 4369, "Episode Step": 490}
{"Training Time": 20.598989717496767, "Episode Reward": 187551.7337431563, "Mean Reward": 64.4286271876181, "Episode": 4370, "Episode Step": 2911}
{"Training Time": 20.600759724179905, "Episode Reward": 6302.467315118485, "Mean Reward": 58.90156369269612, "Episode": 4371, "Episode Step": 107}
{"Training Time": 20.609174199170536, "Episode Reward": 44543.93918865384, "Mean Reward": 63.63419884093406, "Episode": 4372, "Episode Step": 700}
{"Training Time": 20.620932456917235, "Episode Reward": 60193.93964970373, "Mean Reward": 61.297290885645346, "Episode": 4373, "Episode Step": 982}
{"Training Time": 20.626215971642072, "Episode Reward": 25108.20887280979, "Mean Reward": 62.458231026890026, "Episode": 4374, "Episode Step": 402}
{"Training Time": 20.639421931637656, "Episode Reward": 76108.97957637649, "Mean Reward": 68.56664826700585, "Episode": 4375, "Episode Step": 1110}
{"Training Time": 20.64763509280152, "Episode Reward": 44166.38394549941, "Mean Reward": 64.19532550217937, "Episode": 4376, "Episode Step": 688}
{"Training Time": 20.654527553584842, "Episode Reward": 35073.75987048025, "Mean Reward": 65.43611916134375, "Episode": 4377, "Episode Step": 536}
{"Training Time": 20.65730245669683, "Episode Reward": 12969.083287132571, "Mean Reward": 55.42343285099389, "Episode": 4378, "Episode Step": 234}
{"Training Time": 20.668990972770587, "Episode Reward": 60642.679467721326, "Mean Reward": 61.8172063891145, "Episode": 4379, "Episode Step": 981}
{"Training Time": 20.66973968611823, "Episode Reward": -103.83671284536182, "Mean Reward": -6.922447523024121, "Episode": 4380, "Episode Step": 15}
{"Training Time": 20.67177020251751, "Episode Reward": 8543.060374120043, "Mean Reward": 49.95941739251487, "Episode": 4381, "Episode Step": 171}
{"Training Time": 20.67386665225029, "Episode Reward": 8016.45479861603, "Mean Reward": 45.0362629135732, "Episode": 4382, "Episode Step": 178}
{"Training Time": 20.6755692444245, "Episode Reward": 5826.949735151828, "Mean Reward": 56.5723275257459, "Episode": 4383, "Episode Step": 103}
{"Training Time": 20.678557383351855, "Episode Reward": 15788.570788315556, "Mean Reward": 62.65305868379189, "Episode": 4384, "Episode Step": 252}
{"Training Time": 20.6815175522036, "Episode Reward": 15452.946503154535, "Mean Reward": 62.562536450018364, "Episode": 4385, "Episode Step": 247}
{"Training Time": 20.688294301364156, "Episode Reward": 33983.42597788095, "Mean Reward": 63.283847258623744, "Episode": 4386, "Episode Step": 537}
{"Training Time": 20.69400298555692, "Episode Reward": 32662.48330144684, "Mean Reward": 67.34532639473575, "Episode": 4387, "Episode Step": 485}
{"Training Time": 20.706456210282113, "Episode Reward": 65907.12775843477, "Mean Reward": 62.05944233374272, "Episode": 4388, "Episode Step": 1062}
{"Training Time": 20.7081806097428, "Episode Reward": 5803.905369874213, "Mean Reward": 54.75382424409635, "Episode": 4389, "Episode Step": 106}
{"Training Time": 20.712234995034006, "Episode Reward": 21097.021954203195, "Mean Reward": 61.68719869650057, "Episode": 4390, "Episode Step": 342}
{"Training Time": 20.723800238635803, "Episode Reward": 62506.46010431102, "Mean Reward": 64.24096619148101, "Episode": 4391, "Episode Step": 973}
{"Training Time": 20.725519962509473, "Episode Reward": 6209.410604532697, "Mean Reward": 58.57934532578016, "Episode": 4392, "Episode Step": 106}
{"Training Time": 20.7261340505547, "Episode Reward": 2325.534002152568, "Mean Reward": 45.59870592456016, "Episode": 4393, "Episode Step": 51}
{"Training Time": 20.727785583602056, "Episode Reward": 6120.110194372603, "Mean Reward": 44.67233718520148, "Episode": 4394, "Episode Step": 137}
{"Training Time": 20.729517114692264, "Episode Reward": 5932.324928626364, "Mean Reward": 57.04158585217658, "Episode": 4395, "Episode Step": 104}
{"Training Time": 20.73531372083558, "Episode Reward": 31789.324813606847, "Mean Reward": 66.50486362679257, "Episode": 4396, "Episode Step": 478}
{"Training Time": 20.73885388387574, "Episode Reward": 17863.332028972585, "Mean Reward": 60.145899087449784, "Episode": 4397, "Episode Step": 297}
{"Training Time": 20.74058312581645, "Episode Reward": 6005.662744870825, "Mean Reward": 56.65719570632854, "Episode": 4398, "Episode Step": 106}
{"Training Time": 20.74142593887117, "Episode Reward": 2678.023603186955, "Mean Reward": 54.65354292218275, "Episode": 4399, "Episode Step": 49}
{"Training Time": 20.74977793024646, "Episode Reward": 42267.94233622821, "Mean Reward": 62.89872371462531, "Episode": 4400, "Episode Step": 672}
{"Training Time": 20.756720276408725, "Episode Reward": 33566.2376034805, "Mean Reward": 61.81627551285543, "Episode": 4401, "Episode Step": 543}
{"Training Time": 20.757316292524337, "Episode Reward": 2796.4632724337507, "Mean Reward": 57.07067902926022, "Episode": 4402, "Episode Step": 49}
{"Training Time": 20.76747546222475, "Episode Reward": 52909.69732959671, "Mean Reward": 61.88268693520083, "Episode": 4403, "Episode Step": 855}
{"Training Time": 20.770097716649374, "Episode Reward": 9172.882092513039, "Mean Reward": 50.67890658846983, "Episode": 4404, "Episode Step": 181}
{"Training Time": 20.773007362484933, "Episode Reward": 16425.45594262335, "Mean Reward": 66.23167718799738, "Episode": 4405, "Episode Step": 248}
{"Training Time": 20.77425318472915, "Episode Reward": 4839.185047075763, "Mean Reward": 45.652689123356254, "Episode": 4406, "Episode Step": 106}
{"Training Time": 20.775979988641208, "Episode Reward": 5875.783351688423, "Mean Reward": 54.913863099891806, "Episode": 4407, "Episode Step": 107}
{"Training Time": 20.776556730535294, "Episode Reward": 2129.8419757521715, "Mean Reward": 44.37170782817024, "Episode": 4408, "Episode Step": 48}
{"Training Time": 20.794358179436788, "Episode Reward": 91857.82254130134, "Mean Reward": 60.47256256833531, "Episode": 4409, "Episode Step": 1519}
{"Training Time": 20.796040094163683, "Episode Reward": 5623.084796562382, "Mean Reward": 54.593056277304676, "Episode": 4410, "Episode Step": 103}
{"Training Time": 20.79665312197473, "Episode Reward": 2177.3084922953353, "Mean Reward": 42.69232337833991, "Episode": 4411, "Episode Step": 51}
{"Training Time": 20.799581142200363, "Episode Reward": 16074.753609371355, "Mean Reward": 65.07997412700954, "Episode": 4412, "Episode Step": 247}
{"Training Time": 20.801311374704042, "Episode Reward": 5963.024565007267, "Mean Reward": 56.79071014292635, "Episode": 4413, "Episode Step": 105}
{"Training Time": 20.80262234389782, "Episode Reward": 5413.8110530474805, "Mean Reward": 49.667991312362204, "Episode": 4414, "Episode Step": 109}
{"Training Time": 20.810704122781754, "Episode Reward": 43640.17964007643, "Mean Reward": 63.894845739496965, "Episode": 4415, "Episode Step": 683}
{"Training Time": 20.813223285807503, "Episode Reward": 8445.314576742476, "Mean Reward": 48.258940438528434, "Episode": 4416, "Episode Step": 175}
{"Training Time": 20.814204503032897, "Episode Reward": 4692.663849848716, "Mean Reward": 56.5381186728761, "Episode": 4417, "Episode Step": 83}
{"Training Time": 20.816281528870263, "Episode Reward": 7831.440146260505, "Mean Reward": 44.49681901284378, "Episode": 4418, "Episode Step": 176}
{"Training Time": 20.81802259027958, "Episode Reward": 5331.744726691919, "Mean Reward": 50.29947855369735, "Episode": 4419, "Episode Step": 106}
{"Training Time": 20.819612231916853, "Episode Reward": 6284.754645156014, "Mean Reward": 46.55373811226677, "Episode": 4420, "Episode Step": 135}
{"Training Time": 20.822534280816715, "Episode Reward": 15526.998773183936, "Mean Reward": 62.862343211270996, "Episode": 4421, "Episode Step": 247}
{"Training Time": 20.8251300580634, "Episode Reward": 8454.16214333185, "Mean Reward": 47.229956107999165, "Episode": 4422, "Episode Step": 179}
{"Training Time": 20.831181598040793, "Episode Reward": 34403.16047512108, "Mean Reward": 67.06269098464149, "Episode": 4423, "Episode Step": 513}
{"Training Time": 20.83396848804421, "Episode Reward": 14350.445870366328, "Mean Reward": 61.06572710794182, "Episode": 4424, "Episode Step": 235}
{"Training Time": 20.83655262609323, "Episode Reward": 9033.498922986608, "Mean Reward": 49.90883382865529, "Episode": 4425, "Episode Step": 181}
{"Training Time": 20.83784871776899, "Episode Reward": 5420.353021789085, "Mean Reward": 50.18845390545449, "Episode": 4426, "Episode Step": 108}
{"Training Time": 20.840668551656936, "Episode Reward": 13997.544747417769, "Mean Reward": 59.06137024226907, "Episode": 4427, "Episode Step": 237}
{"Training Time": 20.844047206375333, "Episode Reward": 16074.610007532887, "Mean Reward": 64.29844003013154, "Episode": 4428, "Episode Step": 250}
{"Training Time": 20.84688993387752, "Episode Reward": 16210.852861030644, "Mean Reward": 66.71132864621664, "Episode": 4429, "Episode Step": 243}
{"Training Time": 20.85171454416381, "Episode Reward": 22921.441960065968, "Mean Reward": 55.63456786423779, "Episode": 4430, "Episode Step": 412}
{"Training Time": 20.85507289111614, "Episode Reward": 16365.918390036288, "Mean Reward": 66.25877890702951, "Episode": 4431, "Episode Step": 247}
{"Training Time": 20.85663048108419, "Episode Reward": 6656.52812796208, "Mean Reward": 50.81319181650443, "Episode": 4432, "Episode Step": 131}
{"Training Time": 20.866073633035025, "Episode Reward": 48708.37487871182, "Mean Reward": 60.28264217662353, "Episode": 4433, "Episode Step": 808}
{"Training Time": 20.873031205866074, "Episode Reward": 35410.613149222794, "Mean Reward": 63.57381175803015, "Episode": 4434, "Episode Step": 557}
{"Training Time": 20.87430272248056, "Episode Reward": 5158.380553089319, "Mean Reward": 48.6639674819747, "Episode": 4435, "Episode Step": 106}
{"Training Time": 20.87847853389051, "Episode Reward": 20949.355234613773, "Mean Reward": 59.01226826651767, "Episode": 4436, "Episode Step": 355}
{"Training Time": 20.8801564633184, "Episode Reward": 5833.796233749693, "Mean Reward": 56.09419455528551, "Episode": 4437, "Episode Step": 104}
{"Training Time": 20.884747681948873, "Episode Reward": 26270.824038753603, "Mean Reward": 66.67721837247107, "Episode": 4438, "Episode Step": 394}
{"Training Time": 20.88760208553738, "Episode Reward": 15393.05220261432, "Mean Reward": 62.82878450046662, "Episode": 4439, "Episode Step": 245}
{"Training Time": 20.89015563276079, "Episode Reward": 8709.38489560096, "Mean Reward": 49.767913689148344, "Episode": 4440, "Episode Step": 175}
{"Training Time": 20.892189479470254, "Episode Reward": 8520.611191854912, "Mean Reward": 50.417817703283504, "Episode": 4441, "Episode Step": 169}
{"Training Time": 20.895151738590663, "Episode Reward": 15812.900143943645, "Mean Reward": 64.01983863944795, "Episode": 4442, "Episode Step": 247}
{"Training Time": 20.897700623604987, "Episode Reward": 8630.36517141372, "Mean Reward": 48.7591252622244, "Episode": 4443, "Episode Step": 177}
{"Training Time": 20.89938686834441, "Episode Reward": 6370.471604565267, "Mean Reward": 46.162837714241064, "Episode": 4444, "Episode Step": 138}
{"Training Time": 20.901074733866587, "Episode Reward": 5643.541036296004, "Mean Reward": 40.02511373259577, "Episode": 4445, "Episode Step": 141}
{"Training Time": 20.9028103322453, "Episode Reward": 5528.35832771416, "Mean Reward": 51.66690025901084, "Episode": 4446, "Episode Step": 107}
{"Training Time": 20.905761960811084, "Episode Reward": 16752.791948577837, "Mean Reward": 66.21656896671081, "Episode": 4447, "Episode Step": 253}
{"Training Time": 20.939923841092323, "Episode Reward": 173474.69987808054, "Mean Reward": 59.32787273532166, "Episode": 4448, "Episode Step": 2924}
{"Training Time": 20.942750614417925, "Episode Reward": 5803.503585031684, "Mean Reward": 54.23835126197836, "Episode": 4449, "Episode Step": 107}
{"Training Time": 20.943689172532824, "Episode Reward": 2241.2388313335946, "Mean Reward": 42.28752511950179, "Episode": 4450, "Episode Step": 53}
{"Training Time": 20.94736532085472, "Episode Reward": 17612.113777858565, "Mean Reward": 57.934584795587384, "Episode": 4451, "Episode Step": 304}
{"Training Time": 20.949120189415083, "Episode Reward": 6144.301378820029, "Mean Reward": 58.51715598876218, "Episode": 4452, "Episode Step": 105}
{"Training Time": 20.95114567524857, "Episode Reward": 7948.192152191011, "Mean Reward": 46.75407148347654, "Episode": 4453, "Episode Step": 170}
{"Training Time": 20.959326481951607, "Episode Reward": 43355.507360201744, "Mean Reward": 63.01672581424672, "Episode": 4454, "Episode Step": 688}
{"Training Time": 20.96265432635943, "Episode Reward": 14141.198132090934, "Mean Reward": 59.16819302130098, "Episode": 4455, "Episode Step": 239}
{"Training Time": 20.96392759303252, "Episode Reward": 5394.281728442675, "Mean Reward": 51.37411169945405, "Episode": 4456, "Episode Step": 105}
{"Training Time": 20.968027969731224, "Episode Reward": 20654.205635734244, "Mean Reward": 59.522206443038165, "Episode": 4457, "Episode Step": 347}
{"Training Time": 20.96972370862961, "Episode Reward": 5769.632178684734, "Mean Reward": 54.94887789223556, "Episode": 4458, "Episode Step": 105}
{"Training Time": 20.971350040833155, "Episode Reward": 6667.759577197009, "Mean Reward": 49.39081168294081, "Episode": 4459, "Episode Step": 135}
{"Training Time": 20.976403618057567, "Episode Reward": 23160.68690796446, "Mean Reward": 54.883144331669335, "Episode": 4460, "Episode Step": 422}
{"Training Time": 20.97815032164256, "Episode Reward": 6162.003722127917, "Mean Reward": 57.05559001970294, "Episode": 4461, "Episode Step": 108}
{"Training Time": 20.98104143195682, "Episode Reward": 16084.814665902493, "Mean Reward": 66.74196956806014, "Episode": 4462, "Episode Step": 241}
{"Training Time": 20.984011446966065, "Episode Reward": 14990.617272430623, "Mean Reward": 60.20328221859688, "Episode": 4463, "Episode Step": 249}
{"Training Time": 20.985716588629618, "Episode Reward": 6478.339852695308, "Mean Reward": 62.291729352839496, "Episode": 4464, "Episode Step": 104}
{"Training Time": 20.988646301693386, "Episode Reward": 16359.725629822184, "Mean Reward": 65.9666356041217, "Episode": 4465, "Episode Step": 248}
{"Training Time": 20.991641607483228, "Episode Reward": 15271.817168875155, "Mean Reward": 60.362913710968996, "Episode": 4466, "Episode Step": 253}
{"Training Time": 20.999516905546187, "Episode Reward": 38314.462641022066, "Mean Reward": 60.816607366701696, "Episode": 4467, "Episode Step": 630}
{"Training Time": 21.000794975823826, "Episode Reward": 5224.044108211668, "Mean Reward": 49.28343498312894, "Episode": 4468, "Episode Step": 106}
{"Training Time": 21.00359868387381, "Episode Reward": 13683.501605188889, "Mean Reward": 57.98093900503766, "Episode": 4469, "Episode Step": 236}
{"Training Time": 21.006091893050407, "Episode Reward": 8759.520406852527, "Mean Reward": 51.22526553714928, "Episode": 4470, "Episode Step": 171}
{"Training Time": 21.00814460443126, "Episode Reward": 8519.87881360252, "Mean Reward": 49.534179148851855, "Episode": 4471, "Episode Step": 172}
{"Training Time": 21.01097760114405, "Episode Reward": 12968.669406271867, "Mean Reward": 54.720124077096486, "Episode": 4472, "Episode Step": 237}
{"Training Time": 21.012750675280888, "Episode Reward": 5616.051066701802, "Mean Reward": 51.52340428166791, "Episode": 4473, "Episode Step": 109}
{"Training Time": 21.015678429139985, "Episode Reward": 16290.703139237048, "Mean Reward": 66.76517680015183, "Episode": 4474, "Episode Step": 244}
{"Training Time": 21.020829748908678, "Episode Reward": 23980.872223934708, "Mean Reward": 55.38307672964136, "Episode": 4475, "Episode Step": 433}
{"Training Time": 21.02358262280623, "Episode Reward": 9011.848036552854, "Mean Reward": 47.43077913975186, "Episode": 4476, "Episode Step": 190}
{"Training Time": 21.02999215722084, "Episode Reward": 33434.527123042026, "Mean Reward": 62.72894394566984, "Episode": 4477, "Episode Step": 533}
{"Training Time": 21.03298470053408, "Episode Reward": 14265.470644954605, "Mean Reward": 56.83454440220958, "Episode": 4478, "Episode Step": 251}
{"Training Time": 21.040827945801947, "Episode Reward": 37298.69065468712, "Mean Reward": 60.1591784753018, "Episode": 4479, "Episode Step": 620}
{"Training Time": 21.043788508905305, "Episode Reward": 16519.75807931509, "Mean Reward": 66.61192773917374, "Episode": 4480, "Episode Step": 248}
{"Training Time": 21.057248831921154, "Episode Reward": 69699.06086711466, "Mean Reward": 61.30084508981061, "Episode": 4481, "Episode Step": 1137}
{"Training Time": 21.058998211953377, "Episode Reward": 5673.765544259786, "Mean Reward": 53.52609004018666, "Episode": 4482, "Episode Step": 106}
{"Training Time": 21.06025525861316, "Episode Reward": 5797.836114721029, "Mean Reward": 54.6965671200097, "Episode": 4483, "Episode Step": 106}
{"Training Time": 21.084063167240885, "Episode Reward": 124839.81626062033, "Mean Reward": 62.140276884330675, "Episode": 4484, "Episode Step": 2009}
{"Training Time": 21.085779734187657, "Episode Reward": 5896.738942948955, "Mean Reward": 55.62961266932977, "Episode": 4485, "Episode Step": 106}
{"Training Time": 21.091771181358233, "Episode Reward": 33638.30293014526, "Mean Reward": 66.34773753480327, "Episode": 4486, "Episode Step": 507}
{"Training Time": 21.09991018778748, "Episode Reward": 43707.387670109994, "Mean Reward": 62.97894476961094, "Episode": 4487, "Episode Step": 694}
{"Training Time": 21.106779958605767, "Episode Reward": 32884.66071314336, "Mean Reward": 59.46593257349613, "Episode": 4488, "Episode Step": 553}
{"Training Time": 21.108088645007875, "Episode Reward": 5406.779228537386, "Mean Reward": 48.709722779616094, "Episode": 4489, "Episode Step": 111}
{"Training Time": 21.136527320543927, "Episode Reward": 156179.6349284027, "Mean Reward": 64.03429066355174, "Episode": 4490, "Episode Step": 2439}
{"Training Time": 21.138275050255988, "Episode Reward": 5232.109448239637, "Mean Reward": 48.001004112290246, "Episode": 4491, "Episode Step": 109}
{"Training Time": 21.139811633030572, "Episode Reward": 6173.181766033226, "Mean Reward": 47.123524931551344, "Episode": 4492, "Episode Step": 131}
{"Training Time": 21.14807449221611, "Episode Reward": 42443.16814111199, "Mean Reward": 60.719839972978534, "Episode": 4493, "Episode Step": 699}
{"Training Time": 21.155173386136692, "Episode Reward": 35396.94500496864, "Mean Reward": 62.98388790919687, "Episode": 4494, "Episode Step": 562}
{"Training Time": 21.15679270029068, "Episode Reward": 5912.725485729788, "Mean Reward": 43.15858018780867, "Episode": 4495, "Episode Step": 137}
{"Training Time": 21.191297503643565, "Episode Reward": 184688.61594912596, "Mean Reward": 62.41588913454747, "Episode": 4496, "Episode Step": 2959}
{"Training Time": 21.2043604947461, "Episode Reward": 67748.68742358674, "Mean Reward": 62.846648815943176, "Episode": 4497, "Episode Step": 1078}
{"Training Time": 21.205979005032116, "Episode Reward": 5696.985667686558, "Mean Reward": 41.583836990412834, "Episode": 4498, "Episode Step": 137}
{"Training Time": 21.216030803587703, "Episode Reward": 43548.03922997742, "Mean Reward": 57.45123908967997, "Episode": 4499, "Episode Step": 758}
{"Training Time": 21.240538266102472, "Episode Reward": 129955.56948869435, "Mean Reward": 64.20729717820868, "Episode": 4500, "Episode Step": 2024}
{"Training Time": 21.246562082767486, "Episode Reward": 33723.57165613649, "Mean Reward": 65.99524785936691, "Episode": 4501, "Episode Step": 511}
{"Training Time": 21.276413679983882, "Episode Reward": 149076.27148429755, "Mean Reward": 58.78401872409209, "Episode": 4502, "Episode Step": 2536}
{"Training Time": 21.284252045287026, "Episode Reward": 39126.670468721495, "Mean Reward": 63.41437677264424, "Episode": 4503, "Episode Step": 617}
{"Training Time": 21.28549554804961, "Episode Reward": 5176.504250914957, "Mean Reward": 50.25732282441706, "Episode": 4504, "Episode Step": 103}
{"Training Time": 21.288586571680174, "Episode Reward": 14890.359800946273, "Mean Reward": 58.85517707883903, "Episode": 4505, "Episode Step": 253}
{"Training Time": 21.291478247245152, "Episode Reward": 9447.02021854503, "Mean Reward": 47.23510109272515, "Episode": 4506, "Episode Step": 200}
{"Training Time": 21.292746954692735, "Episode Reward": 5117.124921862976, "Mean Reward": 49.680824484106566, "Episode": 4507, "Episode Step": 103}
{"Training Time": 21.29570534553793, "Episode Reward": 14799.64182103293, "Mean Reward": 60.903875806719874, "Episode": 4508, "Episode Step": 243}
{"Training Time": 21.30443992945883, "Episode Reward": 42483.815011946484, "Mean Reward": 62.29298388848458, "Episode": 4509, "Episode Step": 682}
{"Training Time": 21.315251592199008, "Episode Reward": 60965.38952707423, "Mean Reward": 67.51427411636128, "Episode": 4510, "Episode Step": 903}
{"Training Time": 21.327241401672364, "Episode Reward": 61414.621857750244, "Mean Reward": 61.41462185775024, "Episode": 4511, "Episode Step": 1000}
{"Training Time": 21.330623170865906, "Episode Reward": 14039.587018880626, "Mean Reward": 57.77607826699846, "Episode": 4512, "Episode Step": 243}
{"Training Time": 21.331887390282418, "Episode Reward": 5373.478856601466, "Mean Reward": 51.17598911049015, "Episode": 4513, "Episode Step": 105}
{"Training Time": 21.345373039709198, "Episode Reward": 66518.03954585137, "Mean Reward": 58.86552172199236, "Episode": 4514, "Episode Step": 1130}
{"Training Time": 21.35591689719094, "Episode Reward": 54947.58562786018, "Mean Reward": 64.72035998570104, "Episode": 4515, "Episode Step": 849}
{"Training Time": 21.358788914746707, "Episode Reward": 15475.552412220515, "Mean Reward": 63.68540087333545, "Episode": 4516, "Episode Step": 243}
{"Training Time": 21.40167908642027, "Episode Reward": 210822.0226948503, "Mean Reward": 58.52915677258476, "Episode": 4517, "Episode Step": 3602}
{"Training Time": 21.430366741418837, "Episode Reward": 148471.72218110683, "Mean Reward": 62.17408801553887, "Episode": 4518, "Episode Step": 2388}
{"Training Time": 21.43244103776084, "Episode Reward": 9065.428122837866, "Mean Reward": 52.100161625504974, "Episode": 4519, "Episode Step": 174}
{"Training Time": 21.47253993054231, "Episode Reward": 204072.35612629424, "Mean Reward": 59.13426720553296, "Episode": 4520, "Episode Step": 3451}
{"Training Time": 21.480792515012954, "Episode Reward": 42548.73166008598, "Mean Reward": 64.07941515073189, "Episode": 4521, "Episode Step": 664}
{"Training Time": 21.492341096401216, "Episode Reward": 65846.90863626896, "Mean Reward": 67.5352909089938, "Episode": 4522, "Episode Step": 975}
{"Training Time": 21.521804753343265, "Episode Reward": 158303.04061729801, "Mean Reward": 63.601060914944966, "Episode": 4523, "Episode Step": 2489}
{"Training Time": 21.538491785526276, "Episode Reward": 86291.64752968802, "Mean Reward": 63.63690820773453, "Episode": 4524, "Episode Step": 1356}
{"Training Time": 21.541350052489175, "Episode Reward": 16246.13074849563, "Mean Reward": 67.69221145206512, "Episode": 4525, "Episode Step": 240}
{"Training Time": 21.550673050814204, "Episode Reward": 49082.581770718054, "Mean Reward": 63.16934590826004, "Episode": 4526, "Episode Step": 777}
{"Training Time": 21.55953279780017, "Episode Reward": 44380.20973592986, "Mean Reward": 62.59550033276425, "Episode": 4527, "Episode Step": 709}
{"Training Time": 21.565999167230395, "Episode Reward": 35825.81082154604, "Mean Reward": 65.49508376882274, "Episode": 4528, "Episode Step": 547}
{"Training Time": 21.569060844977695, "Episode Reward": 15698.542170271456, "Mean Reward": 60.612131931550024, "Episode": 4529, "Episode Step": 259}
{"Training Time": 21.576969573365318, "Episode Reward": 36172.62271140125, "Mean Reward": 58.061994721350324, "Episode": 4530, "Episode Step": 623}
{"Training Time": 21.58167815360758, "Episode Reward": 25119.374607854006, "Mean Reward": 64.0800372649337, "Episode": 4531, "Episode Step": 392}
{"Training Time": 21.584780503908792, "Episode Reward": 16297.029816303631, "Mean Reward": 62.922895043643365, "Episode": 4532, "Episode Step": 259}
{"Training Time": 21.609756619466676, "Episode Reward": 132945.94460575914, "Mean Reward": 64.1321488691554, "Episode": 4533, "Episode Step": 2073}
{"Training Time": 21.61121111002233, "Episode Reward": 6288.814113120368, "Mean Reward": 51.54765666492105, "Episode": 4534, "Episode Step": 122}
{"Training Time": 21.614273933900726, "Episode Reward": 16099.689785053812, "Mean Reward": 62.16096442105719, "Episode": 4535, "Episode Step": 259}
{"Training Time": 21.628324091699387, "Episode Reward": 73050.31118451722, "Mean Reward": 64.07922033729581, "Episode": 4536, "Episode Step": 1140}
{"Training Time": 21.6296445100175, "Episode Reward": 5863.619361713446, "Mean Reward": 53.794673043242625, "Episode": 4537, "Episode Step": 109}
{"Training Time": 21.63270609219869, "Episode Reward": 16344.656138721617, "Mean Reward": 63.35138038264193, "Episode": 4538, "Episode Step": 258}
{"Training Time": 21.640489510562684, "Episode Reward": 35658.438545881385, "Mean Reward": 57.60652430675506, "Episode": 4539, "Episode Step": 619}
{"Training Time": 21.651747338043318, "Episode Reward": 62251.10902800599, "Mean Reward": 65.59653216860484, "Episode": 4540, "Episode Step": 949}
{"Training Time": 21.660260024468105, "Episode Reward": 44942.97211809785, "Mean Reward": 62.85730366167532, "Episode": 4541, "Episode Step": 715}
{"Training Time": 21.68478986998399, "Episode Reward": 129995.23154716333, "Mean Reward": 63.62957980771578, "Episode": 4542, "Episode Step": 2043}
{"Training Time": 21.687776161697176, "Episode Reward": 16732.62836369393, "Mean Reward": 66.13687100274281, "Episode": 4543, "Episode Step": 253}
{"Training Time": 21.706396157476636, "Episode Reward": 100503.42024289488, "Mean Reward": 63.4892105135154, "Episode": 4544, "Episode Step": 1583}
{"Training Time": 21.722279876934156, "Episode Reward": 80963.14844424934, "Mean Reward": 62.3272890255961, "Episode": 4545, "Episode Step": 1299}
{"Training Time": 21.7251976802614, "Episode Reward": 15669.230685584647, "Mean Reward": 63.95604361463121, "Episode": 4546, "Episode Step": 245}
{"Training Time": 21.73144786000252, "Episode Reward": 32706.115077169183, "Mean Reward": 62.17892600222278, "Episode": 4547, "Episode Step": 526}
{"Training Time": 21.733420270548926, "Episode Reward": 4831.824525262933, "Mean Reward": 38.34781369256296, "Episode": 4548, "Episode Step": 126}
{"Training Time": 21.741789745026164, "Episode Reward": 37045.5022271654, "Mean Reward": 60.53186638425719, "Episode": 4549, "Episode Step": 612}
{"Training Time": 21.745143777794308, "Episode Reward": 15555.020496714696, "Mean Reward": 61.726271812359904, "Episode": 4550, "Episode Step": 252}
{"Training Time": 21.748590732746653, "Episode Reward": 15697.43461541914, "Mean Reward": 62.045196108376054, "Episode": 4551, "Episode Step": 253}
{"Training Time": 21.751431680586602, "Episode Reward": 14486.858650273853, "Mean Reward": 61.64620702244193, "Episode": 4552, "Episode Step": 235}
{"Training Time": 21.78352433330483, "Episode Reward": 176936.6846234563, "Mean Reward": 65.80018022441662, "Episode": 4553, "Episode Step": 2689}
{"Training Time": 21.792423310014936, "Episode Reward": 45223.219758521205, "Mean Reward": 64.78971312109056, "Episode": 4554, "Episode Step": 698}
{"Training Time": 21.794659073087903, "Episode Reward": 8911.251555908633, "Mean Reward": 48.168927329235856, "Episode": 4555, "Episode Step": 185}
{"Training Time": 21.813517971105046, "Episode Reward": 105818.46275451982, "Mean Reward": 67.22901064454881, "Episode": 4556, "Episode Step": 1574}
{"Training Time": 21.83181329747041, "Episode Reward": 88122.96926499458, "Mean Reward": 59.42209660485137, "Episode": 4557, "Episode Step": 1483}
{"Training Time": 21.839861089189846, "Episode Reward": 45531.02979922075, "Mean Reward": 67.75450862979278, "Episode": 4558, "Episode Step": 672}
{"Training Time": 21.841684768332374, "Episode Reward": 6797.93828330603, "Mean Reward": 44.723278179644936, "Episode": 4559, "Episode Step": 152}
{"Training Time": 21.849057379166286, "Episode Reward": 35953.15676595945, "Mean Reward": 62.636161613169776, "Episode": 4560, "Episode Step": 574}
{"Training Time": 21.852034188045394, "Episode Reward": 16203.700810575954, "Mean Reward": 65.602027573182, "Episode": 4561, "Episode Step": 247}
{"Training Time": 21.85358523554272, "Episode Reward": 6379.691286286951, "Mean Reward": 49.07454835605347, "Episode": 4562, "Episode Step": 130}
{"Training Time": 21.87214947362741, "Episode Reward": 92160.52191104753, "Mean Reward": 60.751827232068244, "Episode": 4563, "Episode Step": 1517}
{"Training Time": 21.878247736957338, "Episode Reward": 31816.232183574954, "Mean Reward": 61.89928440384232, "Episode": 4564, "Episode Step": 514}
{"Training Time": 21.88121068947845, "Episode Reward": 15888.715952710569, "Mean Reward": 63.810104227753285, "Episode": 4565, "Episode Step": 249}
{"Training Time": 21.88760395858023, "Episode Reward": 31807.826220587613, "Mean Reward": 65.04667938770473, "Episode": 4566, "Episode Step": 489}
{"Training Time": 21.893323037756815, "Episode Reward": 29972.537847959786, "Mean Reward": 62.31296849887689, "Episode": 4567, "Episode Step": 481}
{"Training Time": 21.901796948313713, "Episode Reward": 45702.42208309325, "Mean Reward": 64.82613061431667, "Episode": 4568, "Episode Step": 705}
{"Training Time": 21.92190023581187, "Episode Reward": 106244.52003898557, "Mean Reward": 64.9416381656391, "Episode": 4569, "Episode Step": 1636}
{"Training Time": 21.923959624701077, "Episode Reward": 8078.370816686859, "Mean Reward": 46.96727219003988, "Episode": 4570, "Episode Step": 172}
{"Training Time": 21.93766011973222, "Episode Reward": 73680.62234495855, "Mean Reward": 63.95887356333208, "Episode": 4571, "Episode Step": 1152}
{"Training Time": 21.957087403337162, "Episode Reward": 104789.36425242653, "Mean Reward": 66.07147809106338, "Episode": 4572, "Episode Step": 1586}
{"Training Time": 21.96270360191663, "Episode Reward": 31646.549508563043, "Mean Reward": 66.76487238093469, "Episode": 4573, "Episode Step": 474}
{"Training Time": 21.967780039178, "Episode Reward": 25585.038933244672, "Mean Reward": 60.05877683860252, "Episode": 4574, "Episode Step": 426}
{"Training Time": 21.996899966398875, "Episode Reward": 153944.9911257164, "Mean Reward": 63.43015703572987, "Episode": 4575, "Episode Step": 2427}
{"Training Time": 21.999863372511335, "Episode Reward": 15229.621533402136, "Mean Reward": 61.16313868836199, "Episode": 4576, "Episode Step": 249}
{"Training Time": 22.002853356136217, "Episode Reward": 16650.297551676846, "Mean Reward": 65.55235256565688, "Episode": 4577, "Episode Step": 254}
{"Training Time": 22.00545005414221, "Episode Reward": 8638.966980864601, "Mean Reward": 48.53352236440787, "Episode": 4578, "Episode Step": 178}
{"Training Time": 22.01020487639639, "Episode Reward": 24319.992353465936, "Mean Reward": 60.95236178813518, "Episode": 4579, "Episode Step": 399}
{"Training Time": 22.011581909457842, "Episode Reward": 4971.959708758018, "Mean Reward": 43.61368165577208, "Episode": 4580, "Episode Step": 114}
{"Training Time": 22.017811445858744, "Episode Reward": 30811.483387247183, "Mean Reward": 63.13828562960488, "Episode": 4581, "Episode Step": 488}
{"Training Time": 22.023728333049352, "Episode Reward": 34939.11662836243, "Mean Reward": 69.7387557452344, "Episode": 4582, "Episode Step": 501}
{"Training Time": 22.031945838861994, "Episode Reward": 45808.79440583269, "Mean Reward": 65.91193439688156, "Episode": 4583, "Episode Step": 695}
{"Training Time": 22.032979655861855, "Episode Reward": 2924.5292673721656, "Mean Reward": 60.92769307025345, "Episode": 4584, "Episode Step": 48}
{"Training Time": 22.03636852721373, "Episode Reward": 19523.67496511373, "Mean Reward": 68.26459778011794, "Episode": 4585, "Episode Step": 286}
{"Training Time": 22.04259464085102, "Episode Reward": 33227.344749197604, "Mean Reward": 63.04999003642809, "Episode": 4586, "Episode Step": 527}
{"Training Time": 22.053286481367216, "Episode Reward": 53366.923975038764, "Mean Reward": 62.34453735401725, "Episode": 4587, "Episode Step": 856}
{"Training Time": 22.055431938634978, "Episode Reward": 9002.081767071782, "Mean Reward": 50.29095959257979, "Episode": 4588, "Episode Step": 179}
{"Training Time": 22.057682926919725, "Episode Reward": 8263.590886889187, "Mean Reward": 44.1903255983379, "Episode": 4589, "Episode Step": 187}
{"Training Time": 22.060273140536413, "Episode Reward": 8557.886125151123, "Mean Reward": 48.07801193905125, "Episode": 4590, "Episode Step": 178}
{"Training Time": 22.063670613302126, "Episode Reward": 19170.266270587657, "Mean Reward": 67.73945678652882, "Episode": 4591, "Episode Step": 283}
{"Training Time": 22.06626572860612, "Episode Reward": 9141.080362172539, "Mean Reward": 42.915870244941495, "Episode": 4592, "Episode Step": 213}
{"Training Time": 22.074130567775832, "Episode Reward": 38208.54279296097, "Mean Reward": 61.6266819241306, "Episode": 4593, "Episode Step": 620}
{"Training Time": 22.08056776192453, "Episode Reward": 36082.40846678327, "Mean Reward": 66.69576426392472, "Episode": 4594, "Episode Step": 541}
{"Training Time": 22.082145498593647, "Episode Reward": 6136.408165015922, "Mean Reward": 46.138407255758814, "Episode": 4595, "Episode Step": 133}
{"Training Time": 22.08471576081382, "Episode Reward": 9122.413777514124, "Mean Reward": 51.24951560401193, "Episode": 4596, "Episode Step": 178}
{"Training Time": 22.08594760947757, "Episode Reward": 5859.441747192634, "Mean Reward": 56.88778395332654, "Episode": 4597, "Episode Step": 103}
{"Training Time": 22.093917573359278, "Episode Reward": 36811.93499087487, "Mean Reward": 55.02531388770534, "Episode": 4598, "Episode Step": 669}
{"Training Time": 22.102899809148578, "Episode Reward": 37508.72927575303, "Mean Reward": 60.30342327291484, "Episode": 4599, "Episode Step": 622}
{"Training Time": 22.109255304733914, "Episode Reward": 33817.65308680428, "Mean Reward": 66.57018324174071, "Episode": 4600, "Episode Step": 508}
{"Training Time": 22.112201999690797, "Episode Reward": 13381.947431402341, "Mean Reward": 54.17792482349126, "Episode": 4601, "Episode Step": 247}
{"Training Time": 22.12019896891382, "Episode Reward": 38327.515746080964, "Mean Reward": 61.03107602879135, "Episode": 4602, "Episode Step": 628}
{"Training Time": 22.124375153316393, "Episode Reward": 21181.317865113793, "Mean Reward": 61.04126185911756, "Episode": 4603, "Episode Step": 347}
{"Training Time": 22.125989116364057, "Episode Reward": 5909.177128509933, "Mean Reward": 44.76649339780252, "Episode": 4604, "Episode Step": 132}
{"Training Time": 22.137193280524677, "Episode Reward": 56880.438041642876, "Mean Reward": 62.78194044331443, "Episode": 4605, "Episode Step": 906}
{"Training Time": 22.140579862793288, "Episode Reward": 19476.924146764442, "Mean Reward": 68.34008472548928, "Episode": 4606, "Episode Step": 285}
{"Training Time": 22.147101180553435, "Episode Reward": 32861.832113078475, "Mean Reward": 60.85524465384903, "Episode": 4607, "Episode Step": 540}
{"Training Time": 22.1496228888962, "Episode Reward": 9127.29089258916, "Mean Reward": 53.065644724355586, "Episode": 4608, "Episode Step": 172}
{"Training Time": 22.15171912252903, "Episode Reward": 8507.135460200483, "Mean Reward": 48.612202629717046, "Episode": 4609, "Episode Step": 175}
{"Training Time": 22.153364682528707, "Episode Reward": 5871.745124977243, "Mean Reward": 43.818993469979425, "Episode": 4610, "Episode Step": 134}
{"Training Time": 22.156834996143978, "Episode Reward": 15563.910237380887, "Mean Reward": 62.505663603939304, "Episode": 4611, "Episode Step": 249}
{"Training Time": 22.162163317799568, "Episode Reward": 28325.876168066305, "Mean Reward": 64.52363591814648, "Episode": 4612, "Episode Step": 439}
{"Training Time": 22.16440180414253, "Episode Reward": 7881.435246832566, "Mean Reward": 42.60235268558144, "Episode": 4613, "Episode Step": 185}
{"Training Time": 22.16758117887709, "Episode Reward": 12776.631631065042, "Mean Reward": 56.28472084169622, "Episode": 4614, "Episode Step": 227}
{"Training Time": 22.169245029158063, "Episode Reward": 6702.084293480161, "Mean Reward": 48.92032331007417, "Episode": 4615, "Episode Step": 137}
{"Training Time": 22.170777990288205, "Episode Reward": 5667.617205269461, "Mean Reward": 45.7065903650763, "Episode": 4616, "Episode Step": 124}
{"Training Time": 22.178796134458647, "Episode Reward": 37103.91920553603, "Mean Reward": 58.61598610669199, "Episode": 4617, "Episode Step": 633}
{"Training Time": 22.18741663277149, "Episode Reward": 49158.75392815918, "Mean Reward": 68.56172095977571, "Episode": 4618, "Episode Step": 717}
{"Training Time": 22.18897605803278, "Episode Reward": 5494.382484146985, "Mean Reward": 42.592112280209186, "Episode": 4619, "Episode Step": 129}
{"Training Time": 22.194324374728733, "Episode Reward": 25741.02288660455, "Mean Reward": 62.93648627531675, "Episode": 4620, "Episode Step": 409}
{"Training Time": 22.195956818328963, "Episode Reward": 6187.6109942447065, "Mean Reward": 45.83415551292375, "Episode": 4621, "Episode Step": 135}
{"Training Time": 22.19904253807333, "Episode Reward": 15922.598382672679, "Mean Reward": 61.955635730243884, "Episode": 4622, "Episode Step": 257}
{"Training Time": 22.207068649994003, "Episode Reward": 37393.58831278084, "Mean Reward": 60.02181109595641, "Episode": 4623, "Episode Step": 623}
{"Training Time": 22.208132484753925, "Episode Reward": 4669.987150329212, "Mean Reward": 54.30217616661875, "Episode": 4624, "Episode Step": 86}
{"Training Time": 22.21484558304151, "Episode Reward": 32662.19703372913, "Mean Reward": 57.707061897047936, "Episode": 4625, "Episode Step": 566}
{"Training Time": 22.243976858324476, "Episode Reward": 154252.9185156177, "Mean Reward": 64.32565409325176, "Episode": 4626, "Episode Step": 2398}
{"Training Time": 22.24560675581296, "Episode Reward": 6468.180366228841, "Mean Reward": 47.56014975168266, "Episode": 4627, "Episode Step": 136}
{"Training Time": 22.24710750805007, "Episode Reward": 5476.473703473811, "Mean Reward": 44.524176451006596, "Episode": 4628, "Episode Step": 123}
{"Training Time": 22.249747741950884, "Episode Reward": 9344.806220461584, "Mean Reward": 52.79551536983946, "Episode": 4629, "Episode Step": 177}
{"Training Time": 22.25102730585469, "Episode Reward": 5820.678245191365, "Mean Reward": 55.96806004991697, "Episode": 4630, "Episode Step": 104}
{"Training Time": 22.259431015584205, "Episode Reward": 45011.08447430398, "Mean Reward": 64.76415032273954, "Episode": 4631, "Episode Step": 695}
{"Training Time": 22.261627849141757, "Episode Reward": 6724.930486060266, "Mean Reward": 48.38079486374292, "Episode": 4632, "Episode Step": 139}
{"Training Time": 22.26519609749317, "Episode Reward": 18658.62046633167, "Mean Reward": 63.89938515867011, "Episode": 4633, "Episode Step": 292}
{"Training Time": 22.266742060250706, "Episode Reward": 6112.042215725584, "Mean Reward": 48.508271553377654, "Episode": 4634, "Episode Step": 126}
{"Training Time": 22.269294469157856, "Episode Reward": 8754.159903687154, "Mean Reward": 49.45853052930595, "Episode": 4635, "Episode Step": 177}
{"Training Time": 22.27141181667646, "Episode Reward": 8303.631105651142, "Mean Reward": 46.6496129530963, "Episode": 4636, "Episode Step": 178}
{"Training Time": 22.279651091959742, "Episode Reward": 44551.55368146171, "Mean Reward": 64.94395580388004, "Episode": 4637, "Episode Step": 686}
{"Training Time": 22.292727661397723, "Episode Reward": 69423.01598805521, "Mean Reward": 66.05424927502874, "Episode": 4638, "Episode Step": 1051}
{"Training Time": 22.294352629184722, "Episode Reward": 6437.973753565043, "Mean Reward": 48.044580250485396, "Episode": 4639, "Episode Step": 134}
{"Training Time": 22.295959028336735, "Episode Reward": 5608.110406320819, "Mean Reward": 42.48568489636984, "Episode": 4640, "Episode Step": 132}
{"Training Time": 22.29857271750768, "Episode Reward": 9141.285786361366, "Mean Reward": 51.35553812562566, "Episode": 4641, "Episode Step": 178}
{"Training Time": 22.300645064446663, "Episode Reward": 8637.70837082027, "Mean Reward": 50.51291444924134, "Episode": 4642, "Episode Step": 171}
{"Training Time": 22.303631638619635, "Episode Reward": 16752.801058737015, "Mean Reward": 68.65902073252875, "Episode": 4643, "Episode Step": 244}
{"Training Time": 22.30692399336232, "Episode Reward": 15004.794146696082, "Mean Reward": 62.781565467347626, "Episode": 4644, "Episode Step": 239}
{"Training Time": 22.308551970852747, "Episode Reward": 7171.345157237505, "Mean Reward": 52.34558508932486, "Episode": 4645, "Episode Step": 137}
{"Training Time": 22.316862992776766, "Episode Reward": 44020.12421817406, "Mean Reward": 63.33830822758858, "Episode": 4646, "Episode Step": 695}
{"Training Time": 22.32833148724503, "Episode Reward": 60522.57265785978, "Mean Reward": 66.07267757408273, "Episode": 4647, "Episode Step": 916}
{"Training Time": 22.331769076916906, "Episode Reward": 18272.405497493197, "Mean Reward": 63.66691810973239, "Episode": 4648, "Episode Step": 287}
{"Training Time": 22.341068288087843, "Episode Reward": 44946.09770084756, "Mean Reward": 65.13927203021386, "Episode": 4649, "Episode Step": 690}
{"Training Time": 22.354204298920102, "Episode Reward": 65798.95677671909, "Mean Reward": 61.783058006309005, "Episode": 4650, "Episode Step": 1065}
{"Training Time": 22.36139300001992, "Episode Reward": 36602.84222398728, "Mean Reward": 60.50056565948311, "Episode": 4651, "Episode Step": 605}
{"Training Time": 22.36414502110746, "Episode Reward": 12325.907430932486, "Mean Reward": 52.900890261512814, "Episode": 4652, "Episode Step": 233}
{"Training Time": 22.377358525858984, "Episode Reward": 68023.95986439251, "Mean Reward": 63.87226278346715, "Episode": 4653, "Episode Step": 1065}
{"Training Time": 22.3808321991894, "Episode Reward": 18995.000178234026, "Mean Reward": 65.0513704734042, "Episode": 4654, "Episode Step": 292}
{"Training Time": 22.383846605552566, "Episode Reward": 13159.138495637582, "Mean Reward": 52.21880355411739, "Episode": 4655, "Episode Step": 252}
{"Training Time": 22.386391278041735, "Episode Reward": 8935.95984390577, "Mean Reward": 50.77249911310096, "Episode": 4656, "Episode Step": 176}
{"Training Time": 22.387636777758598, "Episode Reward": 5618.154588408696, "Mean Reward": 55.079946945183295, "Episode": 4657, "Episode Step": 102}
{"Training Time": 22.39056509779559, "Episode Reward": 13903.056285955632, "Mean Reward": 56.979738876867344, "Episode": 4658, "Episode Step": 244}
{"Training Time": 22.3931434286303, "Episode Reward": 9359.198401804819, "Mean Reward": 53.78849656209666, "Episode": 4659, "Episode Step": 174}
{"Training Time": 22.39521886302365, "Episode Reward": 8683.019954439409, "Mean Reward": 50.777894470405904, "Episode": 4660, "Episode Step": 171}
{"Training Time": 22.403408421675366, "Episode Reward": 39794.72085617978, "Mean Reward": 58.00979716644283, "Episode": 4661, "Episode Step": 686}
{"Training Time": 22.411343358357747, "Episode Reward": 38703.08850728951, "Mean Reward": 61.8260199796957, "Episode": 4662, "Episode Step": 626}
{"Training Time": 22.412961448033652, "Episode Reward": 7232.477219571441, "Mean Reward": 53.57390533015882, "Episode": 4663, "Episode Step": 135}
{"Training Time": 22.41507817665736, "Episode Reward": 7697.345358952611, "Mean Reward": 43.73491681223074, "Episode": 4664, "Episode Step": 176}
{"Training Time": 22.41766526195738, "Episode Reward": 8855.578961640444, "Mean Reward": 49.47250816558907, "Episode": 4665, "Episode Step": 179}
{"Training Time": 22.418885003593232, "Episode Reward": 5821.238080946903, "Mean Reward": 57.070961577910815, "Episode": 4666, "Episode Step": 102}
{"Training Time": 22.428131587240433, "Episode Reward": 49109.952406187585, "Mean Reward": 62.72024572948606, "Episode": 4667, "Episode Step": 783}
{"Training Time": 22.430683416657978, "Episode Reward": 8980.788507463323, "Mean Reward": 51.02720742876888, "Episode": 4668, "Episode Step": 176}
{"Training Time": 22.432761665582657, "Episode Reward": 8574.571937938417, "Mean Reward": 49.56399964126253, "Episode": 4669, "Episode Step": 173}
{"Training Time": 22.434199990034102, "Episode Reward": 6239.5556224599095, "Mean Reward": 51.143898544753355, "Episode": 4670, "Episode Step": 122}
{"Training Time": 22.43679824305905, "Episode Reward": 8767.37337178182, "Mean Reward": 48.979739507161, "Episode": 4671, "Episode Step": 179}
{"Training Time": 22.43891783667935, "Episode Reward": 8713.475095032372, "Mean Reward": 50.07744307489869, "Episode": 4672, "Episode Step": 174}
{"Training Time": 22.441943457523983, "Episode Reward": 14591.835662253747, "Mean Reward": 59.076257741918006, "Episode": 4673, "Episode Step": 247}
{"Training Time": 22.444506046970684, "Episode Reward": 8872.152347383377, "Mean Reward": 49.84355251338976, "Episode": 4674, "Episode Step": 178}
{"Training Time": 22.454138432476256, "Episode Reward": 52965.856499473535, "Mean Reward": 66.20732062434192, "Episode": 4675, "Episode Step": 800}
{"Training Time": 22.460904560287794, "Episode Reward": 33940.43309920782, "Mean Reward": 59.440338177246616, "Episode": 4676, "Episode Step": 571}
{"Training Time": 22.468670655820105, "Episode Reward": 38143.81183743504, "Mean Reward": 61.82141302663702, "Episode": 4677, "Episode Step": 617}
{"Training Time": 22.485303041934966, "Episode Reward": 96404.82376185954, "Mean Reward": 68.42074078201529, "Episode": 4678, "Episode Step": 1409}
{"Training Time": 22.486323855254387, "Episode Reward": 4803.001859504143, "Mean Reward": 55.84885883144352, "Episode": 4679, "Episode Step": 86}
{"Training Time": 22.494072694977124, "Episode Reward": 38457.25249058364, "Mean Reward": 62.32942056820687, "Episode": 4680, "Episode Step": 617}
{"Training Time": 22.495311633878284, "Episode Reward": 6144.45696295616, "Mean Reward": 59.08131695150154, "Episode": 4681, "Episode Step": 104}
{"Training Time": 22.497401572532123, "Episode Reward": 8255.51439734303, "Mean Reward": 46.379294367095675, "Episode": 4682, "Episode Step": 178}
{"Training Time": 22.499998248351943, "Episode Reward": 8784.548362825497, "Mean Reward": 49.91220660696305, "Episode": 4683, "Episode Step": 176}
{"Training Time": 22.511128116382494, "Episode Reward": 64243.98799581144, "Mean Reward": 68.34466808065046, "Episode": 4684, "Episode Step": 940}
{"Training Time": 22.51413985636499, "Episode Reward": 16335.077505212312, "Mean Reward": 64.31132876067839, "Episode": 4685, "Episode Step": 254}
{"Training Time": 22.537359222239918, "Episode Reward": 127075.63910103771, "Mean Reward": 65.80820253808271, "Episode": 4686, "Episode Step": 1931}
{"Training Time": 22.540275647242865, "Episode Reward": 16097.379797438303, "Mean Reward": 65.97286802228813, "Episode": 4687, "Episode Step": 244}
{"Training Time": 22.543280443880292, "Episode Reward": 14220.572325360128, "Mean Reward": 56.20779575241157, "Episode": 4688, "Episode Step": 253}
{"Training Time": 22.55705672389931, "Episode Reward": 75809.95955585336, "Mean Reward": 67.02914195919837, "Episode": 4689, "Episode Step": 1131}
{"Training Time": 22.55910374502341, "Episode Reward": 8249.090333230635, "Mean Reward": 47.4085651335094, "Episode": 4690, "Episode Step": 174}
{"Training Time": 22.562097515861193, "Episode Reward": 14638.502185455722, "Mean Reward": 58.08929438672905, "Episode": 4691, "Episode Step": 252}
{"Training Time": 22.569804105824893, "Episode Reward": 38471.31248300027, "Mean Reward": 62.352208238250036, "Episode": 4692, "Episode Step": 617}
{"Training Time": 22.571868963042895, "Episode Reward": 8642.252216514911, "Mean Reward": 49.95521512436365, "Episode": 4693, "Episode Step": 173}
{"Training Time": 22.5748248780436, "Episode Reward": 15987.417886256255, "Mean Reward": 64.9895036026677, "Episode": 4694, "Episode Step": 246}
{"Training Time": 22.582180198629697, "Episode Reward": 36358.540955357086, "Mean Reward": 61.939592768921784, "Episode": 4695, "Episode Step": 587}
{"Training Time": 22.59019771191809, "Episode Reward": 42702.20116683084, "Mean Reward": 62.43011866495737, "Episode": 4696, "Episode Step": 684}
{"Training Time": 22.603551177514923, "Episode Reward": 71875.7842314328, "Mean Reward": 63.55064918782741, "Episode": 4697, "Episode Step": 1131}
{"Training Time": 22.6586033460829, "Episode Reward": 314687.0119658662, "Mean Reward": 68.55926186620178, "Episode": 4698, "Episode Step": 4590}
{"Training Time": 22.666257952253023, "Episode Reward": 33091.927736716054, "Mean Reward": 60.05794507570972, "Episode": 4699, "Episode Step": 551}
{"Training Time": 22.668075824711057, "Episode Reward": 5602.492574840706, "Mean Reward": 43.769473240943015, "Episode": 4700, "Episode Step": 128}
{"Training Time": 22.6767139866617, "Episode Reward": 47068.67235481182, "Mean Reward": 68.8138484719471, "Episode": 4701, "Episode Step": 684}
{"Training Time": 22.681558912793797, "Episode Reward": 24678.57614019002, "Mean Reward": 61.38949288604483, "Episode": 4702, "Episode Step": 402}
{"Training Time": 22.682894906666544, "Episode Reward": 4560.776239148641, "Mean Reward": 41.46160217407856, "Episode": 4703, "Episode Step": 110}
{"Training Time": 22.706355191402967, "Episode Reward": 132824.45558682876, "Mean Reward": 68.892352482795, "Episode": 4704, "Episode Step": 1928}
{"Training Time": 22.718606229159565, "Episode Reward": 66698.83101976207, "Mean Reward": 64.4433149949392, "Episode": 4705, "Episode Step": 1035}
{"Training Time": 22.72163212802675, "Episode Reward": 15300.021116919856, "Mean Reward": 60.23630360992069, "Episode": 4706, "Episode Step": 254}
{"Training Time": 22.7338044091728, "Episode Reward": 67702.92553085813, "Mean Reward": 69.43889798036732, "Episode": 4707, "Episode Step": 975}
{"Training Time": 22.73501614583863, "Episode Reward": 5722.233095473234, "Mean Reward": 56.10032446542387, "Episode": 4708, "Episode Step": 102}
{"Training Time": 22.736551326645746, "Episode Reward": 6097.014232923626, "Mean Reward": 47.63292369471583, "Episode": 4709, "Episode Step": 128}
{"Training Time": 22.73907939500279, "Episode Reward": 9266.313059079785, "Mean Reward": 53.56250323167505, "Episode": 4710, "Episode Step": 173}
{"Training Time": 22.75746499584781, "Episode Reward": 104889.29211534196, "Mean Reward": 68.51031490224818, "Episode": 4711, "Episode Step": 1531}
{"Training Time": 22.760544990566043, "Episode Reward": 16486.80600307839, "Mean Reward": 64.40158594952496, "Episode": 4712, "Episode Step": 256}
{"Training Time": 22.763966978324785, "Episode Reward": 16755.350497805397, "Mean Reward": 69.52427592450373, "Episode": 4713, "Episode Step": 241}
{"Training Time": 22.76609485414293, "Episode Reward": 9142.794111474703, "Mean Reward": 52.54479374410749, "Episode": 4714, "Episode Step": 174}
{"Training Time": 22.768253080248833, "Episode Reward": 8756.145687653407, "Mean Reward": 49.19182970591802, "Episode": 4715, "Episode Step": 178}
{"Training Time": 22.770312732193204, "Episode Reward": 7109.586857968476, "Mean Reward": 53.45554028547726, "Episode": 4716, "Episode Step": 133}
{"Training Time": 22.77242455250687, "Episode Reward": 9023.244544640887, "Mean Reward": 52.460724096749345, "Episode": 4717, "Episode Step": 172}
{"Training Time": 22.77451985253228, "Episode Reward": 9032.880665486957, "Mean Reward": 51.32318559935771, "Episode": 4718, "Episode Step": 176}
{"Training Time": 22.778015096386273, "Episode Reward": 17284.679491455798, "Mean Reward": 68.8632649061984, "Episode": 4719, "Episode Step": 251}
{"Training Time": 22.785294379989306, "Episode Reward": 40252.10041954087, "Mean Reward": 66.86395418528383, "Episode": 4720, "Episode Step": 602}
{"Training Time": 22.79467699891991, "Episode Reward": 49151.8600061895, "Mean Reward": 62.773767568568964, "Episode": 4721, "Episode Step": 783}
{"Training Time": 22.797226449449855, "Episode Reward": 9802.73600189263, "Mean Reward": 56.33756322926799, "Episode": 4722, "Episode Step": 174}
{"Training Time": 22.80512740360366, "Episode Reward": 46107.83923397252, "Mean Reward": 70.28634029568981, "Episode": 4723, "Episode Step": 656}
{"Training Time": 22.817239813870852, "Episode Reward": 65226.64282275487, "Mean Reward": 64.77323021127593, "Episode": 4724, "Episode Step": 1007}
{"Training Time": 22.82602789858977, "Episode Reward": 45154.3427967135, "Mean Reward": 65.72684541006332, "Episode": 4725, "Episode Step": 687}
{"Training Time": 22.828699382212427, "Episode Reward": 14245.053585684804, "Mean Reward": 63.87916406136683, "Episode": 4726, "Episode Step": 223}
{"Training Time": 22.83963557753298, "Episode Reward": 58308.89926695286, "Mean Reward": 64.28765079046622, "Episode": 4727, "Episode Step": 907}
{"Training Time": 22.85587250775761, "Episode Reward": 94950.2222948331, "Mean Reward": 71.12376201860158, "Episode": 4728, "Episode Step": 1335}
{"Training Time": 22.870177029702397, "Episode Reward": 83983.07559418782, "Mean Reward": 69.63770778954213, "Episode": 4729, "Episode Step": 1206}
{"Training Time": 22.892971471680536, "Episode Reward": 125426.06771358057, "Mean Reward": 65.08877411187368, "Episode": 4730, "Episode Step": 1927}
{"Training Time": 22.905941940016216, "Episode Reward": 70246.41370973406, "Mean Reward": 67.15718327890445, "Episode": 4731, "Episode Step": 1046}
{"Training Time": 22.91014039364126, "Episode Reward": 22916.320836735395, "Mean Reward": 65.10318419527101, "Episode": 4732, "Episode Step": 352}
{"Training Time": 22.91312750140826, "Episode Reward": 16602.69268124697, "Mean Reward": 67.21737927630352, "Episode": 4733, "Episode Step": 247}
{"Training Time": 22.926687735584046, "Episode Reward": 75147.88763287323, "Mean Reward": 68.62820788390249, "Episode": 4734, "Episode Step": 1095}
{"Training Time": 22.934912362496057, "Episode Reward": 48130.66767791646, "Mean Reward": 69.85583117259283, "Episode": 4735, "Episode Step": 689}
{"Training Time": 22.948018714984258, "Episode Reward": 74546.63133501419, "Mean Reward": 68.07911537444218, "Episode": 4736, "Episode Step": 1095}
{"Training Time": 22.991286167767313, "Episode Reward": 243741.25784542487, "Mean Reward": 67.23896768149652, "Episode": 4737, "Episode Step": 3625}
{"Training Time": 22.99334779805607, "Episode Reward": 9384.718833597251, "Mean Reward": 53.626964763412865, "Episode": 4738, "Episode Step": 175}
{"Training Time": 23.000503789981206, "Episode Reward": 37556.51349125389, "Mean Reward": 62.07688180372544, "Episode": 4739, "Episode Step": 605}
{"Training Time": 23.003960637516446, "Episode Reward": 16781.627981433707, "Mean Reward": 67.39609631097875, "Episode": 4740, "Episode Step": 249}
{"Training Time": 23.012015994985898, "Episode Reward": 45101.46054872634, "Mean Reward": 67.21529142880229, "Episode": 4741, "Episode Step": 671}
{"Training Time": 23.04431729608112, "Episode Reward": 181590.5706090046, "Mean Reward": 66.20144754247342, "Episode": 4742, "Episode Step": 2743}
{"Training Time": 23.052125587794517, "Episode Reward": 39236.87729394784, "Mean Reward": 63.285285957980385, "Episode": 4743, "Episode Step": 620}
{"Training Time": 23.07001190086206, "Episode Reward": 103714.67134563759, "Mean Reward": 68.68521281168051, "Episode": 4744, "Episode Step": 1510}
{"Training Time": 23.072963967190848, "Episode Reward": 16464.327581992184, "Mean Reward": 65.85731032796873, "Episode": 4745, "Episode Step": 250}
{"Training Time": 23.08729493525293, "Episode Reward": 81104.63098961303, "Mean Reward": 69.08401276798384, "Episode": 4746, "Episode Step": 1174}
{"Training Time": 23.105301785005462, "Episode Reward": 102033.93937452251, "Mean Reward": 66.86365620873035, "Episode": 4747, "Episode Step": 1526}
{"Training Time": 23.144560211698213, "Episode Reward": 222197.52367263407, "Mean Reward": 66.92696496163677, "Episode": 4748, "Episode Step": 3320}
{"Training Time": 23.148177088035478, "Episode Reward": 9150.581519142146, "Mean Reward": 51.69820067311947, "Episode": 4749, "Episode Step": 177}
{"Training Time": 23.15053874168131, "Episode Reward": 8208.457888936382, "Mean Reward": 47.447733462060015, "Episode": 4750, "Episode Step": 173}
{"Training Time": 23.184238406684663, "Episode Reward": 193477.65346676495, "Mean Reward": 67.39033558577671, "Episode": 4751, "Episode Step": 2871}
{"Training Time": 23.203593662248718, "Episode Reward": 107730.9721321332, "Mean Reward": 67.62772889650546, "Episode": 4752, "Episode Step": 1593}
{"Training Time": 23.216610892746182, "Episode Reward": 68631.6781846654, "Mean Reward": 62.22273634149175, "Episode": 4753, "Episode Step": 1103}
{"Training Time": 23.235156291392116, "Episode Reward": 102613.37918220574, "Mean Reward": 65.48396884633424, "Episode": 4754, "Episode Step": 1567}
{"Training Time": 23.269785111943882, "Episode Reward": 202590.13596956237, "Mean Reward": 69.47535527076899, "Episode": 4755, "Episode Step": 2916}
{"Training Time": 23.272613553073672, "Episode Reward": 14663.663595475271, "Mean Reward": 60.59365122097219, "Episode": 4756, "Episode Step": 242}
{"Training Time": 23.285845088627603, "Episode Reward": 76733.95680844449, "Mean Reward": 67.42878454169112, "Episode": 4757, "Episode Step": 1138}
{"Training Time": 23.289771041936344, "Episode Reward": 19310.79911763658, "Mean Reward": 65.23918620823169, "Episode": 4758, "Episode Step": 296}
{"Training Time": 23.29244268861082, "Episode Reward": 13302.231686236395, "Mean Reward": 58.60013958694447, "Episode": 4759, "Episode Step": 227}
{"Training Time": 23.295218483871885, "Episode Reward": 15902.044935980697, "Mean Reward": 67.09723601679619, "Episode": 4760, "Episode Step": 237}
{"Training Time": 23.303702896965873, "Episode Reward": 46403.361659122886, "Mean Reward": 68.04011973478428, "Episode": 4761, "Episode Step": 682}
{"Training Time": 23.306551960574257, "Episode Reward": 14625.615978230237, "Mean Reward": 61.4521679757573, "Episode": 4762, "Episode Step": 238}
{"Training Time": 23.31473209970527, "Episode Reward": 47512.67561351147, "Mean Reward": 68.7592990065289, "Episode": 4763, "Episode Step": 691}
{"Training Time": 23.327518162528673, "Episode Reward": 70230.2938523096, "Mean Reward": 66.82235380809666, "Episode": 4764, "Episode Step": 1051}
{"Training Time": 23.345302754176988, "Episode Reward": 104998.39469478499, "Mean Reward": 68.71622689449279, "Episode": 4765, "Episode Step": 1528}
{"Training Time": 23.378889977203475, "Episode Reward": 195437.32222811083, "Mean Reward": 67.74257269605228, "Episode": 4766, "Episode Step": 2885}
{"Training Time": 23.382214782238005, "Episode Reward": 16717.583349956738, "Mean Reward": 69.08092293370552, "Episode": 4767, "Episode Step": 242}
{"Training Time": 23.38511351307233, "Episode Reward": 16847.797749059147, "Mean Reward": 68.76652142473121, "Episode": 4768, "Episode Step": 245}
{"Training Time": 23.398182687759398, "Episode Reward": 74197.20329897433, "Mean Reward": 66.24750294551279, "Episode": 4769, "Episode Step": 1120}
{"Training Time": 23.405879086653393, "Episode Reward": 39200.37673168811, "Mean Reward": 63.6369752137794, "Episode": 4770, "Episode Step": 616}
{"Training Time": 23.410573569138844, "Episode Reward": 25299.384527764407, "Mean Reward": 62.933792357622906, "Episode": 4771, "Episode Step": 402}
{"Training Time": 23.413462612231573, "Episode Reward": 16597.049893988118, "Mean Reward": 67.46768249588666, "Episode": 4772, "Episode Step": 246}
{"Training Time": 23.433057607478567, "Episode Reward": 102925.98559736727, "Mean Reward": 62.91319413042009, "Episode": 4773, "Episode Step": 1636}
{"Training Time": 23.435117591685717, "Episode Reward": 9053.330902705447, "Mean Reward": 52.63564478317121, "Episode": 4774, "Episode Step": 172}
{"Training Time": 23.437295561962657, "Episode Reward": 9396.294048498625, "Mean Reward": 51.34586911747883, "Episode": 4775, "Episode Step": 183}
{"Training Time": 23.455818831390804, "Episode Reward": 103020.28920883786, "Mean Reward": 66.37905232528213, "Episode": 4776, "Episode Step": 1552}
{"Training Time": 23.458724171386823, "Episode Reward": 16419.3984722015, "Mean Reward": 67.01795294776123, "Episode": 4777, "Episode Step": 245}
{"Training Time": 23.472202249434257, "Episode Reward": 74442.75112665648, "Mean Reward": 65.47295613602154, "Episode": 4778, "Episode Step": 1137}
{"Training Time": 23.49534359163708, "Episode Reward": 129606.02076225785, "Mean Reward": 67.01448850168451, "Episode": 4779, "Episode Step": 1934}
{"Training Time": 23.50686286667983, "Episode Reward": 65081.39444617807, "Mean Reward": 65.73878226886674, "Episode": 4780, "Episode Step": 990}
{"Training Time": 23.50979861835639, "Episode Reward": 16983.17573692621, "Mean Reward": 67.93270294770484, "Episode": 4781, "Episode Step": 250}
{"Training Time": 23.549078619413905, "Episode Reward": 222201.8917819216, "Mean Reward": 66.76739536716394, "Episode": 4782, "Episode Step": 3328}
{"Training Time": 23.55902163611518, "Episode Reward": 54496.01877077877, "Mean Reward": 64.6453366201409, "Episode": 4783, "Episode Step": 843}
{"Training Time": 23.567183289726575, "Episode Reward": 44282.75305548494, "Mean Reward": 64.27104942740921, "Episode": 4784, "Episode Step": 689}
{"Training Time": 23.600023406412866, "Episode Reward": 176360.44045553112, "Mean Reward": 64.01467893122727, "Episode": 4785, "Episode Step": 2755}
{"Training Time": 23.602022592226664, "Episode Reward": 8050.68267671433, "Mean Reward": 47.637175601859944, "Episode": 4786, "Episode Step": 169}
{"Training Time": 23.61015603363514, "Episode Reward": 44989.979949714725, "Mean Reward": 64.73378410030895, "Episode": 4787, "Episode Step": 695}
{"Training Time": 23.63422563413779, "Episode Reward": 119816.52035807837, "Mean Reward": 59.11027151360551, "Episode": 4788, "Episode Step": 2027}
{"Training Time": 23.63705381969611, "Episode Reward": 15314.831553823562, "Mean Reward": 63.28442790836183, "Episode": 4789, "Episode Step": 242}
{"Training Time": 23.645077995525465, "Episode Reward": 46968.45548657688, "Mean Reward": 68.36747523519196, "Episode": 4790, "Episode Step": 687}
{"Training Time": 23.69031658053398, "Episode Reward": 239957.5665979052, "Mean Reward": 63.11351041501978, "Episode": 4791, "Episode Step": 3802}
{"Training Time": 23.695000432795947, "Episode Reward": 25352.55816318558, "Mean Reward": 64.51032611497602, "Episode": 4792, "Episode Step": 393}
{"Training Time": 23.697111945814555, "Episode Reward": 8872.903221079168, "Mean Reward": 49.29390678377316, "Episode": 4793, "Episode Step": 180}
{"Training Time": 23.7259836969773, "Episode Reward": 155889.10640982265, "Mean Reward": 64.15189564190233, "Episode": 4794, "Episode Step": 2430}
{"Training Time": 23.737686795261173, "Episode Reward": 61594.62516947801, "Mean Reward": 61.22726159987874, "Episode": 4795, "Episode Step": 1006}
{"Training Time": 23.740683292746542, "Episode Reward": 15802.98411491523, "Mean Reward": 62.21647289336705, "Episode": 4796, "Episode Step": 254}
{"Training Time": 23.74372963084115, "Episode Reward": 11147.026008238983, "Mean Reward": 50.89966213807755, "Episode": 4797, "Episode Step": 219}
{"Training Time": 23.759413201080427, "Episode Reward": 83994.7425035819, "Mean Reward": 62.58922690281811, "Episode": 4798, "Episode Step": 1342}
{"Training Time": 23.763531115584904, "Episode Reward": 16610.04192750588, "Mean Reward": 65.39386585632236, "Episode": 4799, "Episode Step": 254}
{"Training Time": 23.786513905260296, "Episode Reward": 119211.17324084461, "Mean Reward": 62.12150768152403, "Episode": 4800, "Episode Step": 1919}
{"Training Time": 23.789215538899104, "Episode Reward": 12776.404274188246, "Mean Reward": 56.532762275169226, "Episode": 4801, "Episode Step": 226}
{"Training Time": 23.79570062610838, "Episode Reward": 34850.22786704616, "Mean Reward": 63.711568312698645, "Episode": 4802, "Episode Step": 547}
{"Training Time": 23.804380808340177, "Episode Reward": 44503.595935743004, "Mean Reward": 64.03395098668058, "Episode": 4803, "Episode Step": 695}
{"Training Time": 23.834434626698496, "Episode Reward": 171365.87591074494, "Mean Reward": 67.3343323814322, "Episode": 4804, "Episode Step": 2545}
{"Training Time": 23.841796694993974, "Episode Reward": 38825.696672272104, "Mean Reward": 62.42073419979438, "Episode": 4805, "Episode Step": 622}
{"Training Time": 23.84390196164449, "Episode Reward": 6577.468433461263, "Mean Reward": 47.3199167874911, "Episode": 4806, "Episode Step": 139}
{"Training Time": 23.86684557888243, "Episode Reward": 131095.77462920686, "Mean Reward": 67.02237966728367, "Episode": 4807, "Episode Step": 1956}
{"Training Time": 23.87495411720541, "Episode Reward": 44447.03514161606, "Mean Reward": 64.50948496606105, "Episode": 4808, "Episode Step": 689}
{"Training Time": 23.877050508591864, "Episode Reward": 6840.0775970530285, "Mean Reward": 49.56577968879006, "Episode": 4809, "Episode Step": 138}
{"Training Time": 23.884877070850795, "Episode Reward": 41527.9412519976, "Mean Reward": 63.20843417351233, "Episode": 4810, "Episode Step": 657}
{"Training Time": 23.901997905837163, "Episode Reward": 95435.81130219484, "Mean Reward": 66.09128206523188, "Episode": 4811, "Episode Step": 1444}
{"Training Time": 23.90954451918602, "Episode Reward": 34354.93021599291, "Mean Reward": 57.83658285520691, "Episode": 4812, "Episode Step": 594}
{"Training Time": 23.91933800862895, "Episode Reward": 53156.67782994733, "Mean Reward": 64.74625801455217, "Episode": 4813, "Episode Step": 821}
{"Training Time": 23.92743855443266, "Episode Reward": 45759.19068921801, "Mean Reward": 67.39203341563773, "Episode": 4814, "Episode Step": 679}
{"Training Time": 23.934867940280174, "Episode Reward": 34227.60780078643, "Mean Reward": 57.71940607215249, "Episode": 4815, "Episode Step": 593}
{"Training Time": 23.936484954423374, "Episode Reward": 6447.301474936971, "Mean Reward": 47.406628492183614, "Episode": 4816, "Episode Step": 136}
{"Training Time": 23.953709780573845, "Episode Reward": 96157.32451551231, "Mean Reward": 65.36867744086493, "Episode": 4817, "Episode Step": 1471}
{"Training Time": 23.961440817779966, "Episode Reward": 38490.11768787109, "Mean Reward": 62.18112712095491, "Episode": 4818, "Episode Step": 619}
{"Training Time": 23.981167456640136, "Episode Reward": 111760.31597255946, "Mean Reward": 66.09125722800678, "Episode": 4819, "Episode Step": 1691}
{"Training Time": 24.00421536915832, "Episode Reward": 130348.79625378994, "Mean Reward": 65.83272538070199, "Episode": 4820, "Episode Step": 1980}
{"Training Time": 24.01258476641443, "Episode Reward": 44744.48169990601, "Mean Reward": 66.1900616862515, "Episode": 4821, "Episode Step": 676}
{"Training Time": 24.019592877493963, "Episode Reward": 36969.067415210375, "Mean Reward": 61.512591373062186, "Episode": 4822, "Episode Step": 601}
{"Training Time": 24.02662515030967, "Episode Reward": 38884.72613857726, "Mean Reward": 65.24282909157257, "Episode": 4823, "Episode Step": 596}
{"Training Time": 24.028305192192395, "Episode Reward": 6428.156440971728, "Mean Reward": 61.80919654780508, "Episode": 4824, "Episode Step": 104}
{"Training Time": 24.029899893866645, "Episode Reward": 6510.905717835088, "Mean Reward": 48.58884864056036, "Episode": 4825, "Episode Step": 134}
{"Training Time": 24.037616633905305, "Episode Reward": 43350.388569688344, "Mean Reward": 65.78207673700811, "Episode": 4826, "Episode Step": 659}
{"Training Time": 24.040188040865793, "Episode Reward": 9209.499200695087, "Mean Reward": 51.73875955446678, "Episode": 4827, "Episode Step": 178}
{"Training Time": 24.05228764752547, "Episode Reward": 67344.50943326655, "Mean Reward": 65.13008649252083, "Episode": 4828, "Episode Step": 1034}
{"Training Time": 24.05433979663584, "Episode Reward": 8469.281222856784, "Mean Reward": 48.6740300164183, "Episode": 4829, "Episode Step": 174}
{"Training Time": 24.06295157916016, "Episode Reward": 44247.68380793223, "Mean Reward": 63.57425834473022, "Episode": 4830, "Episode Step": 696}
{"Training Time": 24.06445047835509, "Episode Reward": 6519.066815052545, "Mean Reward": 51.33123476419327, "Episode": 4831, "Episode Step": 127}
{"Training Time": 24.06545470443037, "Episode Reward": 4249.42383368075, "Mean Reward": 49.99322157271471, "Episode": 4832, "Episode Step": 85}
{"Training Time": 24.07394283917215, "Episode Reward": 46588.792429763795, "Mean Reward": 67.71626806651715, "Episode": 4833, "Episode Step": 688}
{"Training Time": 24.07735580470827, "Episode Reward": 17468.180054766493, "Mean Reward": 60.653402967939215, "Episode": 4834, "Episode Step": 288}
{"Training Time": 24.1275789872143, "Episode Reward": 288186.5233021148, "Mean Reward": 66.91119649457042, "Episode": 4835, "Episode Step": 4307}
{"Training Time": 24.141243723895816, "Episode Reward": 76544.06770807515, "Mean Reward": 67.97874574429409, "Episode": 4836, "Episode Step": 1126}
{"Training Time": 24.144661238061058, "Episode Reward": 19311.330725745727, "Mean Reward": 66.1346942662525, "Episode": 4837, "Episode Step": 292}
{"Training Time": 24.14669276972612, "Episode Reward": 9277.83188713645, "Mean Reward": 53.62908605281185, "Episode": 4838, "Episode Step": 173}
{"Training Time": 24.1492080075211, "Episode Reward": 9409.961528498936, "Mean Reward": 53.46569050283486, "Episode": 4839, "Episode Step": 176}
{"Training Time": 24.158259308338167, "Episode Reward": 50802.45284499532, "Mean Reward": 65.72115503880377, "Episode": 4840, "Episode Step": 773}
{"Training Time": 24.16542589750555, "Episode Reward": 38793.22450698258, "Mean Reward": 63.69987603773823, "Episode": 4841, "Episode Step": 609}
{"Training Time": 24.18587053279082, "Episode Reward": 113249.8949483039, "Mean Reward": 66.26676123364769, "Episode": 4842, "Episode Step": 1709}
{"Training Time": 24.18881880806552, "Episode Reward": 16572.160078533896, "Mean Reward": 66.02454214555337, "Episode": 4843, "Episode Step": 251}
{"Training Time": 24.197417109476195, "Episode Reward": 49448.90969449397, "Mean Reward": 67.55315532034695, "Episode": 4844, "Episode Step": 732}
{"Training Time": 24.20598583585686, "Episode Reward": 44557.06084268783, "Mean Reward": 64.29590309190164, "Episode": 4845, "Episode Step": 693}
{"Training Time": 24.210672492252456, "Episode Reward": 25912.885668439863, "Mean Reward": 64.78221417109965, "Episode": 4846, "Episode Step": 400}
{"Training Time": 24.21271677778827, "Episode Reward": 8802.931299553984, "Mean Reward": 50.591559192838986, "Episode": 4847, "Episode Step": 174}
{"Training Time": 24.219563242197037, "Episode Reward": 33666.56493768293, "Mean Reward": 61.773513647124645, "Episode": 4848, "Episode Step": 545}
{"Training Time": 24.225336568024424, "Episode Reward": 24505.49379765392, "Mean Reward": 60.958939795159004, "Episode": 4849, "Episode Step": 402}
{"Training Time": 24.232835559977424, "Episode Reward": 39374.53524593763, "Mean Reward": 64.76074875976583, "Episode": 4850, "Episode Step": 608}
{"Training Time": 24.249279941916466, "Episode Reward": 84665.8030393673, "Mean Reward": 62.90178531899502, "Episode": 4851, "Episode Step": 1346}
{"Training Time": 24.251909799178442, "Episode Reward": 13608.89417021664, "Mean Reward": 60.753991831324285, "Episode": 4852, "Episode Step": 224}
{"Training Time": 24.256380728085837, "Episode Reward": 25481.806990038778, "Mean Reward": 67.95148530677008, "Episode": 4853, "Episode Step": 375}
{"Training Time": 24.274860034187636, "Episode Reward": 89453.10226128489, "Mean Reward": 59.083951295432556, "Episode": 4854, "Episode Step": 1514}
{"Training Time": 24.275471664998268, "Episode Reward": 2276.8143840429457, "Mean Reward": 46.46559967434583, "Episode": 4855, "Episode Step": 49}
{"Training Time": 24.293115220268568, "Episode Reward": 97500.94187994179, "Mean Reward": 65.65719991915272, "Episode": 4856, "Episode Step": 1485}
{"Training Time": 24.297088972793684, "Episode Reward": 18674.611608900777, "Mean Reward": 63.30376816576535, "Episode": 4857, "Episode Step": 295}
{"Training Time": 24.300604493882922, "Episode Reward": 19059.370959552496, "Mean Reward": 65.49612013591923, "Episode": 4858, "Episode Step": 291}
{"Training Time": 24.307858858307203, "Episode Reward": 39472.49248110706, "Mean Reward": 65.02881792604128, "Episode": 4859, "Episode Step": 607}
{"Training Time": 24.314783382482, "Episode Reward": 32520.637028872137, "Mean Reward": 60.44728072281067, "Episode": 4860, "Episode Step": 538}
{"Training Time": 24.321278171936672, "Episode Reward": 35712.33928844814, "Mean Reward": 65.76858064170929, "Episode": 4861, "Episode Step": 543}
{"Training Time": 24.344090383052826, "Episode Reward": 128732.89959628908, "Mean Reward": 66.90899147416272, "Episode": 4862, "Episode Step": 1924}
{"Training Time": 24.348085832794506, "Episode Reward": 18508.850471021684, "Mean Reward": 62.31936185529187, "Episode": 4863, "Episode Step": 297}
{"Training Time": 24.35090733859274, "Episode Reward": 15157.975399098508, "Mean Reward": 64.50202297488727, "Episode": 4864, "Episode Step": 235}
{"Training Time": 24.35300281445185, "Episode Reward": 9157.009409660874, "Mean Reward": 52.93069022925361, "Episode": 4865, "Episode Step": 173}
{"Training Time": 24.371134505536823, "Episode Reward": 98116.94503004706, "Mean Reward": 65.32419775635623, "Episode": 4866, "Episode Step": 1502}
{"Training Time": 24.373226401143604, "Episode Reward": 8531.31932062687, "Mean Reward": 49.0305708082004, "Episode": 4867, "Episode Step": 174}
{"Training Time": 24.380279972751936, "Episode Reward": 39375.2432150256, "Mean Reward": 65.625405358376, "Episode": 4868, "Episode Step": 600}
{"Training Time": 24.407552306652068, "Episode Reward": 148712.20311935697, "Mean Reward": 65.8893234910753, "Episode": 4869, "Episode Step": 2257}
{"Training Time": 24.40859355138408, "Episode Reward": 4981.78310472058, "Mean Reward": 60.02148318940458, "Episode": 4870, "Episode Step": 83}
{"Training Time": 24.4160006708569, "Episode Reward": 38448.544377168444, "Mean Reward": 63.030400618308924, "Episode": 4871, "Episode Step": 610}
{"Training Time": 24.45950829969512, "Episode Reward": 229081.54065698208, "Mean Reward": 63.40479951757046, "Episode": 4872, "Episode Step": 3613}
{"Training Time": 24.46157079749637, "Episode Reward": 8747.051691835031, "Mean Reward": 50.27041202204041, "Episode": 4873, "Episode Step": 174}
{"Training Time": 24.49918588419755, "Episode Reward": 208800.14706686942, "Mean Reward": 65.97161044766807, "Episode": 4874, "Episode Step": 3165}
{"Training Time": 24.506952999432883, "Episode Reward": 36155.8768851403, "Mean Reward": 58.8857929725412, "Episode": 4875, "Episode Step": 614}
{"Training Time": 24.508204987777603, "Episode Reward": 5888.907563561378, "Mean Reward": 57.73438787805273, "Episode": 4876, "Episode Step": 102}
{"Training Time": 24.51875324441327, "Episode Reward": 58036.751269340915, "Mean Reward": 64.91806629680192, "Episode": 4877, "Episode Step": 894}
{"Training Time": 24.527071215311686, "Episode Reward": 41472.081948985906, "Mean Reward": 62.457954742448656, "Episode": 4878, "Episode Step": 664}
{"Training Time": 24.54603189640575, "Episode Reward": 101322.65357715929, "Mean Reward": 62.89426044516405, "Episode": 4879, "Episode Step": 1611}
{"Training Time": 24.547291422486307, "Episode Reward": 5798.235547307494, "Mean Reward": 55.75226487795668, "Episode": 4880, "Episode Step": 104}
{"Training Time": 24.576128209431968, "Episode Reward": 158010.35082447887, "Mean Reward": 65.53726703628323, "Episode": 4881, "Episode Step": 2411}
{"Training Time": 24.578245549466875, "Episode Reward": 9016.942024306176, "Mean Reward": 51.8215058868171, "Episode": 4882, "Episode Step": 174}
{"Training Time": 24.585477325254015, "Episode Reward": 37303.960396267845, "Mean Reward": 61.15403343650466, "Episode": 4883, "Episode Step": 610}
{"Training Time": 24.60223940802945, "Episode Reward": 93308.34741282077, "Mean Reward": 68.2577523136948, "Episode": 4884, "Episode Step": 1367}
{"Training Time": 24.60577050831583, "Episode Reward": 19290.703265492644, "Mean Reward": 66.0640522790844, "Episode": 4885, "Episode Step": 292}
{"Training Time": 24.618367184731696, "Episode Reward": 68346.39531898638, "Mean Reward": 65.65455842361804, "Episode": 4886, "Episode Step": 1041}
{"Training Time": 24.632128316097788, "Episode Reward": 73824.86549940766, "Mean Reward": 65.85625825103271, "Episode": 4887, "Episode Step": 1121}
{"Training Time": 24.635132642520798, "Episode Reward": 16368.323350568426, "Mean Reward": 65.73623835569649, "Episode": 4888, "Episode Step": 249}
{"Training Time": 24.646087332765262, "Episode Reward": 62198.50204883438, "Mean Reward": 67.46041436966853, "Episode": 4889, "Episode Step": 922}
{"Training Time": 24.653904750016, "Episode Reward": 39678.29485432554, "Mean Reward": 63.48527176692087, "Episode": 4890, "Episode Step": 625}
{"Training Time": 24.656039109428722, "Episode Reward": 8529.021184883175, "Mean Reward": 47.64816304404008, "Episode": 4891, "Episode Step": 179}
{"Training Time": 24.67862915224499, "Episode Reward": 126929.84109540713, "Mean Reward": 66.66483250809198, "Episode": 4892, "Episode Step": 1904}
{"Training Time": 24.686393929455015, "Episode Reward": 39674.175480283215, "Mean Reward": 63.78484803904054, "Episode": 4893, "Episode Step": 622}
{"Training Time": 24.702131251692773, "Episode Reward": 87923.14528208801, "Mean Reward": 66.35709077893435, "Episode": 4894, "Episode Step": 1325}
{"Training Time": 24.713942408031887, "Episode Reward": 66480.07847868466, "Mean Reward": 66.74706674566734, "Episode": 4895, "Episode Step": 996}
{"Training Time": 24.717161207199098, "Episode Reward": 13045.239466518155, "Mean Reward": 56.966111207502856, "Episode": 4896, "Episode Step": 229}
{"Training Time": 24.719259248044757, "Episode Reward": 9494.021808905383, "Mean Reward": 54.251553193745046, "Episode": 4897, "Episode Step": 175}
{"Training Time": 24.727751231392226, "Episode Reward": 49005.58956517348, "Mean Reward": 68.15798270538733, "Episode": 4898, "Episode Step": 719}
{"Training Time": 24.7368248247438, "Episode Reward": 38935.47376638007, "Mean Reward": 62.49674761858759, "Episode": 4899, "Episode Step": 623}
{"Training Time": 24.738586141135958, "Episode Reward": 6557.968424637639, "Mean Reward": 53.31681646046861, "Episode": 4900, "Episode Step": 123}
{"Training Time": 24.79884160776933, "Episode Reward": 339044.2723124343, "Mean Reward": 67.80885446248685, "Episode": 4901, "Episode Step": 5000}
{"Training Time": 24.838530700008075, "Episode Reward": 221769.0681287043, "Mean Reward": 67.86079196104782, "Episode": 4902, "Episode Step": 3268}
{"Training Time": 24.846539620293512, "Episode Reward": 44176.55792767457, "Mean Reward": 66.23172103099635, "Episode": 4903, "Episode Step": 667}
{"Training Time": 24.85662351999018, "Episode Reward": 53419.17565498399, "Mean Reward": 64.36045259636626, "Episode": 4904, "Episode Step": 830}
{"Training Time": 24.875315702491335, "Episode Reward": 100097.42978975209, "Mean Reward": 65.68072820849875, "Episode": 4905, "Episode Step": 1524}
{"Training Time": 24.877440353035926, "Episode Reward": 8716.103933819146, "Mean Reward": 50.092551343788195, "Episode": 4906, "Episode Step": 174}
{"Training Time": 24.894696994158956, "Episode Reward": 90051.49353311317, "Mean Reward": 62.753654030044025, "Episode": 4907, "Episode Step": 1435}
{"Training Time": 24.90258593916893, "Episode Reward": 39922.32159791294, "Mean Reward": 64.18379678121052, "Episode": 4908, "Episode Step": 622}
{"Training Time": 24.910757990810605, "Episode Reward": 44662.29709306854, "Mean Reward": 65.58340248615058, "Episode": 4909, "Episode Step": 681}
{"Training Time": 24.91290550304784, "Episode Reward": 8810.136330379974, "Mean Reward": 49.21863871720656, "Episode": 4910, "Episode Step": 179}
{"Training Time": 24.915545629461608, "Episode Reward": 8877.324827908187, "Mean Reward": 48.50997173720321, "Episode": 4911, "Episode Step": 183}
{"Training Time": 24.948105976647803, "Episode Reward": 177016.33894182046, "Mean Reward": 64.29943296106809, "Episode": 4912, "Episode Step": 2753}
{"Training Time": 24.95021587835418, "Episode Reward": 9065.676317011095, "Mean Reward": 51.80386466863483, "Episode": 4913, "Episode Step": 175}
{"Training Time": 24.958258298900393, "Episode Reward": 40169.60408450957, "Mean Reward": 63.45909018089979, "Episode": 4914, "Episode Step": 633}
{"Training Time": 24.96547600362036, "Episode Reward": 37242.99020910156, "Mean Reward": 61.15433531872178, "Episode": 4915, "Episode Step": 609}
{"Training Time": 25.024182520839904, "Episode Reward": 334497.7116679041, "Mean Reward": 66.89954233358083, "Episode": 4916, "Episode Step": 5000}
{"Training Time": 25.030203857223192, "Episode Reward": 30146.02224008176, "Mean Reward": 64.0042935033583, "Episode": 4917, "Episode Step": 471}
{"Training Time": 25.032284362249904, "Episode Reward": 8866.084202848142, "Mean Reward": 51.249041634960356, "Episode": 4918, "Episode Step": 173}
{"Training Time": 25.042300735579598, "Episode Reward": 55778.36274668574, "Mean Reward": 65.9318708589666, "Episode": 4919, "Episode Step": 846}
{"Training Time": 25.044953794413143, "Episode Reward": 9048.723977932743, "Mean Reward": 49.177847706156214, "Episode": 4920, "Episode Step": 184}
{"Training Time": 25.04702335000038, "Episode Reward": 9122.653532184417, "Mean Reward": 52.73210134210645, "Episode": 4921, "Episode Step": 173}
{"Training Time": 25.049122084445422, "Episode Reward": 8891.083463846322, "Mean Reward": 50.806191221978985, "Episode": 4922, "Episode Step": 175}
{"Training Time": 25.056796861953206, "Episode Reward": 39490.03732235623, "Mean Reward": 64.42094179829728, "Episode": 4923, "Episode Step": 613}
{"Training Time": 25.061432018611168, "Episode Reward": 25487.746623360672, "Mean Reward": 64.68971224203216, "Episode": 4924, "Episode Step": 394}
{"Training Time": 25.06350902001063, "Episode Reward": 8193.487184125368, "Mean Reward": 47.089006805318206, "Episode": 4925, "Episode Step": 174}
{"Training Time": 25.06606539275911, "Episode Reward": 9413.58563563442, "Mean Reward": 53.18409963635265, "Episode": 4926, "Episode Step": 177}
{"Training Time": 25.067034179700745, "Episode Reward": 4728.837522077145, "Mean Reward": 57.66875026923348, "Episode": 4927, "Episode Step": 82}
{"Training Time": 25.069098407493698, "Episode Reward": 9016.522874685073, "Mean Reward": 51.8190969809487, "Episode": 4928, "Episode Step": 174}
{"Training Time": 25.07673442999522, "Episode Reward": 38958.26321387153, "Mean Reward": 63.657292833123414, "Episode": 4929, "Episode Step": 612}
{"Training Time": 25.088799777759448, "Episode Reward": 68408.43035972066, "Mean Reward": 65.65108479819641, "Episode": 4930, "Episode Step": 1042}
{"Training Time": 25.09086897386445, "Episode Reward": 8290.316699131115, "Mean Reward": 46.57481291646694, "Episode": 4931, "Episode Step": 178}
{"Training Time": 25.09347648806042, "Episode Reward": 9329.202835356355, "Mean Reward": 51.25935623822173, "Episode": 4932, "Episode Step": 182}
{"Training Time": 25.094679976966646, "Episode Reward": 6025.360430897477, "Mean Reward": 58.498644960169685, "Episode": 4933, "Episode Step": 103}
{"Training Time": 25.096773338052962, "Episode Reward": 8998.71131748214, "Mean Reward": 50.84017693492735, "Episode": 4934, "Episode Step": 177}
{"Training Time": 25.116829712788263, "Episode Reward": 114368.31483679618, "Mean Reward": 68.81366717015415, "Episode": 4935, "Episode Step": 1662}
{"Training Time": 25.129895935257277, "Episode Reward": 74977.17922751592, "Mean Reward": 66.82458041668086, "Episode": 4936, "Episode Step": 1122}
{"Training Time": 25.13701455944114, "Episode Reward": 38569.806691153746, "Mean Reward": 63.54169141870469, "Episode": 4937, "Episode Step": 607}
{"Training Time": 25.14150441057152, "Episode Reward": 21866.46650349969, "Mean Reward": 64.6936878801766, "Episode": 4938, "Episode Step": 338}
{"Training Time": 25.144915883077516, "Episode Reward": 18871.741815835416, "Mean Reward": 65.98511124417978, "Episode": 4939, "Episode Step": 286}
{"Training Time": 25.147045491668912, "Episode Reward": 9047.977426146152, "Mean Reward": 50.5473599226042, "Episode": 4940, "Episode Step": 179}
{"Training Time": 25.20215919918484, "Episode Reward": 302608.3075991433, "Mean Reward": 64.46704465256568, "Episode": 4941, "Episode Step": 4694}
{"Training Time": 25.204171274171934, "Episode Reward": 8774.165132203401, "Mean Reward": 51.01258797792675, "Episode": 4942, "Episode Step": 172}
{"Training Time": 25.206217540568776, "Episode Reward": 8888.14580032217, "Mean Reward": 51.08129770300098, "Episode": 4943, "Episode Step": 174}
{"Training Time": 25.219866656131213, "Episode Reward": 72909.77610830462, "Mean Reward": 64.12469314714566, "Episode": 4944, "Episode Step": 1137}
{"Training Time": 25.22187387638622, "Episode Reward": 8456.332322756845, "Mean Reward": 49.452235805595585, "Episode": 4945, "Episode Step": 171}
{"Training Time": 25.225958410832618, "Episode Reward": 21621.42743607238, "Mean Reward": 61.250502651763114, "Episode": 4946, "Episode Step": 353}
{"Training Time": 25.22853741692172, "Episode Reward": 8761.352215214489, "Mean Reward": 48.9461017609748, "Episode": 4947, "Episode Step": 179}
{"Training Time": 25.245527686079342, "Episode Reward": 97100.6166065101, "Mean Reward": 66.05484122891843, "Episode": 4948, "Episode Step": 1470}
{"Training Time": 25.25375044418706, "Episode Reward": 37870.60615312876, "Mean Reward": 61.67851165004684, "Episode": 4949, "Episode Step": 614}
{"Training Time": 25.25698607530859, "Episode Reward": 15027.77316236832, "Mean Reward": 63.14190404356437, "Episode": 4950, "Episode Step": 238}
{"Training Time": 25.262594460844994, "Episode Reward": 32639.67497980113, "Mean Reward": 67.85795214095869, "Episode": 4951, "Episode Step": 481}
{"Training Time": 25.269831599725617, "Episode Reward": 37724.28636481998, "Mean Reward": 61.14146898674227, "Episode": 4952, "Episode Step": 617}
{"Training Time": 25.27335225303968, "Episode Reward": 16256.68487235386, "Mean Reward": 63.01040648199171, "Episode": 4953, "Episode Step": 258}
{"Training Time": 25.275328596962822, "Episode Reward": 8371.88261472044, "Mean Reward": 50.131033621080476, "Episode": 4954, "Episode Step": 167}
{"Training Time": 25.277430742250548, "Episode Reward": 9115.798554129335, "Mean Reward": 52.38964686281227, "Episode": 4955, "Episode Step": 174}
{"Training Time": 25.285151180028915, "Episode Reward": 38720.59582088784, "Mean Reward": 62.553466592710556, "Episode": 4956, "Episode Step": 619}
{"Training Time": 25.287784551646975, "Episode Reward": 13187.299676919047, "Mean Reward": 58.35088352619047, "Episode": 4957, "Episode Step": 226}
{"Training Time": 25.294977756407526, "Episode Reward": 38775.51342392026, "Mean Reward": 64.304334036352, "Episode": 4958, "Episode Step": 603}
{"Training Time": 25.307193630006577, "Episode Reward": 64106.728588941136, "Mean Reward": 65.14911441965563, "Episode": 4959, "Episode Step": 984}
{"Training Time": 25.310779051118427, "Episode Reward": 18386.019108484037, "Mean Reward": 61.49170270395999, "Episode": 4960, "Episode Step": 299}
{"Training Time": 25.312921125557686, "Episode Reward": 9045.887074265702, "Mean Reward": 51.1067066342695, "Episode": 4961, "Episode Step": 177}
{"Training Time": 25.32070663081275, "Episode Reward": 38055.304809853194, "Mean Reward": 61.979323794549174, "Episode": 4962, "Episode Step": 614}
{"Training Time": 25.33326321164767, "Episode Reward": 66854.04482395573, "Mean Reward": 64.09783779861527, "Episode": 4963, "Episode Step": 1043}
{"Training Time": 25.340487495263417, "Episode Reward": 38780.84405961956, "Mean Reward": 63.889364183887245, "Episode": 4964, "Episode Step": 607}
{"Training Time": 25.34228158944183, "Episode Reward": 5971.872055075173, "Mean Reward": 55.81188836518854, "Episode": 4965, "Episode Step": 107}
{"Training Time": 25.34354758501053, "Episode Reward": 5461.1600150607, "Mean Reward": 53.0209710200068, "Episode": 4966, "Episode Step": 103}
{"Training Time": 25.34574059638712, "Episode Reward": 8641.725305107502, "Mean Reward": 48.549018568019676, "Episode": 4967, "Episode Step": 178}
{"Training Time": 25.364014668597115, "Episode Reward": 97040.57201187254, "Mean Reward": 65.21543818002188, "Episode": 4968, "Episode Step": 1488}
{"Training Time": 25.367597143318918, "Episode Reward": 17975.45055750045, "Mean Reward": 59.918168525001505, "Episode": 4969, "Episode Step": 300}
{"Training Time": 25.369771920575037, "Episode Reward": 8326.393878809591, "Mean Reward": 47.04177332660786, "Episode": 4970, "Episode Step": 177}
{"Training Time": 25.38808407664299, "Episode Reward": 101373.5361415732, "Mean Reward": 67.67258754444138, "Episode": 4971, "Episode Step": 1498}
{"Training Time": 25.390134089456666, "Episode Reward": 8706.686609718927, "Mean Reward": 50.916295963268574, "Episode": 4972, "Episode Step": 171}
{"Training Time": 25.39225557638539, "Episode Reward": 7871.738296258899, "Mean Reward": 44.22324885538708, "Episode": 4973, "Episode Step": 178}
{"Training Time": 25.40003965775172, "Episode Reward": 39642.166199388485, "Mean Reward": 64.88079574368001, "Episode": 4974, "Episode Step": 611}
{"Training Time": 25.402823934157688, "Episode Reward": 13477.16253789645, "Mean Reward": 57.841899304276616, "Episode": 4975, "Episode Step": 233}
{"Training Time": 25.404871152771843, "Episode Reward": 8058.014092669047, "Mean Reward": 46.848919143424695, "Episode": 4976, "Episode Step": 172}
{"Training Time": 25.428119904465145, "Episode Reward": 129222.54037682708, "Mean Reward": 66.88537286585253, "Episode": 4977, "Episode Step": 1932}
{"Training Time": 25.43020524084568, "Episode Reward": 9236.874509641797, "Mean Reward": 52.48224153205567, "Episode": 4978, "Episode Step": 176}
{"Training Time": 25.431686537530688, "Episode Reward": 5532.95383251319, "Mean Reward": 43.91233200407294, "Episode": 4979, "Episode Step": 126}
{"Training Time": 25.43503062003189, "Episode Reward": 16867.24258406998, "Mean Reward": 68.56602676451212, "Episode": 4980, "Episode Step": 246}
{"Training Time": 25.436272763344977, "Episode Reward": 5823.0502465694435, "Mean Reward": 56.53446841329557, "Episode": 4981, "Episode Step": 103}
{"Training Time": 25.438363821970093, "Episode Reward": 8786.625515142387, "Mean Reward": 49.64195206295134, "Episode": 4982, "Episode Step": 177}
{"Training Time": 25.45523349304994, "Episode Reward": 94080.17537616836, "Mean Reward": 66.53477749375415, "Episode": 4983, "Episode Step": 1414}
{"Training Time": 25.45733247723844, "Episode Reward": 8120.907118470221, "Mean Reward": 45.88083117779786, "Episode": 4984, "Episode Step": 177}
{"Training Time": 25.474895537495613, "Episode Reward": 91968.81130877916, "Mean Reward": 61.80699684729782, "Episode": 4985, "Episode Step": 1488}
{"Training Time": 25.492721457216476, "Episode Reward": 96280.62360800212, "Mean Reward": 65.14250582408803, "Episode": 4986, "Episode Step": 1478}
{"Training Time": 25.494771832227705, "Episode Reward": 8985.641745631343, "Mean Reward": 51.940125697291, "Episode": 4987, "Episode Step": 173}
{"Training Time": 25.500489613877402, "Episode Reward": 30641.151683351887, "Mean Reward": 62.78924525277026, "Episode": 4988, "Episode Step": 488}
{"Training Time": 25.503036972483, "Episode Reward": 8533.088632850826, "Mean Reward": 48.48345814119787, "Episode": 4989, "Episode Step": 176}
{"Training Time": 25.509071234464646, "Episode Reward": 34472.90775265022, "Mean Reward": 66.93768495660237, "Episode": 4990, "Episode Step": 515}
{"Training Time": 25.52135002752145, "Episode Reward": 62834.04168620223, "Mean Reward": 60.07078555086255, "Episode": 4991, "Episode Step": 1046}
{"Training Time": 25.523876929746734, "Episode Reward": 8839.003383240793, "Mean Reward": 50.50859076137596, "Episode": 4992, "Episode Step": 175}
{"Training Time": 25.526562436421713, "Episode Reward": 14054.839891147149, "Mean Reward": 61.915594234128406, "Episode": 4993, "Episode Step": 227}
{"Training Time": 25.527866671681405, "Episode Reward": 4998.196197114703, "Mean Reward": 45.4381472464973, "Episode": 4994, "Episode Step": 110}
{"Training Time": 25.53511386639542, "Episode Reward": 34701.08264635774, "Mean Reward": 60.98608549447757, "Episode": 4995, "Episode Step": 569}
{"Training Time": 25.542183878355555, "Episode Reward": 37947.12926519599, "Mean Reward": 63.66967997516105, "Episode": 4996, "Episode Step": 596}
{"Training Time": 25.547084602514904, "Episode Reward": 24359.996009050068, "Mean Reward": 59.12620390546133, "Episode": 4997, "Episode Step": 412}
{"Training Time": 25.550264345275032, "Episode Reward": 13578.459343656268, "Mean Reward": 60.0816785117534, "Episode": 4998, "Episode Step": 226}
{"Training Time": 25.554168001678256, "Episode Reward": 13888.633096530564, "Mean Reward": 59.86479782987312, "Episode": 4999, "Episode Step": 232}
{"Training Time": 25.556582087808184, "Episode Reward": 7658.823618363011, "Mean Reward": 43.02709897956748, "Episode": 5000, "Episode Step": 178}
{"Training Time": 25.55918333027098, "Episode Reward": 8726.067106158132, "Mean Reward": 48.748978246693476, "Episode": 5001, "Episode Step": 179}
{"Training Time": 25.560787073903615, "Episode Reward": 6020.089671912997, "Mean Reward": 44.26536523465439, "Episode": 5002, "Episode Step": 136}
{"Training Time": 25.583337831960783, "Episode Reward": 116794.7669941865, "Mean Reward": 61.05319759236095, "Episode": 5003, "Episode Step": 1913}
{"Training Time": 25.58594453500377, "Episode Reward": 9529.296140623961, "Mean Reward": 53.236291288402015, "Episode": 5004, "Episode Step": 179}
{"Training Time": 25.588046929174, "Episode Reward": 8541.469374077238, "Mean Reward": 48.53107598907522, "Episode": 5005, "Episode Step": 176}
{"Training Time": 25.60341766026285, "Episode Reward": 84784.1916007401, "Mean Reward": 64.62209725666166, "Episode": 5006, "Episode Step": 1312}
{"Training Time": 25.605970377524695, "Episode Reward": 9091.723614775165, "Mean Reward": 50.79175203785008, "Episode": 5007, "Episode Step": 179}
{"Training Time": 25.608986513084837, "Episode Reward": 14451.937075378213, "Mean Reward": 57.80774830151285, "Episode": 5008, "Episode Step": 250}
{"Training Time": 25.611925969454976, "Episode Reward": 15795.527471596955, "Mean Reward": 64.47154070039574, "Episode": 5009, "Episode Step": 245}
{"Training Time": 25.619754028055404, "Episode Reward": 39904.76448290573, "Mean Reward": 65.41764669328809, "Episode": 5010, "Episode Step": 610}
{"Training Time": 25.622419338623683, "Episode Reward": 12052.568912895986, "Mean Reward": 54.04739422823312, "Episode": 5011, "Episode Step": 223}
{"Training Time": 25.632976901663675, "Episode Reward": 57235.622266607075, "Mean Reward": 64.52719534003053, "Episode": 5012, "Episode Step": 887}
{"Training Time": 25.63554023279084, "Episode Reward": 8771.996876269697, "Mean Reward": 49.84089134244146, "Episode": 5013, "Episode Step": 176}
{"Training Time": 25.6382185855839, "Episode Reward": 13046.409210985972, "Mean Reward": 57.221093030640226, "Episode": 5014, "Episode Step": 228}
{"Training Time": 25.651384651925827, "Episode Reward": 72142.4221725144, "Mean Reward": 64.70172392153758, "Episode": 5015, "Episode Step": 1115}
{"Training Time": 25.653994865285025, "Episode Reward": 8951.184241653244, "Mean Reward": 50.287551919400244, "Episode": 5016, "Episode Step": 178}
{"Training Time": 25.656783060034115, "Episode Reward": 12931.126558717908, "Mean Reward": 56.467801566453744, "Episode": 5017, "Episode Step": 229}
{"Training Time": 25.659609280029933, "Episode Reward": 14175.006101521816, "Mean Reward": 60.836936058033544, "Episode": 5018, "Episode Step": 233}
{"Training Time": 25.662246062755585, "Episode Reward": 9159.625731098977, "Mean Reward": 50.60566702264628, "Episode": 5019, "Episode Step": 181}
{"Training Time": 25.665267518030273, "Episode Reward": 16106.102730631268, "Mean Reward": 64.94396262351317, "Episode": 5020, "Episode Step": 248}
{"Training Time": 25.667295101682345, "Episode Reward": 7898.2254050766405, "Mean Reward": 46.460149441627294, "Episode": 5021, "Episode Step": 170}
{"Training Time": 25.677794387804138, "Episode Reward": 54931.40764323957, "Mean Reward": 65.47247633282427, "Episode": 5022, "Episode Step": 839}
{"Training Time": 25.680490736365318, "Episode Reward": 13686.759055516895, "Mean Reward": 59.767506792650195, "Episode": 5023, "Episode Step": 229}
{"Training Time": 25.689676246643067, "Episode Reward": 49114.005986058204, "Mean Reward": 63.701693885938006, "Episode": 5024, "Episode Step": 771}
{"Training Time": 25.69223519278897, "Episode Reward": 9008.468057604148, "Mean Reward": 51.47696032916656, "Episode": 5025, "Episode Step": 175}
{"Training Time": 25.700805805855328, "Episode Reward": 47631.62601063203, "Mean Reward": 66.15503612587783, "Episode": 5026, "Episode Step": 720}
{"Training Time": 25.72344437248177, "Episode Reward": 124218.00944902966, "Mean Reward": 64.76434277843047, "Episode": 5027, "Episode Step": 1918}
{"Training Time": 25.728849285840987, "Episode Reward": 25636.361232386498, "Mean Reward": 62.68058981023594, "Episode": 5028, "Episode Step": 409}
{"Training Time": 25.73100276834435, "Episode Reward": 7750.076019159789, "Mean Reward": 43.296514073518374, "Episode": 5029, "Episode Step": 179}
{"Training Time": 25.743442462219132, "Episode Reward": 65636.82543332009, "Mean Reward": 63.11233214742316, "Episode": 5030, "Episode Step": 1040}
{"Training Time": 25.76112916694747, "Episode Reward": 96933.80024030962, "Mean Reward": 67.54968657861298, "Episode": 5031, "Episode Step": 1435}
{"Training Time": 25.762608016398218, "Episode Reward": 5612.275225366415, "Mean Reward": 46.38243987906128, "Episode": 5032, "Episode Step": 121}
{"Training Time": 25.76555489752028, "Episode Reward": 15499.30447393355, "Mean Reward": 62.75022054224109, "Episode": 5033, "Episode Step": 247}
{"Training Time": 25.77287475248178, "Episode Reward": 36699.691692402695, "Mean Reward": 64.61213326127235, "Episode": 5034, "Episode Step": 568}
{"Training Time": 25.77408910082446, "Episode Reward": 4915.286545425108, "Mean Reward": 48.18908377867753, "Episode": 5035, "Episode Step": 102}
{"Training Time": 25.77704682363404, "Episode Reward": 16179.098329810024, "Mean Reward": 65.76869239760173, "Episode": 5036, "Episode Step": 246}
{"Training Time": 25.78426266974873, "Episode Reward": 37126.98019015767, "Mean Reward": 65.71146936311092, "Episode": 5037, "Episode Step": 565}
{"Training Time": 25.790381437208918, "Episode Reward": 32906.41988142741, "Mean Reward": 64.14506799498521, "Episode": 5038, "Episode Step": 513}
{"Training Time": 25.80060515721639, "Episode Reward": 55203.73471633135, "Mean Reward": 65.17560179023772, "Episode": 5039, "Episode Step": 847}
{"Training Time": 25.80270604636934, "Episode Reward": 6415.598236473819, "Mean Reward": 47.173516444660436, "Episode": 5040, "Episode Step": 136}
{"Training Time": 25.80488355749183, "Episode Reward": 9085.883802574215, "Mean Reward": 51.04429102569784, "Episode": 5041, "Episode Step": 178}
{"Training Time": 25.838653840819994, "Episode Reward": 187472.53831244967, "Mean Reward": 66.85896516135865, "Episode": 5042, "Episode Step": 2804}
{"Training Time": 25.841209820575184, "Episode Reward": 8604.482057958667, "Mean Reward": 48.88910260203788, "Episode": 5043, "Episode Step": 176}
{"Training Time": 25.843373943302367, "Episode Reward": 8065.88830443645, "Mean Reward": 45.31397923840702, "Episode": 5044, "Episode Step": 178}
{"Training Time": 25.8455087719361, "Episode Reward": 8577.855689837546, "Mean Reward": 48.19020050470532, "Episode": 5045, "Episode Step": 178}
{"Training Time": 25.84879376941257, "Episode Reward": 13229.261274007473, "Mean Reward": 57.269529324707676, "Episode": 5046, "Episode Step": 231}
{"Training Time": 25.856681750284302, "Episode Reward": 42272.305211435814, "Mean Reward": 64.43948965157898, "Episode": 5047, "Episode Step": 656}
{"Training Time": 25.863830565810204, "Episode Reward": 37790.8138543921, "Mean Reward": 62.98468975732017, "Episode": 5048, "Episode Step": 600}
{"Training Time": 25.87123435417811, "Episode Reward": 32464.154160912483, "Mean Reward": 66.93640033177832, "Episode": 5049, "Episode Step": 485}
{"Training Time": 25.873652999136183, "Episode Reward": 8469.83968785448, "Mean Reward": 47.58336903289034, "Episode": 5050, "Episode Step": 178}
{"Training Time": 25.877208991977902, "Episode Reward": 18038.208380288652, "Mean Reward": 61.774686233865246, "Episode": 5051, "Episode Step": 292}
{"Training Time": 25.88460560778777, "Episode Reward": 36612.65560833088, "Mean Reward": 64.34561618335832, "Episode": 5052, "Episode Step": 569}
{"Training Time": 25.8881151308616, "Episode Reward": 17094.672523334542, "Mean Reward": 58.94714663218808, "Episode": 5053, "Episode Step": 290}
{"Training Time": 25.8960286955701, "Episode Reward": 42831.57731630344, "Mean Reward": 64.79815025159371, "Episode": 5054, "Episode Step": 661}
{"Training Time": 25.898085229727958, "Episode Reward": 6539.563738946251, "Mean Reward": 48.80271446974814, "Episode": 5055, "Episode Step": 134}
{"Training Time": 25.900193621648683, "Episode Reward": 8004.8196198884325, "Mean Reward": 46.00471045912892, "Episode": 5056, "Episode Step": 174}
{"Training Time": 25.932799433072407, "Episode Reward": 180788.06274872544, "Mean Reward": 66.44177241776018, "Episode": 5057, "Episode Step": 2721}
{"Training Time": 25.940722823871507, "Episode Reward": 37584.83012453218, "Mean Reward": 60.62069374924545, "Episode": 5058, "Episode Step": 620}
{"Training Time": 25.942786318858463, "Episode Reward": 9090.500863905927, "Mean Reward": 53.16082376553174, "Episode": 5059, "Episode Step": 171}
{"Training Time": 25.948538531661033, "Episode Reward": 31406.772776300855, "Mean Reward": 65.43077661729345, "Episode": 5060, "Episode Step": 480}
{"Training Time": 25.956416699753866, "Episode Reward": 38380.589264291455, "Mean Reward": 61.60608228618211, "Episode": 5061, "Episode Step": 623}
{"Training Time": 25.97262034224139, "Episode Reward": 90858.5613787309, "Mean Reward": 66.51432018940768, "Episode": 5062, "Episode Step": 1366}
{"Training Time": 25.98885616613759, "Episode Reward": 93109.40965085816, "Mean Reward": 67.8145736714189, "Episode": 5063, "Episode Step": 1373}
{"Training Time": 25.996620589428478, "Episode Reward": 37312.38307652759, "Mean Reward": 61.06773007614991, "Episode": 5064, "Episode Step": 611}
{"Training Time": 25.998714183635183, "Episode Reward": 8016.207694224083, "Mean Reward": 46.336460660254815, "Episode": 5065, "Episode Step": 173}
{"Training Time": 26.0066756439209, "Episode Reward": 44588.745480418365, "Mean Reward": 66.84969337394058, "Episode": 5066, "Episode Step": 667}
{"Training Time": 26.022256662249564, "Episode Reward": 87503.99274843784, "Mean Reward": 68.90078169168333, "Episode": 5067, "Episode Step": 1270}
{"Training Time": 26.02695255835851, "Episode Reward": 24821.522499758245, "Mean Reward": 62.68061237312688, "Episode": 5068, "Episode Step": 396}
{"Training Time": 26.0382658525308, "Episode Reward": 66532.03262384237, "Mean Reward": 69.81325563886922, "Episode": 5069, "Episode Step": 953}
{"Training Time": 26.040795522530875, "Episode Reward": 8545.508802337084, "Mean Reward": 48.83147887049763, "Episode": 5070, "Episode Step": 175}
{"Training Time": 26.04222950498263, "Episode Reward": 5763.596375995369, "Mean Reward": 47.24259324586368, "Episode": 5071, "Episode Step": 122}
{"Training Time": 26.044266599151822, "Episode Reward": 8721.900021424823, "Mean Reward": 51.005263283186096, "Episode": 5072, "Episode Step": 171}
{"Training Time": 26.046876436670622, "Episode Reward": 8398.991630105575, "Mean Reward": 47.18534623654817, "Episode": 5073, "Episode Step": 178}
{"Training Time": 26.050244601964952, "Episode Reward": 17046.79882536056, "Mean Reward": 60.02393952591747, "Episode": 5074, "Episode Step": 284}
{"Training Time": 26.06428821888235, "Episode Reward": 78450.0499622948, "Mean Reward": 67.1086826024763, "Episode": 5075, "Episode Step": 1169}
{"Training Time": 26.072047602468068, "Episode Reward": 38174.0591728998, "Mean Reward": 62.17273480928306, "Episode": 5076, "Episode Step": 614}
{"Training Time": 26.074771559172206, "Episode Reward": 13281.666169934466, "Mean Reward": 58.768434380241, "Episode": 5077, "Episode Step": 226}
{"Training Time": 26.086333344446288, "Episode Reward": 65118.36370359096, "Mean Reward": 66.78806533701638, "Episode": 5078, "Episode Step": 975}
{"Training Time": 26.088919255865946, "Episode Reward": 8528.452380788314, "Mean Reward": 48.18334678411477, "Episode": 5079, "Episode Step": 177}
{"Training Time": 26.091017990840808, "Episode Reward": 8151.571603458128, "Mean Reward": 46.580409162617876, "Episode": 5080, "Episode Step": 175}
{"Training Time": 26.109223238892024, "Episode Reward": 105889.15278500554, "Mean Reward": 68.93825051107132, "Episode": 5081, "Episode Step": 1536}
{"Training Time": 26.112647834751343, "Episode Reward": 15580.104890843286, "Mean Reward": 62.5707023728646, "Episode": 5082, "Episode Step": 249}
{"Training Time": 26.116113456951247, "Episode Reward": 17783.693187899524, "Mean Reward": 61.96408776271611, "Episode": 5083, "Episode Step": 287}
{"Training Time": 26.175413995583853, "Episode Reward": 336080.1761415689, "Mean Reward": 67.21603522831379, "Episode": 5084, "Episode Step": 5000}
{"Training Time": 26.183322027193174, "Episode Reward": 37985.4799629157, "Mean Reward": 61.76500806978162, "Episode": 5085, "Episode Step": 615}
{"Training Time": 26.185425051914322, "Episode Reward": 8415.044548947491, "Mean Reward": 48.92467761015983, "Episode": 5086, "Episode Step": 172}
{"Training Time": 26.229226133624714, "Episode Reward": 253619.93918509816, "Mean Reward": 68.76896398728258, "Episode": 5087, "Episode Step": 3688}
{"Training Time": 26.23243405083815, "Episode Reward": 14195.344792753875, "Mean Reward": 62.811260144928646, "Episode": 5088, "Episode Step": 226}
{"Training Time": 26.23514115141498, "Episode Reward": 13570.09043394276, "Mean Reward": 60.3115130397456, "Episode": 5089, "Episode Step": 225}
{"Training Time": 26.238086055848335, "Episode Reward": 17407.101722994666, "Mean Reward": 71.93017240906887, "Episode": 5090, "Episode Step": 242}
{"Training Time": 26.240695574747193, "Episode Reward": 9078.52378705317, "Mean Reward": 51.87727878316097, "Episode": 5091, "Episode Step": 175}
{"Training Time": 26.24420199473699, "Episode Reward": 18991.022034922084, "Mean Reward": 65.94104873236834, "Episode": 5092, "Episode Step": 288}
{"Training Time": 26.24720043056541, "Episode Reward": 16746.761097949464, "Mean Reward": 68.35412693040597, "Episode": 5093, "Episode Step": 245}
{"Training Time": 26.253497126698495, "Episode Reward": 31540.79741425959, "Mean Reward": 65.16693680632146, "Episode": 5094, "Episode Step": 484}
{"Training Time": 26.256958437230853, "Episode Reward": 17492.6633883011, "Mean Reward": 60.52824701834291, "Episode": 5095, "Episode Step": 289}
{"Training Time": 26.25901837832398, "Episode Reward": 8372.291326980114, "Mean Reward": 48.67611236616345, "Episode": 5096, "Episode Step": 172}
{"Training Time": 26.267259056369465, "Episode Reward": 44059.84156126305, "Mean Reward": 66.96024553383442, "Episode": 5097, "Episode Step": 658}
{"Training Time": 26.275232356124455, "Episode Reward": 42302.24965489546, "Mean Reward": 63.42166365051793, "Episode": 5098, "Episode Step": 667}
{"Training Time": 26.284511942532326, "Episode Reward": 41992.0996691112, "Mean Reward": 61.212973278587754, "Episode": 5099, "Episode Step": 686}
{"Training Time": 26.287031963070234, "Episode Reward": 9044.54491259993, "Mean Reward": 53.203205368234876, "Episode": 5100, "Episode Step": 170}
{"Training Time": 26.290405154161984, "Episode Reward": 14644.766222988947, "Mean Reward": 52.490201516089414, "Episode": 5101, "Episode Step": 279}
{"Training Time": 26.29188012831741, "Episode Reward": 6070.019761984488, "Mean Reward": 50.1654525783842, "Episode": 5102, "Episode Step": 121}
{"Training Time": 26.303256851964527, "Episode Reward": 63075.43130601579, "Mean Reward": 68.8596411637727, "Episode": 5103, "Episode Step": 916}
{"Training Time": 26.309312965008946, "Episode Reward": 34774.180401421654, "Mean Reward": 68.45311102642057, "Episode": 5104, "Episode Step": 508}
{"Training Time": 26.317432060837746, "Episode Reward": 43601.090141672, "Mean Reward": 63.93121721652786, "Episode": 5105, "Episode Step": 682}
{"Training Time": 26.335728679696718, "Episode Reward": 96560.47573525006, "Mean Reward": 65.19951096235656, "Episode": 5106, "Episode Step": 1481}
{"Training Time": 26.33697535554568, "Episode Reward": 5639.382998924809, "Mean Reward": 55.28806861690989, "Episode": 5107, "Episode Step": 102}
{"Training Time": 26.337577323582437, "Episode Reward": 2356.5848420024777, "Mean Reward": 50.14010302132931, "Episode": 5108, "Episode Step": 47}
{"Training Time": 26.350057493050894, "Episode Reward": 65359.490138770816, "Mean Reward": 65.29419594282798, "Episode": 5109, "Episode Step": 1001}
{"Training Time": 26.35342391497559, "Episode Reward": 17912.717359215385, "Mean Reward": 63.29582105729818, "Episode": 5110, "Episode Step": 283}
{"Training Time": 26.35550159109963, "Episode Reward": 8343.633321487558, "Mean Reward": 47.95191564073309, "Episode": 5111, "Episode Step": 174}
{"Training Time": 26.37822291387452, "Episode Reward": 125553.73888546198, "Mean Reward": 66.39541982308936, "Episode": 5112, "Episode Step": 1891}
{"Training Time": 26.381542279720307, "Episode Reward": 19209.034333424715, "Mean Reward": 67.87644640786118, "Episode": 5113, "Episode Step": 283}
{"Training Time": 26.383620406654146, "Episode Reward": 8737.597369583718, "Mean Reward": 49.929127826192676, "Episode": 5114, "Episode Step": 175}
{"Training Time": 26.40246014303631, "Episode Reward": 104548.39022234804, "Mean Reward": 66.80408320916807, "Episode": 5115, "Episode Step": 1565}
{"Training Time": 26.409435026380752, "Episode Reward": 38049.067014929664, "Mean Reward": 64.27207266035416, "Episode": 5116, "Episode Step": 592}
{"Training Time": 26.422598046925334, "Episode Reward": 76186.38345492985, "Mean Reward": 67.7814799421084, "Episode": 5117, "Episode Step": 1124}
{"Training Time": 26.449868795275687, "Episode Reward": 152075.2662711146, "Mean Reward": 65.7764992522122, "Episode": 5118, "Episode Step": 2312}
{"Training Time": 26.455312851667404, "Episode Reward": 33036.24355822991, "Mean Reward": 70.59026401331177, "Episode": 5119, "Episode Step": 468}
{"Training Time": 26.46331188890669, "Episode Reward": 46713.53645505509, "Mean Reward": 68.59550140243037, "Episode": 5120, "Episode Step": 681}
{"Training Time": 26.485994838873545, "Episode Reward": 121684.67943668319, "Mean Reward": 64.21355115392252, "Episode": 5121, "Episode Step": 1895}
{"Training Time": 26.486598872211243, "Episode Reward": 2077.4882332941024, "Mean Reward": 41.54976466588205, "Episode": 5122, "Episode Step": 50}
{"Training Time": 26.489460343321163, "Episode Reward": 14991.81288466618, "Mean Reward": 61.94964001928174, "Episode": 5123, "Episode Step": 242}
{"Training Time": 26.5289453611109, "Episode Reward": 216649.19023102548, "Mean Reward": 64.82620892609978, "Episode": 5124, "Episode Step": 3342}
{"Training Time": 26.529530519180827, "Episode Reward": 2019.211664864447, "Mean Reward": 42.06690968467598, "Episode": 5125, "Episode Step": 48}
{"Training Time": 26.535187255011664, "Episode Reward": 31811.482393355833, "Mean Reward": 66.1361380319248, "Episode": 5126, "Episode Step": 481}
{"Training Time": 26.53854590806696, "Episode Reward": 16789.704866981792, "Mean Reward": 67.97451363150523, "Episode": 5127, "Episode Step": 247}
{"Training Time": 26.541447022226123, "Episode Reward": 15230.785596618847, "Mean Reward": 61.66309958145282, "Episode": 5128, "Episode Step": 247}
{"Training Time": 26.547046470310953, "Episode Reward": 31881.736886481915, "Mean Reward": 66.42028518017065, "Episode": 5129, "Episode Step": 480}
{"Training Time": 26.55472301363945, "Episode Reward": 37943.763415834364, "Mean Reward": 61.298486939958586, "Episode": 5130, "Episode Step": 619}
{"Training Time": 26.55756390498744, "Episode Reward": 16615.869792096903, "Mean Reward": 68.09782701679059, "Episode": 5131, "Episode Step": 244}
{"Training Time": 26.56538708223237, "Episode Reward": 46558.56827989873, "Mean Reward": 69.4904004177593, "Episode": 5132, "Episode Step": 670}
{"Training Time": 26.574057781696318, "Episode Reward": 45174.104041583654, "Mean Reward": 64.81220092049304, "Episode": 5133, "Episode Step": 697}
{"Training Time": 26.576979730526606, "Episode Reward": 13674.535151187485, "Mean Reward": 56.50634359994829, "Episode": 5134, "Episode Step": 242}
{"Training Time": 26.579927749170196, "Episode Reward": 16271.798170566675, "Mean Reward": 66.14552101856373, "Episode": 5135, "Episode Step": 246}
{"Training Time": 26.604353641404046, "Episode Reward": 134979.67789829083, "Mean Reward": 67.5573963454909, "Episode": 5136, "Episode Step": 1998}
{"Training Time": 26.607246529195045, "Episode Reward": 16040.519203550435, "Mean Reward": 67.39713951071612, "Episode": 5137, "Episode Step": 238}
{"Training Time": 26.61022017247147, "Episode Reward": 16043.418263173615, "Mean Reward": 65.48333984968822, "Episode": 5138, "Episode Step": 245}
{"Training Time": 26.618768100010023, "Episode Reward": 43597.47756528932, "Mean Reward": 65.07086203774526, "Episode": 5139, "Episode Step": 670}
{"Training Time": 26.621637704968453, "Episode Reward": 15371.001175407322, "Mean Reward": 64.5840385521316, "Episode": 5140, "Episode Step": 238}
{"Training Time": 26.623204176359707, "Episode Reward": 6322.863121544264, "Mean Reward": 50.1814533455894, "Episode": 5141, "Episode Step": 126}
{"Training Time": 26.631948931945693, "Episode Reward": 42837.22818009727, "Mean Reward": 62.99592379426069, "Episode": 5142, "Episode Step": 680}
{"Training Time": 26.634410688877107, "Episode Reward": 10693.887900787788, "Mean Reward": 52.42101912150876, "Episode": 5143, "Episode Step": 204}
{"Training Time": 26.64539534330368, "Episode Reward": 61553.513490285, "Mean Reward": 67.4928875989967, "Episode": 5144, "Episode Step": 912}
{"Training Time": 26.652801097499, "Episode Reward": 36528.77688077659, "Mean Reward": 63.86149804331571, "Episode": 5145, "Episode Step": 572}
{"Training Time": 26.65810277250078, "Episode Reward": 26018.00889958025, "Mean Reward": 59.131838408136936, "Episode": 5146, "Episode Step": 440}
{"Training Time": 26.661072058346537, "Episode Reward": 16487.65803188611, "Mean Reward": 67.5723689831398, "Episode": 5147, "Episode Step": 244}
{"Training Time": 26.68461675080988, "Episode Reward": 124619.4620123163, "Mean Reward": 64.56966943643332, "Episode": 5148, "Episode Step": 1930}
{"Training Time": 26.695956849455833, "Episode Reward": 50999.501298272655, "Mean Reward": 59.02720057670446, "Episode": 5149, "Episode Step": 864}
{"Training Time": 26.699246613581977, "Episode Reward": 16218.510947176765, "Mean Reward": 65.13458211717577, "Episode": 5150, "Episode Step": 249}
{"Training Time": 26.720975183910795, "Episode Reward": 119404.24246415793, "Mean Reward": 66.63183173223099, "Episode": 5151, "Episode Step": 1792}
{"Training Time": 26.723730274438857, "Episode Reward": 11049.130444686898, "Mean Reward": 47.83173352678311, "Episode": 5152, "Episode Step": 231}
{"Training Time": 26.734602713916036, "Episode Reward": 62145.29090138138, "Mean Reward": 67.84420404080936, "Episode": 5153, "Episode Step": 916}
{"Training Time": 26.764955693085987, "Episode Reward": 159298.68309251047, "Mean Reward": 63.56691264665223, "Episode": 5154, "Episode Step": 2506}
{"Training Time": 26.772590089970166, "Episode Reward": 37373.413813001986, "Mean Reward": 58.3048577425928, "Episode": 5155, "Episode Step": 641}
{"Training Time": 26.775578053063818, "Episode Reward": 16470.995287979986, "Mean Reward": 65.621495171235, "Episode": 5156, "Episode Step": 251}
{"Training Time": 26.788431858089236, "Episode Reward": 66690.95826058241, "Mean Reward": 63.51519834341182, "Episode": 5157, "Episode Step": 1050}
{"Training Time": 26.789685240851508, "Episode Reward": 5263.979456795388, "Mean Reward": 50.1331376837656, "Episode": 5158, "Episode Step": 105}
{"Training Time": 26.805864470269945, "Episode Reward": 91101.5328662605, "Mean Reward": 66.69219097090813, "Episode": 5159, "Episode Step": 1366}
{"Training Time": 26.814463864167532, "Episode Reward": 44264.19081824327, "Mean Reward": 64.52505950181234, "Episode": 5160, "Episode Step": 686}
{"Training Time": 26.816552606688607, "Episode Reward": 8183.778770526905, "Mean Reward": 47.305079598421415, "Episode": 5161, "Episode Step": 173}
{"Training Time": 26.824546112484402, "Episode Reward": 45442.54320763817, "Mean Reward": 66.7291383372073, "Episode": 5162, "Episode Step": 681}
{"Training Time": 26.827809828586048, "Episode Reward": 15885.039919872053, "Mean Reward": 67.30949118589854, "Episode": 5163, "Episode Step": 236}
{"Training Time": 26.830664766364627, "Episode Reward": 13630.300183344074, "Mean Reward": 56.792917430600305, "Episode": 5164, "Episode Step": 240}
{"Training Time": 26.833624686929916, "Episode Reward": 15681.8415952325, "Mean Reward": 63.23323223884072, "Episode": 5165, "Episode Step": 248}
{"Training Time": 26.893176476690503, "Episode Reward": 322544.81458147115, "Mean Reward": 64.50896291629422, "Episode": 5166, "Episode Step": 5000}
{"Training Time": 26.89469291885694, "Episode Reward": 5193.019737208961, "Mean Reward": 49.9328820885477, "Episode": 5167, "Episode Step": 104}
{"Training Time": 26.903849776652123, "Episode Reward": 48062.75491538173, "Mean Reward": 61.61891655818171, "Episode": 5168, "Episode Step": 780}
{"Training Time": 26.92368192308479, "Episode Reward": 109255.37666645812, "Mean Reward": 67.60852516488745, "Episode": 5169, "Episode Step": 1616}
{"Training Time": 26.93004395193524, "Episode Reward": 29729.062657864633, "Mean Reward": 55.776853016631584, "Episode": 5170, "Episode Step": 533}
{"Training Time": 26.958232481678326, "Episode Reward": 154285.3909826741, "Mean Reward": 65.01702106307378, "Episode": 5171, "Episode Step": 2373}
{"Training Time": 26.960345204141404, "Episode Reward": 6534.578861370491, "Mean Reward": 47.352020734568775, "Episode": 5172, "Episode Step": 138}
{"Training Time": 26.961635102762116, "Episode Reward": 4904.43906177656, "Mean Reward": 45.83587908202393, "Episode": 5173, "Episode Step": 107}
{"Training Time": 26.97491639998224, "Episode Reward": 72966.78043905825, "Mean Reward": 65.91398413645732, "Episode": 5174, "Episode Step": 1107}
{"Training Time": 27.002945810291504, "Episode Reward": 156039.67622369726, "Mean Reward": 67.43287650116562, "Episode": 5175, "Episode Step": 2314}
{"Training Time": 27.004199201663337, "Episode Reward": 4770.91065602994, "Mean Reward": 45.43724434314228, "Episode": 5176, "Episode Step": 105}
{"Training Time": 27.02448715031147, "Episode Reward": 114637.25560757788, "Mean Reward": 66.30263482219658, "Episode": 5177, "Episode Step": 1729}
{"Training Time": 27.02981515612867, "Episode Reward": 27055.641029881757, "Mean Reward": 65.51002670673549, "Episode": 5178, "Episode Step": 413}
{"Training Time": 27.032587144441074, "Episode Reward": 11981.170527328946, "Mean Reward": 52.09204577099542, "Episode": 5179, "Episode Step": 230}
{"Training Time": 27.03469013220734, "Episode Reward": 8552.816110478183, "Mean Reward": 48.32099497445301, "Episode": 5180, "Episode Step": 177}
{"Training Time": 27.036441043350433, "Episode Reward": 5811.652899231838, "Mean Reward": 54.826914143696584, "Episode": 5181, "Episode Step": 106}
{"Training Time": 27.044280629754066, "Episode Reward": 37854.57059905123, "Mean Reward": 58.05915736050802, "Episode": 5182, "Episode Step": 652}
{"Training Time": 27.05272420697742, "Episode Reward": 44640.245060673675, "Mean Reward": 64.230568432624, "Episode": 5183, "Episode Step": 695}
{"Training Time": 27.055362104177476, "Episode Reward": 8726.232790034752, "Mean Reward": 48.74990385494275, "Episode": 5184, "Episode Step": 179}
{"Training Time": 27.06678009139167, "Episode Reward": 58999.11010391373, "Mean Reward": 62.104326425172346, "Episode": 5185, "Episode Step": 950}
{"Training Time": 27.093143758310212, "Episode Reward": 141437.66017487305, "Mean Reward": 64.37763321569096, "Episode": 5186, "Episode Step": 2197}
{"Training Time": 27.099935830831527, "Episode Reward": 34477.279276657144, "Mean Reward": 65.7963344974373, "Episode": 5187, "Episode Step": 524}
{"Training Time": 27.102636276086173, "Episode Reward": 13980.957176876731, "Mean Reward": 62.41498739677112, "Episode": 5188, "Episode Step": 224}
{"Training Time": 27.11555675248305, "Episode Reward": 67906.9187963351, "Mean Reward": 62.81861128245615, "Episode": 5189, "Episode Step": 1081}
{"Training Time": 27.117293272217115, "Episode Reward": 6347.846661849901, "Mean Reward": 60.455682493808574, "Episode": 5190, "Episode Step": 105}
{"Training Time": 27.118552333315215, "Episode Reward": 4789.590563525583, "Mean Reward": 45.184816637033805, "Episode": 5191, "Episode Step": 106}
{"Training Time": 27.134137182765535, "Episode Reward": 87217.47311091522, "Mean Reward": 67.45357549181378, "Episode": 5192, "Episode Step": 1293}
{"Training Time": 27.13591239942445, "Episode Reward": 6103.959563082178, "Mean Reward": 57.04635105684278, "Episode": 5193, "Episode Step": 107}
{"Training Time": 27.137577166689766, "Episode Reward": 5575.954751327226, "Mean Reward": 40.99966728917078, "Episode": 5194, "Episode Step": 136}
{"Training Time": 27.15975542916192, "Episode Reward": 126955.28919264997, "Mean Reward": 68.47642351275618, "Episode": 5195, "Episode Step": 1854}
{"Training Time": 27.161474128630427, "Episode Reward": 5854.5609059873905, "Mean Reward": 55.2317066602584, "Episode": 5196, "Episode Step": 106}
{"Training Time": 27.185427511400647, "Episode Reward": 133433.6813469834, "Mean Reward": 66.38491609302656, "Episode": 5197, "Episode Step": 2010}
{"Training Time": 27.197374459703763, "Episode Reward": 64726.76337698272, "Mean Reward": 65.71245012891647, "Episode": 5198, "Episode Step": 985}
{"Training Time": 27.20388391415278, "Episode Reward": 26049.574127675667, "Mean Reward": 62.469002704258195, "Episode": 5199, "Episode Step": 417}
{"Training Time": 27.21276497138871, "Episode Reward": 48565.387562651085, "Mean Reward": 67.63981554686781, "Episode": 5200, "Episode Step": 718}
{"Training Time": 27.24624907275041, "Episode Reward": 185958.48180525447, "Mean Reward": 66.6040407611943, "Episode": 5201, "Episode Step": 2792}
{"Training Time": 27.24884724252754, "Episode Reward": 9079.826706729582, "Mean Reward": 50.72528886441107, "Episode": 5202, "Episode Step": 179}
{"Training Time": 27.266010376678572, "Episode Reward": 94688.69253345192, "Mean Reward": 65.80173212887556, "Episode": 5203, "Episode Step": 1439}
{"Training Time": 27.273211919135516, "Episode Reward": 39082.125605523695, "Mean Reward": 65.02849518389966, "Episode": 5204, "Episode Step": 601}
{"Training Time": 27.286146043075455, "Episode Reward": 66399.15447152083, "Mean Reward": 62.87798718894018, "Episode": 5205, "Episode Step": 1056}
{"Training Time": 27.2895943499936, "Episode Reward": 18459.38603966517, "Mean Reward": 63.217075478305375, "Episode": 5206, "Episode Step": 292}
{"Training Time": 27.32755394524998, "Episode Reward": 216991.1237645921, "Mean Reward": 67.6617161723081, "Episode": 5207, "Episode Step": 3207}
{"Training Time": 27.329684539172383, "Episode Reward": 6479.135627071793, "Mean Reward": 46.612486525696355, "Episode": 5208, "Episode Step": 139}
{"Training Time": 27.336864403618705, "Episode Reward": 35198.204016706084, "Mean Reward": 58.95846568962493, "Episode": 5209, "Episode Step": 597}
{"Training Time": 27.33962355832259, "Episode Reward": 14418.189095152873, "Mean Reward": 63.516251520497235, "Episode": 5210, "Episode Step": 227}
{"Training Time": 27.34684999499056, "Episode Reward": 35022.112641310916, "Mean Reward": 61.65864901639246, "Episode": 5211, "Episode Step": 568}
{"Training Time": 27.34840513335334, "Episode Reward": 6492.2256990927635, "Mean Reward": 49.18352802343003, "Episode": 5212, "Episode Step": 132}
{"Training Time": 27.360730118354162, "Episode Reward": 67806.50831789615, "Mean Reward": 65.13593498356978, "Episode": 5213, "Episode Step": 1041}
{"Training Time": 27.36603870636887, "Episode Reward": 24656.48310774785, "Mean Reward": 60.43255663663688, "Episode": 5214, "Episode Step": 408}
{"Training Time": 27.36807726389832, "Episode Reward": 8748.842689804658, "Mean Reward": 51.162822747395666, "Episode": 5215, "Episode Step": 171}
{"Training Time": 27.395602796938686, "Episode Reward": 158382.92605487062, "Mean Reward": 67.6850111345601, "Episode": 5216, "Episode Step": 2340}
{"Training Time": 27.40225935637951, "Episode Reward": 33577.680096868826, "Mean Reward": 64.20206519477787, "Episode": 5217, "Episode Step": 523}
{"Training Time": 27.40565439330207, "Episode Reward": 18104.724561381725, "Mean Reward": 63.303232732103936, "Episode": 5218, "Episode Step": 286}
{"Training Time": 27.425019258923, "Episode Reward": 110426.8147305787, "Mean Reward": 67.78809989599675, "Episode": 5219, "Episode Step": 1629}
{"Training Time": 27.440581590268348, "Episode Reward": 82851.49052550174, "Mean Reward": 65.03256713147702, "Episode": 5220, "Episode Step": 1274}
{"Training Time": 27.444051243861516, "Episode Reward": 18081.314010402923, "Mean Reward": 62.135099692106266, "Episode": 5221, "Episode Step": 291}
{"Training Time": 27.471400719417467, "Episode Reward": 153750.3732845923, "Mean Reward": 66.41484807109818, "Episode": 5222, "Episode Step": 2315}
{"Training Time": 27.475294549995, "Episode Reward": 18199.29493861203, "Mean Reward": 62.9733388879309, "Episode": 5223, "Episode Step": 289}
{"Training Time": 27.481441776421335, "Episode Reward": 33087.609942241885, "Mean Reward": 64.12327508186412, "Episode": 5224, "Episode Step": 516}
{"Training Time": 27.483548857503468, "Episode Reward": 8826.656998833008, "Mean Reward": 51.317773249029116, "Episode": 5225, "Episode Step": 172}
{"Training Time": 27.492682510018348, "Episode Reward": 47439.70923091764, "Mean Reward": 65.43408169781743, "Episode": 5226, "Episode Step": 725}
{"Training Time": 27.495629341933462, "Episode Reward": 16800.302277573315, "Mean Reward": 68.01741812782718, "Episode": 5227, "Episode Step": 247}
{"Training Time": 27.502669945028092, "Episode Reward": 37410.793405317534, "Mean Reward": 63.087341324312874, "Episode": 5228, "Episode Step": 593}
{"Training Time": 27.505228412217566, "Episode Reward": 9125.462491537352, "Mean Reward": 51.55628526292289, "Episode": 5229, "Episode Step": 177}
{"Training Time": 27.507284470266764, "Episode Reward": 9148.739229904293, "Mean Reward": 52.57896109140398, "Episode": 5230, "Episode Step": 174}
{"Training Time": 27.5092767983675, "Episode Reward": 8206.11358492331, "Mean Reward": 49.434419186285005, "Episode": 5231, "Episode Step": 166}
{"Training Time": 27.511376240849494, "Episode Reward": 6168.051411562377, "Mean Reward": 45.35331920266454, "Episode": 5232, "Episode Step": 136}
{"Training Time": 27.51340642637677, "Episode Reward": 8727.626482886084, "Mean Reward": 51.95015763622669, "Episode": 5233, "Episode Step": 168}
{"Training Time": 27.516061391366854, "Episode Reward": 13924.796459470012, "Mean Reward": 62.72430837599104, "Episode": 5234, "Episode Step": 222}
{"Training Time": 27.518184897502262, "Episode Reward": 6503.52386982941, "Mean Reward": 47.12698456398123, "Episode": 5235, "Episode Step": 138}
{"Training Time": 27.51918127053314, "Episode Reward": 4712.6130214646255, "Mean Reward": 56.77847013812802, "Episode": 5236, "Episode Step": 83}
{"Training Time": 27.521874319447413, "Episode Reward": 14241.894782607997, "Mean Reward": 63.29731014492443, "Episode": 5237, "Episode Step": 225}
{"Training Time": 27.5239547850026, "Episode Reward": 6468.886381789129, "Mean Reward": 48.27527150588902, "Episode": 5238, "Episode Step": 134}
{"Training Time": 27.535741842190426, "Episode Reward": 63941.55283094606, "Mean Reward": 64.1983462158093, "Episode": 5239, "Episode Step": 996}
{"Training Time": 27.53972263753414, "Episode Reward": 21327.577361209842, "Mean Reward": 63.099341305354564, "Episode": 5240, "Episode Step": 338}
{"Training Time": 27.54638987362385, "Episode Reward": 33630.381475661845, "Mean Reward": 64.67381053011893, "Episode": 5241, "Episode Step": 520}
{"Training Time": 27.54801797111829, "Episode Reward": 6565.162168669055, "Mean Reward": 48.630830879030036, "Episode": 5242, "Episode Step": 135}
{"Training Time": 27.552230095532206, "Episode Reward": 21753.659323085045, "Mean Reward": 62.69066087344393, "Episode": 5243, "Episode Step": 347}
{"Training Time": 27.5548687038819, "Episode Reward": 7587.446301535601, "Mean Reward": 42.86692825726328, "Episode": 5244, "Episode Step": 177}
{"Training Time": 27.56330781724718, "Episode Reward": 47761.90840123259, "Mean Reward": 67.55574031291738, "Episode": 5245, "Episode Step": 707}
{"Training Time": 27.564884945551555, "Episode Reward": 6127.476914826014, "Mean Reward": 47.13443780635395, "Episode": 5246, "Episode Step": 130}
{"Training Time": 27.568374483320447, "Episode Reward": 15946.862518934435, "Mean Reward": 63.78745007573774, "Episode": 5247, "Episode Step": 250}
{"Training Time": 27.57447248220444, "Episode Reward": 34935.04586550416, "Mean Reward": 68.90541590829223, "Episode": 5248, "Episode Step": 507}
{"Training Time": 27.59302231444253, "Episode Reward": 98207.76557341557, "Mean Reward": 66.990290295645, "Episode": 5249, "Episode Step": 1466}
{"Training Time": 27.5955977180269, "Episode Reward": 8827.700706494175, "Mean Reward": 49.874015290927545, "Episode": 5250, "Episode Step": 177}
{"Training Time": 27.5983003052738, "Episode Reward": 14048.667534760742, "Mean Reward": 61.616962871757636, "Episode": 5251, "Episode Step": 228}
{"Training Time": 27.600353492233488, "Episode Reward": 8803.945777224877, "Mean Reward": 51.48506302470688, "Episode": 5252, "Episode Step": 171}
{"Training Time": 27.608074815008376, "Episode Reward": 37928.42521006023, "Mean Reward": 61.974550996830445, "Episode": 5253, "Episode Step": 612}
{"Training Time": 27.609299181964662, "Episode Reward": 5941.266705628756, "Mean Reward": 58.247712800281924, "Episode": 5254, "Episode Step": 102}
{"Training Time": 27.610557707746825, "Episode Reward": 5724.724771983438, "Mean Reward": 55.04543049984075, "Episode": 5255, "Episode Step": 104}
{"Training Time": 27.62091438803408, "Episode Reward": 56216.69412280911, "Mean Reward": 67.2448494291975, "Episode": 5256, "Episode Step": 836}
{"Training Time": 27.623041711913213, "Episode Reward": 8733.437320161755, "Mean Reward": 48.79015262660198, "Episode": 5257, "Episode Step": 179}
{"Training Time": 27.624285547799534, "Episode Reward": 5666.38403437925, "Mean Reward": 55.01343722698301, "Episode": 5258, "Episode Step": 103}
{"Training Time": 27.626848660575018, "Episode Reward": 9020.902400117546, "Mean Reward": 50.96555028314997, "Episode": 5259, "Episode Step": 177}
{"Training Time": 27.629730684691005, "Episode Reward": 16259.710276869266, "Mean Reward": 66.63815687241502, "Episode": 5260, "Episode Step": 244}
{"Training Time": 27.640964497526486, "Episode Reward": 63744.79671629301, "Mean Reward": 66.74847823695603, "Episode": 5261, "Episode Step": 955}
{"Training Time": 27.64494332081742, "Episode Reward": 18008.06301551367, "Mean Reward": 60.429741662797554, "Episode": 5262, "Episode Step": 298}
{"Training Time": 27.649145024749966, "Episode Reward": 22158.477243539946, "Mean Reward": 62.77189020832846, "Episode": 5263, "Episode Step": 353}
{"Training Time": 27.651913864745033, "Episode Reward": 15505.391780272093, "Mean Reward": 66.54674583807765, "Episode": 5264, "Episode Step": 233}
{"Training Time": 27.654471206400128, "Episode Reward": 8557.113417443594, "Mean Reward": 48.619962599111325, "Episode": 5265, "Episode Step": 176}
{"Training Time": 27.656584046416814, "Episode Reward": 8972.13053462296, "Mean Reward": 51.56396858978713, "Episode": 5266, "Episode Step": 174}
{"Training Time": 27.65817337638802, "Episode Reward": 5898.9882449202905, "Mean Reward": 44.689304885759775, "Episode": 5267, "Episode Step": 132}
{"Training Time": 27.67621939526664, "Episode Reward": 95043.09478408797, "Mean Reward": 64.30520621386195, "Episode": 5268, "Episode Step": 1478}
{"Training Time": 27.68704684085316, "Episode Reward": 61371.999243419414, "Mean Reward": 67.36772694118487, "Episode": 5269, "Episode Step": 911}
{"Training Time": 27.746031071941058, "Episode Reward": 345903.3330176786, "Mean Reward": 69.18066660353571, "Episode": 5270, "Episode Step": 5000}
{"Training Time": 27.748581654429437, "Episode Reward": 8811.029726063856, "Mean Reward": 51.22691701199916, "Episode": 5271, "Episode Step": 172}
{"Training Time": 27.750644589993687, "Episode Reward": 8760.24319560491, "Mean Reward": 52.14430473574351, "Episode": 5272, "Episode Step": 168}
{"Training Time": 27.78657710108492, "Episode Reward": 214266.38988284112, "Mean Reward": 70.7616875438709, "Episode": 5273, "Episode Step": 3028}
{"Training Time": 27.808185440566806, "Episode Reward": 120837.07747175018, "Mean Reward": 68.26953529477412, "Episode": 5274, "Episode Step": 1770}
{"Training Time": 27.825692762798734, "Episode Reward": 95285.57555939269, "Mean Reward": 65.0413485047049, "Episode": 5275, "Episode Step": 1465}
{"Training Time": 27.83218630472819, "Episode Reward": 37008.694793540926, "Mean Reward": 67.4111016275791, "Episode": 5276, "Episode Step": 549}
{"Training Time": 27.83983294725418, "Episode Reward": 38209.13472488711, "Mean Reward": 63.05137743380711, "Episode": 5277, "Episode Step": 606}
{"Training Time": 27.853080689178572, "Episode Reward": 71075.39213270834, "Mean Reward": 64.0896232035242, "Episode": 5278, "Episode Step": 1109}
{"Training Time": 27.854547189739016, "Episode Reward": 5763.272166730235, "Mean Reward": 47.239935792870774, "Episode": 5279, "Episode Step": 122}
{"Training Time": 27.86697519030836, "Episode Reward": 65406.29288874984, "Mean Reward": 65.60310219533585, "Episode": 5280, "Episode Step": 997}
{"Training Time": 27.877303456399176, "Episode Reward": 55431.39544356588, "Mean Reward": 64.45511098089057, "Episode": 5281, "Episode Step": 860}
{"Training Time": 27.87790442360772, "Episode Reward": 2240.5078027775694, "Mean Reward": 45.72464903627693, "Episode": 5282, "Episode Step": 49}
{"Training Time": 27.885540245307816, "Episode Reward": 38071.00187608992, "Mean Reward": 63.031460059751524, "Episode": 5283, "Episode Step": 604}
{"Training Time": 27.8927642061313, "Episode Reward": 39473.12251375304, "Mean Reward": 65.02985587109232, "Episode": 5284, "Episode Step": 607}
{"Training Time": 27.893941673636437, "Episode Reward": 5213.2006588056265, "Mean Reward": 54.304173529225274, "Episode": 5285, "Episode Step": 96}
{"Training Time": 27.91772748053074, "Episode Reward": 136458.15756413701, "Mean Reward": 69.19784866335549, "Episode": 5286, "Episode Step": 1972}
{"Training Time": 27.922497892512215, "Episode Reward": 26201.919166921114, "Mean Reward": 66.16646254273009, "Episode": 5287, "Episode Step": 396}
{"Training Time": 27.92388355864419, "Episode Reward": 5901.72619388879, "Mean Reward": 51.319358207728605, "Episode": 5288, "Episode Step": 115}
{"Training Time": 27.935014849437607, "Episode Reward": 58584.55181400018, "Mean Reward": 65.0939464600002, "Episode": 5289, "Episode Step": 900}
{"Training Time": 27.93561256918642, "Episode Reward": 2882.98568366441, "Mean Reward": 58.836442523763466, "Episode": 5290, "Episode Step": 49}
{"Training Time": 27.937031069729063, "Episode Reward": 6093.751548110722, "Mean Reward": 52.53234093198898, "Episode": 5291, "Episode Step": 116}
{"Training Time": 27.961075311700505, "Episode Reward": 136172.85859319495, "Mean Reward": 68.87853241942081, "Episode": 5292, "Episode Step": 1977}
{"Training Time": 27.961671556962862, "Episode Reward": 2710.718646727378, "Mean Reward": 55.320788708722006, "Episode": 5293, "Episode Step": 49}
{"Training Time": 27.962925239139132, "Episode Reward": 5493.618228409493, "Mean Reward": 53.85900223930876, "Episode": 5294, "Episode Step": 102}
{"Training Time": 27.970683766404786, "Episode Reward": 37059.20195402407, "Mean Reward": 61.254879262849705, "Episode": 5295, "Episode Step": 605}
{"Training Time": 27.972669973903233, "Episode Reward": 8957.54124694722, "Mean Reward": 53.96109184907964, "Episode": 5296, "Episode Step": 166}
{"Training Time": 27.98428884221448, "Episode Reward": 65103.34625715599, "Mean Reward": 66.63597365113202, "Episode": 5297, "Episode Step": 977}
{"Training Time": 28.000471835864914, "Episode Reward": 89464.10828835177, "Mean Reward": 67.31686101456116, "Episode": 5298, "Episode Step": 1329}
{"Training Time": 28.00316468609704, "Episode Reward": 8541.161881312892, "Mean Reward": 47.450899340627174, "Episode": 5299, "Episode Step": 180}
{"Training Time": 28.006368695828648, "Episode Reward": 16595.410216272245, "Mean Reward": 67.73636822968263, "Episode": 5300, "Episode Step": 245}
{"Training Time": 28.024313686357605, "Episode Reward": 94966.55551281129, "Mean Reward": 63.950542432869554, "Episode": 5301, "Episode Step": 1485}
{"Training Time": 28.026429024736085, "Episode Reward": 8860.542967533343, "Mean Reward": 49.77833127827721, "Episode": 5302, "Episode Step": 178}
{"Training Time": 28.05775022274918, "Episode Reward": 178714.98875516208, "Mean Reward": 67.13560809735615, "Episode": 5303, "Episode Step": 2662}
{"Training Time": 28.083834885292582, "Episode Reward": 145158.90431934103, "Mean Reward": 67.64161431469759, "Episode": 5304, "Episode Step": 2146}
{"Training Time": 28.085910984741318, "Episode Reward": 8948.427137385796, "Mean Reward": 51.725012354831186, "Episode": 5305, "Episode Step": 173}
{"Training Time": 28.0869272061189, "Episode Reward": 5115.189356462068, "Mean Reward": 61.628787427253826, "Episode": 5306, "Episode Step": 83}
{"Training Time": 28.11890572640631, "Episode Reward": 174429.95858191085, "Mean Reward": 65.32957250258833, "Episode": 5307, "Episode Step": 2670}
{"Training Time": 28.119521618882814, "Episode Reward": 2687.7756445226205, "Mean Reward": 54.85256417393103, "Episode": 5308, "Episode Step": 49}
{"Training Time": 28.122456923590764, "Episode Reward": 16715.453841013546, "Mean Reward": 68.50595836480962, "Episode": 5309, "Episode Step": 244}
{"Training Time": 28.13613720364041, "Episode Reward": 72120.05309683169, "Mean Reward": 65.14909945513251, "Episode": 5310, "Episode Step": 1107}
{"Training Time": 28.137376371357178, "Episode Reward": 5310.199262773221, "Mean Reward": 52.06077708601197, "Episode": 5311, "Episode Step": 102}
{"Training Time": 28.139395811955133, "Episode Reward": 8140.942075128711, "Mean Reward": 48.17125488241841, "Episode": 5312, "Episode Step": 169}
{"Training Time": 28.15585724969705, "Episode Reward": 88063.7637480538, "Mean Reward": 65.86668941514868, "Episode": 5313, "Episode Step": 1337}
{"Training Time": 28.15644618358877, "Episode Reward": 2868.5239713735473, "Mean Reward": 61.03242492284143, "Episode": 5314, "Episode Step": 47}
{"Training Time": 28.157431241936155, "Episode Reward": 4879.964975072776, "Mean Reward": 60.246481173737976, "Episode": 5315, "Episode Step": 81}
{"Training Time": 28.163364207479688, "Episode Reward": 30682.980941343973, "Mean Reward": 66.12711409772407, "Episode": 5316, "Episode Step": 464}
{"Training Time": 28.163958074715403, "Episode Reward": 2640.1203089046307, "Mean Reward": 55.00250643551314, "Episode": 5317, "Episode Step": 48}
{"Training Time": 28.165960488054488, "Episode Reward": 8429.903618174201, "Mean Reward": 51.09032495863152, "Episode": 5318, "Episode Step": 165}
{"Training Time": 28.221440072788134, "Episode Reward": 301475.83263983676, "Mean Reward": 64.80563900254445, "Episode": 5319, "Episode Step": 4652}
{"Training Time": 28.22354006720914, "Episode Reward": 8434.390338869462, "Mean Reward": 48.19651622211121, "Episode": 5320, "Episode Step": 175}
{"Training Time": 28.226440502471394, "Episode Reward": 16624.262341538695, "Mean Reward": 68.13222271122416, "Episode": 5321, "Episode Step": 244}
{"Training Time": 28.237551215026112, "Episode Reward": 59449.21613012697, "Mean Reward": 66.20179969947324, "Episode": 5322, "Episode Step": 898}
{"Training Time": 28.23814589308368, "Episode Reward": 2772.182167988619, "Mean Reward": 57.75379516642956, "Episode": 5323, "Episode Step": 48}
{"Training Time": 28.244088090260824, "Episode Reward": 35448.745267575505, "Mean Reward": 70.61503041349702, "Episode": 5324, "Episode Step": 502}
{"Training Time": 28.259314741690954, "Episode Reward": 78937.96893472735, "Mean Reward": 64.38659782604189, "Episode": 5325, "Episode Step": 1226}
{"Training Time": 28.259923091663254, "Episode Reward": 2855.121782808957, "Mean Reward": 59.48170380851994, "Episode": 5326, "Episode Step": 48}
{"Training Time": 28.26626683248414, "Episode Reward": 34445.45279027425, "Mean Reward": 65.8612864058781, "Episode": 5327, "Episode Step": 523}
{"Training Time": 28.277801043325, "Episode Reward": 58546.4775663393, "Mean Reward": 63.430636583249516, "Episode": 5328, "Episode Step": 923}
{"Training Time": 28.278384011917645, "Episode Reward": 2796.210287660005, "Mean Reward": 59.49383590765969, "Episode": 5329, "Episode Step": 47}
{"Training Time": 28.285431786643134, "Episode Reward": 38025.49597615198, "Mean Reward": 64.55941591876397, "Episode": 5330, "Episode Step": 589}
{"Training Time": 28.299304804139666, "Episode Reward": 73273.40705833047, "Mean Reward": 65.13191738518265, "Episode": 5331, "Episode Step": 1125}
{"Training Time": 28.299916995565095, "Episode Reward": 2770.915378496264, "Mean Reward": 56.549293438699266, "Episode": 5332, "Episode Step": 49}
{"Training Time": 28.322458380858105, "Episode Reward": 129719.48196435759, "Mean Reward": 68.63464654198815, "Episode": 5333, "Episode Step": 1890}
{"Training Time": 28.330170386367374, "Episode Reward": 37164.93801709227, "Mean Reward": 60.727022903745535, "Episode": 5334, "Episode Step": 612}
{"Training Time": 28.33221483250459, "Episode Reward": 9053.31132447614, "Mean Reward": 53.56988949394166, "Episode": 5335, "Episode Step": 169}
{"Training Time": 28.35038441889816, "Episode Reward": 105061.9533461975, "Mean Reward": 68.71285372543983, "Episode": 5336, "Episode Step": 1529}
{"Training Time": 28.367789118621083, "Episode Reward": 87765.51880750565, "Mean Reward": 61.20329066074313, "Episode": 5337, "Episode Step": 1434}
{"Training Time": 28.372509417798785, "Episode Reward": 25311.65881624191, "Mean Reward": 63.27914704060478, "Episode": 5338, "Episode Step": 400}
{"Training Time": 28.432074582510523, "Episode Reward": 331836.0300003431, "Mean Reward": 66.36720600006862, "Episode": 5339, "Episode Step": 5000}
{"Training Time": 28.43467744304074, "Episode Reward": 8952.243278340091, "Mean Reward": 50.293501563708375, "Episode": 5340, "Episode Step": 178}
{"Training Time": 28.436814869973393, "Episode Reward": 8853.544313269822, "Mean Reward": 50.020024368756054, "Episode": 5341, "Episode Step": 177}
{"Training Time": 28.470172640283902, "Episode Reward": 182304.4259548291, "Mean Reward": 64.78479955750856, "Episode": 5342, "Episode Step": 2814}
{"Training Time": 28.47845484779941, "Episode Reward": 42857.9386388363, "Mean Reward": 64.83803122365552, "Episode": 5343, "Episode Step": 661}
{"Training Time": 28.479041255844965, "Episode Reward": 2863.260875642654, "Mean Reward": 58.43389542127865, "Episode": 5344, "Episode Step": 49}
{"Training Time": 28.510639842748642, "Episode Reward": 174696.0828742881, "Mean Reward": 65.16079182181578, "Episode": 5345, "Episode Step": 2681}
{"Training Time": 28.51262120280001, "Episode Reward": 6019.530764702568, "Mean Reward": 47.397880037028095, "Episode": 5346, "Episode Step": 127}
{"Training Time": 28.514748326937358, "Episode Reward": 8754.609209797303, "Mean Reward": 49.18319780785002, "Episode": 5347, "Episode Step": 178}
{"Training Time": 28.51689534081353, "Episode Reward": 8197.73328653865, "Mean Reward": 47.113409692750864, "Episode": 5348, "Episode Step": 174}
{"Training Time": 28.549895906647045, "Episode Reward": 168138.73242421757, "Mean Reward": 63.44857827328965, "Episode": 5349, "Episode Step": 2650}
{"Training Time": 28.556641717222004, "Episode Reward": 35802.43120927897, "Mean Reward": 66.1782462278724, "Episode": 5350, "Episode Step": 541}
{"Training Time": 28.562423433330324, "Episode Reward": 31685.902524634505, "Mean Reward": 64.93012812425103, "Episode": 5351, "Episode Step": 488}
{"Training Time": 28.576217813624275, "Episode Reward": 70545.44432751424, "Mean Reward": 63.440147776541586, "Episode": 5352, "Episode Step": 1112}
{"Training Time": 28.58090336614185, "Episode Reward": 26681.792529363713, "Mean Reward": 67.54884184649042, "Episode": 5353, "Episode Step": 395}
{"Training Time": 28.610045347478653, "Episode Reward": 158432.1801939388, "Mean Reward": 64.74547617243107, "Episode": 5354, "Episode Step": 2447}
{"Training Time": 28.612006889184315, "Episode Reward": 6325.134137044477, "Mean Reward": 50.19947727813077, "Episode": 5355, "Episode Step": 126}
{"Training Time": 28.614084043635263, "Episode Reward": 8634.569874181547, "Mean Reward": 50.79158749518557, "Episode": 5356, "Episode Step": 170}
{"Training Time": 28.668076215253937, "Episode Reward": 290311.311223575, "Mean Reward": 63.90299608707351, "Episode": 5357, "Episode Step": 4543}
{"Training Time": 28.67006103363302, "Episode Reward": 5793.412647015834, "Mean Reward": 45.617422417447514, "Episode": 5358, "Episode Step": 127}
{"Training Time": 28.676386636098226, "Episode Reward": 32730.18971360641, "Mean Reward": 61.63877535519098, "Episode": 5359, "Episode Step": 531}
{"Training Time": 28.72956383109093, "Episode Reward": 298092.3491711104, "Mean Reward": 66.31642918155961, "Episode": 5360, "Episode Step": 4495}
{"Training Time": 28.7357497486141, "Episode Reward": 31762.803918312948, "Mean Reward": 65.49031735734629, "Episode": 5361, "Episode Step": 485}
{"Training Time": 28.737760997811954, "Episode Reward": 8609.629340854684, "Mean Reward": 50.34870959564143, "Episode": 5362, "Episode Step": 171}
{"Training Time": 28.7534913949834, "Episode Reward": 88200.88800003564, "Mean Reward": 65.8707154593246, "Episode": 5363, "Episode Step": 1339}
{"Training Time": 28.75542864580949, "Episode Reward": 6362.922480796426, "Mean Reward": 51.731077079645736, "Episode": 5364, "Episode Step": 123}
{"Training Time": 28.756020545827017, "Episode Reward": 2921.3816675180997, "Mean Reward": 59.62003403098163, "Episode": 5365, "Episode Step": 49}
{"Training Time": 28.76173174030251, "Episode Reward": 31085.805744773188, "Mean Reward": 65.03306641165939, "Episode": 5366, "Episode Step": 478}
{"Training Time": 28.763716641399597, "Episode Reward": 6465.315806701781, "Mean Reward": 51.312030211918895, "Episode": 5367, "Episode Step": 126}
{"Training Time": 28.765811810824605, "Episode Reward": 8696.21667556737, "Mean Reward": 50.26714841368422, "Episode": 5368, "Episode Step": 173}
{"Training Time": 28.775573895838527, "Episode Reward": 54146.403002384024, "Mean Reward": 65.71165412910682, "Episode": 5369, "Episode Step": 824}
{"Training Time": 28.7826728855239, "Episode Reward": 34192.282985008125, "Mean Reward": 60.94881102496992, "Episode": 5370, "Episode Step": 561}
{"Training Time": 28.783941466410955, "Episode Reward": 5951.293084254764, "Mean Reward": 56.678981754807275, "Episode": 5371, "Episode Step": 105}
{"Training Time": 28.814656272199418, "Episode Reward": 174502.55557128377, "Mean Reward": 67.32351680990887, "Episode": 5372, "Episode Step": 2592}
{"Training Time": 28.821792408360377, "Episode Reward": 34041.881885782255, "Mean Reward": 60.68071637394341, "Episode": 5373, "Episode Step": 561}
{"Training Time": 28.824752328594524, "Episode Reward": 14634.565826917735, "Mean Reward": 58.77335673460938, "Episode": 5374, "Episode Step": 249}
{"Training Time": 28.851388078596855, "Episode Reward": 153745.4787457622, "Mean Reward": 68.27063887467239, "Episode": 5375, "Episode Step": 2252}
{"Training Time": 28.874072404437594, "Episode Reward": 121962.38235594906, "Mean Reward": 65.04660392317282, "Episode": 5376, "Episode Step": 1875}
{"Training Time": 28.876996690564685, "Episode Reward": 13127.567948637585, "Mean Reward": 53.58190999443912, "Episode": 5377, "Episode Step": 245}
{"Training Time": 28.904301335016886, "Episode Reward": 154878.21025967025, "Mean Reward": 67.01783221967557, "Episode": 5378, "Episode Step": 2311}
{"Training Time": 28.9062437088622, "Episode Reward": 6478.239967758146, "Mean Reward": 53.10032760457497, "Episode": 5379, "Episode Step": 122}
{"Training Time": 28.907838294439845, "Episode Reward": 5052.945341014195, "Mean Reward": 37.99207023318944, "Episode": 5380, "Episode Step": 133}
{"Training Time": 28.919326768053903, "Episode Reward": 62953.057871757985, "Mean Reward": 64.76652044419546, "Episode": 5381, "Episode Step": 972}
{"Training Time": 28.921849212778937, "Episode Reward": 8921.184368600048, "Mean Reward": 51.27117453218418, "Episode": 5382, "Episode Step": 174}
{"Training Time": 28.928151402804588, "Episode Reward": 33102.53270249286, "Mean Reward": 61.989761615155174, "Episode": 5383, "Episode Step": 534}
{"Training Time": 28.940525586936207, "Episode Reward": 65226.29446922338, "Mean Reward": 63.20377371048777, "Episode": 5384, "Episode Step": 1032}
{"Training Time": 28.942440322240195, "Episode Reward": 6505.47136802235, "Mean Reward": 53.76422618200289, "Episode": 5385, "Episode Step": 121}
{"Training Time": 28.953464961912896, "Episode Reward": 59525.112049084906, "Mean Reward": 64.14343970806563, "Episode": 5386, "Episode Step": 928}
{"Training Time": 28.991189406646622, "Episode Reward": 205387.55129850353, "Mean Reward": 64.22374962429754, "Episode": 5387, "Episode Step": 3198}
{"Training Time": 28.998313606116508, "Episode Reward": 35425.193985847036, "Mean Reward": 63.71437767238675, "Episode": 5388, "Episode Step": 556}
{"Training Time": 29.00362664057149, "Episode Reward": 28421.48522048674, "Mean Reward": 64.15685151351408, "Episode": 5389, "Episode Step": 443}
{"Training Time": 29.009127871923976, "Episode Reward": 28785.046528849485, "Mean Reward": 62.440448001842704, "Episode": 5390, "Episode Step": 461}
{"Training Time": 29.016301334434086, "Episode Reward": 34567.04852189772, "Mean Reward": 61.397954745821885, "Episode": 5391, "Episode Step": 563}
{"Training Time": 29.02495880636904, "Episode Reward": 45241.41164266735, "Mean Reward": 62.315993998164394, "Episode": 5392, "Episode Step": 726}
{"Training Time": 29.02773407611582, "Episode Reward": 12511.751344490283, "Mean Reward": 54.63646875323268, "Episode": 5393, "Episode Step": 229}
{"Training Time": 29.035610941913394, "Episode Reward": 38409.48873969785, "Mean Reward": 62.25200768184417, "Episode": 5394, "Episode Step": 617}
{"Training Time": 29.04949451724688, "Episode Reward": 74957.88184501888, "Mean Reward": 63.957237069128745, "Episode": 5395, "Episode Step": 1172}
{"Training Time": 29.061152246660658, "Episode Reward": 62150.10354625545, "Mean Reward": 63.28931114689964, "Episode": 5396, "Episode Step": 982}
{"Training Time": 29.073470982246928, "Episode Reward": 65808.03446209354, "Mean Reward": 66.27193802829157, "Episode": 5397, "Episode Step": 993}
{"Training Time": 29.080645244717598, "Episode Reward": 38026.8841260633, "Mean Reward": 62.85435392737735, "Episode": 5398, "Episode Step": 605}
{"Training Time": 29.083681314984958, "Episode Reward": 7627.39440863911, "Mean Reward": 46.50850249170189, "Episode": 5399, "Episode Step": 164}
{"Training Time": 29.089877639744017, "Episode Reward": 30841.71569996777, "Mean Reward": 64.52241778235935, "Episode": 5400, "Episode Step": 478}
{"Training Time": 29.096563104987144, "Episode Reward": 36497.81183955638, "Mean Reward": 65.29125552693449, "Episode": 5401, "Episode Step": 559}
{"Training Time": 29.108190824455686, "Episode Reward": 62485.407353238734, "Mean Reward": 64.3516038653334, "Episode": 5402, "Episode Step": 971}
{"Training Time": 29.11071083386739, "Episode Reward": 8962.559178260846, "Mean Reward": 51.508960794602565, "Episode": 5403, "Episode Step": 174}
{"Training Time": 29.112837167514694, "Episode Reward": 9334.799280045014, "Mean Reward": 53.03863227298303, "Episode": 5404, "Episode Step": 176}
{"Training Time": 29.135538635849954, "Episode Reward": 122458.02753047625, "Mean Reward": 64.55352004769439, "Episode": 5405, "Episode Step": 1897}
{"Training Time": 29.138803246683544, "Episode Reward": 14606.64390413168, "Mean Reward": 63.78447119708157, "Episode": 5406, "Episode Step": 229}
{"Training Time": 29.14046705669827, "Episode Reward": 6624.54516667664, "Mean Reward": 48.354344282311246, "Episode": 5407, "Episode Step": 137}
{"Training Time": 29.19204740557406, "Episode Reward": 286963.236005578, "Mean Reward": 66.34988115735908, "Episode": 5408, "Episode Step": 4325}
{"Training Time": 29.195311408903862, "Episode Reward": 14914.79616355257, "Mean Reward": 64.56621715823623, "Episode": 5409, "Episode Step": 231}
{"Training Time": 29.197455196115705, "Episode Reward": 9030.669932444887, "Mean Reward": 51.60382818539936, "Episode": 5410, "Episode Step": 175}
{"Training Time": 29.240684677759806, "Episode Reward": 238825.9470057634, "Mean Reward": 65.48559007561376, "Episode": 5411, "Episode Step": 3647}
{"Training Time": 29.246715999444326, "Episode Reward": 29968.47049431597, "Mean Reward": 64.17231369232542, "Episode": 5412, "Episode Step": 467}
{"Training Time": 29.247955811685987, "Episode Reward": 6166.875110660936, "Mean Reward": 60.45955990844055, "Episode": 5413, "Episode Step": 102}
{"Training Time": 29.24999808225367, "Episode Reward": 8493.236124807034, "Mean Reward": 50.25583505802979, "Episode": 5414, "Episode Step": 169}
{"Training Time": 29.25298752056228, "Episode Reward": 11930.176208684103, "Mean Reward": 57.63370149122755, "Episode": 5415, "Episode Step": 207}
{"Training Time": 29.25509510530366, "Episode Reward": 8934.576576976828, "Mean Reward": 52.248985830273845, "Episode": 5416, "Episode Step": 171}
{"Training Time": 29.266281463305155, "Episode Reward": 62536.5840765016, "Mean Reward": 66.52828093244851, "Episode": 5417, "Episode Step": 940}
{"Training Time": 29.269661282234722, "Episode Reward": 15767.972628021129, "Mean Reward": 65.15691168603772, "Episode": 5418, "Episode Step": 242}
{"Training Time": 29.27590464141634, "Episode Reward": 33929.44037208922, "Mean Reward": 65.24892379247927, "Episode": 5419, "Episode Step": 520}
{"Training Time": 29.278848075535564, "Episode Reward": 15497.526811935557, "Mean Reward": 63.255211477287986, "Episode": 5420, "Episode Step": 245}
{"Training Time": 29.28218354139063, "Episode Reward": 15974.352110079246, "Mean Reward": 66.28361871402177, "Episode": 5421, "Episode Step": 241}
{"Training Time": 29.28425593641069, "Episode Reward": 9267.566514644128, "Mean Reward": 53.56974863956143, "Episode": 5422, "Episode Step": 173}
{"Training Time": 29.33541906442907, "Episode Reward": 284273.67767462326, "Mean Reward": 65.71282424286252, "Episode": 5423, "Episode Step": 4326}
{"Training Time": 29.36197165330251, "Episode Reward": 151883.16686541826, "Mean Reward": 68.38503685971105, "Episode": 5424, "Episode Step": 2221}
{"Training Time": 29.368692226145004, "Episode Reward": 35658.27415133363, "Mean Reward": 63.448886390273366, "Episode": 5425, "Episode Step": 562}
{"Training Time": 29.37436063302888, "Episode Reward": 29690.610310936976, "Mean Reward": 62.114247512420455, "Episode": 5426, "Episode Step": 478}
{"Training Time": 29.403397128582, "Episode Reward": 160192.62758361863, "Mean Reward": 65.9228920097196, "Episode": 5427, "Episode Step": 2430}
{"Training Time": 29.405123773879474, "Episode Reward": 6365.386107557078, "Mean Reward": 44.513189563336205, "Episode": 5428, "Episode Step": 143}
{"Training Time": 29.413189230561258, "Episode Reward": 43306.15858452008, "Mean Reward": 63.68552733017659, "Episode": 5429, "Episode Step": 680}
{"Training Time": 29.41778970890575, "Episode Reward": 19638.371421360254, "Mean Reward": 55.79082790159163, "Episode": 5430, "Episode Step": 352}
{"Training Time": 29.433587573038206, "Episode Reward": 92704.2262987873, "Mean Reward": 68.77168123055438, "Episode": 5431, "Episode Step": 1348}
{"Training Time": 29.441381526125802, "Episode Reward": 43179.74156801601, "Mean Reward": 64.93194220754287, "Episode": 5432, "Episode Step": 665}
{"Training Time": 29.45183384358883, "Episode Reward": 54368.439675348505, "Mean Reward": 63.81272262364848, "Episode": 5433, "Episode Step": 852}
{"Training Time": 29.456865813334783, "Episode Reward": 26268.728018948892, "Mean Reward": 61.232466244636115, "Episode": 5434, "Episode Step": 429}
{"Training Time": 29.459783849981097, "Episode Reward": 16503.452104115695, "Mean Reward": 66.5461778391762, "Episode": 5435, "Episode Step": 248}
{"Training Time": 29.46228820025921, "Episode Reward": 8916.242917182317, "Mean Reward": 51.24277538610527, "Episode": 5436, "Episode Step": 174}
{"Training Time": 29.47016392442915, "Episode Reward": 42278.65666903326, "Mean Reward": 63.76871292463539, "Episode": 5437, "Episode Step": 663}
{"Training Time": 29.47719442612595, "Episode Reward": 38338.08256906428, "Mean Reward": 64.76027460990588, "Episode": 5438, "Episode Step": 592}
{"Training Time": 29.478894182509848, "Episode Reward": 5892.137328517978, "Mean Reward": 56.115593604933125, "Episode": 5439, "Episode Step": 105}
{"Training Time": 29.487430277533, "Episode Reward": 50191.95966762396, "Mean Reward": 69.13493067165835, "Episode": 5440, "Episode Step": 726}
{"Training Time": 29.49408392164442, "Episode Reward": 34477.49749908777, "Mean Reward": 61.022119467411976, "Episode": 5441, "Episode Step": 565}
{"Training Time": 29.496675894459088, "Episode Reward": 8720.153228574845, "Mean Reward": 49.26640242132681, "Episode": 5442, "Episode Step": 177}
{"Training Time": 29.500168544186486, "Episode Reward": 18168.745744921915, "Mean Reward": 62.22173200315724, "Episode": 5443, "Episode Step": 292}
{"Training Time": 29.503101357751422, "Episode Reward": 15512.266413274298, "Mean Reward": 63.31537311540529, "Episode": 5444, "Episode Step": 245}
{"Training Time": 29.506384071376587, "Episode Reward": 15299.478516393672, "Mean Reward": 64.28352317812467, "Episode": 5445, "Episode Step": 238}
{"Training Time": 29.519878260029685, "Episode Reward": 77404.44309738555, "Mean Reward": 67.72042265738018, "Episode": 5446, "Episode Step": 1143}
{"Training Time": 29.52277872138553, "Episode Reward": 16176.9493675189, "Mean Reward": 66.5718080967856, "Episode": 5447, "Episode Step": 243}
{"Training Time": 29.525328869753412, "Episode Reward": 8759.12487882907, "Mean Reward": 49.76775499334699, "Episode": 5448, "Episode Step": 176}
{"Training Time": 29.543920721080568, "Episode Reward": 100496.34569176225, "Mean Reward": 68.17933900390926, "Episode": 5449, "Episode Step": 1474}
{"Training Time": 29.564757390552096, "Episode Reward": 118009.16489998375, "Mean Reward": 67.66580556191728, "Episode": 5450, "Episode Step": 1744}
{"Training Time": 29.56734227836132, "Episode Reward": 8751.433277172953, "Mean Reward": 50.00819015527402, "Episode": 5451, "Episode Step": 175}
{"Training Time": 29.584854629437128, "Episode Reward": 98188.52557902515, "Mean Reward": 66.74950753162825, "Episode": 5452, "Episode Step": 1471}
{"Training Time": 29.58694388608138, "Episode Reward": 8455.804826794047, "Mean Reward": 48.877484547942466, "Episode": 5453, "Episode Step": 173}
{"Training Time": 29.59018313083384, "Episode Reward": 15485.417280547063, "Mean Reward": 65.6161749175723, "Episode": 5454, "Episode Step": 236}
{"Training Time": 29.59686885330412, "Episode Reward": 37752.06014308521, "Mean Reward": 67.05516899304655, "Episode": 5455, "Episode Step": 563}
{"Training Time": 29.59893277724584, "Episode Reward": 8260.554633584816, "Mean Reward": 47.74887071436309, "Episode": 5456, "Episode Step": 173}
{"Training Time": 29.60413732919428, "Episode Reward": 25878.74535801888, "Mean Reward": 64.37498845278328, "Episode": 5457, "Episode Step": 402}
{"Training Time": 29.605708464185398, "Episode Reward": 7009.594768978827, "Mean Reward": 53.10299067408202, "Episode": 5458, "Episode Step": 132}
{"Training Time": 29.60777033030987, "Episode Reward": 8206.190637049453, "Mean Reward": 47.71041068052007, "Episode": 5459, "Episode Step": 172}
{"Training Time": 29.610392484466235, "Episode Reward": 8973.525079510076, "Mean Reward": 50.413062244438635, "Episode": 5460, "Episode Step": 178}
{"Training Time": 29.615728304982184, "Episode Reward": 29889.466523636547, "Mean Reward": 67.62322742904196, "Episode": 5461, "Episode Step": 442}
{"Training Time": 29.618699376384416, "Episode Reward": 15065.943475136635, "Mean Reward": 61.49364683729239, "Episode": 5462, "Episode Step": 245}
{"Training Time": 29.62125451889303, "Episode Reward": 8808.69728954658, "Mean Reward": 51.21335633457314, "Episode": 5463, "Episode Step": 172}
{"Training Time": 29.627603990303147, "Episode Reward": 36186.844581669415, "Mean Reward": 67.76562655743336, "Episode": 5464, "Episode Step": 534}
{"Training Time": 29.63048958586322, "Episode Reward": 14329.802045094768, "Mean Reward": 59.21405803758169, "Episode": 5465, "Episode Step": 242}
{"Training Time": 29.63309692502022, "Episode Reward": 9324.659360398196, "Mean Reward": 52.38572674381009, "Episode": 5466, "Episode Step": 178}
{"Training Time": 29.63514478113916, "Episode Reward": 9115.148468477038, "Mean Reward": 53.935789754302, "Episode": 5467, "Episode Step": 169}
{"Training Time": 29.638151661952335, "Episode Reward": 16551.714422817084, "Mean Reward": 67.28339196267108, "Episode": 5468, "Episode Step": 246}
{"Training Time": 29.639870808323224, "Episode Reward": 6295.359852139834, "Mean Reward": 60.53230627057533, "Episode": 5469, "Episode Step": 104}
{"Training Time": 29.641326982511416, "Episode Reward": 6583.136133448599, "Mean Reward": 54.85946777873833, "Episode": 5470, "Episode Step": 120}
{"Training Time": 29.643436650302675, "Episode Reward": 8971.667572175025, "Mean Reward": 52.46589223494167, "Episode": 5471, "Episode Step": 171}
{"Training Time": 29.645969142516453, "Episode Reward": 8943.875666773489, "Mean Reward": 51.40158429180166, "Episode": 5472, "Episode Step": 174}
{"Training Time": 29.653194752203092, "Episode Reward": 39528.989363055865, "Mean Reward": 66.32380765613401, "Episode": 5473, "Episode Step": 596}
{"Training Time": 29.656156761977407, "Episode Reward": 16462.56693576901, "Mean Reward": 67.19415075824085, "Episode": 5474, "Episode Step": 245}
{"Training Time": 29.658740042249363, "Episode Reward": 9079.63902499402, "Mean Reward": 51.297395621435136, "Episode": 5475, "Episode Step": 177}
{"Training Time": 29.660840299725532, "Episode Reward": 8817.24006732507, "Mean Reward": 50.67379349037397, "Episode": 5476, "Episode Step": 174}
{"Training Time": 29.67400895025995, "Episode Reward": 74395.2364166136, "Mean Reward": 67.44808378659438, "Episode": 5477, "Episode Step": 1103}
{"Training Time": 29.682075824141503, "Episode Reward": 38548.89508081579, "Mean Reward": 61.38359089301877, "Episode": 5478, "Episode Step": 628}
{"Training Time": 29.689312086370258, "Episode Reward": 36556.66311511201, "Mean Reward": 60.6246486154428, "Episode": 5479, "Episode Step": 603}
{"Training Time": 29.69142845776346, "Episode Reward": 8925.594695670045, "Mean Reward": 50.71360622539798, "Episode": 5480, "Episode Step": 176}
{"Training Time": 29.69263698750072, "Episode Reward": 2816.4026065511093, "Mean Reward": 54.16158858752134, "Episode": 5481, "Episode Step": 52}
{"Training Time": 29.694800684981875, "Episode Reward": 9122.199518092042, "Mean Reward": 51.83067908006842, "Episode": 5482, "Episode Step": 176}
{"Training Time": 29.712247854471208, "Episode Reward": 95181.8641235194, "Mean Reward": 65.32729178004077, "Episode": 5483, "Episode Step": 1457}
{"Training Time": 29.71432962331507, "Episode Reward": 6905.700247743901, "Mean Reward": 50.777207703999274, "Episode": 5484, "Episode Step": 136}
{"Training Time": 29.725812189976374, "Episode Reward": 63432.51417423475, "Mean Reward": 65.66512854475647, "Episode": 5485, "Episode Step": 966}
{"Training Time": 29.727874430020652, "Episode Reward": 8546.892146574977, "Mean Reward": 49.69123341031963, "Episode": 5486, "Episode Step": 172}
{"Training Time": 29.72987533165349, "Episode Reward": 6829.802584930957, "Mean Reward": 54.638420679447655, "Episode": 5487, "Episode Step": 125}
{"Training Time": 29.7366509408421, "Episode Reward": 37351.15190838939, "Mean Reward": 66.3430762138355, "Episode": 5488, "Episode Step": 563}
{"Training Time": 29.744723396367498, "Episode Reward": 45417.073988165714, "Mean Reward": 67.68565422975516, "Episode": 5489, "Episode Step": 671}
{"Training Time": 29.750709031952752, "Episode Reward": 27131.70918272877, "Mean Reward": 58.34776168328768, "Episode": 5490, "Episode Step": 465}
{"Training Time": 29.757516990303994, "Episode Reward": 37108.98084924611, "Mean Reward": 65.44793800572506, "Episode": 5491, "Episode Step": 567}
{"Training Time": 29.758758749696945, "Episode Reward": 5580.554050190604, "Mean Reward": 54.71131421755494, "Episode": 5492, "Episode Step": 102}
{"Training Time": 29.76053124719196, "Episode Reward": 5697.516445590551, "Mean Reward": 51.79560405082319, "Episode": 5493, "Episode Step": 110}
{"Training Time": 29.767735633320278, "Episode Reward": 37828.42833322522, "Mean Reward": 62.94247642799538, "Episode": 5494, "Episode Step": 601}
{"Training Time": 29.790598522490924, "Episode Reward": 123009.44227609452, "Mean Reward": 64.70775501109654, "Episode": 5495, "Episode Step": 1901}
{"Training Time": 29.79323719580968, "Episode Reward": 8761.091256556298, "Mean Reward": 49.77892759406987, "Episode": 5496, "Episode Step": 176}
{"Training Time": 29.794894608921474, "Episode Reward": 7003.856425803619, "Mean Reward": 51.498944307379546, "Episode": 5497, "Episode Step": 136}
{"Training Time": 29.83709472219149, "Episode Reward": 234842.2662445388, "Mean Reward": 67.02119470449166, "Episode": 5498, "Episode Step": 3504}
{"Training Time": 29.84020163860586, "Episode Reward": 6877.027409427959, "Mean Reward": 52.49639243838137, "Episode": 5499, "Episode Step": 131}
{"Training Time": 29.852665731377073, "Episode Reward": 68613.5508489591, "Mean Reward": 67.40034464534293, "Episode": 5500, "Episode Step": 1018}
{"Training Time": 29.912656615840064, "Episode Reward": 348804.32689039607, "Mean Reward": 69.76086537807922, "Episode": 5501, "Episode Step": 5000}
{"Training Time": 29.924212702777652, "Episode Reward": 58815.97661104795, "Mean Reward": 63.65365434096098, "Episode": 5502, "Episode Step": 924}
{"Training Time": 29.93147631002797, "Episode Reward": 38247.345454716764, "Mean Reward": 63.114431443427, "Episode": 5503, "Episode Step": 606}
{"Training Time": 29.966306707527902, "Episode Reward": 205225.2729443676, "Mean Reward": 70.62122262366401, "Episode": 5504, "Episode Step": 2906}
{"Training Time": 29.96888218389617, "Episode Reward": 9339.843651305222, "Mean Reward": 52.767478255961706, "Episode": 5505, "Episode Step": 177}
{"Training Time": 29.970584418906107, "Episode Reward": 6290.95211205676, "Mean Reward": 45.25864828817813, "Episode": 5506, "Episode Step": 139}
{"Training Time": 29.97476534942786, "Episode Reward": 22592.492205430128, "Mean Reward": 65.48548465342066, "Episode": 5507, "Episode Step": 345}
{"Training Time": 29.98368836833371, "Episode Reward": 44886.2886011454, "Mean Reward": 64.30700372656935, "Episode": 5508, "Episode Step": 698}
{"Training Time": 29.98583502974775, "Episode Reward": 8486.301779430732, "Mean Reward": 47.94520779339397, "Episode": 5509, "Episode Step": 177}
{"Training Time": 30.04562523669667, "Episode Reward": 347019.0371943938, "Mean Reward": 69.40380743887876, "Episode": 5510, "Episode Step": 5000}
{"Training Time": 30.0473576022519, "Episode Reward": 5071.68703263775, "Mean Reward": 48.30178126321667, "Episode": 5511, "Episode Step": 105}
{"Training Time": 30.04941093722979, "Episode Reward": 9030.982473764698, "Mean Reward": 53.12342631626293, "Episode": 5512, "Episode Step": 170}
{"Training Time": 30.06866907556852, "Episode Reward": 110968.73849411831, "Mean Reward": 69.18250529558499, "Episode": 5513, "Episode Step": 1604}
{"Training Time": 30.070422145525615, "Episode Reward": 6231.277231831312, "Mean Reward": 58.78563426255955, "Episode": 5514, "Episode Step": 106}
{"Training Time": 30.08986197054386, "Episode Reward": 110780.98401686132, "Mean Reward": 67.7559535271323, "Episode": 5515, "Episode Step": 1635}
{"Training Time": 30.099102634456422, "Episode Reward": 54615.60981977344, "Mean Reward": 70.02001258945313, "Episode": 5516, "Episode Step": 780}
{"Training Time": 30.101747081677118, "Episode Reward": 9075.450137451418, "Mean Reward": 49.59262370192032, "Episode": 5517, "Episode Step": 183}
{"Training Time": 30.113164382775626, "Episode Reward": 62527.25722125331, "Mean Reward": 64.39470362641947, "Episode": 5518, "Episode Step": 971}
{"Training Time": 30.1247113408645, "Episode Reward": 67461.27363972721, "Mean Reward": 69.04941007136868, "Episode": 5519, "Episode Step": 977}
{"Training Time": 30.127297853893705, "Episode Reward": 8936.246097798963, "Mean Reward": 49.64581165443868, "Episode": 5520, "Episode Step": 180}
{"Training Time": 30.129293644163344, "Episode Reward": 8872.200399339952, "Mean Reward": 52.18941411376442, "Episode": 5521, "Episode Step": 170}
{"Training Time": 30.14081315000852, "Episode Reward": 68148.26241386854, "Mean Reward": 70.18358642004999, "Episode": 5522, "Episode Step": 971}
{"Training Time": 30.143435896635054, "Episode Reward": 9189.1169189211, "Mean Reward": 51.33584870905642, "Episode": 5523, "Episode Step": 179}
{"Training Time": 30.155810029175548, "Episode Reward": 69232.2399206269, "Mean Reward": 67.15057218295529, "Episode": 5524, "Episode Step": 1031}
{"Training Time": 30.188072028623687, "Episode Reward": 190894.27618043433, "Mean Reward": 70.38874490428995, "Episode": 5525, "Episode Step": 2712}
{"Training Time": 30.191415283613736, "Episode Reward": 14352.484230272605, "Mean Reward": 59.80201762613585, "Episode": 5526, "Episode Step": 240}
{"Training Time": 30.19342183219062, "Episode Reward": 9017.377586041435, "Mean Reward": 53.996272970308, "Episode": 5527, "Episode Step": 167}
{"Training Time": 30.195494225554995, "Episode Reward": 8983.839289191146, "Mean Reward": 52.84611346583027, "Episode": 5528, "Episode Step": 170}
{"Training Time": 30.198773436082735, "Episode Reward": 14579.782853283676, "Mean Reward": 62.574175335981444, "Episode": 5529, "Episode Step": 233}
{"Training Time": 30.206121787495082, "Episode Reward": 36115.29491729832, "Mean Reward": 59.302618911819906, "Episode": 5530, "Episode Step": 609}
{"Training Time": 30.2082333938943, "Episode Reward": 8726.136963079101, "Mean Reward": 49.58032365385853, "Episode": 5531, "Episode Step": 176}
{"Training Time": 30.21165391392178, "Episode Reward": 15821.024838484587, "Mean Reward": 63.28409935393835, "Episode": 5532, "Episode Step": 250}
{"Training Time": 30.218828697800635, "Episode Reward": 37192.82063141139, "Mean Reward": 62.09152025277361, "Episode": 5533, "Episode Step": 599}
{"Training Time": 30.22091952138477, "Episode Reward": 8776.072361829092, "Mean Reward": 51.023676522262164, "Episode": 5534, "Episode Step": 172}
{"Training Time": 30.223533509439893, "Episode Reward": 8775.288051523403, "Mean Reward": 49.29937107597417, "Episode": 5535, "Episode Step": 178}
{"Training Time": 30.226484256916574, "Episode Reward": 15891.91034198894, "Mean Reward": 64.33971798376089, "Episode": 5536, "Episode Step": 247}
{"Training Time": 30.233801301121712, "Episode Reward": 38683.73082323623, "Mean Reward": 63.415952169239716, "Episode": 5537, "Episode Step": 610}
{"Training Time": 30.23638506472111, "Episode Reward": 8828.097316702664, "Mean Reward": 49.876256026568726, "Episode": 5538, "Episode Step": 177}
{"Training Time": 30.241052479412822, "Episode Reward": 23652.080723942294, "Mean Reward": 60.64636083062127, "Episode": 5539, "Episode Step": 390}
{"Training Time": 30.242283142209054, "Episode Reward": 6054.924630331217, "Mean Reward": 59.36200617971781, "Episode": 5540, "Episode Step": 102}
{"Training Time": 30.244845072494613, "Episode Reward": 8751.903629609582, "Mean Reward": 49.44578321813323, "Episode": 5541, "Episode Step": 177}
{"Training Time": 30.247757908039624, "Episode Reward": 16160.48091985945, "Mean Reward": 66.50403670724053, "Episode": 5542, "Episode Step": 243}
{"Training Time": 30.254143249193827, "Episode Reward": 36830.645288388136, "Mean Reward": 68.5859316357321, "Episode": 5543, "Episode Step": 537}
{"Training Time": 30.260295382208295, "Episode Reward": 30749.11977340441, "Mean Reward": 64.5989911205975, "Episode": 5544, "Episode Step": 476}
{"Training Time": 30.26232626583841, "Episode Reward": 9018.551769343369, "Mean Reward": 54.32862511652632, "Episode": 5545, "Episode Step": 166}
{"Training Time": 30.279885488616095, "Episode Reward": 99410.65866049755, "Mean Reward": 67.30579462457519, "Episode": 5546, "Episode Step": 1477}
{"Training Time": 30.29382799612151, "Episode Reward": 73323.6949953835, "Mean Reward": 65.00327570512721, "Episode": 5547, "Episode Step": 1128}
{"Training Time": 30.295843838916884, "Episode Reward": 8962.591135344423, "Mean Reward": 53.66821039128397, "Episode": 5548, "Episode Step": 167}
{"Training Time": 30.313926159474583, "Episode Reward": 95618.0697150396, "Mean Reward": 66.86578301751021, "Episode": 5549, "Episode Step": 1430}
{"Training Time": 30.317396389974487, "Episode Reward": 16738.340168944214, "Mean Reward": 67.22224967447475, "Episode": 5550, "Episode Step": 249}
{"Training Time": 30.317975712219873, "Episode Reward": 2492.323306060829, "Mean Reward": 54.18094143610498, "Episode": 5551, "Episode Step": 46}
{"Training Time": 30.320121559434465, "Episode Reward": 8407.188168956505, "Mean Reward": 47.49823824269212, "Episode": 5552, "Episode Step": 177}
{"Training Time": 30.331512906418908, "Episode Reward": 59406.51477248986, "Mean Reward": 64.99618684079854, "Episode": 5553, "Episode Step": 914}
{"Training Time": 30.332088377806876, "Episode Reward": 2233.3495307538396, "Mean Reward": 48.55107675551825, "Episode": 5554, "Episode Step": 46}
{"Training Time": 30.348779221375782, "Episode Reward": 95546.89555574345, "Mean Reward": 68.39434184376768, "Episode": 5555, "Episode Step": 1397}
{"Training Time": 30.35139876332548, "Episode Reward": 8959.545282798681, "Mean Reward": 49.77525157110378, "Episode": 5556, "Episode Step": 180}
{"Training Time": 30.35197126441532, "Episode Reward": 2625.206105619401, "Mean Reward": 57.06969794824785, "Episode": 5557, "Episode Step": 46}
{"Training Time": 30.35355841332012, "Episode Reward": 6763.068220318611, "Mean Reward": 50.47065836058665, "Episode": 5558, "Episode Step": 134}
{"Training Time": 30.356237483024596, "Episode Reward": 8925.516896724388, "Mean Reward": 47.98664998238918, "Episode": 5559, "Episode Step": 186}
{"Training Time": 30.363398416108556, "Episode Reward": 38823.68312467185, "Mean Reward": 64.81416214469424, "Episode": 5560, "Episode Step": 599}
{"Training Time": 30.380115091933146, "Episode Reward": 98545.99971537046, "Mean Reward": 70.94744399954676, "Episode": 5561, "Episode Step": 1389}
{"Training Time": 30.387996281385423, "Episode Reward": 38618.136140410126, "Mean Reward": 61.98737743244001, "Episode": 5562, "Episode Step": 623}
{"Training Time": 30.394425799979103, "Episode Reward": 34055.34624813459, "Mean Reward": 63.893707782616495, "Episode": 5563, "Episode Step": 533}
{"Training Time": 30.39606858001815, "Episode Reward": 6950.182570146189, "Mean Reward": 51.86703410556858, "Episode": 5564, "Episode Step": 134}
{"Training Time": 30.39788644141621, "Episode Reward": 5584.366313691379, "Mean Reward": 49.41917091762282, "Episode": 5565, "Episode Step": 113}
{"Training Time": 30.415503247247802, "Episode Reward": 100481.83573918258, "Mean Reward": 68.54149777570436, "Episode": 5566, "Episode Step": 1466}
{"Training Time": 30.416194497214423, "Episode Reward": 2591.0028840996997, "Mean Reward": 47.10914334726727, "Episode": 5567, "Episode Step": 55}
{"Training Time": 30.424299009707237, "Episode Reward": 37215.76461407959, "Mean Reward": 58.2406331988726, "Episode": 5568, "Episode Step": 639}
{"Training Time": 30.436348403626017, "Episode Reward": 68453.8247308722, "Mean Reward": 66.84943821374239, "Episode": 5569, "Episode Step": 1024}
{"Training Time": 30.437574899726442, "Episode Reward": 6141.207549147098, "Mean Reward": 60.20791714850096, "Episode": 5570, "Episode Step": 102}
{"Training Time": 30.444826650553278, "Episode Reward": 35421.296614922954, "Mean Reward": 62.91526929826457, "Episode": 5571, "Episode Step": 563}
{"Training Time": 30.447825412220425, "Episode Reward": 16223.519124661021, "Mean Reward": 65.15469527976313, "Episode": 5572, "Episode Step": 249}
{"Training Time": 30.46502205140061, "Episode Reward": 94652.90766507598, "Mean Reward": 65.45844236865558, "Episode": 5573, "Episode Step": 1446}
{"Training Time": 30.473114452494514, "Episode Reward": 37664.12289230901, "Mean Reward": 59.22031901306448, "Episode": 5574, "Episode Step": 636}
{"Training Time": 30.48020843055513, "Episode Reward": 36774.38900808396, "Mean Reward": 61.909745804855156, "Episode": 5575, "Episode Step": 594}
{"Training Time": 30.49689659052425, "Episode Reward": 97749.69034394101, "Mean Reward": 69.27688897515308, "Episode": 5576, "Episode Step": 1411}
{"Training Time": 30.504829217526648, "Episode Reward": 36185.04904399902, "Mean Reward": 57.3455610839921, "Episode": 5577, "Episode Step": 631}
{"Training Time": 30.50773408472538, "Episode Reward": 17337.98960894165, "Mean Reward": 71.34975147712613, "Episode": 5578, "Episode Step": 243}
{"Training Time": 30.519165226419766, "Episode Reward": 66279.39587794687, "Mean Reward": 68.61221105377523, "Episode": 5579, "Episode Step": 966}
{"Training Time": 30.52184610247612, "Episode Reward": 8463.332843043141, "Mean Reward": 46.24772045378766, "Episode": 5580, "Episode Step": 183}
{"Training Time": 30.52385639972157, "Episode Reward": 8306.793929674319, "Mean Reward": 49.741281016013886, "Episode": 5581, "Episode Step": 167}
{"Training Time": 30.52509470919768, "Episode Reward": 6045.290448182925, "Mean Reward": 59.26755341355808, "Episode": 5582, "Episode Step": 102}
{"Training Time": 30.53113461971283, "Episode Reward": 28112.20936506686, "Mean Reward": 59.68621945874068, "Episode": 5583, "Episode Step": 471}
{"Training Time": 30.53448448750708, "Episode Reward": 18159.989629241158, "Mean Reward": 64.3971263448268, "Episode": 5584, "Episode Step": 282}
{"Training Time": 30.53611996114254, "Episode Reward": 6577.61955744073, "Mean Reward": 49.08671311522933, "Episode": 5585, "Episode Step": 134}
{"Training Time": 30.539564184414015, "Episode Reward": 15697.155780167675, "Mean Reward": 61.799825906171954, "Episode": 5586, "Episode Step": 254}
{"Training Time": 30.543035281697907, "Episode Reward": 18071.865386622296, "Mean Reward": 62.10263019457834, "Episode": 5587, "Episode Step": 291}
{"Training Time": 30.554703525304795, "Episode Reward": 65182.24748507351, "Mean Reward": 67.54637045085337, "Episode": 5588, "Episode Step": 965}
{"Training Time": 30.56273155530294, "Episode Reward": 36968.17436744494, "Mean Reward": 58.49394678393187, "Episode": 5589, "Episode Step": 632}
{"Training Time": 30.564790480004415, "Episode Reward": 8195.011506121024, "Mean Reward": 48.49119234391138, "Episode": 5590, "Episode Step": 169}
{"Training Time": 30.56688064608309, "Episode Reward": 8788.518552250654, "Mean Reward": 51.09603809448055, "Episode": 5591, "Episode Step": 172}
{"Training Time": 30.5703167680237, "Episode Reward": 14639.396402710803, "Mean Reward": 59.2688113470073, "Episode": 5592, "Episode Step": 247}
{"Training Time": 30.582461752494176, "Episode Reward": 67312.01775240606, "Mean Reward": 65.47861649066736, "Episode": 5593, "Episode Step": 1028}
{"Training Time": 30.585467858314516, "Episode Reward": 16341.95312643422, "Mean Reward": 65.10738297384151, "Episode": 5594, "Episode Step": 251}
{"Training Time": 30.607623227503563, "Episode Reward": 112613.92552250183, "Mean Reward": 61.53766421994636, "Episode": 5595, "Episode Step": 1830}
{"Training Time": 30.619860279692546, "Episode Reward": 66123.51136216208, "Mean Reward": 63.88745059146095, "Episode": 5596, "Episode Step": 1035}
{"Training Time": 30.627006783882777, "Episode Reward": 39121.77574355698, "Mean Reward": 64.55738571544056, "Episode": 5597, "Episode Step": 606}
{"Training Time": 30.63345298641258, "Episode Reward": 31543.234101239865, "Mean Reward": 61.849478629882086, "Episode": 5598, "Episode Step": 510}
{"Training Time": 30.637937669422893, "Episode Reward": 19482.10997896075, "Mean Reward": 67.41214525591955, "Episode": 5599, "Episode Step": 289}
{"Training Time": 30.640254864427778, "Episode Reward": 8791.827739546774, "Mean Reward": 51.1152775555045, "Episode": 5600, "Episode Step": 172}
{"Training Time": 30.643825171391168, "Episode Reward": 15690.750239236651, "Mean Reward": 60.582047255739965, "Episode": 5601, "Episode Step": 259}
{"Training Time": 30.64586177693473, "Episode Reward": 8539.704822946813, "Mean Reward": 49.64944664503961, "Episode": 5602, "Episode Step": 172}
{"Training Time": 30.64747452000777, "Episode Reward": 7053.411183911554, "Mean Reward": 52.63739689486234, "Episode": 5603, "Episode Step": 134}
{"Training Time": 30.651015018026033, "Episode Reward": 15012.226529161577, "Mean Reward": 58.41333279829407, "Episode": 5604, "Episode Step": 257}
{"Training Time": 30.653717218637468, "Episode Reward": 13299.499824490595, "Mean Reward": 58.07641844755718, "Episode": 5605, "Episode Step": 229}
{"Training Time": 30.65535671969255, "Episode Reward": 7271.072799418229, "Mean Reward": 53.8597985142091, "Episode": 5606, "Episode Step": 135}
{"Training Time": 30.658995750546456, "Episode Reward": 16341.28045053582, "Mean Reward": 62.13414619975597, "Episode": 5607, "Episode Step": 263}
{"Training Time": 30.661902575559086, "Episode Reward": 15725.543087795326, "Mean Reward": 64.9815830074187, "Episode": 5608, "Episode Step": 242}
{"Training Time": 30.66356362303098, "Episode Reward": 6856.834645659723, "Mean Reward": 51.17040780343077, "Episode": 5609, "Episode Step": 134}
{"Training Time": 30.675259236362244, "Episode Reward": 58870.07792380659, "Mean Reward": 62.761277104271414, "Episode": 5610, "Episode Step": 938}
{"Training Time": 30.687519193026755, "Episode Reward": 66263.07990744844, "Mean Reward": 63.775822817563466, "Episode": 5611, "Episode Step": 1039}
{"Training Time": 30.689161736369133, "Episode Reward": 6528.642698049042, "Mean Reward": 48.00472572094884, "Episode": 5612, "Episode Step": 136}
{"Training Time": 30.691828739974234, "Episode Reward": 9146.366920349405, "Mean Reward": 49.98014710573445, "Episode": 5613, "Episode Step": 183}
{"Training Time": 30.69531325889958, "Episode Reward": 18381.9373177003, "Mean Reward": 63.60531943840934, "Episode": 5614, "Episode Step": 289}
{"Training Time": 30.696906084749433, "Episode Reward": 6764.882777832718, "Mean Reward": 50.48419983457252, "Episode": 5615, "Episode Step": 134}
{"Training Time": 30.708383945292898, "Episode Reward": 59017.87368237691, "Mean Reward": 64.35973138754298, "Episode": 5616, "Episode Step": 917}
{"Training Time": 30.72342800219854, "Episode Reward": 84016.87634339776, "Mean Reward": 65.99911731610193, "Episode": 5617, "Episode Step": 1273}
{"Training Time": 30.724901168081495, "Episode Reward": 6858.945585932573, "Mean Reward": 56.22086545846371, "Episode": 5618, "Episode Step": 122}
{"Training Time": 30.73369042860137, "Episode Reward": 44806.30865632227, "Mean Reward": 64.56240440392257, "Episode": 5619, "Episode Step": 694}
{"Training Time": 30.7365901488728, "Episode Reward": 15879.912335842453, "Mean Reward": 65.6194724621589, "Episode": 5620, "Episode Step": 242}
{"Training Time": 30.738602288365364, "Episode Reward": 9397.146241945988, "Mean Reward": 55.6044156328165, "Episode": 5621, "Episode Step": 169}
{"Training Time": 30.744959055582683, "Episode Reward": 30636.408629253463, "Mean Reward": 61.7669528815594, "Episode": 5622, "Episode Step": 496}
{"Training Time": 30.750589359468883, "Episode Reward": 31639.754714791976, "Mean Reward": 66.75053737297885, "Episode": 5623, "Episode Step": 474}
{"Training Time": 30.752056596676507, "Episode Reward": 6852.820908743705, "Mean Reward": 55.7139911279976, "Episode": 5624, "Episode Step": 123}
{"Training Time": 30.765873112214937, "Episode Reward": 70974.0276271289, "Mean Reward": 63.25670911508815, "Episode": 5625, "Episode Step": 1122}
{"Training Time": 30.769867740273476, "Episode Reward": 22419.517355350228, "Mean Reward": 66.72475403378044, "Episode": 5626, "Episode Step": 336}
{"Training Time": 30.77701028664907, "Episode Reward": 39302.047862534535, "Mean Reward": 65.17752547684003, "Episode": 5627, "Episode Step": 603}
{"Training Time": 30.790936308900516, "Episode Reward": 76162.06823808789, "Mean Reward": 67.04407415324638, "Episode": 5628, "Episode Step": 1136}
{"Training Time": 30.80868652919928, "Episode Reward": 94370.4851921196, "Mean Reward": 63.50638303641965, "Episode": 5629, "Episode Step": 1486}
{"Training Time": 30.810827860832216, "Episode Reward": 8608.245112683468, "Mean Reward": 48.360927599345324, "Episode": 5630, "Episode Step": 178}
{"Training Time": 30.822420811918047, "Episode Reward": 60249.586175400684, "Mean Reward": 65.13468775718992, "Episode": 5631, "Episode Step": 925}
{"Training Time": 30.83350239581532, "Episode Reward": 62487.95920367421, "Mean Reward": 67.33616293499377, "Episode": 5632, "Episode Step": 928}
{"Training Time": 30.83499944753117, "Episode Reward": 6103.971668323736, "Mean Reward": 50.03255465839128, "Episode": 5633, "Episode Step": 122}
{"Training Time": 30.85356582277351, "Episode Reward": 99435.74482520093, "Mean Reward": 65.76438149814877, "Episode": 5634, "Episode Step": 1512}
{"Training Time": 30.867516693605317, "Episode Reward": 75327.92068355212, "Mean Reward": 64.82609353145621, "Episode": 5635, "Episode Step": 1162}
{"Training Time": 30.868777035805913, "Episode Reward": 5834.756079515386, "Mean Reward": 57.20349097564104, "Episode": 5636, "Episode Step": 102}
{"Training Time": 30.871937779188155, "Episode Reward": 14190.60759984537, "Mean Reward": 63.63501165849942, "Episode": 5637, "Episode Step": 223}
{"Training Time": 30.874026981658407, "Episode Reward": 8527.06559152026, "Mean Reward": 49.0061240891969, "Episode": 5638, "Episode Step": 174}
{"Training Time": 30.880762181414497, "Episode Reward": 36763.61891890349, "Mean Reward": 66.48032354232096, "Episode": 5639, "Episode Step": 553}
{"Training Time": 30.89754120886326, "Episode Reward": 88950.74429372884, "Mean Reward": 65.50128445782684, "Episode": 5640, "Episode Step": 1358}
{"Training Time": 30.899613736139404, "Episode Reward": 8911.725401348, "Mean Reward": 52.73210296655621, "Episode": 5641, "Episode Step": 169}
{"Training Time": 30.90947026113669, "Episode Reward": 52202.37626844214, "Mean Reward": 64.20956490583289, "Episode": 5642, "Episode Step": 813}
{"Training Time": 30.912019626100857, "Episode Reward": 8924.511202174312, "Mean Reward": 50.99720686956749, "Episode": 5643, "Episode Step": 175}
{"Training Time": 30.91327357530594, "Episode Reward": 5696.566173139558, "Mean Reward": 54.774674741726514, "Episode": 5644, "Episode Step": 104}
{"Training Time": 30.925718132191236, "Episode Reward": 70260.12680074072, "Mean Reward": 67.55781423148146, "Episode": 5645, "Episode Step": 1040}
{"Training Time": 30.933679890566403, "Episode Reward": 37517.9832179159, "Mean Reward": 60.70871070860178, "Episode": 5646, "Episode Step": 618}
{"Training Time": 30.946239400572246, "Episode Reward": 67509.8537067953, "Mean Reward": 64.47932541241194, "Episode": 5647, "Episode Step": 1047}
{"Training Time": 30.951036599145993, "Episode Reward": 26665.95459967979, "Mean Reward": 66.83196641523757, "Episode": 5648, "Episode Step": 399}
{"Training Time": 30.95991161611345, "Episode Reward": 36410.66525673352, "Mean Reward": 59.01242343068642, "Episode": 5649, "Episode Step": 617}
{"Training Time": 30.98314814971553, "Episode Reward": 121434.22303382657, "Mean Reward": 63.4121269106144, "Episode": 5650, "Episode Step": 1915}
{"Training Time": 30.99975951419936, "Episode Reward": 98537.46644449323, "Mean Reward": 71.30062694970566, "Episode": 5651, "Episode Step": 1382}
{"Training Time": 31.005834367805058, "Episode Reward": 28926.54601390829, "Mean Reward": 62.20762583636191, "Episode": 5652, "Episode Step": 465}
{"Training Time": 31.009322201410928, "Episode Reward": 19249.678271789697, "Mean Reward": 67.07204972749024, "Episode": 5653, "Episode Step": 287}
{"Training Time": 31.02181649638547, "Episode Reward": 68594.64833351536, "Mean Reward": 65.89303394189756, "Episode": 5654, "Episode Step": 1041}
{"Training Time": 31.03059270997842, "Episode Reward": 44690.278683376375, "Mean Reward": 64.5813275771335, "Episode": 5655, "Episode Step": 692}
{"Training Time": 31.047258933054078, "Episode Reward": 91825.66331539706, "Mean Reward": 65.73061081989768, "Episode": 5656, "Episode Step": 1397}
{"Training Time": 31.050060415863992, "Episode Reward": 13279.834269027982, "Mean Reward": 56.509933059693545, "Episode": 5657, "Episode Step": 235}
{"Training Time": 31.056035164727106, "Episode Reward": 30326.304929661346, "Mean Reward": 65.35841579668394, "Episode": 5658, "Episode Step": 464}
{"Training Time": 31.07628094361888, "Episode Reward": 113312.97738335675, "Mean Reward": 66.1102551828219, "Episode": 5659, "Episode Step": 1714}
{"Training Time": 31.098742946386338, "Episode Reward": 127952.03449150971, "Mean Reward": 67.77120470948607, "Episode": 5660, "Episode Step": 1888}
{"Training Time": 31.10714555475447, "Episode Reward": 43132.589564689064, "Mean Reward": 64.28105747345613, "Episode": 5661, "Episode Step": 671}
{"Training Time": 31.11440420779917, "Episode Reward": 35958.396151988134, "Mean Reward": 58.46893683250103, "Episode": 5662, "Episode Step": 615}
{"Training Time": 31.122739254169993, "Episode Reward": 48197.95667512076, "Mean Reward": 68.46300664079654, "Episode": 5663, "Episode Step": 704}
{"Training Time": 31.125209032230906, "Episode Reward": 8688.663018974394, "Mean Reward": 50.810894847803475, "Episode": 5664, "Episode Step": 171}
{"Training Time": 31.1312899247143, "Episode Reward": 35022.4768159308, "Mean Reward": 67.48068750661041, "Episode": 5665, "Episode Step": 519}
{"Training Time": 31.14825626141495, "Episode Reward": 98936.16664874926, "Mean Reward": 68.0909612173085, "Episode": 5666, "Episode Step": 1453}
{"Training Time": 31.150803103314505, "Episode Reward": 8684.842813049583, "Mean Reward": 49.62767321742619, "Episode": 5667, "Episode Step": 175}
{"Training Time": 31.153689590030247, "Episode Reward": 16847.72736760265, "Mean Reward": 67.66155569318333, "Episode": 5668, "Episode Step": 249}
{"Training Time": 31.1612811366717, "Episode Reward": 45761.71730461679, "Mean Reward": 69.75871540337926, "Episode": 5669, "Episode Step": 656}
{"Training Time": 31.163797043032115, "Episode Reward": 8742.09738643725, "Mean Reward": 49.95484220821286, "Episode": 5670, "Episode Step": 175}
{"Training Time": 31.16780723306868, "Episode Reward": 21717.9513846406, "Mean Reward": 63.50278182643451, "Episode": 5671, "Episode Step": 342}
{"Training Time": 31.170545095801355, "Episode Reward": 15549.954557227771, "Mean Reward": 67.90373169095096, "Episode": 5672, "Episode Step": 229}
{"Training Time": 31.17309243692292, "Episode Reward": 9006.785404391894, "Mean Reward": 50.599918002201655, "Episode": 5673, "Episode Step": 178}
{"Training Time": 31.174501695301796, "Episode Reward": 6092.403939835022, "Mean Reward": 50.77003283195852, "Episode": 5674, "Episode Step": 120}
{"Training Time": 31.17603398780028, "Episode Reward": 6944.384133008389, "Mean Reward": 53.41833948467991, "Episode": 5675, "Episode Step": 130}
{"Training Time": 31.178566611674096, "Episode Reward": 8939.48039790178, "Mean Reward": 51.376324125872294, "Episode": 5676, "Episode Step": 174}
{"Training Time": 31.181487876375517, "Episode Reward": 15729.089400426727, "Mean Reward": 64.46348114928986, "Episode": 5677, "Episode Step": 244}
{"Training Time": 31.185979127486547, "Episode Reward": 26010.59332863023, "Mean Reward": 68.99361625631362, "Episode": 5678, "Episode Step": 377}
{"Training Time": 31.189395621948773, "Episode Reward": 16148.24378727626, "Mean Reward": 64.85238468785647, "Episode": 5679, "Episode Step": 249}
{"Training Time": 31.192057938310835, "Episode Reward": 11674.461275163136, "Mean Reward": 52.11813069269257, "Episode": 5680, "Episode Step": 224}
{"Training Time": 31.193523828056122, "Episode Reward": 7062.76672844472, "Mean Reward": 57.89153056102229, "Episode": 5681, "Episode Step": 122}
{"Training Time": 31.205647615525457, "Episode Reward": 65828.4797436364, "Mean Reward": 65.89437411775415, "Episode": 5682, "Episode Step": 999}
{"Training Time": 31.208527766929734, "Episode Reward": 15370.54650904553, "Mean Reward": 63.25327781500218, "Episode": 5683, "Episode Step": 243}
{"Training Time": 31.247025709152222, "Episode Reward": 232100.57618155464, "Mean Reward": 70.71924929358764, "Episode": 5684, "Episode Step": 3282}
{"Training Time": 31.252899564173486, "Episode Reward": 28171.084215473515, "Mean Reward": 61.24148742494242, "Episode": 5685, "Episode Step": 460}
{"Training Time": 31.254280814462238, "Episode Reward": 5679.937434033861, "Mean Reward": 48.546473795161205, "Episode": 5686, "Episode Step": 117}
{"Training Time": 31.287264776362314, "Episode Reward": 195043.6346252539, "Mean Reward": 69.13989174946965, "Episode": 5687, "Episode Step": 2821}
{"Training Time": 31.28978075808949, "Episode Reward": 9082.678497379646, "Mean Reward": 52.199301709078426, "Episode": 5688, "Episode Step": 174}
{"Training Time": 31.291167267494732, "Episode Reward": 6040.291064061731, "Mean Reward": 51.18890732255704, "Episode": 5689, "Episode Step": 118}
{"Training Time": 31.29665345026387, "Episode Reward": 32271.88959804827, "Mean Reward": 68.08415527014402, "Episode": 5690, "Episode Step": 474}
{"Training Time": 31.299141513639025, "Episode Reward": 8763.113211076348, "Mean Reward": 50.6538335900367, "Episode": 5691, "Episode Step": 173}
{"Training Time": 31.302028394473922, "Episode Reward": 16629.575397930672, "Mean Reward": 67.87581795073744, "Episode": 5692, "Episode Step": 245}
{"Training Time": 31.314152114192645, "Episode Reward": 69431.54310697001, "Mean Reward": 67.4747746423421, "Episode": 5693, "Episode Step": 1029}
{"Training Time": 31.32031440443463, "Episode Reward": 32173.920903573424, "Mean Reward": 66.33798124448128, "Episode": 5694, "Episode Step": 485}
{"Training Time": 31.323206128875416, "Episode Reward": 15848.67322770813, "Mean Reward": 64.68846215391073, "Episode": 5695, "Episode Step": 245}
{"Training Time": 31.3258307986127, "Episode Reward": 15346.324951618322, "Mean Reward": 68.8176006799028, "Episode": 5696, "Episode Step": 223}
{"Training Time": 31.33921472887198, "Episode Reward": 74347.02239073701, "Mean Reward": 67.46553755965246, "Episode": 5697, "Episode Step": 1102}
{"Training Time": 31.346219922502836, "Episode Reward": 35020.69975373476, "Mean Reward": 58.077445694419175, "Episode": 5698, "Episode Step": 603}
{"Training Time": 31.35538963470194, "Episode Reward": 46280.90459503981, "Mean Reward": 66.97670708399393, "Episode": 5699, "Episode Step": 691}
{"Training Time": 31.368689114716318, "Episode Reward": 71376.88211018969, "Mean Reward": 65.24395074057558, "Episode": 5700, "Episode Step": 1094}
{"Training Time": 31.371595428321097, "Episode Reward": 16119.85884306053, "Mean Reward": 64.73838892795393, "Episode": 5701, "Episode Step": 249}
{"Training Time": 31.37946301692062, "Episode Reward": 48188.07547024552, "Mean Reward": 71.70844564024631, "Episode": 5702, "Episode Step": 672}
{"Training Time": 31.381968353589375, "Episode Reward": 8653.06846403988, "Mean Reward": 49.730278528964824, "Episode": 5703, "Episode Step": 174}
{"Training Time": 31.386658365858924, "Episode Reward": 24778.176055095657, "Mean Reward": 61.790962730911865, "Episode": 5704, "Episode Step": 401}
{"Training Time": 31.38938238196903, "Episode Reward": 15989.47830546042, "Mean Reward": 69.51947089330618, "Episode": 5705, "Episode Step": 230}
{"Training Time": 31.396937738921906, "Episode Reward": 38006.16317420397, "Mean Reward": 62.61311890313669, "Episode": 5706, "Episode Step": 607}
{"Training Time": 31.399818349414403, "Episode Reward": 17152.696111089906, "Mean Reward": 70.29793488151601, "Episode": 5707, "Episode Step": 244}
{"Training Time": 31.403308399717012, "Episode Reward": 19430.528418245718, "Mean Reward": 65.42265460688795, "Episode": 5708, "Episode Step": 297}
{"Training Time": 31.405831644998656, "Episode Reward": 8416.054276773306, "Mean Reward": 48.64771258250466, "Episode": 5709, "Episode Step": 173}
{"Training Time": 31.418104626933733, "Episode Reward": 67170.63312744083, "Mean Reward": 64.09411557961911, "Episode": 5710, "Episode Step": 1048}
{"Training Time": 31.43043828388055, "Episode Reward": 69626.70718913639, "Mean Reward": 65.99687885226199, "Episode": 5711, "Episode Step": 1055}
{"Training Time": 31.433684430585966, "Episode Reward": 14887.99682562527, "Mean Reward": 62.29287374738607, "Episode": 5712, "Episode Step": 239}
{"Training Time": 31.438822788331244, "Episode Reward": 28283.345564282256, "Mean Reward": 64.42675527171356, "Episode": 5713, "Episode Step": 439}
{"Training Time": 31.449933759437666, "Episode Reward": 63349.701649331335, "Mean Reward": 66.12703721224565, "Episode": 5714, "Episode Step": 958}
{"Training Time": 31.4560610591703, "Episode Reward": 30211.33228880936, "Mean Reward": 62.29140678105023, "Episode": 5715, "Episode Step": 485}
{"Training Time": 31.46646858447128, "Episode Reward": 57402.805938754114, "Mean Reward": 64.35292145600236, "Episode": 5716, "Episode Step": 892}
{"Training Time": 31.492679298321406, "Episode Reward": 146610.56901192747, "Mean Reward": 65.24724922649197, "Episode": 5717, "Episode Step": 2247}
{"Training Time": 31.51073967721727, "Episode Reward": 94407.31665831142, "Mean Reward": 63.14870679485714, "Episode": 5718, "Episode Step": 1495}
{"Training Time": 31.512802610264885, "Episode Reward": 7881.041267571088, "Mean Reward": 46.087960629070686, "Episode": 5719, "Episode Step": 171}
{"Training Time": 31.51543176472187, "Episode Reward": 13656.014034179183, "Mean Reward": 61.23773109497392, "Episode": 5720, "Episode Step": 223}
{"Training Time": 31.521491740014817, "Episode Reward": 31579.946618756545, "Mean Reward": 65.92890734604707, "Episode": 5721, "Episode Step": 479}
{"Training Time": 31.52675553308593, "Episode Reward": 27992.976616723045, "Mean Reward": 61.523025531259435, "Episode": 5722, "Episode Step": 455}
{"Training Time": 31.545781922803986, "Episode Reward": 109010.93200845686, "Mean Reward": 66.96003194622658, "Episode": 5723, "Episode Step": 1628}
{"Training Time": 31.55186373942428, "Episode Reward": 32874.52640758832, "Mean Reward": 68.63157913901527, "Episode": 5724, "Episode Step": 479}
{"Training Time": 31.56080650276608, "Episode Reward": 48355.948755211524, "Mean Reward": 63.29312664294702, "Episode": 5725, "Episode Step": 764}
{"Training Time": 31.597269013060465, "Episode Reward": 207120.32015837388, "Mean Reward": 66.5981736843646, "Episode": 5726, "Episode Step": 3110}
{"Training Time": 31.603382367491722, "Episode Reward": 32782.63349561449, "Mean Reward": 68.29715311586352, "Episode": 5727, "Episode Step": 480}
{"Training Time": 31.618787720269626, "Episode Reward": 84770.56042202393, "Mean Reward": 64.07449767348747, "Episode": 5728, "Episode Step": 1323}
{"Training Time": 31.620841067234675, "Episode Reward": 9403.74023287533, "Mean Reward": 54.67290833067052, "Episode": 5729, "Episode Step": 172}
{"Training Time": 31.629115373624696, "Episode Reward": 42997.34131417394, "Mean Reward": 64.17513628981185, "Episode": 5730, "Episode Step": 670}
{"Training Time": 31.644982989430428, "Episode Reward": 86084.12337510512, "Mean Reward": 63.67168888691207, "Episode": 5731, "Episode Step": 1352}
{"Training Time": 31.673936304185126, "Episode Reward": 168903.9714636424, "Mean Reward": 68.21646666544524, "Episode": 5732, "Episode Step": 2476}
{"Training Time": 31.67709017250273, "Episode Reward": 14193.682376671637, "Mean Reward": 62.252992880138756, "Episode": 5733, "Episode Step": 228}
{"Training Time": 31.682548998329374, "Episode Reward": 28042.209610303467, "Mean Reward": 60.04755805204169, "Episode": 5734, "Episode Step": 467}
{"Training Time": 31.696290067500538, "Episode Reward": 79720.13382083921, "Mean Reward": 68.31202555341835, "Episode": 5735, "Episode Step": 1167}
{"Training Time": 31.698824836942883, "Episode Reward": 8829.349984675044, "Mean Reward": 50.166761276562745, "Episode": 5736, "Episode Step": 176}
{"Training Time": 31.70598767830266, "Episode Reward": 36686.39844736514, "Mean Reward": 60.141636798959254, "Episode": 5737, "Episode Step": 610}
{"Training Time": 31.71699853387144, "Episode Reward": 65219.96365656393, "Mean Reward": 69.16220960399144, "Episode": 5738, "Episode Step": 943}
{"Training Time": 31.730488758352067, "Episode Reward": 72865.73694429568, "Mean Reward": 65.4678678744795, "Episode": 5739, "Episode Step": 1113}
{"Training Time": 31.732554832233323, "Episode Reward": 8963.5261727741, "Mean Reward": 51.81229001603526, "Episode": 5740, "Episode Step": 173}
{"Training Time": 31.734625218311944, "Episode Reward": 9237.764555161308, "Mean Reward": 53.70793346024016, "Episode": 5741, "Episode Step": 172}
{"Training Time": 31.74230673028363, "Episode Reward": 37386.9064175772, "Mean Reward": 61.089716368590196, "Episode": 5742, "Episode Step": 612}
{"Training Time": 31.75083990169896, "Episode Reward": 47478.43641076998, "Mean Reward": 65.21763243237635, "Episode": 5743, "Episode Step": 728}
{"Training Time": 31.78890785303381, "Episode Reward": 227803.8175351138, "Mean Reward": 70.33152748845748, "Episode": 5744, "Episode Step": 3239}
{"Training Time": 31.810834516419305, "Episode Reward": 119530.24757223476, "Mean Reward": 66.25845209103922, "Episode": 5745, "Episode Step": 1804}
{"Training Time": 31.82152904331684, "Episode Reward": 57786.4688443598, "Mean Reward": 63.71165252961389, "Episode": 5746, "Episode Step": 907}
{"Training Time": 31.82868802944819, "Episode Reward": 39590.37719130352, "Mean Reward": 65.54698210480716, "Episode": 5747, "Episode Step": 604}
{"Training Time": 31.83495111776723, "Episode Reward": 31277.24233113167, "Mean Reward": 63.96164075896047, "Episode": 5748, "Episode Step": 489}
{"Training Time": 31.86457158221139, "Episode Reward": 164002.32621783667, "Mean Reward": 67.62982524446873, "Episode": 5749, "Episode Step": 2425}
{"Training Time": 31.87296150419447, "Episode Reward": 45542.1577034771, "Mean Reward": 67.5699669191055, "Episode": 5750, "Episode Step": 674}
{"Training Time": 31.923242740829785, "Episode Reward": 274900.5818757051, "Mean Reward": 65.09604117350345, "Episode": 5751, "Episode Step": 4223}
{"Training Time": 31.982023246685664, "Episode Reward": 328829.3378634607, "Mean Reward": 65.76586757269214, "Episode": 5752, "Episode Step": 5000}
{"Training Time": 31.994549465841718, "Episode Reward": 68962.2885110474, "Mean Reward": 66.30989279908404, "Episode": 5753, "Episode Step": 1040}
{"Training Time": 32.0115965880288, "Episode Reward": 89832.29332656208, "Mean Reward": 64.39590919466816, "Episode": 5754, "Episode Step": 1395}
{"Training Time": 32.03212881306807, "Episode Reward": 109295.11378437978, "Mean Reward": 63.21290560114504, "Episode": 5755, "Episode Step": 1729}
{"Training Time": 32.070510414706334, "Episode Reward": 220196.4759519257, "Mean Reward": 68.04588255621931, "Episode": 5756, "Episode Step": 3236}
{"Training Time": 32.07395588417848, "Episode Reward": 16069.011741729924, "Mean Reward": 63.513880402094564, "Episode": 5757, "Episode Step": 253}
{"Training Time": 32.07959869417879, "Episode Reward": 28164.957267741822, "Mean Reward": 59.41974107118528, "Episode": 5758, "Episode Step": 474}
{"Training Time": 32.08365808831321, "Episode Reward": 23175.41042389728, "Mean Reward": 67.37037913923628, "Episode": 5759, "Episode Step": 344}
{"Training Time": 32.086308523085386, "Episode Reward": 8263.114088712431, "Mean Reward": 45.15362890006793, "Episode": 5760, "Episode Step": 183}
{"Training Time": 32.0905072700315, "Episode Reward": 22478.300780824884, "Mean Reward": 63.49802480459007, "Episode": 5761, "Episode Step": 354}
{"Training Time": 32.100348840819464, "Episode Reward": 56020.693942133374, "Mean Reward": 67.01039945231265, "Episode": 5762, "Episode Step": 836}
{"Training Time": 32.10900448441505, "Episode Reward": 43138.695796602195, "Mean Reward": 62.51984898058289, "Episode": 5763, "Episode Step": 690}
{"Training Time": 32.13237435804473, "Episode Reward": 124377.31570409512, "Mean Reward": 62.59552878917721, "Episode": 5764, "Episode Step": 1987}
{"Training Time": 32.13384655886226, "Episode Reward": 6588.603075494472, "Mean Reward": 53.565878662556685, "Episode": 5765, "Episode Step": 123}
{"Training Time": 32.153115127219095, "Episode Reward": 104138.55478328481, "Mean Reward": 65.29062995817229, "Episode": 5766, "Episode Step": 1595}
{"Training Time": 32.168279989427994, "Episode Reward": 78905.24468209688, "Mean Reward": 61.98369574398812, "Episode": 5767, "Episode Step": 1273}
{"Training Time": 32.170323111083775, "Episode Reward": 9104.26373359403, "Mean Reward": 53.55449255055312, "Episode": 5768, "Episode Step": 170}
{"Training Time": 32.207319493028855, "Episode Reward": 196428.82498915424, "Mean Reward": 64.10862434371874, "Episode": 5769, "Episode Step": 3064}
{"Training Time": 32.21572943919235, "Episode Reward": 44781.62870736128, "Mean Reward": 63.07271648924124, "Episode": 5770, "Episode Step": 710}
{"Training Time": 32.21778100530307, "Episode Reward": 8760.486141580148, "Mean Reward": 51.230913108655834, "Episode": 5771, "Episode Step": 171}
{"Training Time": 32.25965297195646, "Episode Reward": 228403.5972544663, "Mean Reward": 65.40767389875896, "Episode": 5772, "Episode Step": 3492}
{"Training Time": 32.262543383042015, "Episode Reward": 13855.941763932387, "Mean Reward": 57.25595770219995, "Episode": 5773, "Episode Step": 242}
{"Training Time": 32.26457150664594, "Episode Reward": 9023.410335235712, "Mean Reward": 53.078884324915954, "Episode": 5774, "Episode Step": 170}
{"Training Time": 32.29888515942626, "Episode Reward": 186036.56045528813, "Mean Reward": 65.13885170003086, "Episode": 5775, "Episode Step": 2856}
{"Training Time": 32.3502099802759, "Episode Reward": 272341.116441251, "Mean Reward": 62.95448831281808, "Episode": 5776, "Episode Step": 4326}
{"Training Time": 32.354949471089576, "Episode Reward": 26336.520189469087, "Mean Reward": 65.35116672324835, "Episode": 5777, "Episode Step": 403}
{"Training Time": 32.35757355471452, "Episode Reward": 8786.764088917389, "Mean Reward": 48.27892356548016, "Episode": 5778, "Episode Step": 182}
{"Training Time": 32.360440884166294, "Episode Reward": 14430.223678644277, "Mean Reward": 61.66762255830888, "Episode": 5779, "Episode Step": 234}
{"Training Time": 32.36252259777652, "Episode Reward": 8732.83573490603, "Mean Reward": 50.77230078433738, "Episode": 5780, "Episode Step": 172}
{"Training Time": 32.3686554472314, "Episode Reward": 28858.793248159316, "Mean Reward": 61.141511118981605, "Episode": 5781, "Episode Step": 472}
{"Training Time": 32.371625698606174, "Episode Reward": 17066.802238023294, "Mean Reward": 68.81775095977135, "Episode": 5782, "Episode Step": 248}
{"Training Time": 32.387819087770254, "Episode Reward": 89409.16146255934, "Mean Reward": 65.83885232883604, "Episode": 5783, "Episode Step": 1358}
{"Training Time": 32.40714720944563, "Episode Reward": 101886.28744199053, "Mean Reward": 64.20055919470103, "Episode": 5784, "Episode Step": 1587}
{"Training Time": 32.40923776639833, "Episode Reward": 8767.247517550464, "Mean Reward": 49.532471850567596, "Episode": 5785, "Episode Step": 177}
{"Training Time": 32.4237616833051, "Episode Reward": 83336.49494018409, "Mean Reward": 67.9743025613247, "Episode": 5786, "Episode Step": 1226}
{"Training Time": 32.43781091252963, "Episode Reward": 77130.90620176491, "Mean Reward": 67.24577698497377, "Episode": 5787, "Episode Step": 1147}
{"Training Time": 32.455680686367884, "Episode Reward": 97967.48592242462, "Mean Reward": 64.53721075258538, "Episode": 5788, "Episode Step": 1518}
{"Training Time": 32.45776966306898, "Episode Reward": 9070.497817379679, "Mean Reward": 52.73545242662604, "Episode": 5789, "Episode Step": 172}
{"Training Time": 32.46109746747547, "Episode Reward": 14440.78995251762, "Mean Reward": 61.9776392811915, "Episode": 5790, "Episode Step": 233}
{"Training Time": 32.47641446140077, "Episode Reward": 85309.2252345832, "Mean Reward": 67.2785687969899, "Episode": 5791, "Episode Step": 1268}
{"Training Time": 32.48056194947826, "Episode Reward": 23432.07130396028, "Mean Reward": 67.9190472578559, "Episode": 5792, "Episode Step": 345}
{"Training Time": 32.493878238598505, "Episode Reward": 66518.94862806352, "Mean Reward": 61.99342835793431, "Episode": 5793, "Episode Step": 1073}
{"Training Time": 32.49592356138759, "Episode Reward": 8254.028192421034, "Mean Reward": 48.26917071591248, "Episode": 5794, "Episode Step": 171}
{"Training Time": 32.50074435002274, "Episode Reward": 24543.132183338523, "Mean Reward": 61.51160948205143, "Episode": 5795, "Episode Step": 399}
{"Training Time": 32.505532678630615, "Episode Reward": 22858.936142352417, "Mean Reward": 63.67391683106523, "Episode": 5796, "Episode Step": 359}
{"Training Time": 32.5076285060909, "Episode Reward": 9171.615709328356, "Mean Reward": 53.015119707100325, "Episode": 5797, "Episode Step": 173}
{"Training Time": 32.50916464805603, "Episode Reward": 6382.322720961759, "Mean Reward": 50.254509613872116, "Episode": 5798, "Episode Step": 127}
{"Training Time": 32.54870534585582, "Episode Reward": 213778.96862935362, "Mean Reward": 66.61856298826851, "Episode": 5799, "Episode Step": 3209}
{"Training Time": 32.55376770973206, "Episode Reward": 25740.548226805517, "Mean Reward": 64.03121449454109, "Episode": 5800, "Episode Step": 402}
{"Training Time": 32.56620955586433, "Episode Reward": 67987.09215368511, "Mean Reward": 64.50388249875247, "Episode": 5801, "Episode Step": 1054}
{"Training Time": 32.586237440572845, "Episode Reward": 106873.5786716301, "Mean Reward": 65.36610316307652, "Episode": 5802, "Episode Step": 1635}
{"Training Time": 32.58832648085223, "Episode Reward": 8546.38194194226, "Mean Reward": 49.40105168752751, "Episode": 5803, "Episode Step": 173}
{"Training Time": 32.595648673905266, "Episode Reward": 37869.74175989198, "Mean Reward": 61.77771902103096, "Episode": 5804, "Episode Step": 613}
{"Training Time": 32.61034085585011, "Episode Reward": 78161.96638427969, "Mean Reward": 65.62717580544054, "Episode": 5805, "Episode Step": 1191}
{"Training Time": 32.61238376723396, "Episode Reward": 9158.064694853589, "Mean Reward": 52.936790143662364, "Episode": 5806, "Episode Step": 173}
{"Training Time": 32.61973035891851, "Episode Reward": 38230.1527019505, "Mean Reward": 62.16284992187073, "Episode": 5807, "Episode Step": 615}
{"Training Time": 32.62231730918089, "Episode Reward": 8265.854370268176, "Mean Reward": 46.437384102630205, "Episode": 5808, "Episode Step": 178}
{"Training Time": 32.62441812528504, "Episode Reward": 9483.238604745029, "Mean Reward": 53.882037526960396, "Episode": 5809, "Episode Step": 176}
{"Training Time": 32.62984764138857, "Episode Reward": 30122.514919141206, "Mean Reward": 65.76968322956596, "Episode": 5810, "Episode Step": 458}
{"Training Time": 32.63660538196564, "Episode Reward": 32940.162363697855, "Mean Reward": 63.10375931742884, "Episode": 5811, "Episode Step": 522}
{"Training Time": 32.63871233085791, "Episode Reward": 8820.564394261355, "Mean Reward": 50.69289881759399, "Episode": 5812, "Episode Step": 174}
{"Training Time": 32.64416833612654, "Episode Reward": 28740.190764761064, "Mean Reward": 63.72547841410436, "Episode": 5813, "Episode Step": 451}
{"Training Time": 32.65559793194135, "Episode Reward": 59136.64672635897, "Mean Reward": 64.77179269042604, "Episode": 5814, "Episode Step": 913}
{"Training Time": 32.65687306139204, "Episode Reward": 6258.624007722439, "Mean Reward": 60.76333988080038, "Episode": 5815, "Episode Step": 103}
{"Training Time": 32.65900328053368, "Episode Reward": 8846.25321712281, "Mean Reward": 50.840535730590865, "Episode": 5816, "Episode Step": 174}
{"Training Time": 32.66167102250788, "Episode Reward": 7991.996299893719, "Mean Reward": 44.399979443853994, "Episode": 5817, "Episode Step": 180}
{"Training Time": 32.67385486914052, "Episode Reward": 64334.370915410924, "Mean Reward": 63.25896845173149, "Episode": 5818, "Episode Step": 1017}
{"Training Time": 32.684560797810555, "Episode Reward": 59194.3914935193, "Mean Reward": 65.84470688934294, "Episode": 5819, "Episode Step": 899}
{"Training Time": 32.691445225278535, "Episode Reward": 33252.4262278099, "Mean Reward": 62.85902878603005, "Episode": 5820, "Episode Step": 529}
{"Training Time": 32.69496675696638, "Episode Reward": 18772.062221425767, "Mean Reward": 64.06847174548044, "Episode": 5821, "Episode Step": 293}
{"Training Time": 32.69555253002379, "Episode Reward": 2684.260436071682, "Mean Reward": 57.11192417173791, "Episode": 5822, "Episode Step": 47}
{"Training Time": 32.698159274193976, "Episode Reward": 8495.436750183588, "Mean Reward": 47.460540503818926, "Episode": 5823, "Episode Step": 179}
{"Training Time": 32.721826158364614, "Episode Reward": 131181.4398689277, "Mean Reward": 65.92032154217472, "Episode": 5824, "Episode Step": 1990}
{"Training Time": 32.72763008111053, "Episode Reward": 30416.472399655573, "Mean Reward": 62.456822175884135, "Episode": 5825, "Episode Step": 487}
{"Training Time": 32.738937018911045, "Episode Reward": 59367.15591557993, "Mean Reward": 65.890295133829, "Episode": 5826, "Episode Step": 901}
{"Training Time": 32.74632045275635, "Episode Reward": 38384.83401978318, "Mean Reward": 61.61289569788632, "Episode": 5827, "Episode Step": 623}
{"Training Time": 32.75678662028577, "Episode Reward": 57818.85054498775, "Mean Reward": 65.77798696813169, "Episode": 5828, "Episode Step": 879}
{"Training Time": 32.76085544890827, "Episode Reward": 18649.179982413145, "Mean Reward": 62.371839406064026, "Episode": 5829, "Episode Step": 299}
{"Training Time": 32.76288206557433, "Episode Reward": 8734.759688853179, "Mean Reward": 51.38093934619517, "Episode": 5830, "Episode Step": 170}
{"Training Time": 32.768378454181885, "Episode Reward": 29595.767570033284, "Mean Reward": 64.61957984723425, "Episode": 5831, "Episode Step": 458}
{"Training Time": 32.78155765891075, "Episode Reward": 67723.78360321425, "Mean Reward": 63.89036188982477, "Episode": 5832, "Episode Step": 1060}
{"Training Time": 32.78445393469599, "Episode Reward": 16920.087980994445, "Mean Reward": 70.20783394603504, "Episode": 5833, "Episode Step": 241}
{"Training Time": 32.78987289276388, "Episode Reward": 29000.93322731187, "Mean Reward": 63.87870754914509, "Episode": 5834, "Episode Step": 454}
{"Training Time": 32.837118566102454, "Episode Reward": 264544.89226669545, "Mean Reward": 66.05365599667802, "Episode": 5835, "Episode Step": 4005}
{"Training Time": 32.83916123112043, "Episode Reward": 8967.02763033315, "Mean Reward": 51.53464155363879, "Episode": 5836, "Episode Step": 174}
{"Training Time": 32.84443487114377, "Episode Reward": 28761.631615733404, "Mean Reward": 63.35161148839957, "Episode": 5837, "Episode Step": 454}
{"Training Time": 32.858101632528836, "Episode Reward": 71480.29760354997, "Mean Reward": 62.92279718622357, "Episode": 5838, "Episode Step": 1136}
{"Training Time": 32.860049433045916, "Episode Reward": 9032.26432196288, "Mean Reward": 53.76347810692191, "Episode": 5839, "Episode Step": 168}
{"Training Time": 32.870405724710885, "Episode Reward": 58637.3039854528, "Mean Reward": 66.25684066152859, "Episode": 5840, "Episode Step": 885}
{"Training Time": 32.91275014307764, "Episode Reward": 230189.9329875166, "Mean Reward": 64.17338527669824, "Episode": 5841, "Episode Step": 3587}
{"Training Time": 32.91946688387129, "Episode Reward": 35706.33169928821, "Mean Reward": 62.6426871917337, "Episode": 5842, "Episode Step": 570}
{"Training Time": 32.922276778618496, "Episode Reward": 16775.325749061667, "Mean Reward": 69.60716078448824, "Episode": 5843, "Episode Step": 241}
{"Training Time": 32.92482329474555, "Episode Reward": 8837.851053309287, "Mean Reward": 49.650848614097114, "Episode": 5844, "Episode Step": 178}
{"Training Time": 32.931892800529795, "Episode Reward": 38157.28808384381, "Mean Reward": 63.06989765924596, "Episode": 5845, "Episode Step": 605}
{"Training Time": 32.937536405523616, "Episode Reward": 31889.24945849847, "Mean Reward": 66.43593637187182, "Episode": 5846, "Episode Step": 480}
{"Training Time": 32.94149877197213, "Episode Reward": 18700.235186345875, "Mean Reward": 62.5425925964745, "Episode": 5847, "Episode Step": 299}
{"Training Time": 32.947796805567215, "Episode Reward": 34579.184735727584, "Mean Reward": 64.39326766429717, "Episode": 5848, "Episode Step": 537}
{"Training Time": 32.950110464692116, "Episode Reward": 5588.4687436843915, "Mean Reward": 53.73527638158069, "Episode": 5849, "Episode Step": 104}
{"Training Time": 32.95275769584709, "Episode Reward": 9178.831672223947, "Mean Reward": 50.157550121442334, "Episode": 5850, "Episode Step": 183}
{"Training Time": 32.95572658777237, "Episode Reward": 16880.09719653409, "Mean Reward": 67.791555006161, "Episode": 5851, "Episode Step": 249}
{"Training Time": 32.956954385836916, "Episode Reward": 5708.140582212999, "Mean Reward": 55.96216257071568, "Episode": 5852, "Episode Step": 102}
{"Training Time": 32.95952357696162, "Episode Reward": 8609.159551900473, "Mean Reward": 48.36606489831726, "Episode": 5853, "Episode Step": 178}
{"Training Time": 32.96235637280676, "Episode Reward": 15177.44909398761, "Mean Reward": 64.31122497452377, "Episode": 5854, "Episode Step": 236}
{"Training Time": 32.96297218057845, "Episode Reward": 2602.0072251162446, "Mean Reward": 52.04014450232489, "Episode": 5855, "Episode Step": 50}
{"Training Time": 32.981316445271176, "Episode Reward": 92584.22455480839, "Mean Reward": 61.55865994335664, "Episode": 5856, "Episode Step": 1504}
{"Training Time": 32.993429916699725, "Episode Reward": 62619.56239887831, "Mean Reward": 61.57282438434446, "Episode": 5857, "Episode Step": 1017}
{"Training Time": 33.00414115276602, "Episode Reward": 62416.74790212132, "Mean Reward": 68.89265772861073, "Episode": 5858, "Episode Step": 906}
{"Training Time": 33.01040144443512, "Episode Reward": 29758.641978366533, "Mean Reward": 61.358024697662955, "Episode": 5859, "Episode Step": 485}
{"Training Time": 33.01249342223009, "Episode Reward": 9316.007456186773, "Mean Reward": 54.16283404759752, "Episode": 5860, "Episode Step": 172}
{"Training Time": 33.014609166648654, "Episode Reward": 9003.940167185858, "Mean Reward": 50.58393352351605, "Episode": 5861, "Episode Step": 178}
{"Training Time": 33.0260585774978, "Episode Reward": 58368.938852404564, "Mean Reward": 63.37561221759453, "Episode": 5862, "Episode Step": 921}
{"Training Time": 33.02874704692099, "Episode Reward": 13929.843375393215, "Mean Reward": 61.636475112359356, "Episode": 5863, "Episode Step": 226}
{"Training Time": 33.044601556393836, "Episode Reward": 88359.02269962779, "Mean Reward": 66.1865338573991, "Episode": 5864, "Episode Step": 1335}
{"Training Time": 33.07672202640109, "Episode Reward": 171826.08006883544, "Mean Reward": 63.757358096042836, "Episode": 5865, "Episode Step": 2695}
{"Training Time": 33.077955877516004, "Episode Reward": 5924.753481196364, "Mean Reward": 58.08581844310161, "Episode": 5866, "Episode Step": 102}
{"Training Time": 33.080550740824805, "Episode Reward": 12474.913085546608, "Mean Reward": 56.70415038884822, "Episode": 5867, "Episode Step": 220}
{"Training Time": 33.08692506141133, "Episode Reward": 30490.566157367743, "Mean Reward": 61.84699017721652, "Episode": 5868, "Episode Step": 493}
{"Training Time": 33.09164042890072, "Episode Reward": 25569.47208388815, "Mean Reward": 64.89713726875165, "Episode": 5869, "Episode Step": 394}
{"Training Time": 33.099674196375744, "Episode Reward": 47093.75089936343, "Mean Reward": 69.35751237019652, "Episode": 5870, "Episode Step": 679}
{"Training Time": 33.11823784000344, "Episode Reward": 92065.38896826877, "Mean Reward": 60.729148395955654, "Episode": 5871, "Episode Step": 1516}
{"Training Time": 33.12024608082241, "Episode Reward": 7936.736599895798, "Mean Reward": 48.10143393876241, "Episode": 5872, "Episode Step": 165}
{"Training Time": 33.12799424860213, "Episode Reward": 39202.47191759502, "Mean Reward": 60.40442514267338, "Episode": 5873, "Episode Step": 649}
{"Training Time": 33.13062027275562, "Episode Reward": 9393.134897036623, "Mean Reward": 52.47561394992527, "Episode": 5874, "Episode Step": 179}
{"Training Time": 33.137131494747265, "Episode Reward": 31950.245065982406, "Mean Reward": 58.84023032409283, "Episode": 5875, "Episode Step": 543}
{"Training Time": 33.139256336688995, "Episode Reward": 8606.071353548026, "Mean Reward": 48.621872053943655, "Episode": 5876, "Episode Step": 177}
{"Training Time": 33.15763915830188, "Episode Reward": 95159.77162481338, "Mean Reward": 63.31322130726107, "Episode": 5877, "Episode Step": 1503}
{"Training Time": 33.19562972194618, "Episode Reward": 211444.61009692485, "Mean Reward": 66.03516867486722, "Episode": 5878, "Episode Step": 3202}
{"Training Time": 33.19769828637441, "Episode Reward": 8964.241190145256, "Mean Reward": 51.51862752957044, "Episode": 5879, "Episode Step": 174}
{"Training Time": 33.21618007414871, "Episode Reward": 97576.31572733076, "Mean Reward": 65.39967542046297, "Episode": 5880, "Episode Step": 1492}
{"Training Time": 33.2208742111259, "Episode Reward": 26444.17804416854, "Mean Reward": 67.97989214439214, "Episode": 5881, "Episode Step": 389}
{"Training Time": 33.22746998137898, "Episode Reward": 34701.01277767286, "Mean Reward": 63.7886264295457, "Episode": 5882, "Episode Step": 544}
{"Training Time": 33.230044423606664, "Episode Reward": 9030.988229066048, "Mean Reward": 51.02253236760479, "Episode": 5883, "Episode Step": 177}
{"Training Time": 33.23212519274818, "Episode Reward": 8804.804306111146, "Mean Reward": 50.31316746349226, "Episode": 5884, "Episode Step": 175}
{"Training Time": 33.23426229304737, "Episode Reward": 8669.81321002558, "Mean Reward": 50.11452722558139, "Episode": 5885, "Episode Step": 173}
{"Training Time": 33.23624750223425, "Episode Reward": 6635.63931719783, "Mean Reward": 53.5132202999825, "Episode": 5886, "Episode Step": 124}
{"Training Time": 33.238319830828246, "Episode Reward": 8414.536670380845, "Mean Reward": 49.79015781290441, "Episode": 5887, "Episode Step": 169}
{"Training Time": 33.24475374552939, "Episode Reward": 34868.163403462706, "Mean Reward": 65.29618614880657, "Episode": 5888, "Episode Step": 534}
{"Training Time": 33.24812398864163, "Episode Reward": 15878.079382195585, "Mean Reward": 65.07409582867044, "Episode": 5889, "Episode Step": 244}
{"Training Time": 33.25021283917957, "Episode Reward": 8087.3489958882765, "Mean Reward": 47.019470906327186, "Episode": 5890, "Episode Step": 172}
{"Training Time": 33.25148526304298, "Episode Reward": 5400.097502873109, "Mean Reward": 52.94213238110891, "Episode": 5891, "Episode Step": 102}
{"Training Time": 33.26073532084624, "Episode Reward": 48189.210839920386, "Mean Reward": 66.28502178806106, "Episode": 5892, "Episode Step": 727}
{"Training Time": 33.26279069913758, "Episode Reward": 8766.335610123466, "Mean Reward": 51.26512052703781, "Episode": 5893, "Episode Step": 171}
{"Training Time": 33.26572925693459, "Episode Reward": 15875.046115162599, "Mean Reward": 64.53270778521382, "Episode": 5894, "Episode Step": 246}
{"Training Time": 33.26831292364332, "Episode Reward": 9178.377131449666, "Mean Reward": 52.14987006505492, "Episode": 5895, "Episode Step": 176}
{"Training Time": 33.27037130276362, "Episode Reward": 9112.754140873843, "Mean Reward": 52.981128726010716, "Episode": 5896, "Episode Step": 172}
{"Training Time": 33.27159312168757, "Episode Reward": 5534.142758894464, "Mean Reward": 53.729541348489946, "Episode": 5897, "Episode Step": 103}
{"Training Time": 33.28926624443796, "Episode Reward": 92778.86042117266, "Mean Reward": 64.4297641813699, "Episode": 5898, "Episode Step": 1440}
{"Training Time": 33.29240144193172, "Episode Reward": 9136.447413630622, "Mean Reward": 53.429517038775565, "Episode": 5899, "Episode Step": 171}
{"Training Time": 33.30165438334147, "Episode Reward": 50389.51394209073, "Mean Reward": 67.81899588437514, "Episode": 5900, "Episode Step": 743}
{"Training Time": 33.320734054976036, "Episode Reward": 100145.06561063026, "Mean Reward": 64.5680629339976, "Episode": 5901, "Episode Step": 1551}
{"Training Time": 33.32346566001574, "Episode Reward": 12400.592706319956, "Mean Reward": 54.86987923150423, "Episode": 5902, "Episode Step": 226}
{"Training Time": 33.32474609222677, "Episode Reward": 5824.33081999642, "Mean Reward": 56.54690116501379, "Episode": 5903, "Episode Step": 103}
{"Training Time": 33.348421539730495, "Episode Reward": 124089.53171102804, "Mean Reward": 64.26179788245885, "Episode": 5904, "Episode Step": 1931}
{"Training Time": 33.35137459192011, "Episode Reward": 16004.686816385762, "Mean Reward": 66.13506948919736, "Episode": 5905, "Episode Step": 242}
{"Training Time": 33.35953432917595, "Episode Reward": 45719.3791380808, "Mean Reward": 67.53231778150783, "Episode": 5906, "Episode Step": 677}
{"Training Time": 33.383837251133386, "Episode Reward": 127071.03446416621, "Mean Reward": 64.20971928457111, "Episode": 5907, "Episode Step": 1979}
{"Training Time": 33.38586348613103, "Episode Reward": 7961.1553494146, "Mean Reward": 47.107428103044974, "Episode": 5908, "Episode Step": 169}
{"Training Time": 33.3881278200282, "Episode Reward": 8766.949165003862, "Mean Reward": 46.632708324488625, "Episode": 5909, "Episode Step": 188}
{"Training Time": 33.391397177245885, "Episode Reward": 14132.166048150706, "Mean Reward": 60.1368768006413, "Episode": 5910, "Episode Step": 235}
{"Training Time": 33.39534735613399, "Episode Reward": 21269.47740147987, "Mean Reward": 64.45296182266628, "Episode": 5911, "Episode Step": 330}
{"Training Time": 33.407855610582565, "Episode Reward": 66555.64480207542, "Mean Reward": 64.30497082326127, "Episode": 5912, "Episode Step": 1035}
{"Training Time": 33.41524312780963, "Episode Reward": 35912.07014922921, "Mean Reward": 62.78333942172938, "Episode": 5913, "Episode Step": 572}
{"Training Time": 33.41872184779909, "Episode Reward": 18817.719830820603, "Mean Reward": 65.79622318468742, "Episode": 5914, "Episode Step": 286}
{"Training Time": 33.430246706671184, "Episode Reward": 63583.86148403238, "Mean Reward": 66.64974998326245, "Episode": 5915, "Episode Step": 954}
{"Training Time": 33.433493814468385, "Episode Reward": 13854.07286364351, "Mean Reward": 60.498134775735856, "Episode": 5916, "Episode Step": 229}
{"Training Time": 33.43554041941961, "Episode Reward": 8137.096145466012, "Mean Reward": 48.435096103964355, "Episode": 5917, "Episode Step": 168}
{"Training Time": 33.44643510275417, "Episode Reward": 56948.685350361804, "Mean Reward": 63.066096733512516, "Episode": 5918, "Episode Step": 903}
{"Training Time": 33.45909226225482, "Episode Reward": 63227.24714317412, "Mean Reward": 62.66327764437475, "Episode": 5919, "Episode Step": 1009}
{"Training Time": 33.460694074432055, "Episode Reward": 6276.603407807307, "Mean Reward": 47.55002581672203, "Episode": 5920, "Episode Step": 132}
{"Training Time": 33.46228852748871, "Episode Reward": 6414.795107606487, "Mean Reward": 48.967901584782346, "Episode": 5921, "Episode Step": 131}
{"Training Time": 33.464376652770575, "Episode Reward": 6645.494976305487, "Mean Reward": 49.96612764139464, "Episode": 5922, "Episode Step": 133}
{"Training Time": 33.48419053475062, "Episode Reward": 105145.791778488, "Mean Reward": 63.68612463869655, "Episode": 5923, "Episode Step": 1651}
{"Training Time": 33.49152876191669, "Episode Reward": 36661.52892025471, "Mean Reward": 60.39790596417579, "Episode": 5924, "Episode Step": 607}
{"Training Time": 33.49932318250338, "Episode Reward": 36557.060773391815, "Mean Reward": 59.92960782523248, "Episode": 5925, "Episode Step": 610}
{"Training Time": 33.51270616306199, "Episode Reward": 73210.39462760012, "Mean Reward": 65.7775333581313, "Episode": 5926, "Episode Step": 1113}
{"Training Time": 33.5143412788709, "Episode Reward": 6127.1618157831745, "Mean Reward": 46.0688858329562, "Episode": 5927, "Episode Step": 133}
{"Training Time": 33.51649318973223, "Episode Reward": 6551.363698662859, "Mean Reward": 47.47364999031057, "Episode": 5928, "Episode Step": 138}
{"Training Time": 33.52741314974096, "Episode Reward": 59581.380715897576, "Mean Reward": 65.54607339482682, "Episode": 5929, "Episode Step": 909}
{"Training Time": 33.53424355970488, "Episode Reward": 35886.67762652657, "Mean Reward": 63.516243586772696, "Episode": 5930, "Episode Step": 565}
{"Training Time": 33.54098532557487, "Episode Reward": 32783.16449871163, "Mean Reward": 63.16602022873147, "Episode": 5931, "Episode Step": 519}
{"Training Time": 33.56460502107938, "Episode Reward": 125158.79881392473, "Mean Reward": 63.75893979313537, "Episode": 5932, "Episode Step": 1963}
{"Training Time": 33.595580605533385, "Episode Reward": 176463.52614307008, "Mean Reward": 68.31727686530007, "Episode": 5933, "Episode Step": 2583}
{"Training Time": 33.597261328366066, "Episode Reward": 4942.227745121671, "Mean Reward": 48.45321318746737, "Episode": 5934, "Episode Step": 102}
{"Training Time": 33.6051485561, "Episode Reward": 43160.25375538647, "Mean Reward": 64.90263722614506, "Episode": 5935, "Episode Step": 665}
{"Training Time": 33.626028075549335, "Episode Reward": 120766.79016495087, "Mean Reward": 68.03762826194415, "Episode": 5936, "Episode Step": 1775}
{"Training Time": 33.63731714725495, "Episode Reward": 59056.35319499062, "Mean Reward": 64.05244381235426, "Episode": 5937, "Episode Step": 922}
{"Training Time": 33.640009141100776, "Episode Reward": 14302.51437405594, "Mean Reward": 61.9156466409348, "Episode": 5938, "Episode Step": 231}
{"Training Time": 33.64719866891702, "Episode Reward": 37455.98675008622, "Mean Reward": 61.10275163146202, "Episode": 5939, "Episode Step": 613}
{"Training Time": 33.65102604336209, "Episode Reward": 17223.91316855507, "Mean Reward": 60.43478304756165, "Episode": 5940, "Episode Step": 285}
{"Training Time": 33.66642733666632, "Episode Reward": 84718.79456642548, "Mean Reward": 64.22956373497004, "Episode": 5941, "Episode Step": 1319}
{"Training Time": 33.679154829449125, "Episode Reward": 75278.60325392932, "Mean Reward": 68.24896033901118, "Episode": 5942, "Episode Step": 1103}
{"Training Time": 33.73838964164257, "Episode Reward": 324862.69155816926, "Mean Reward": 64.97253831163385, "Episode": 5943, "Episode Step": 5000}
{"Training Time": 33.7544439236323, "Episode Reward": 82842.3693032216, "Mean Reward": 62.85460493415903, "Episode": 5944, "Episode Step": 1318}
{"Training Time": 33.77023856553767, "Episode Reward": 92613.78723271049, "Mean Reward": 69.79185172020384, "Episode": 5945, "Episode Step": 1327}
{"Training Time": 33.77233425749673, "Episode Reward": 6916.162228579901, "Mean Reward": 51.23083132281408, "Episode": 5946, "Episode Step": 135}
{"Training Time": 33.82381031778124, "Episode Reward": 296702.3750995171, "Mean Reward": 68.1604353548167, "Episode": 5947, "Episode Step": 4353}
{"Training Time": 33.836187845534745, "Episode Reward": 68895.10678319844, "Mean Reward": 65.61438741256994, "Episode": 5948, "Episode Step": 1050}
{"Training Time": 33.83980633305179, "Episode Reward": 8652.183772487551, "Mean Reward": 49.441050128500294, "Episode": 5949, "Episode Step": 175}
{"Training Time": 33.850882167220114, "Episode Reward": 61632.627227981124, "Mean Reward": 67.43175845512158, "Episode": 5950, "Episode Step": 914}
{"Training Time": 33.89373188085026, "Episode Reward": 244908.80473389395, "Mean Reward": 67.65436594858949, "Episode": 5951, "Episode Step": 3620}
{"Training Time": 33.95307606445419, "Episode Reward": 324553.68357375613, "Mean Reward": 64.91073671475122, "Episode": 5952, "Episode Step": 5000}
{"Training Time": 33.95839832888709, "Episode Reward": 26029.23457187034, "Mean Reward": 60.81596862586528, "Episode": 5953, "Episode Step": 428}
{"Training Time": 33.96707554221153, "Episode Reward": 47326.680127285814, "Mean Reward": 64.47776584098885, "Episode": 5954, "Episode Step": 734}
{"Training Time": 33.98375895473692, "Episode Reward": 88054.01675073079, "Mean Reward": 64.27300492754073, "Episode": 5955, "Episode Step": 1370}
{"Training Time": 33.98890749666426, "Episode Reward": 25377.20903583143, "Mean Reward": 58.338411576623976, "Episode": 5956, "Episode Step": 435}
{"Training Time": 33.99045609553655, "Episode Reward": 6014.935109046759, "Mean Reward": 45.567690220051205, "Episode": 5957, "Episode Step": 132}
{"Training Time": 34.03564862469832, "Episode Reward": 238312.26436589268, "Mean Reward": 63.83934218213037, "Episode": 5958, "Episode Step": 3733}
{"Training Time": 34.041328188909425, "Episode Reward": 31050.50003439843, "Mean Reward": 65.09538791278497, "Episode": 5959, "Episode Step": 477}
{"Training Time": 34.048090050021806, "Episode Reward": 35424.418987427496, "Mean Reward": 62.58731269863515, "Episode": 5960, "Episode Step": 566}
{"Training Time": 34.0618912872341, "Episode Reward": 72183.19903265173, "Mean Reward": 64.1628435845793, "Episode": 5961, "Episode Step": 1125}
{"Training Time": 34.069158369170296, "Episode Reward": 37461.8029416356, "Mean Reward": 61.21209630986209, "Episode": 5962, "Episode Step": 612}
{"Training Time": 34.07593192418416, "Episode Reward": 33485.570090079855, "Mean Reward": 58.43904029682348, "Episode": 5963, "Episode Step": 573}
{"Training Time": 34.08225869695345, "Episode Reward": 32654.576685280055, "Mean Reward": 66.91511615836077, "Episode": 5964, "Episode Step": 488}
{"Training Time": 34.08438996553421, "Episode Reward": 9097.322358551404, "Mean Reward": 51.98469919172231, "Episode": 5965, "Episode Step": 175}
{"Training Time": 34.08650072164006, "Episode Reward": 8771.440728170988, "Mean Reward": 50.410578897534414, "Episode": 5966, "Episode Step": 174}
{"Training Time": 34.1315565097332, "Episode Reward": 237106.33365580387, "Mean Reward": 63.68690133113185, "Episode": 5967, "Episode Step": 3723}
{"Training Time": 34.132132360537845, "Episode Reward": 2422.635027727217, "Mean Reward": 51.545426121855684, "Episode": 5968, "Episode Step": 47}
{"Training Time": 34.186713440285786, "Episode Reward": 313188.99777460477, "Mean Reward": 68.56151439899403, "Episode": 5969, "Episode Step": 4568}
{"Training Time": 34.18929792139265, "Episode Reward": 8407.879382680168, "Mean Reward": 47.77204194704641, "Episode": 5970, "Episode Step": 176}
{"Training Time": 34.19513999276691, "Episode Reward": 31526.723796843155, "Mean Reward": 65.00355422029516, "Episode": 5971, "Episode Step": 485}
{"Training Time": 34.198659020000036, "Episode Reward": 19098.911731443215, "Mean Reward": 64.96228480082726, "Episode": 5972, "Episode Step": 294}
{"Training Time": 34.253403023348916, "Episode Reward": 291361.35139922623, "Mean Reward": 63.629908582490984, "Episode": 5973, "Episode Step": 4579}
{"Training Time": 34.257847156922026, "Episode Reward": 23822.14708022333, "Mean Reward": 64.21063903025157, "Episode": 5974, "Episode Step": 371}
{"Training Time": 34.261413691971036, "Episode Reward": 19957.96412045742, "Mean Reward": 66.7490438811285, "Episode": 5975, "Episode Step": 299}
{"Training Time": 34.27974909471141, "Episode Reward": 87745.12038686404, "Mean Reward": 58.613974874324676, "Episode": 5976, "Episode Step": 1497}
{"Training Time": 34.28549441112413, "Episode Reward": 31788.722003872357, "Mean Reward": 66.36476409994229, "Episode": 5977, "Episode Step": 479}
{"Training Time": 34.33707676668962, "Episode Reward": 297763.3332392404, "Mean Reward": 68.18487136231747, "Episode": 5978, "Episode Step": 4367}
{"Training Time": 34.341050454179445, "Episode Reward": 15795.139251250135, "Mean Reward": 53.18228704124625, "Episode": 5979, "Episode Step": 297}
{"Training Time": 34.35354287889269, "Episode Reward": 66366.9062459725, "Mean Reward": 63.266831502357, "Episode": 5980, "Episode Step": 1049}
{"Training Time": 34.37087386919392, "Episode Reward": 96371.77845133208, "Mean Reward": 65.64835044368671, "Episode": 5981, "Episode Step": 1468}
{"Training Time": 34.392462595303854, "Episode Reward": 106732.20888624406, "Mean Reward": 59.46084060514989, "Episode": 5982, "Episode Step": 1795}
{"Training Time": 34.41051014304161, "Episode Reward": 103513.92449171291, "Mean Reward": 67.3480315495855, "Episode": 5983, "Episode Step": 1537}
{"Training Time": 34.43975591553582, "Episode Reward": 164901.5834057535, "Mean Reward": 67.00592580485717, "Episode": 5984, "Episode Step": 2461}
{"Training Time": 34.469506819446885, "Episode Reward": 153490.53659251245, "Mean Reward": 62.04144567199371, "Episode": 5985, "Episode Step": 2474}
{"Training Time": 34.48031305776702, "Episode Reward": 58407.8893351128, "Mean Reward": 64.25510377900198, "Episode": 5986, "Episode Step": 909}
{"Training Time": 34.486107848882675, "Episode Reward": 30607.17567751639, "Mean Reward": 63.107578716528636, "Episode": 5987, "Episode Step": 485}
{"Training Time": 34.48876575330893, "Episode Reward": 8250.093736148934, "Mean Reward": 45.580628376513445, "Episode": 5988, "Episode Step": 181}
{"Training Time": 34.4903088830577, "Episode Reward": 6169.4264381330295, "Mean Reward": 47.825011148318055, "Episode": 5989, "Episode Step": 129}
{"Training Time": 34.518624981972906, "Episode Reward": 162846.58818464165, "Mean Reward": 68.33679739179254, "Episode": 5990, "Episode Step": 2383}
{"Training Time": 34.52128491553995, "Episode Reward": 7742.173165130301, "Mean Reward": 42.07702807136033, "Episode": 5991, "Episode Step": 184}
{"Training Time": 34.52336199581623, "Episode Reward": 8176.494646724434, "Mean Reward": 47.26297483655742, "Episode": 5992, "Episode Step": 173}
{"Training Time": 34.52891868862841, "Episode Reward": 29032.995694173944, "Mean Reward": 62.03631558584176, "Episode": 5993, "Episode Step": 468}
{"Training Time": 34.53299087305864, "Episode Reward": 16796.720706850832, "Mean Reward": 55.989069022836105, "Episode": 5994, "Episode Step": 300}
{"Training Time": 34.54024353497558, "Episode Reward": 35757.41870350588, "Mean Reward": 58.61871918607521, "Episode": 5995, "Episode Step": 610}
{"Training Time": 34.55857488665316, "Episode Reward": 103228.77452465586, "Mean Reward": 66.72836103726947, "Episode": 5996, "Episode Step": 1547}
{"Training Time": 34.56119898358981, "Episode Reward": 7790.310166336562, "Mean Reward": 43.04038765931802, "Episode": 5997, "Episode Step": 181}
{"Training Time": 34.576345745523774, "Episode Reward": 83785.19252390723, "Mean Reward": 65.66237658613419, "Episode": 5998, "Episode Step": 1276}
{"Training Time": 34.58007844805717, "Episode Reward": 13696.789357071464, "Mean Reward": 60.073637531015194, "Episode": 5999, "Episode Step": 228}
